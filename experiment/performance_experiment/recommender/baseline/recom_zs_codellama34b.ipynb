{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab84911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T04:53:52.105808Z",
     "iopub.status.busy": "2025-06-10T04:53:52.105577Z",
     "iopub.status.idle": "2025-06-10T04:57:46.480532Z",
     "shell.execute_reply": "2025-06-10T04:57:46.479636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-10 04:54:01 [importing.py:53] Triton module has been replaced with a placeholder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-10 04:54:01 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 04:54:02,993\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.3: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.5.\n",
      "   \\\\   /|    Tesla V100-SXM2-32GB. Num GPUs = 1. Max memory: 31.749 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   0%|                                                                     | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  14%|████████▋                                                    | 1/7 [00:28<02:52, 28.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  29%|█████████████████▍                                           | 2/7 [00:59<02:28, 29.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  43%|██████████████████████████▏                                  | 3/7 [01:30<02:01, 30.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  57%|██████████████████████████████████▊                          | 4/7 [02:01<01:31, 30.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  71%|███████████████████████████████████████████▌                 | 5/7 [02:31<01:01, 30.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  86%|████████████████████████████████████████████████████▎        | 6/7 [03:02<00:30, 30.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████| 7/7 [03:31<00:00, 29.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████| 7/7 [03:31<00:00, 30.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codellama/CodeLlama-34b-Instruct-hf does not have a padding token! Will use pad_token = <unk>.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 16384 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"codellama/CodeLlama-34b-Instruct-hf\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2126b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T04:57:46.484546Z",
     "iopub.status.busy": "2025-06-10T04:57:46.484062Z",
     "iopub.status.idle": "2025-06-10T04:57:47.995492Z",
     "shell.execute_reply": "2025-06-10T04:57:47.994695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map:   0%|                                                                                  | 0/662 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 662/662 [00:00<00:00, 1238.41 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 662/662 [00:00<00:00, 1229.86 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map:   0%|                                                                                  | 0/142 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 6241.00 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map:   0%|                                                                                  | 0/143 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 6542.02 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Define the paths to your dataset files\n",
    "data_files = {\n",
    "    'train': 'vuln_data_train.csv',\n",
    "    'val': 'vuln_data_val.csv',\n",
    "    'test': 'vuln_data_test.csv'\n",
    "}\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files=data_files)\n",
    "\n",
    "import random\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "SYSTEM_PROMPT = [\n",
    "    \"\"\"You are the smartest AI solidity smart contract security auditor in the world\"\"\",\n",
    "]\n",
    "\n",
    "PROMPTS = [\n",
    "    \"\"\"The given Solidity function is vulnerable and there was an explanation about the vulnerability. Give your patch recommendation based on that vulnerability. Just straight to the recommendation without any additional information.\n",
    "    \n",
    "    This is the vulnerable functions:\n",
    "    ```solidity\n",
    "    {code}\n",
    "    ```\n",
    "    \n",
    "This is the vulnerability explanation: \n",
    "{explanation}\n",
    "\n",
    "Recommendation:\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "def make_conversational(examples):\n",
    "    code = examples['vuln_code']\n",
    "    desc = examples['vuln_explanation']\n",
    "    recom = examples['vuln_recommendation']\n",
    "    selected_system_prompt = random.choice(SYSTEM_PROMPT)\n",
    "    selected_user_prompt = random.choice(PROMPTS) \n",
    "    conversation = [{\"role\": \"system\", \"content\": selected_system_prompt}, \n",
    "                    {\"role\": \"user\", \"content\": selected_user_prompt.format(code=code, explanation=desc)}]\n",
    "    return { \"conversations\" : conversation, \"label\": recom}\n",
    "\n",
    "dataset = dataset.map(make_conversational)\n",
    "\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d9eb3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T04:57:47.999412Z",
     "iopub.status.busy": "2025-06-10T04:57:47.999159Z",
     "iopub.status.idle": "2025-06-10T05:39:31.696294Z",
     "shell.execute_reply": "2025-06-10T05:39:31.695286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   0%|                                                                          | 0/143 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   1%|▍                                                                 | 1/143 [00:10<24:29, 10.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   1%|▉                                                                 | 2/143 [00:22<26:35, 11.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   2%|█▍                                                                | 3/143 [00:31<23:44, 10.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   3%|█▊                                                                | 4/143 [00:41<23:51, 10.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   3%|██▎                                                               | 5/143 [00:52<24:28, 10.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   4%|██▊                                                               | 6/143 [01:04<25:04, 10.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   5%|███▏                                                              | 7/143 [01:17<26:19, 11.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   6%|███▋                                                              | 8/143 [02:10<55:38, 24.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   6%|████▏                                                             | 9/143 [02:27<50:02, 22.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   7%|████▌                                                            | 10/143 [02:36<40:09, 18.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   8%|█████                                                            | 11/143 [02:44<33:08, 15.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   8%|█████▍                                                           | 12/143 [03:07<38:12, 17.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:   9%|█████▉                                                           | 13/143 [03:16<32:15, 14.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  10%|██████▎                                                          | 14/143 [03:38<36:42, 17.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  10%|██████▊                                                          | 15/143 [03:50<33:21, 15.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  11%|███████▎                                                         | 16/143 [04:10<35:44, 16.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  12%|███████▋                                                         | 17/143 [04:19<30:51, 14.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  13%|████████▏                                                        | 18/143 [04:35<31:19, 15.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  13%|████████▋                                                        | 19/143 [04:53<32:49, 15.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  14%|█████████                                                        | 20/143 [05:28<44:27, 21.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  15%|█████████▌                                                       | 21/143 [05:50<44:04, 21.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  15%|██████████                                                       | 22/143 [05:58<35:08, 17.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  16%|██████████▍                                                      | 23/143 [06:02<27:17, 13.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  17%|██████████▉                                                      | 24/143 [06:15<26:43, 13.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  17%|███████████▎                                                     | 25/143 [06:37<31:11, 15.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  18%|███████████▊                                                     | 26/143 [06:48<27:55, 14.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  19%|████████████▎                                                    | 27/143 [07:15<34:58, 18.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  20%|████████████▋                                                    | 28/143 [07:26<30:44, 16.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  20%|█████████████▏                                                   | 29/143 [07:42<30:44, 16.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  21%|█████████████▋                                                   | 30/143 [07:57<29:33, 15.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  22%|██████████████                                                   | 31/143 [08:15<30:54, 16.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  22%|██████████████▌                                                  | 32/143 [08:36<32:43, 17.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  23%|███████████████                                                  | 33/143 [09:09<41:11, 22.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  24%|███████████████▍                                                 | 34/143 [09:16<32:22, 17.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  24%|███████████████▉                                                 | 35/143 [09:24<26:28, 14.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  25%|████████████████▎                                                | 36/143 [09:48<31:09, 17.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  26%|████████████████▊                                                | 37/143 [10:25<41:19, 23.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  27%|█████████████████▎                                               | 38/143 [10:38<35:35, 20.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  27%|█████████████████▋                                               | 39/143 [11:14<43:08, 24.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  28%|██████████████████▏                                              | 40/143 [11:29<38:04, 22.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  29%|██████████████████▋                                              | 41/143 [11:33<28:15, 16.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  29%|███████████████████                                              | 42/143 [11:55<30:28, 18.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  30%|███████████████████▌                                             | 43/143 [12:09<28:04, 16.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  31%|████████████████████                                             | 44/143 [12:38<33:49, 20.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  31%|████████████████████▍                                            | 45/143 [12:45<26:49, 16.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  32%|████████████████████▉                                            | 46/143 [13:03<27:19, 16.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  33%|█████████████████████▎                                           | 47/143 [13:36<34:45, 21.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  34%|█████████████████████▊                                           | 48/143 [13:40<26:12, 16.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  34%|██████████████████████▎                                          | 49/143 [13:50<23:01, 14.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  35%|██████████████████████▋                                          | 50/143 [14:00<20:33, 13.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  36%|███████████████████████▏                                         | 51/143 [14:16<21:36, 14.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  36%|███████████████████████▋                                         | 52/143 [14:34<22:56, 15.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  37%|████████████████████████                                         | 53/143 [14:47<21:53, 14.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  38%|████████████████████████▌                                        | 54/143 [14:56<18:54, 12.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  38%|█████████████████████████                                        | 55/143 [15:18<22:58, 15.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  39%|█████████████████████████▍                                       | 56/143 [15:31<21:21, 14.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  40%|█████████████████████████▉                                       | 57/143 [15:39<18:31, 12.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  41%|██████████████████████████▎                                      | 58/143 [15:50<17:20, 12.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  41%|██████████████████████████▊                                      | 59/143 [15:59<15:52, 11.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  42%|███████████████████████████▎                                     | 60/143 [16:32<24:44, 17.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  43%|███████████████████████████▋                                     | 61/143 [16:42<21:07, 15.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  43%|████████████████████████████▏                                    | 62/143 [17:18<29:17, 21.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  44%|████████████████████████████▋                                    | 63/143 [17:21<21:05, 15.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  45%|█████████████████████████████                                    | 64/143 [17:49<25:52, 19.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  45%|█████████████████████████████▌                                   | 65/143 [18:04<23:50, 18.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  46%|██████████████████████████████                                   | 66/143 [18:13<19:43, 15.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  47%|██████████████████████████████▍                                  | 67/143 [18:22<17:06, 13.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  48%|██████████████████████████████▉                                  | 68/143 [18:56<24:33, 19.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  48%|███████████████████████████████▎                                 | 69/143 [19:03<19:28, 15.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  49%|███████████████████████████████▊                                 | 70/143 [19:22<20:37, 16.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  50%|████████████████████████████████▎                                | 71/143 [19:33<18:07, 15.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  50%|████████████████████████████████▋                                | 72/143 [19:58<21:09, 17.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  51%|█████████████████████████████████▏                               | 73/143 [20:27<24:43, 21.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  52%|█████████████████████████████████▋                               | 74/143 [21:37<41:18, 35.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  52%|██████████████████████████████████                               | 75/143 [22:03<37:22, 32.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  53%|██████████████████████████████████▌                              | 76/143 [22:26<33:22, 29.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  54%|███████████████████████████████████                              | 77/143 [22:37<26:54, 24.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  55%|███████████████████████████████████▍                             | 78/143 [22:45<21:07, 19.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  55%|███████████████████████████████████▉                             | 79/143 [22:56<18:02, 16.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  56%|████████████████████████████████████▎                            | 80/143 [23:04<14:46, 14.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  57%|████████████████████████████████████▊                            | 81/143 [23:22<15:50, 15.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  57%|█████████████████████████████████████▎                           | 82/143 [23:57<21:42, 21.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  58%|█████████████████████████████████████▋                           | 83/143 [24:16<20:38, 20.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  59%|██████████████████████████████████████▏                          | 84/143 [24:24<16:21, 16.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  59%|██████████████████████████████████████▋                          | 85/143 [24:33<13:59, 14.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  60%|███████████████████████████████████████                          | 86/143 [24:55<15:56, 16.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  61%|███████████████████████████████████████▌                         | 87/143 [25:05<13:47, 14.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  62%|████████████████████████████████████████                         | 88/143 [25:16<12:17, 13.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  62%|████████████████████████████████████████▍                        | 89/143 [25:48<17:18, 19.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  63%|████████████████████████████████████████▉                        | 90/143 [26:15<19:04, 21.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  64%|█████████████████████████████████████████▎                       | 91/143 [26:29<16:40, 19.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  64%|█████████████████████████████████████████▊                       | 92/143 [26:50<16:50, 19.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  65%|██████████████████████████████████████████▎                      | 93/143 [27:10<16:26, 19.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  66%|██████████████████████████████████████████▋                      | 94/143 [27:32<16:47, 20.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  66%|███████████████████████████████████████████▏                     | 95/143 [27:41<13:29, 16.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  67%|███████████████████████████████████████████▋                     | 96/143 [27:59<13:39, 17.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  68%|████████████████████████████████████████████                     | 97/143 [28:08<11:21, 14.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  69%|████████████████████████████████████████████▌                    | 98/143 [28:14<09:05, 12.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  69%|█████████████████████████████████████████████                    | 99/143 [28:28<09:15, 12.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  70%|████████████████████████████████████████████▊                   | 100/143 [28:51<11:22, 15.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  71%|█████████████████████████████████████████████▏                  | 101/143 [29:08<11:14, 16.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  71%|█████████████████████████████████████████████▋                  | 102/143 [29:18<09:42, 14.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  72%|██████████████████████████████████████████████                  | 103/143 [29:28<08:43, 13.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  73%|██████████████████████████████████████████████▌                 | 104/143 [30:09<13:53, 21.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  73%|██████████████████████████████████████████████▉                 | 105/143 [30:28<13:06, 20.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  74%|███████████████████████████████████████████████▍                | 106/143 [30:33<09:49, 15.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  75%|███████████████████████████████████████████████▉                | 107/143 [30:41<08:12, 13.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  76%|████████████████████████████████████████████████▎               | 108/143 [31:02<09:15, 15.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  76%|████████████████████████████████████████████████▊               | 109/143 [31:22<09:41, 17.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  77%|█████████████████████████████████████████████████▏              | 110/143 [31:34<08:29, 15.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  78%|█████████████████████████████████████████████████▋              | 111/143 [31:47<07:54, 14.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  78%|██████████████████████████████████████████████████▏             | 112/143 [32:38<13:20, 25.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  79%|██████████████████████████████████████████████████▌             | 113/143 [32:55<11:27, 22.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  80%|███████████████████████████████████████████████████             | 114/143 [33:07<09:32, 19.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  80%|███████████████████████████████████████████████████▍            | 115/143 [33:11<07:02, 15.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  81%|███████████████████████████████████████████████████▉            | 116/143 [33:23<06:21, 14.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  82%|████████████████████████████████████████████████████▎           | 117/143 [33:34<05:38, 13.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  83%|████████████████████████████████████████████████████▊           | 118/143 [33:39<04:26, 10.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  83%|█████████████████████████████████████████████████████▎          | 119/143 [34:12<06:57, 17.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  84%|█████████████████████████████████████████████████████▋          | 120/143 [34:35<07:20, 19.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  85%|██████████████████████████████████████████████████████▏         | 121/143 [34:52<06:49, 18.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  85%|██████████████████████████████████████████████████████▌         | 122/143 [35:01<05:28, 15.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  86%|███████████████████████████████████████████████████████         | 123/143 [35:15<05:01, 15.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  87%|███████████████████████████████████████████████████████▍        | 124/143 [35:29<04:39, 14.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  87%|███████████████████████████████████████████████████████▉        | 125/143 [35:31<03:20, 11.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  88%|████████████████████████████████████████████████████████▍       | 126/143 [36:25<06:43, 23.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  89%|████████████████████████████████████████████████████████▊       | 127/143 [36:38<05:30, 20.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  90%|█████████████████████████████████████████████████████████▎      | 128/143 [36:52<04:38, 18.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  90%|█████████████████████████████████████████████████████████▋      | 129/143 [37:06<04:03, 17.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  91%|██████████████████████████████████████████████████████████▏     | 130/143 [37:22<03:38, 16.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  92%|██████████████████████████████████████████████████████████▋     | 131/143 [37:27<02:39, 13.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  92%|███████████████████████████████████████████████████████████     | 132/143 [37:43<02:35, 14.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  93%|███████████████████████████████████████████████████████████▌    | 133/143 [38:14<03:11, 19.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  94%|███████████████████████████████████████████████████████████▉    | 134/143 [38:21<02:18, 15.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  94%|████████████████████████████████████████████████████████████▍   | 135/143 [38:49<02:34, 19.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  95%|████████████████████████████████████████████████████████████▊   | 136/143 [38:53<01:41, 14.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  96%|█████████████████████████████████████████████████████████████▎  | 137/143 [39:13<01:37, 16.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  97%|█████████████████████████████████████████████████████████████▊  | 138/143 [39:45<01:45, 21.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  97%|██████████████████████████████████████████████████████████████▏ | 139/143 [40:09<01:27, 21.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  98%|██████████████████████████████████████████████████████████████▋ | 140/143 [40:20<00:55, 18.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  99%|███████████████████████████████████████████████████████████████ | 141/143 [40:49<00:43, 21.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset:  99%|███████████████████████████████████████████████████████████████▌| 142/143 [41:13<00:22, 22.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset: 100%|████████████████████████████████████████████████████████████████| 143/143 [41:43<00:00, 24.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing dataset: 100%|████████████████████████████████████████████████████████████████| 143/143 [41:43<00:00, 17.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "import pandas as pd\n",
    "\n",
    "def extract_llm_res(raw_llm):\n",
    "    # Regex pattern to extract the assistant's response after the \"Vulnerability Explanation\" section\n",
    "    pattern = r'\\[/INST](.*?)</s>'\n",
    "\n",
    "    match = re.search(pattern, raw_llm, re.DOTALL)\n",
    "\n",
    "    if match:\n",
    "        assistant_response = match.group(1).strip()\n",
    "        return assistant_response\n",
    "    else:\n",
    "        print(f\"No response found. Response: {raw_llm}\")\n",
    "\n",
    "# Set up the tokenizer and model for fast inference\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template=\"llama\",\n",
    ")\n",
    "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
    "\n",
    "# Initialize the result collection\n",
    "results = []\n",
    "\n",
    "# Iterate over the dataset with tqdm for progress bar\n",
    "for idx, example in tqdm(enumerate(test_dataset), total=len(test_dataset), desc=\"Processing dataset\"):\n",
    "    messages = example['conversations']  # Get the conversation for the current entry\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,  # Must add for generation\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # Get LLM output\n",
    "    outputs = model.generate(input_ids=inputs, max_new_tokens=1024, use_cache=True, repetition_penalty=1.2,\n",
    "                             temperature=0.1, min_p=0.1)\n",
    "    raw_out = tokenizer.batch_decode(outputs)[0]\n",
    "    \n",
    "    # Extract LLM response\n",
    "    llm_output = extract_llm_res(raw_out)\n",
    "    \n",
    "    # Get the ground truth for the current entry\n",
    "    ground_truth = example['label']\n",
    "    \n",
    "    results.append({\n",
    "        \"vuln_code\": example['vuln_code'],\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"llm_output\": llm_output\n",
    "    })\n",
    "\n",
    "# After the loop, you can convert the results list to a DataFrame or another suitable format if needed\n",
    "verification_results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d4355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T05:39:31.716974Z",
     "iopub.status.busy": "2025-06-10T05:39:31.716733Z",
     "iopub.status.idle": "2025-06-10T05:39:31.729621Z",
     "shell.execute_reply": "2025-06-10T05:39:31.728659Z"
    }
   },
   "outputs": [],
   "source": [
    "verification_results_df.to_csv(\"zeroshot_codellama34b_recommendation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
